---
title: 1.03 tf.keras 与 keras 区别
toc: true
date: 2019-09-04
---
# tf.keras 和 keras有什么区别

作者：蔡善清

链接：

来源：知乎

著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

要回答这个问题，首先需要简单谈一下 keras 的历史。keras是 François Chollet于 2014-2015年开始编写的开源高层深度学习 API。所谓“高层”，是相对于“底层”运算而言（例如 add，matmul，transpose，conv2d）。keras把这些底层运算封装成一些常用的神经网络模块类型（例如 Dense, Conv2D, LSTM等），再加上像 Model、Optimizer等的一些的抽象，来增强 API 的易用性和代码的可读性，提高深度学习开发者编写模型的效率。keras本身并不具备底层运算的能力，所以它需要和一个具备这种底层运算能力的 backend（后端）协同工作。keras的特性之一就是**可以互换的后端**，你在所有后端上写的 keras 代码都是一样的。从一个后端训练并存储的模型，可以用别的后端加载并运行。

 keras最初发行的时候，tensorflow还没有开源（fchollet开始写 keras 的时候还未加入 Google）。那时的 keras 主要使用的是 Theano 后端。2015年底 TensorFlow 开源后，keras才开始搭建 TensorFlow 后端。今天 TensorFlow 是 keras 最常用的后端。

2016－2017年间，Google Brain组根据开源用户对 TensorFlow 易用性的反馈，决定采纳 keras 为首推、并内置支持的高层 API。当时 TensorFlow 已经有 tf.estimator、slim、sonnet、TensorLayers等诸多高层次 API，选择 keras 主要是考虑它的优秀性以及在用户群中的受欢迎程度，不过那个是另一个故事线就不展开说了。

所以，keras的代码被逐渐吸收进入 tensorflow 的代码库，那时 fchollet 也加入了 Google Brain组。所以就产生了**tf.keras：一个不强调后端可互换性、和 tensorflow 更紧密整合、得到 tensorflow 其他组建更好支持、且符合 keras 标准的高层次 API**。

那 keras 和 tf.keras到底有什么异同呢？下面我们先看一下共同点，再看一下不同点。

**keras和 tf.keras的主要共同点：**

1. **基于同一个 API**：如果不使用 tf.keras的特有特性（见下文）的话，模型搭建、训练、和推断的代码应该是可以互换的。把`import keras` 换成`from tensorflow import keras`，所有功能都应该可以工作。反之则未必，因为 tf.keras有一些 keras 不支持的特性，见下文。Google Brain组负责两个代码库之间的同步，每个代码库的重要 bug fix和新特性，只要是后端无关的，都会被同步到另一个代码库。
2. **相同的 JSON 和 HDF5 模型序列化格式和语义。**从一方用`model.to_json()`　或`model.save()`保存的模型，可以在另一方加载并以同一语义运行。TensorFlow的生态里面那些支持 HDF5 或 JSON 格式的其他库，比如[TensorFlow.js](https://link.zhihu.com/?target=https%3A//js.tensorflow.org/tutorials/import-keras.html)，也同等支持 keras 和 tf.keras保存的模型。

**keras和 tf.keras的主要差别：**

1. **tf.keras全面支持 tensorflow 的 eager execution模式。**eager execution是 TensorFlow 未来首推的另一个主要特性，也和易用性有关。但是这个对于 tf.keras的用户有什么影响呢？如果你只是使用`keras.Sequential()`或`keras.Model()`的“乐高式”模型搭建 API 的话，这个没有影响。Eager execution相对于 graph mode的性能劣势，通过 tf.function的 imperative-to-graph变换来弥补。但是你如果是要自己编写模型内部的运算逻辑的话，结合 eager execution和 tf.keras.Model方便动态模型的编写。下图里的代码实例展示了如何用这个 API 来编写一个动态 RNN（图片来源：[https://twitter.com/fchollet/status/1052228463300493312?lang=en](https://link.zhihu.com/?target=https%3A//twitter.com/fchollet/status/1052228463300493312%3Flang%3Den)）。这样写相对于仅仅使用 tensorflow 的底层 API 的好处，在于可以使用｀tf.keras.Model`类型所提供的`fit()、predict()`等抽象。这个特性主要是面向做深度学习研究的用户。

![img](https://pic4.zhimg.com/50/v2-de84d0cc9366388de1f427c8ef383c3e_hd.jpg)![img](https://pic4.zhimg.com/80/v2-de84d0cc9366388de1f427c8ef383c3e_hd.jpg)

\2. **tf.keras支持基于 tf.data的模型训练**。[tf.data](https://link.zhihu.com/?target=https%3A//www.tensorflow.org/guide/datasets)是 TensorFlow 自 2017 年初左右推出的新特性。由于基于 lazy 范式、使用了多线程数据输入管路，tf.data可以显著提高模型训练的效率，同时降低数据相关的代码的复杂性。tf.data带来的性能提高，对于 TPU 训练来说至关重要。`tf.keras.Mode.fit()`直接支持`tf.data.Dataset `或`iterator`对象作为输入参数。比如这个 MNIST 训练例子：

https://gist.github.com/datlife/abfe263803691a8864b7a2d4f87c4ab8gist.github.com



\3. **tf.keras支持 TPU 训练**。TPU是 Google 自己研发的深度学习模型训练加速硬件，现在在很多训练任务上持有 State of the art的性能。用户可以用`tf.contrib.tpu.keras_to_tpu_model()`将一个`tf.keras.Model`对象转换成一个可以在 TPU 上进行训练的模型对象。见以下例子：

https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/fashion_mnist.ipynbcolab.sandbox.google.com



\4.  **tf.keras支持 tf.distribution里面的 DistributionStrategy 进行多 GPU 或多机分布式训练**。tf.distribution是 tensorflow 里面比较新的 API，提供一套易用的分布式训练的抽象，帮助用户实现多卡或多机模型训练。比如，keras用户应该知道，普通版的 keras 是不支持多 GPU 训练的。tf.keras可以克服这一局限，详见官方文档里面的例子：

https://www.tensorflow.org/guide/distribute_strategy#example_with_keras_apiwww.tensorflow.org



\5. **tf.keras的其他特有特性：**

- `tf.keras.models.model_to_estimator()` ：将模型转换成 estimator 对象 。见[文档](https://link.zhihu.com/?target=https%3A//www.tensorflow.org/api_docs/python/tf/keras/estimator/model_to_estimator)。
- `tf.contrib.saved_model.save_keras_model()`：将模型保存为 tensorflow 的 SavedModel 格式。见[文档](https://link.zhihu.com/?target=https%3A//www.tensorflow.org/api_docs/python/tf/contrib/saved_model/save_keras_model)。

**那我应该选择 keras 还是 tf.keras呢？**

- 如果你需要任何一个上述 tf.keras的特有特性的话，那当然应该选择 tf.keras。
- 如果后端可互换性对你很重要的话，那选择 keras。
- 如果以上两条对你都不重要的话，那选用哪个都可以。

希望以上有帮助。

————————

勘误和增补：

1. 关于上面差异第 4 点：keras也支持多 GPU 训练，但是基于一个不同的 API：`keras.utils.multi_gpu_model`


# 相关

- [tf.keras 和 keras有什么区别？](https://www.zhihu.com/question/313111229/answer/606660552) 蔡善清
