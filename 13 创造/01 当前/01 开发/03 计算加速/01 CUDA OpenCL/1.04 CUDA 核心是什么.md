# CUDA 核心是什么？

上面提到在一个 GPU 芯片里，会很几千个 CUDA 核心，被分布在多个流处理单元（SM）中，比如上面提到早期的 GTX980 中的 16 个 SM 中各包含了 128 个 CUDA 核心。如下图所示，作为 GPU 架构中的最小单元，其实它的设计和 CPU 有着非常类似的结构，其中包括了一个浮点运算单元和整型运算单元，和控制单元。同一个流处理器中，所有的 CUDA 核心将同步执行同一个指令，但是作用于不同的数据点上。

<center>

![](http://images.iterate.site/blog/image/20190722/5v4B86JFuSbV.jpg?imageslim){ width=55% }

</center>

> CUDA简单介绍

一般来说，更加多的 CUDA 核心意味着有更多的并行执行单元，所以也就可以片面地认为是有更加高的性能。但是，其实这个也是取决于很多方面，最重要的是算法在并行实现的时候有没有高效地调度和内存的使用优化。在现在我们使用的大部分 GPU 加速的深度学习框架里，包括 Tensorflow，PyTorch等都是依赖于底层的 GPU 的矩阵加速代码的实现。为此 Nvidia 公司也是制定和实现了统一的接口，比如 cuDNN，方便上层框架更好的利用 GPU 的性能。
