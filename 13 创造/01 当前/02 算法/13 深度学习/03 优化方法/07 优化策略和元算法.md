---
title: 07 优化策略和元算法
toc: true
date: 2019-06-05
---

# 优化策略和元算法

许多优化技术并非真正的算法，而是一般化的模板，可以特定地产生算法，或是并入到很多不同的算法中。


## 坐标下降

在某些情况下，将一个优化问题分解成几个部分，可以更快地解决原问题。如果我们相对于某个单一变量 $x_i$ 最小化 $f(\boldsymbol x)$，然后相对于另一个变量 $x_j$ 等等，反复循环所有的变量，我们会保证到达（局部）极小值。这种做法被称为坐标下降，因为我们一次优化一个坐标。更一般地，块坐标下降是指对于某个子集的变量同时最小化。术语"坐标下降"通常既指块坐标下降，也指严格的单个坐标下降。


当优化问题中的不同变量能够清楚地分成相对独立的组，或是当优化一组变量明显比优化所有变量效率更高时，坐标下降最有意义。例如，考虑代价函数

$$
J(\boldsymbol H, \boldsymbol W) = \sum_{i,j} |H_{i,j}| + \sum_{i,j} \left( \boldsymbol X - \boldsymbol W^\top \boldsymbol H \right)_{i,j}^2 .
$$

该函数描述了一种被称为稀疏编码的学习问题，其目标是寻求一个权重矩阵 $\boldsymbol W$，可以线性解码激活值矩阵 $\boldsymbol H$ 以重构训练集 $\boldsymbol X$。稀疏编码的大多数应用还涉及到权重衰减或 $\boldsymbol W$ 列范数的约束，以避免极小 $\boldsymbol H$ 和极大 $\boldsymbol W$ 的病态解。

函数 $J$ 不是凸的。然而，我们可以将训练算法的输入分成两个集合：字典参数 $\boldsymbol W$ 和编码表示 $\boldsymbol H$。最小化关于这两者之一的任意一组变量的目标函数都是凸问题。因此，块坐标下降允许我们使用高效的凸优化算法，交替固定 $\boldsymbol H$ 优化 $\boldsymbol W$ 和固定 $\boldsymbol W$ 优化 $\boldsymbol H$。

当一个变量的值很大程度地影响另一个变量的最优值时，坐标下降不是一个很好的方法，如函数 $f(\boldsymbol x)=(x_1 - x_2)^2+\alpha(x_1^2 + x_2^2)$，其中 $\alpha$ 是正值常数。第一项鼓励两个变量具有相似的值，而第二项鼓励它们接近零。解是两者都为零。牛顿法可以一步解决这个问题，因为它是一个正定二次问题。但是，对于小值 $\alpha$ 而言，坐标下降会使进展非常缓慢，因为第一项不允许单个变量变为和其他变量当前值显著不同的值。



## Polyak平均

Polyak平均会平均优化算法在参数空间访问轨迹中的几个点。如果 $t$ 次迭代梯度下降访问了点 $\boldsymbol \theta^{(1)},\dots,\boldsymbol \theta^{(t)}$，那么 Polyak 平均算法的输出是 $\hat{\boldsymbol \theta}^{(t)} = \frac{1}{t} \sum_i \boldsymbol \theta^{(i)}$。在某些问题中，如梯度下降应用于凸问题时，这种方法具有较强的收敛保证。当应用于神经网络时，其验证更多是启发式的，但在实践中表现良好。基本想法是，优化算法可能会来回穿过山谷好几次而没经过山谷底部附近的点。尽管两边所有位置的均值应比较接近谷底。


在非凸问题中，优化轨迹的路径可以非常复杂，并且经过了许多不同的区域。包括参数空间中遥远过去的点，可能与当前点在代价函数上相隔很大的障碍，看上去不像一个有用的行为。其结果是，当应用 Polyak 平均于非凸问题时，通常会使用指数衰减计算平均值：

$$
\hat{\boldsymbol \theta}^{(t)} = \alpha \hat{\boldsymbol \theta}^{(t-1)} + (1-\alpha) \boldsymbol \theta^{(t)} .
$$


这个计算平均值的方法被用于大量数值应用中。最近的例子请查看{Szegedy-et-al-2015}。


## 监督预训练

有时，如果模型太复杂难以优化，或是如果任务非常困难，直接训练模型来解决特定任务的挑战可能太大。有时训练一个较简单的模型来求解问题，然后使模型更复杂会更有效。训练模型来求解一个简化的问题，然后转移到最后的问题，有时也会更有效些。这些在直接训练目标模型求解目标问题之前，训练简单模型求解简化问题的方法统称为预训练。


贪心算法将问题分解成许多部分，然后独立地在每个部分求解最优值。令人遗憾的是，结合各个最佳的部分不能保证得到一个最佳的完整解。然而，贪心算法计算上比求解最优联合解的算法高效得多，并且贪心算法的解在不是最优的情况下，往往也是可以接受的。贪心算法也可以紧接一个精调阶段，联合优化算法搜索全问题的最优解。使用贪心解初始化联合优化算法，可以极大地加速算法，并提高寻找到的解的质量。

预训练算法，特别是贪心预训练，在深度学习中是普遍存在的。在本节中，我们会具体描述这些将监督学习问题分解成其他简化的监督学习问题的预训练算法。这种方法被称为贪心监督预训练。


在贪心监督预训练的原始版本中，每个阶段包括一个仅涉及最终神经网络的子集层的监督学习训练任务。贪心监督预训练的一个例子如\fig?所示，其中每个附加的隐藏层作为浅层监督多层感知机的一部分预训练，以先前训练的隐藏层输出作为输入。{Simonyan2015} 预训练深度卷积网络（11层权重），然后使用该网络前四层和最后三层初始化更深的网络（多达 19 层权重），并非一次预训练一层。非常深的新网络的中间层是随机初始化的。然后联合训练新网络。还有一种选择，由{Yu+al-2010}提出，将先前训练多层感知机的\emph{输出}，以及原始输入，作为每个附加阶段的输入。



<center>

![](http://images.iterate.site/blog/image/20190718/Y6aqV7tKm6rK.png?imageslim){ width=55% }

</center>
> 8.7 一种形式的贪心监督预训练的示意图。
> - (a)我们从训练一个足够浅的架构开始。
> - (b)同一个架构的另一描绘。
> - (c)我们只保留原始网络的输入到隐藏层，并丢弃隐藏到输出层。我们将第一层隐藏层的输出作为输入发送到另一监督单隐层\,MLP（使用与第一个网络相同的目标训练），从而可以添加第二层隐藏层。这可以根据需要重复多层。
> - (d)所得架构的另一种描绘，可视为前馈网络。为了进一步改进优化，我们可以联合地精调所有层（仅在该过程的结束或者该过程的每个阶段）。






为什么贪心监督预训练会有帮助呢？最初由 {Bengio-nips-2006}提出的假说是，其有助于更好地指导深层结构的中间层的学习。一般情况下，预训练对于优化和泛化都是有帮助的。

另一个与监督预训练有关的方法扩展了迁移学习的想法：{yosinski-nips2014}在一组任务上预训练了 $8$ 层权重的深度卷积网络（1000个 ImageNet 对象类的子集），然而用该网络的前 $k$ 层初始化同样规模的网络。然后第二个网络的所有层（上层随机初始化）联合训练以执行不同的任务（1000个 ImageNet 对象类的另一个子集），但训练样本少于第一个任务。神经网络中另一个和迁移学习相关的方法将在\sec?讨论。

另一条相关的工作线是 FitNets 方法。这种方法始于训练深度足够低和宽度足够大（每层单元数），容易训练的网络。然后，这个网络成为第二个网络（被指定为学生）的老师。学生网络更深更窄（11至 19 层），且在正常情况下很难用 SGD 训练。训练学生网络不仅需要预测原任务的输出，还需要预测教师网络中间层的值，这样使得训练学生网络变得更容易。这个额外的任务说明了隐藏层应如何使用，并且能够简化优化问题。附加参数被引入来从更深的学生网络中间层去回归 $5$ 层教师网络的中间层。然而，该目标是预测教师网络的中间隐藏层，并非预测最终分类目标。学生网络的低层因而具有两个目标：帮助学生网络的输出完成其目标和预测教师网络的中间层。尽管一个窄而深的网络似乎比宽而浅的网络更难训练，但窄而深网络的泛化能力可能更好，并且如果其足够窄，参数足够少，那么其计算代价更小。没有隐藏层的提示，学生网络在训练集和测试集上的实验表现都很差。因而中间层的提示是有助于训练很难训练的网络的方法之一，但是其他优化技术或是架构上的变化也可能解决这个问题。



## 设计有助于优化的模型

改进优化的最好方法并不总是改进优化算法。相反，深度模型中优化的许多改进来自于设计易于优化的模型。

原则上，我们可以使用呈锯齿非单调模式上上下下的激活函数，但是，这将使优化极为困难。在实践中，\emph{选择一族容易优化的模型比使用一个强大的优化算法更重要}。神经网络学习在过去 30 年的大多数进步主要来自于改变模型族，而非改变优化过程。1980年代用于训练神经网络的带动量的随机梯度下降，仍然是现代神经网络应用中的前沿算法。

具体来说，现代神经网络的\emph{设计选择}体现在层之间的线性变换，几乎处处可导的激活函数，和大部分定义域都有明显的梯度。特别地，创新的模型，如\,LSTM，整流线性单元和\,maxout\，单元都比先前的模型（如基于\,sigmoid\，单元的深度网络）使用更多的线性函数。这些模型都具有简化优化的性质。如果线性变换的\,Jacobian\，具有相对合理的奇异值，那么梯度能够流经很多层。此外，线性函数在一个方向上一致增加，所以即使模型的输出远离正确值，也可以简单清晰地计算梯度，使其输出方向朝降低损失函数的方向移动。换言之，现代神经网络的设计方案旨在使其\emph{局部}梯度信息合理地对应着移向一个遥远的解。

其他的模型设计策略有助于使优化更简单。例如，层之间的线性路径或是跳跃连接减少了从较低层参数到输出最短路径的长度，因而缓解了梯度消失的问题。一个和跳跃连接相关的想法是添加和网络中间隐藏层相连的输出的额外副本，如 GoogLeNet~和深度监督网络。这些"辅助头"被训练来执行和网络顶层主要输出相同的任务，以确保底层网络能够接受较大的梯度。当训练完成时，辅助头可能被丢弃。这是之前小节介绍到的预训练策略的替代方法。以这种方式，我们可以在一个阶段联合训练所有层，而不改变架构，使得中间层（特别是低层）能够通过更短的路径得到一些如何更新的有用信息。这些信息为底层提供了误差信号。



## 延拓法和课程学习

正如\sec?探讨的，许多优化挑战都来自于代价函数的全局结构，不能仅通过局部更新方向上更好的估计来解决。解决这个问题的主要方法是尝试初始化参数到某种区域内，该区域可以通过局部下降很快连接到参数空间中的解。


延拓法是一族通过挑选初始点使优化更容易的方法，以确保局部优化花费大部分时间在表现良好的空间。延拓法的背后想法是构造一系列具有相同参数的目标函数。为了最小化代价函数 $J(\boldsymbol \theta)$，我们构建新的代价函数 $\{J^{(0)},\dots,J^{(n)}\}$。这些代价函数的难度逐步提高，其中 $J^{(0)}$ 是最容易最小化的，$J^{(n)}$ 是最难的，真正的代价函数驱动整个过程。当我们说 $J^{(i)}$ 比 $J^{(i+1)}$ 更容易时，是指其在更多的 $\boldsymbol \theta$ 空间上表现良好。随机初始化更有可能落入局部下降可以成功最小化代价函数的区域，因为其良好区域更大。这系列代价函数设计为前一个解是下一个的良好初始点。因此，我们首先解决一个简单的问题，然后改进解以解决逐步变难的问题，直到我们求解真正问题的解。

传统的延拓法（用于神经网络训练之前的延拓法）通常基于平滑目标函数。读者可以查看 {Wu-97} 了解这类方法的示例，以及一些相关方法的综述。延拓法也和参数中加入噪声的模拟退火紧密相关。延拓法在最近几年非常成功。参考 {Mobahi+Fisher-AAAI2015} 了解近期文献的概述，特别是在 AI 方面的应用。


传统上，延拓法主要用来克服局部极小值的问题。具体地，它被设计来在有很多局部极小值的情况下，求解一个全局最小点。这些连续方法会通过"模糊"原来的代价函数来构建更容易的代价函数。这些模糊操作可以是用采样来近似

$$
J^{(i)}(\boldsymbol \theta) = \mathbb E_{\theta' \sim \mathcal{N}(\boldsymbol \theta'; \boldsymbol \theta, \sigma^{(i)2})} J(\boldsymbol \theta')
$$

这个方法的直觉是有些非凸函数在模糊后会近似凸的。在许多情况下，这种模糊保留了关于全局极小值的足够信息，我们可以通过逐步求解模糊更少的问题来求解全局极小值。这种方法有三种可能失败的方式。首先，它可能成功地定义了一连串代价函数，并从开始的一个凸函数起（逐一地）沿着函数链最佳轨迹逼近全局最小值，但可能需要非常多的逐步代价函数，整个过程的成本仍然很高。另外，即使延拓法可以适用，NP-hard的优化问题仍然是 NP-hard。其他两种延拓法失败的原因是不实用。其一，不管如何模糊，函数都没法变成凸的，比如函数 $J(\boldsymbol \theta) = -\boldsymbol \theta^\top \boldsymbol \theta$。其二，函数可能在模糊后是凸的，但模糊函数的最小值可能会追踪到一个局部最小值，而非原始代价函数的全局最小值。


尽管延拓法最初用来解决局部最小值的问题，而局部最小值已不再认为是神经网络优化中的主要问题了。幸运的是，延拓法仍然有所帮助。延拓法引入的简化目标函数能够消除平坦区域，减少梯度估计的方差，提高 Hessian 矩阵的条件数，使局部更新更容易计算，或是改进局部更新方向与朝向全局解方向之间的对应关系。

Bengio 指出被称为课程学习或者塑造, % ？ 整的方法可以被解释为延拓法。课程学习基于规划学习过程的想法，首先学习简单的概念，然后逐步学习依赖于这些简化概念的复杂概念。之前这一基本策略被用来加速动物训练过程和机器学习过程。{Bengio+al-2009}验证这一策略为延拓法，通过增加简单样本的影响（通过分配它们较大的系数到代价函数，或者更频繁地采样），先前的 $J^{(i)}$ 会变得更容易。实验证明，在大规模的神经语言模型任务上使用课程学习，可以获得更好的结果。课程学习已经成功应用于大量的自然语言和计算机视觉任务上。课程学习被证实为与人类教学方式一致：教师刚开始会展示更容易、更典型的示例，然后帮助学习者在不太显然的情况下提炼决策面。在人类教学上，基于课程学习的策略比基于样本均匀采样的策略\emph{更有效}，也能提高其他学习策略的效率。


课程学习研究的另一个重要贡献体现在训练循环神经网络捕获长期依赖：Zaremba 发现使用**随机课程**获得了更好的结果，其中容易和困难的示例混合在一起，随机提供给学习者，更难示例（这些具有长期依赖）的平均比例在逐渐上升。而使用确定性课程，并没有发现超过基线（完整训练集的普通训练）的改进。

现在我们已经介绍了一些基本的神经网络模型，以及如何进行正则化和优化。在接下来的章节中，我们转向特化的神经网络家族，允许其扩展到能够处理很大规模的数据和具有特殊结构的数据。在本章中讨论的优化算法在较少改动后或者无需改动，通常就可以直接用于这些特化的架构。



# 相关

- 《深度学习》花书
