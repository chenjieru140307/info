

# 读取和归一化 CIFAR10

我们使用 CIFAR10 数据集，它有如下 10 个类别：

‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’。

CIFAR-10的图像都是 3x32x32 大小的，即，3 颜色通道，32x32 像素。

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190627/zKmNnFxcGchF.png?imageslim">
</p>



举例：

```python
import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np

transform = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.CIFAR10(root='./data',
                                        train=True,
                                        download=True,
                                        transform=transform)
trainloader = torch.utils.data.DataLoader(trainset,
                                          batch_size=4,
                                          shuffle=True,
                                          num_workers=1)

testset = torchvision.datasets.CIFAR10(root='./data',
                                       train=False,
                                       download=True,
                                       transform=transform)
testloader = torch.utils.data.DataLoader(testset,
                                         batch_size=4,
                                         shuffle=False,
                                         num_workers=1)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')


# 展示图像的函数
def imshow(img):
    img = img / 2 + 0.5  # unnormalize
    npimg = img.numpy()
    print(npimg)
    print(npimg.shape)
    print(type(npimg))
    img_for_show = np.transpose(npimg, (1, 2, 0))
    print(img_for_show)
    print(img_for_show.shape)
    print(type(img_for_show))
    plt.imshow(img_for_show)
    plt.show()


if __name__ == "__main__":
    # 获取数据
    dataiter = iter(trainloader)
    print(dataiter)

    images, labels = dataiter.next()
    print(images)
    print(images.shape)
    print(type(images))

    print('\n')

    print(labels)
    print(labels.shape)
    print(type(labels))

    print('\n')

    # 展示图像
    img = torchvision.utils.make_grid(images)
    print(img)
    print(img.shape)
    print(type(img))
    imshow(img)

    # 显示图像标签
    print(' '.join('%5s' % classes[labels[j]] for j in range(4)))
```


输出：


```
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\cifar-10-python.tar.gz
100.0%
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
<torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x00000154DDE37DC8>
tensor([[[[ 0.0824,  0.0824,  0.0980,  ...,  0.2392,  0.1529,  0.1137],
          [-0.0902, -0.0667, -0.0667,  ...,  0.4588,  0.4745,  0.4745],
          [ 0.0510, -0.0118, -0.0353,  ...,  0.3255,  0.3961,  0.3804],
          ...,
          [ 0.6549,  0.6549,  0.5765,  ...,  0.8039,  0.4039, -0.0353],
          [ 0.6157,  0.6627,  0.6157,  ...,  0.8196,  0.6314,  0.3725],
          [ 0.5686,  0.5373,  0.5843,  ...,  0.6941,  0.6471,  0.6235]],

         [[ 0.0745,  0.0824,  0.1608,  ...,  0.3020,  0.3412,  0.3569],
          [-0.0588, -0.0196,  0.0039,  ...,  0.4745,  0.4510,  0.4745],
          [ 0.0431, -0.0039, -0.0431,  ...,  0.1608,  0.1765,  0.2157],
          ...,
          [ 0.7098,  0.6784,  0.6392,  ...,  0.7569,  0.3569, -0.0431],
          [ 0.6627,  0.6784,  0.6706,  ...,  0.7412,  0.5765,  0.3647],
          [ 0.6000,  0.5765,  0.6392,  ...,  0.6471,  0.6392,  0.6627]],

         [[ 0.1137,  0.1216,  0.1529,  ...,  0.2941,  0.3176,  0.3098],
          [ 0.0196,  0.0667,  0.0745,  ...,  0.3647,  0.3804,  0.4039],
          [ 0.0196,  0.0118, -0.0353,  ...,  0.0745,  0.0824,  0.1137],
          ...,
          [ 0.1451,  0.1451,  0.0902,  ...,  0.5216,  0.2000, -0.2235],
          [ 0.1137,  0.1373,  0.1059,  ...,  0.4275,  0.2941,  0.0039],
          [-0.0118,  0.0118,  0.0510,  ...,  0.2157,  0.2157,  0.1686]]],


        [[[-0.2471, -0.2627, -0.4745,  ...,  0.1137,  0.1216,  0.1373],
          [-0.3176, -0.3333, -0.4980,  ...,  0.1294,  0.1451,  0.1059],
          [-0.1137, -0.3412, -0.4118,  ...,  0.1686,  0.1294,  0.0196],
          ...,
          [ 0.0196, -0.0275, -0.1373,  ...,  0.2471,  0.2000,  0.2000],
          [-0.0275, -0.1373, -0.2078,  ...,  0.1765,  0.1529,  0.1608],
          [-0.0588, -0.0431, -0.0980,  ...,  0.0980,  0.1294,  0.1608]],

         [[-0.2000, -0.2392, -0.4118,  ...,  0.5216,  0.5373,  0.4275],
          [-0.2471, -0.3255, -0.4745,  ...,  0.5216,  0.5059,  0.2941],
          [ 0.0118, -0.3569, -0.4510,  ...,  0.5608,  0.4902,  0.2000],
          ...,
          [-0.0980, -0.1608, -0.2941,  ...,  0.1294,  0.1059,  0.1216],
          [-0.1294, -0.2392, -0.3255,  ...,  0.0902,  0.0902,  0.1216],
          [-0.1451, -0.1294, -0.2000,  ...,  0.0588,  0.0902,  0.1216]],

         [[-0.5608, -0.5059, -0.7490,  ...,  0.8980,  0.8902,  0.6471],
          [-0.4118, -0.4980, -0.7647,  ...,  0.9059,  0.8431,  0.4196],
          [-0.0118, -0.3882, -0.5765,  ...,  0.9216,  0.8196,  0.3255],
          ...,
          [-0.4431, -0.4980, -0.5686,  ..., -0.0980, -0.1059, -0.0902],
          [-0.4902, -0.6000, -0.6471,  ..., -0.1294, -0.0980, -0.0588],
          [-0.5137, -0.4824, -0.5216,  ..., -0.1373, -0.0980, -0.0431]]],


        [[[-0.9922, -0.9843, -0.9765,  ..., -0.9765, -0.9765, -0.9686],
          [-0.9922, -0.9843, -0.9608,  ..., -0.9216, -0.9843, -0.9451],
          [-0.9922, -0.9922, -0.9765,  ..., -0.8275, -0.9686, -0.9216],
          ...,
          [ 0.1373,  0.1137,  0.0980,  ...,  0.1922,  0.1686,  0.1373],
          [ 0.1529,  0.1294,  0.1451,  ...,  0.1843,  0.1686,  0.1373],
          [ 0.1373,  0.1451,  0.1529,  ...,  0.1843,  0.1686,  0.1294]],

         [[-0.9922, -0.9843, -0.9765,  ..., -0.9686, -0.9843, -0.9765],
          [-0.9922, -0.9843, -0.9608,  ..., -0.8980, -0.9765, -0.9373],
          [-0.9922, -0.9922, -0.9765,  ..., -0.7804, -0.9529, -0.9137],
          ...,
          [-0.4118, -0.4275, -0.4510,  ..., -0.3490, -0.3569, -0.3725],
          [-0.3961, -0.4196, -0.4353,  ..., -0.3647, -0.3647, -0.3725],
          [-0.3882, -0.3961, -0.4196,  ..., -0.3569, -0.3569, -0.3647]],

         [[-0.9922, -0.9843, -0.9765,  ..., -0.9843, -0.9922, -0.9686],
          [-0.9922, -0.9843, -0.9608,  ..., -0.9451, -0.9922, -0.9451],
          [-0.9922, -0.9922, -0.9765,  ..., -0.8588, -0.9765, -0.9373],
          ...,
          [-0.5059, -0.5216, -0.5529,  ..., -0.4667, -0.4745, -0.4745],
          [-0.4980, -0.5294, -0.5529,  ..., -0.4824, -0.4745, -0.4745],
          [-0.4980, -0.5137, -0.5529,  ..., -0.4745, -0.4667, -0.4667]]],


        [[[-0.8275, -0.8118, -0.8275,  ..., -0.5451, -0.4824, -0.5451],
          [-0.7725, -0.7804, -0.8039,  ..., -0.5294, -0.4588, -0.6157],
          [-0.7176, -0.7569, -0.7569,  ..., -0.6549, -0.5922, -0.7490],
          ...,
          [-0.1922, -0.1922, -0.1843,  ..., -0.8118, -0.8196, -0.6549],
          [-0.2000, -0.2000, -0.1922,  ..., -0.9608, -0.9451, -0.9059],
          [-0.2000, -0.2157, -0.2000,  ..., -0.9608, -0.9608, -0.9294]],

         [[-0.7961, -0.7490, -0.7490,  ..., -0.4431, -0.3333, -0.3961],
          [-0.7490, -0.7255, -0.7412,  ..., -0.4353, -0.3412, -0.4902],
          [-0.6941, -0.7176, -0.6941,  ..., -0.5686, -0.4902, -0.6471],
          ...,
          [-0.1765, -0.1765, -0.1765,  ..., -0.7647, -0.7804, -0.6157],
          [-0.1843, -0.1843, -0.1765,  ..., -0.9373, -0.9294, -0.8902],
          [-0.1843, -0.2000, -0.1843,  ..., -0.9608, -0.9529, -0.9294]],

         [[-0.8824, -0.8196, -0.8118,  ..., -0.4667, -0.2784, -0.3647],
          [-0.7961, -0.7647, -0.7647,  ..., -0.4196, -0.2784, -0.4510],
          [-0.7098, -0.7176, -0.6863,  ..., -0.5294, -0.4431, -0.6235],
          ...,
          [-0.2157, -0.2157, -0.2157,  ..., -0.7490, -0.7647, -0.6078],
          [-0.2235, -0.2235, -0.2157,  ..., -0.9294, -0.9137, -0.8824],
          [-0.2235, -0.2392, -0.2235,  ..., -0.9451, -0.9373, -0.9137]]]])
torch.Size([4, 3, 32, 32])
<class 'torch.Tensor'>


tensor([7, 9, 1, 1])
torch.Size([4])
<class 'torch.Tensor'>


tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0824,  ..., -0.5451,  0.0000,  0.0000],
         ...,
         [ 0.0000,  0.0000,  0.5686,  ..., -0.9294,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0745,  ..., -0.3961,  0.0000,  0.0000],
         ...,
         [ 0.0000,  0.0000,  0.6000,  ..., -0.9294,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],

        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.1137,  ..., -0.3647,  0.0000,  0.0000],
         ...,
         [ 0.0000,  0.0000, -0.0118,  ..., -0.9137,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])
torch.Size([3, 36, 138])
<class 'torch.Tensor'>


[[[0.5        0.5        0.5        ... 0.5        0.5        0.5       ]
  [0.5        0.5        0.5        ... 0.5        0.5        0.5       ]
  [0.5        0.5        0.5411765  ... 0.22745097 0.5        0.5       ]
  ...
  [0.5        0.5        0.78431374 ... 0.03529412 0.5        0.5       ]
  [0.5        0.5        0.5        ... 0.5        0.5        0.5       ]
  [0.5        0.5        0.5        ... 0.5        0.5        0.5       ]]

 [[0.5        0.5        0.5        ... 0.5        0.5        0.5       ]
  [0.5        0.5        0.5        ... 0.5        0.5        0.5       ]
  [0.5        0.5        0.5372549  ... 0.3019608  0.5        0.5       ]
  ...
  [0.5        0.5        0.8        ... 0.03529412 0.5        0.5       ]
  [0.5        0.5        0.5        ... 0.5        0.5        0.5       ]
  [0.5        0.5        0.5        ... 0.5        0.5        0.5       ]]

 [[0.5        0.5        0.5        ... 0.5        0.5        0.5       ]
  [0.5        0.5        0.5        ... 0.5        0.5        0.5       ]
  [0.5        0.5        0.5568628  ... 0.31764707 0.5        0.5       ]
  ...
  [0.5        0.5        0.49411765 ... 0.04313725 0.5        0.5       ]
  [0.5        0.5        0.5        ... 0.5        0.5        0.5       ]
  [0.5        0.5        0.5        ... 0.5        0.5        0.5       ]]]
(3, 36, 138)
<class 'numpy.ndarray'>
[[[0.5        0.5        0.5       ]
  [0.5        0.5        0.5       ]
  [0.5        0.5        0.5       ]
  ...
  [0.5        0.5        0.5       ]
  [0.5        0.5        0.5       ]
  [0.5        0.5        0.5       ]]

 ...

 [[0.5        0.5        0.5       ]
  [0.5        0.5        0.5       ]
  [0.5        0.5        0.5       ]
  ...
  [0.5        0.5        0.5       ]
  [0.5        0.5        0.5       ]
  [0.5        0.5        0.5       ]]]
(36, 138, 3)
<class 'numpy.ndarray'>


horse truck   car   car
```


输出图片：


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20191205/VHwdc2suS0bE.png?imageslim">
</p>

说明：

- 从 DataLoader 中提供的，无论是图片还是 label 都是 Tensor 格式的。
- 使用 `torchvision.utils.make_grid` 生成的简图也是 Tensor 格式的。
- `torch.Size([3, 36, 138])` 说明这个拼接成的图是 3 个channel ，36 的高度， 138 的宽度。<span style="color:red;">嗯，也就是说，高度在前，宽度在后。</span>
- 而且从打印出来的 `torch.Size([3, 36, 138])` 和 images 的 `torch.Size([4, 3, 32, 32])` 可以看出 `torchvision.utils.make_grid(images)` 实际上是把 4 张图合到一张图片上了。嗯，边框是两个像素，垂直方向：32+2+2=36 水平方向：32*4+2+2+2+2+2=138 。嗯。还挺好的。
- `' '.join('%5s' % classes[labels[j]] for j in range(4))` 这句挺好的，join 后面接一个 list，而这个 list 是一个列表推导式，而且，列表推导式的每个 item 是一个 `'%5s' % classes[labels[j]]` 字符串。

说明，imshow 函数：

- `img = img / 2 + 0.5` 由于 DataLoader 提供的图像是 -1~1 的范围的，因此转化成 0~1 的范围。
- `npimg = img.numpy()` 将图片从 Tensor 转化为 `numpy.ndarray` 格式。
- `img_for_show = np.transpose(npimg, (1, 2, 0))` 对 npimg 图像的维度进行调换，将原来的 0,1,2 调换为 1,2,0 。即将(3, 36, 138) 调换为 (36, 138, 3)，使排列顺序为 ：高度、宽度、channel 个数。这样是为了可以使 `plt.imshow(img_for_show)` 正确的将图片显示出来。<span style="color:blue;">确认下，是否 imshow 是要是这样的格式。经确认，是的。如同opencv 一样，经过 `cv2.imread()` 读取的图片的 shape  为 `(高、宽、channel 个数)`</span>

值得强调的：

- <span style="color:red;">我们看到 `print(images.shape)` 打出来的 `torch.Size([4, 3, 32, 32])` ，再结合 `print(images)` 的输出，我们可以知道，当我们看一个矩阵的输出的时候，我们从 最外层的括号看，看里面有多少个个体，可以看到是 4 个，然后再看每个个体里面的有多少个子个体，是 3 个，以此类推。这样来看，对于比较大的矩阵的输出就比较清楚了。</span>


不是很清楚的：

- <span style="color:red;">`transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])` 这个不是特别理解。</span>
- <span style="color:red;">这个 `transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))` 没看懂。是什么意思？</span>
- <span style="color:red;">`transforms` 里面的所有函数还是要总结下，不然不知道有哪些功能。</span>
- <span style="color:red;">这个 `num_workers=2` 一直不知道是什么效果。</span>






# 相关

- [pytorch-handbook](https://github.com/zergtant/pytorch-handbook)
