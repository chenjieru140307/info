

# 如何寻找超参数的最优值？

在使用机器学习算法时，总有一些难调的超参数。例如权重衰减大小，高斯核宽度等等。<span style="color:red;">什么是高斯核宽度？</span>这些参数需要人为设置，设置的值对结果产生较大影响。常见设置超参数的方法有：

1. 猜测和检查：根据经验或直觉，选择参数，一直迭代。
1. 网格搜索：让计算机尝试在一定范围内均匀分布的一组值。
1. 随机搜索：让计算机随机挑选一组值。
1. 贝叶斯优化：使用贝叶斯优化超参数，会遇到贝叶斯优化算法本身就需要很多的参数的困难。<span style="color:red;">怎么用贝叶斯优化？</span>
1. MITIE 方法，好初始猜测的前提下进行局部优化。它使用 BOBYQA 算法，并有一个精心选择的起始点。由于 BOBYQA 只寻找最近的局部最优解，所以这个方法是否成功很大程度上取决于是否有一个好的起点。<span style="color:red;">那么怎么选择一个好的起始点呢？</span>在 MITIE 的情况下，我们知道一个好的起点，但这不是一个普遍的解决方案，因为通常你不会知道好的起点在哪里。从好的方面来说，这种方法非常适合寻找局部最优解。稍后我会再讨论这一点。<span style="color:red;">怎么选择？</span>
1. 最新提出的 LIPO 的全局优化方法。这个方法没有参数，而且经验证比随机搜索方法好。<span style="color:red;">什么是 LIPO 全局优化方法？没听说过。补充下。</span>

<span style="color:red;">一般在实际应用中怎么去找最优的超参数？</span>
