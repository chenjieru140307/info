
# 大纲


深度学习算法在许多情况下都涉及到优化。

在深度学习涉及到的诸多优化问题中，最难的是神经网络训练。甚至是用几百台机器投入几天到几个月来解决单个神经网络训练问题，也是很常见的。因为这其中的优化问题很重要，代价也很高，因此研究者们开发了一组专门为此设计的优化技术。本章会介绍神经网络训练中的这些优化技术。


主要关注这一类特定的优化问题：

- 寻找神经网络上的一组参数 $\boldsymbol \theta$，它能显著地降低代价函数 $J(\boldsymbol \theta)$，该代价函数通常包括整个训练集上的性能评估和额外的正则化项。

## 主要内容如下

- 首先，我们会介绍在机器学习任务中作为训练算法使用的优化与纯优化有哪些不同。
- 接下来，我们会介绍导致神经网络优化困难的几个具体挑战。
- 然后，我们会介绍几个实用算法，包括优化算法本身和初始化参数的策略。
- 更高级的算法能够在训练中自适应调整学习率，或者使用代价函数二阶导数包含的信息。
- 最后，我们会介绍几个将简单优化算法结合成高级过程的优化策略，以此作为总结。

<span style="color:red;">简直酷到爆炸！</span>
