---
title: 07 图像数据不足时候的处理方法
toc: true
date: 2019-03-23
---

# 图像数据不足时的处理方法


在机器学习中，绝大部分模型都需要大量的数据进行训练和学习（包括有监督学习和无监督学习），然而在实际应用中经常会遇到训练数据不足的问题。比如图像分类，作为计算机视觉最基本的任务之一，其目标是将每幅图像划分到指定类别集合中的一个或多个类别中。当训练一个图像分类模型时，如果训练样本比较少，该如何处理呢？<span style="color:red;">是的，这个是经常会遇到的，一般来说是肯定会遇到的。</span>


## 在图像分类任务中，训练数据不足会带来什么问题？如何缓解数据量不足带来的问题？

迁移学习（Transfer Learning），生成对抗网络，图像处理，上采样技术，数据扩充


一个模型所能提供的信息一般来源于两个方面，一是训练数据中蕴含的信息；二是在模型的形成过程中（包括构造、学习、推理等），人们提供的先验信息。当训练数据不足时，说明模型从原始数据中获取的信息比较少，这种情况下要想保证模型的效果，就需要更多先验信息。<span style="color:red;">哇塞，这个之前好像没有看到过。</span>

先验信息可以作用在模型上，例如让模型采用特定的内在结构、条件假设或添加其他一些约束条件；先验信息也可以直接施加在数据集上，即根据特定的先验假设去调整、变换或扩展训练数据，让其展现出更多的、更有用的信息，以利于后续模型的训练和学习。<span style="color:red;">嗯，这个地方好好体会下。</span>

具体到图像分类任务上，训练数据不足带来的问题主要表现在过拟合方面，即模型在训练样本上的效果可能不错，但在测试集上的泛化效果不佳。根据上述讨论，对应的处理方法大致也可以分两类，

- 一是基于模型的方法，主要是采用降低过拟合风险的措施，包括简化模型（如将非线性模型简化为线性模型）、添加约束项以缩小假设空间（如 L1/L2正则项）、集成学习、Dropout超参数等；<span style="color:red;">集成学习在这个地方要怎么使用？</span>
- 二是基于数据的方法，主要通过数据扩充（Data Augmentation），即根据一些先验知识，在保持特定信息的前提下，对原始数据进行适当变换以达到扩充数据集的效果。具体到图像分类任务中，在保持图像类别不变的前提下，可以对训练集中的每幅图像进行以下变换。
  - （1）一定程度内的随机旋转、平移、缩放、裁剪、填充、左右翻转等，这些变换对应着同一个目标在不同角度的观察结果。
  - （2）对图像中的像素添加噪声扰动，比如椒盐噪声、高斯白噪声等。
  - （3）颜色变换。例如，在图像的 RGB 颜色空间上进行主成分分析，得到 3 个主成分的特征向量 $p_1$，$p_2$，$p_3$ 及其对应的特征值 $λ_1$，$λ_2$，$λ_3$，然后在每个像素的 RGB 值上添加增量 $[p_1,p_2,p_3]·[α_1λ_1,α_2λ_2,α_3λ_3]^T$，其中 $α_1$，$α_2$，$α_3$ 是均值为 $0$、方差较小的高斯分布随机数。<span style="color:red;">嗯，这个之前好像没有试过。要怎么做？要把代码补充下。</span>
  - （4）改变图像的亮度、清晰度、对比度、锐度等。


图 1.4展示了一些图像扩充的具体样例：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190323/CFydJaGTsaUH.png?imageslim">
</p>

<span style="color:red;">好吧，这样的数据增强还是有些厉害的。</span>


除了直接在图像空间进行变换，**还可以先对图像进行特征提取，然后在图像的特征空间内进行变换，利用一些通用的数据扩充或上采样技术，例如 SMOTE（Synthetic Minority Over-sampling Technique）算法**<span style="color:red;"> 对图像进行特征提取，然后在图像的特征空间内进行变换是什么意思？ SMOTE 具体是什么？要补充下。</span>

**抛开上述这些启发式的变换方法，使用生成模型也可以合成一些新样本，例如当今非常流行的生成式对抗网络模型。**<span style="color:red;">之前有稍微看过，但是没有深入理解，还是要从头到尾实现下，看看效果怎么样。</span>

**此外，借助已有的其他模型或数据来进行迁移学习在深度学习中也十分常见。** 例如，对于大部分图像分类任务，并不需要从头开始训练模型，而是借用一个在大规模数据集上预训练好的通用模型，并在针对目标任务的小数据集上进行微调（fine-tune），这种微调操作就可以看成是一种简单的迁移学习。<span style="color:red;">嗯，是的，想更多的了解下在不同的场景中，的各种迁徙方式，比如，从哪里取得已经训练好的通用模型？要怎么把这个模型应用在当前的场景下？有区别的时候怎么取舍？什么是真正迁移过来的？</span>




# 相关

- 《百面机器学习》
