

**PixelLink模型**

自然场景图像中一组文字块经常紧挨在一起，通过语义分割方法很难将它们识别开来，所以 PixelLink 模型尝试用实例分割方法解决这个问题。

该模型的特征提取部分，为 VGG16 基础上构建的 FCN 网络。模型执行流程如下图所示。首先，借助于 CNN 模块执行两个像素级预测：一个文本二分类预测，一个链接二分类预测。接着，用正链接去连接邻居正文本像素，得到文字块实例分割结果。然后，由分割结果直接就获得文字块边框， 而且允许生成倾斜边框。

上述过程中，省掉了其他模型中常见的边框回归步骤，因此训练收敛速度更快些。训练阶段，使用了平衡策略，使得每个文字块在总 LOSS 中的权值相同。训练过程中，通过预处理增加了各种方向角度的文字块实例。

![mark](http://images.iterate.site/blog/image/20190729/6Q5x0gml9xAQ.png?imageslim)（选自 arXiv: 1801.01315，’Detecting Scene Text via Instance Segmentation’）
