---
title: 2.13 SegNet
toc: true
date: 2019-09-01
---

**2.SegNet**

SegNet和 FCN 思路十分相似，只是 Encoder,Decoder(Upsampling)使用的技术不一致。此外 SegNet 的编码器部分使用的是 VGG16 的前 13 层卷积网络，每个编码器层都对应一个解码器层，最终解码器的输出被送入 soft-max分类器以独立的为每个像素产生类概率。

![img](https://pic2.zhimg.com/80/v2-bc50b394c51c45d0ac286bcec85abf79_hd.jpg)



## 9.4 SegNet

可训练的图像分割引擎，包含一个 encoder 网络，一个对应的 decoder 网络，衔接像素级分类层，解码网络与 VGG16 的 13 层卷积层相同。解码网络是将低分辨率的编码特征图映射到全分辨率的特征图。解码网络使用最大池化层的池化索引进行非线性上采样，上采样过程就不需要学习。<span style="color:red;">怎么使用池化索引进行非线性上采样的？</span>上采样得到的稀疏图与可训练的滤波器卷积得到致密的特征图。<span style="color:red;">怎么得到致密的特征图的？</span>

使用池化层索引进行上采样的优势：

1. 提升边缘刻画度；
2. 减少训练的参数；
3. 这种上采样模式可以包含到任何编码-解码网络中。

SegNet 网络的结构如下图所示：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/K66NKq7thhY5.jpg?imageslim">
</p>

> 图 1

SegNet 网络结构如图 1 所示，Input为输入图片，Output为输出分割的图像，不同颜色代表不同的分类。语义分割的重要性就在于不仅告诉你图片中某个东西是什么，而且告知你他在图片的位置。

我们可以看到是一个对称网络，由中间绿色 pooling 层与红色 upsampling 层作为分割：

- 左边是卷积提取高维特征，并通过 pooling 使图片变小，SegNet作者称为 Encoder
- 右边是反卷积（在这里反卷积与卷积没有区别）与 upsampling，通过反卷积使得图像分类后特征得以重现，upsampling 使图像变大，SegNet作者称为 Decoder，

最后通过 Softmax，输出不同分类的最大值。这就是大致的 SegNet 过程，下面对这个过程里面使用到的方法进行介绍。

编码网络与滤波器族卷积得到特征图，进行 BN，ReLU，最大池化。最大池化是为了获得空间小位移的平移不变。<span style="color:red;">为了获得这种小位移的平移不变损失了一些信息，是值得的吗？</span>最大池化和下采样损失了边缘细节，因此，在编码过程中保存边缘信息很重要。考虑到内存原因，只保存最大池化索引，如最大特征值的位置。<span style="color:red;">嗯，难道还要保存什么别的吗？这个最大池化索引是必须保存的吧？是要进行反向传播的时候要用的吧？</span><span style="color:blue;">嗯，这里还作为最大池化索引上采样的时候使用。</span>

SegNet 解码技术如下图所示：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/kpDX0Y2TLUyk.jpg?imageslim">
</p>

> 图 3 SegNet 与 FCN 对比。

SegNet 与 FCN 对比如下：

- 左侧的 SegNet 解码网络使用保存的最大池化索引上采样，得到稀疏的特征图，将特征图与可训练的解码滤波器族卷积得到致密的特征图。<span style="color:red;">上图有说是什么尺寸的卷积核吗？</span>之后进行 BN。<span style="color:red;">为什么要进行 BN？</span>高维的特征图输入 soft-max 层，对每个像素进行分类，得到每个像素属于 $K$ 类的概率。
- 图 3 中右边是 FCN 的解码技术，FCN 对编码的特征图进行降维，降维后输入到解码网络，解码网络中，上采样使用反卷积实现，上采样的特征图与降维的编码图进行 element-wise add 得到最终的解码特征图。FCN 解码模型需要存储编码特征图，在嵌入式设备中内存紧张。<span style="color:red;">嗯嗯，是的，的确，因为要用到之前的层的特征，因此要保存在内存里。的确会使内存紧张。</span>

SegNet 的 Encoder 过程中，卷积的作用是提取特征，SegNet使用的卷积为 same 卷积，即卷积后不改变图片大小；在 Decoder 过程中，同样使用 same 卷积，不过卷积的作用是为 upsampling 变大的图像丰富信息，使得在 pooling 过程丢失的信息可以通过学习在 Decoder 得到。<span style="color:red;">真的可以得到吗？</span>SegNet 中的卷积与传统 CNN 的卷积并没有区别。


# 相关

- [2019年最新基于深度学习的语义分割技术讲解](https://zhuanlan.zhihu.com/p/76418243)
