---
title: 02.12 MTCNN
toc: true
date: 2019-09-03
---

# 基于多任务卷积神经网络的人脸检测（MTCNN）

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/ChCNqjHi2GDF.png?imageslim">
</p>


<span style="color:red;">P-Net 图缺失了</span>

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/vAA1Bxz1bE2g.png?imageslim">
</p>


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/4zeNq1ONncpY.png?imageslim">
</p>


1.MTCNN 模型有三个子网络。分别是 P-Net,R-Net,O-Net。<span style="color:red;">想问一下，1.模型中的三个 input size 是指的是同一张图 resize 到不同尺度下喂给不同模型，还是同一张图，依次经过三个模型，然后是不同的输入尺寸？（这部分能给我讲一下吗）2.每个模型它都有对应三个结果（face classification;bounding box;facial landmark）这三个在网络上是如何对应的呢？</span>

为了检测不同大小的人脸，开始需要构建图像金字塔，先经过 pNet 模型，输出人脸类别和边界框（边界框的预测为了对特征图映射到原图的框平移和缩放得到更准确的框），将识别为人脸的框映射到原图框位置可以获取 patch，<span style="color:red;">什么是 patch？</span>之后每一个 patch 通过 resize 的方式输入到 rNet，识别为人脸的框并且预测更准确的人脸框，最后 rNet 识别为人脸的的每一个 patch 通过 resize 的方式输入到 oNet，跟 rNet 类似，关键点是为了在训练集有限情况下使模型更鲁棒。<span style="color:red;">怎么在训练集有限的情况下使模型更鲁棒的？</span>

还要注意一点构建图像金字塔的的缩放比例要保留，为了将边界框映射到最开始原图上的

还要注意一点：如何从 featureMap 映射回原图。<span style="color:red;">怎么映射回原图的？</span>






# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
