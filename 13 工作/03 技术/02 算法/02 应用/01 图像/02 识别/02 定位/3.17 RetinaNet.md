---
title: 3.17 RetinaNet
toc: true
date: 2019-09-03
---

### 8.3.7 RetinaNet

<span style="color:red;">没明白。</span>

**研究背景**

- Two-Stage 检测器（如 Faster R-CNN、FPN）效果好，但速度相对慢
- One-Stage 检测器（如 YOLO、SSD）速度快，但效果一般

<center>

![](http://images.iterate.site/blog/image/20190722/yTYKcNYM6Rdn.png?imageslim){ width=75% }

</center>

作者对 one-stage 检测器准确率不高的问题进行探究，发现主要问题在于正负类别不均衡（简单-难分类别不均衡）。

> We discover that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause.

作者建议通过重新设计标准的交叉熵损失（cross entropy loss）来解决这种类别不平衡（class inbalance）问题，即提出 Focal Loss。

> We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples. Our novel Focal Loss focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training.

结合 Focal Loss 的 one-stage 检测器称为 RetinaNet，该检测器在 COCO 上 mAP 可以和特征金字塔网络（feature pyramid network，FPN）或者 Mask R-CNN 接近。<span style="color:red;">这么厉害。</span>

**问：什么是类别不均衡（class imbalance）？**

答：负样本的数量极大于正样本的数量，比如包含物体的区域（正样本）很少，而不包含物体的区域（负样本）很多。比如检测算法在早期会生成一大波的 bbox。而一幅常规的图片中，顶多就那么几个 object。这意味着，绝大多数的 bbox 属于 background。

**问：样本的类别不均衡会带来什么问题？**

答：由于大多数都是简单易分的负样本（属于背景的样本），使得训练过程不能充分学习到属于那些有类别样本的信息；其次简单易分的负样本太多，可能掩盖了其他有类别样本的作用（这些简单易分的负样本仍产生一定幅度的 loss，见下图蓝色曲线，数量多会对 loss 起主要贡献作用，因此就主导了梯度的更新方向，掩盖了重要的信息）<span style="color:red;">为什么仍会产生一定幅度的 loss？</span>

> This imbalance causes two problems: (1) training is inefficient as most locations are easy negatives that contribute no useful learning signal; (2) en masse, the easy negatives can overwhelm training and lead to degenerate models.

简单来说，因为 bbox 数量爆炸。 正是因为 bbox 中属于 background 的 bbox 太多了，所以如果分类器无脑地把所有 bbox 统一归类为 background，accuracy 也可以刷得很高。于是乎，分类器的训练就失败了。分类器训练失败，检测精度自然就低了。<span style="color:red;">是的，主要是分类器训练失败。</span>

**问：为什么在 two-stage 检测器中，没有出现类别不均衡（class imbalamce）问题呢？**

答：因为通过 RPN 阶段可以减少候选目标区域，而在分类阶段，可以固定前景与背景比值（foreground-to-background ratio）为 1:3，或者使用 OHEM（online hard example mining）使得前景和背景的数量达到均衡。<span style="color:red;">怎么固定前景和背景比值的？怎么使用 OHEM 来达到均衡的？</span>

**RetinaNet 有哪些创新点？**

**概述：**

- New loss：提出 Focal Loss 函数解决 class imbalance

$$
FL(p_t) = -(1-p_t)^\gamma \log(p_t)FL(pt)=−(1−pt) \gamma log(pt)
$$

<span style="color:red;">没看懂上面的式子。</span>

- New detector：RetinaNet = ResNet + FPN + Two sub-networks + Focal Loss

Focal Loss 更加聚焦在困难样本（hard examples）上的训练。

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/TDRieXgG0Heh.png?imageslim">
</p>


将 Focal Loss 与 ResNet-101-FPN backbone 结合提出 RetinaNet（one-stage 检测器），RetinaNet 在 COCO test-dev 上达到 39.1mAP，速度为 5FPS。

RetinaNet 检测器与当时最佳的其它检测器进行比较，无论是速度上还是准确率上都是最佳：<span style="color:red;">这么厉害。</span>

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/esydgMHzhiiv.png?imageslim">
</p>


**详解：**

作者提出一种新的损失函数，思路是希望那些 hard examples 对损失的贡献变大，使网络更倾向于从这些样本上学习。

作者以二分类为例进行说明：

**交叉熵函数 CE**

首先是我们常使用的交叉熵损失函数：

$$
\operatorname{CE}(p, y)=\left\{\begin{array}{ll}{-\log (p)} & {\text { if } y=1} \\ {-\log (1-p)} & {\text { otherwise. }}\end{array}\right.\tag{1}
$$


上式中，$y=+1$ 或者 $y=-1$。$p\in [0,1]$ 是 $y=+1$ 的估计概率。作者定义 pt 为：

$$
p_{\mathrm{t}}=\left\{\begin{array}{ll}{p} & {\text { if } y=1} \\ {1-p} & {\text { otherwise }}\end{array}\right.\tag{2}
$$


$$
\operatorname{CE}(p, y)=\operatorname{CE}\left(p_{\mathrm{t}}\right)=-\log \left(p_{\mathrm{t}}\right)
$$


注：对交叉熵函数不了解的，可以参考[理解交叉熵作为损失函数在神经网络中的作用](https://blog.csdn.net/chaipp0607/article/details/73392175)

**均衡交叉熵函数**

要对类别不均衡问题对 loss 的贡献进行一个控制，即加上一个控制权重即可，最初作者的想法即如下这样，对于属于少数类别的样本，增大 $\alpha$ 即可

$$
\mathrm{CE}\left(p_{\mathrm{t}}\right)=-\alpha_{\mathrm{t}} \log \left(p_{\mathrm{t}}\right)\tag{3}
$$


但这样有一个问题，它仅仅解决了正负样本之间的平衡问题，并没有区分易分/难分样本，按作者的话说：

> While  $\alpha$  balances the importance of positive/negative examples, it does not differentiate between easy/hard examples. Instead, we propose to reshape the loss function to down-weight easy examples and thus focus training on hard negatives.

问：为什么公式(3)只解决正负样本不均衡问题？

答：增加了一个系数 $\alpha t$ ，跟 $pt$ 的定义类似，当 $label=1$ 的时候， $\alpha t=a$ ；当 $label=-1$ 的时候， $\alpha t=1-a$ ，$a$ 的范围也是 $0$ 到 $1$。因此可以通过设定 $a$ 的值（一般而言假如 $1$ 这个类的样本数比 $-1$ 这个类的样本数多很多，那么 $a$ 会取 $0$ 到 $0.5$ 来增加 $-1$ 这个类的样本的权重）来控制正负样本对总的 loss 的共享权重。

**Focal Loss**

作者一开始给交叉熵损失函数添加 modulating factor：

$$
(1-p t)^{\gamma}(1-p t) \gamma
$$

$$
\mathrm{FL}\left(p_{\mathrm{t}}\right)=-\left(1-p_{\mathrm{t}}\right)^{\gamma} \log \left(p_{\mathrm{t}}\right)\tag{4}
$$


显然，样本越易分，$pt$ 就越大（$pt->1$），modulating factor 趋近于 $0$，则贡献的 loss 就越小，同样地，样本越难分，其 $pt$ 就越小，modulating factor 接近于 $1$，则贡献的 loss 不受影响。

问：为什么 $pt$ 越大，FL 值越小？

答：根据公式（4）可知，FL 与 $log(pt)$ 中的 $pt$ 成反比，与 $1-pt$ 成正比，因此 FL 与 $pt$ 的关系成反比。这是交叉熵函数的基本性质。当 $pt$ 很大时（接近于 $1$），FL 值很小；而当 $pt$ 很小时（接近于 $0$），FL 值会很大。

注：这里有个超参数 focusing parameter  $\gamma$ 。

$\gamma$  放大了 modulating factor 的作用。

举原文中的一个例子，当 $pt=0.9$ 时，带有 modulating factor 的 focal loss 是 CE loss 的 100 分之一，即进一步减小了正确分类的损失。

> For instance, with  $\gamma= 2$  , an example classified with pt = 0.9 would have 100× lower loss compared with CE and with pt ≈ 0.968 it would have 1000× lower loss. This in turn increases the importance of correcting misclassified examples (whose loss is scaled down by at most 4× for pt ≤ .5 and  $\gamma$  = 2).

在实际中，作者采用如下公式，即综合了公式(3)和公式(4)的形式，这样机能调整正负样本的权重，又能控制难易分类样本的权重：

$$
\mathrm{FL}\left(p_{\mathrm{t}}\right)=-\alpha_{\mathrm{t}}\left(1-p_{\mathrm{t}}\right)^{\gamma} \log \left(p_{\mathrm{t}}\right)
$$


这里的两个参数  $\alpha$ 和 $\gamma$  来控制，在实验中 $a$ 的选择范围也很广，一般而言当 $\gamma$ 增加的时候，$a$ 需要减小一点，本文作者采用 $\alpha=0.25$ ， $\gamma$ =2 效果最好。

**RetinaNet Detector**

RetinaNet 是由 backbone 网络和两个特殊任务的子网络（subnet）组成（属于 one-stage 检测器）。Backbone 用来计算 feature map；第一个子网络用来 object classification，第二个子网络用来 bounding box regression。<span style="color:red;">什么是  backbone 网络？</span>

**Feature Pyramid Network Backbone**

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/9IDDG3kc9ja9.png?imageslim">
</p>


**Anchor**

**Classification Subnet**

**Box Regression Subnet**

<center>

![](http://images.iterate.site/blog/image/20190722/IdIfkDXfPwvi.png?imageslim){ width=75% }

</center>


<center>

![](http://images.iterate.site/blog/image/20190722/7jOxN4Br8dCf.png?imageslim){ width=75% }

</center>


RetinaNet 结构注意内容：

1. 训练时 FPN 每一级的所有 example 都被用于计算 Focal Loss，loss 值加到一起用来训练；
2. 测试时 FPN 每一级只选取 score 最大的 1000 个 example 来做 nms；
3. 整个结构不同层的 head 部分(上图中的 c 和 d 部分)共享参数，但分类和回归分支间的参数不共享；
4. 分类分支的最后一级卷积的 bias 初始化成前面提到的 $-log((1-π)/π)$;


**实验结果**

Table1 是关于 RetinaNet 和 Focal Loss 的一些实验结果。

a. 是在交叉熵的基础上加上参数 a，a=0.5 就表示传统的交叉熵，可以看出当 a=0.75 的时候效果最好，AP 值提升了 0.9。
b. 是对比不同的参数 $\gamma$ 和 a 的实验结果，可以看出随着 $\gamma$ 的增加，AP 提升比较明显。
d. 通过和 OHEM 的对比可以看出最好的 Focal Loss 比最好的 OHEM 提高了 3.2AP。这里 OHEM1:3 表示在通过 OHEM 得到的 minibatch 上强制 positive 和 negative 样本的比例为 1:3，通过对比可以看出这种强制的操作并没有提升 AP。
e. 加入了运算时间的对比，可以和前面的 Figure2 结合起来看，速度方面也有优势！注意这里 RetinaNet-101-800 的 AP 是 37.8，当把训练时间扩大 1.5 倍同时采用 scale jitter，AP 可以提高到 39.1，这就是全文和 table2 中的最高的 39.1AP 的由来。

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/aGGIAYdYP9yw.png?imageslim">
</p>


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/hYc2yfNdLRCb.png?imageslim">
</p>






# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
