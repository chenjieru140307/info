---
title: 2.13 Faster R-CNN
toc: true
date: 2019-09-03
---

### 8.2.3 Faster R-CNN




Faster RCNN

SPPNet和 Faster RCNN都需要独立的候选区域生成模块，这个模块计算量很大，而且不易用 GPU 加速。针对这个问题，Shaoqin Ren 等人在 Faster RCNN基础上提出 Faster R-CNN ，在主干网络中增加了 RPN （Region Proposal Network）网络，通过一定规则设置不同尺度的锚点（Anchor）在 RPN 的卷积特征层提取候选框来代替 Selective Search等传统的候选框生成方法，实现了网络的端到端训练。候选区域生成、候选区域特征提取、框回归和分类全过程一气呵成，在训练过程中模型各部分不仅学习如何完成自己的任务，还自主学习如何相互配合。这也是第一个真正意义上的深度学习目标检测算法。



注：Shaoqin Ren实现的 matlab 版本中 RPN 阶段和 FRCNN 阶段是分开训练的，但是在实际的实践中（RBG实现的 Python 版本）发现二者可以一起优化训练，而且精度没有损失，可以说 Faster RCNN真正实现了端到端的训练。

![mark](http://images.iterate.site/blog/image/20190905/ypUkjOKIuXp6.png?imageslim)
Fast RCNN（左） 和 Faster RCNN（右）框架结构对比





**Faster R-CNN 有哪些创新点？**

Fast R-CNN 依赖于外部候选区域方法，如选择性搜索。但这些算法在 CPU 上运行且速度很慢。在测试中，Fast R-CNN 需要 2.3 秒 来进行预测，其中 2 秒用于生成 2000 个 ROI。

Faster R-CNN 采用与 Fast R-CNN 相同的设计，只是它用内部深层网络代替了候选区域方法。新的候选区域网络（RPN）在生成 ROI 时效率更高，并且以每幅图像 10 毫秒的速度运行。

<center>

![](http://images.iterate.site/blog/image/20190722/PSB4U4UOjKBB.png?imageslim){ width=85% }

</center>

> Faster R-CNN 的流程图

Faster R-CNN 的流程图与 Fast R-CNN 相同，采用外部候选区域方法代替了内部深层网络。

<center>

![](http://images.iterate.site/blog/image/20190722/cwYAufdJ1DQv.png?imageslim){ width=85% }

</center>

<span style="color:red;">这个 region proposal network 是怎么训练的？</span>

**候选区域网络**

<span style="color:red;">还是没明白这个地方。</span>

候选区域网络（RPN）将第一个卷积网络的输出特征图作为输入。它在特征图上滑动一个 3×3 的卷积核，以使用卷积网络（如下所示的 ZF 网络）构建与类别无关的候选区域。其他深度网络（如 VGG 或 ResNet）可用于更全面的特征提取，但这需要以速度为代价。

ZF 网络最后会输出 256 个值，它们将馈送到两个独立的全连接层，以预测边界框和两个 objectness 分数，这两个 objectness 分数度量了边界框是否包含目标。<span style="color:red;">？为什么要这样来训练？</span>

我们其实可以使用回归器计算单个 objectness 分数，但为简洁起见，Faster R-CNN 使用只有两个类别的分类器：即带有目标的类别和不带有目标的类别。<span style="color:red;">嗯。</span>

<center>

![](http://images.iterate.site/blog/image/20190722/xL6wX5kgzYlr.png?imageslim){ width=85% }

</center>


对于特征图中的每一个位置，RPN 会做 $k$ 次预测。因此，RPN 将输出 4×k 个坐标和每个位置上 2×k 个得分。下图展示了 8×8 的特征图，且有一个 3×3 的卷积核执行运算，它最后输出 8×8×3 个 ROI（其中 k=3）。下图（右）展示了单个位置的 3 个候选区域。

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/74Turru9XbIU.png?imageslim">
</p>

假设最好涵盖不同的形状和大小。因此，Faster R-CNN 不会创建随机边界框。相反，它会预测一些与左上角名为锚点的参考框相关的偏移量（如 x, y ）。我们限制这些偏移量的值，因此我们的猜想仍然类似于锚点。

<center>

![](http://images.iterate.site/blog/image/20190722/qwfB3bVv2NyC.png?imageslim){ width=45% }

</center>


要对每个位置进行 $k$ 个预测，我们需要以每个位置为中心的 $k$ 个锚点。每个预测与特定锚点相关联，但不同位置共享相同形状的锚点。

<center>

![](http://images.iterate.site/blog/image/20190722/P0nSrhJzXR2u.png?imageslim){ width=35% }

</center>


这些锚点是精心挑选的，因此它们是多样的，且覆盖具有不同比例和宽高比的现实目标。这使得我们可以用更好的猜想来指导初始训练，并允许每个预测专门用于特定的形状。该策略使早期训练更加稳定和简便。

<center>

![](http://images.iterate.site/blog/image/20190722/pDPjNc1xW34p.png?imageslim){ width=65% }

</center>


Faster R-CNN 使用更多的锚点。它部署 9 个锚点框：3 个不同宽高比的 3 个不同大小的锚点（Anchor）框。每一个位置使用 9 个锚点，每个位置会生成 2×9 个 objectness 分数和 4×9 个坐标。






# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
