---
title: 3.14 YOLOv3
toc: true
date: 2019-09-03
---
# 可以补充进来的

- [探索 YOLO v3 源码 - 完结篇 预测](https://mp.weixin.qq.com/s?__biz=MzU2MTY4NjAyOQ==&mid=2247483688&idx=2&sn=b7ebaf0532ee45b65f6c7632499b5782&chksm=fc75b24acb023b5c6dd9e4445cd4a6394954ebca9a141061873b3a1d9d85e4e6e6a29c4dfa06&mpshare=1&scene=1&srcid=08175U4vczOvJsf74rZuft4b#rd)

# YOLOv3

YOLOv3在 YOLOv2 的基础上使用了全新设计的 Darknet53 残差网络并结合 FPN 网络结构，在网络后两个特征图上采样后于网络前期相应尺寸的特征图聚合再经过卷积网络后得到预测结果。这些改进使得 YOLOv3 用三分之一的时间达到与 SSD 相当的精确度。在 COCO test-dev 上 mAP@0.5 达到 57.9%，与 RetinaNet（FocalLoss论文所提出的单阶段网络）的结果相近，但速度快 4 倍。



YOLOv3的模型比之前的版本复杂了不少，可以通过改变模型结构的大小来权衡速度与精度。

YOLOv3的改进点：

\1. 多尺度预测（FPN）

\2. 更好的 Backbone 网络（Darknet53残差网络）

\3. 分类损失采用 binary cross-entropy损失函数替换 Softmax 损失函数（Softmax会选择分数最高的类别判定为当前框所属的类别，而现实中一个目标可能属于多个类别标签）

![mark](http://images.iterate.site/blog/image/20190905/27czL3pI7mMW.png?imageslim)





YOLOv3 总结了自己在 YOLOv2 的基础上做的一些尝试性改进，有的尝试取得了成功，而有的尝试并没有提升模型性能。

其中有两个值得一提的亮点：

- 一个是使用残差模型，进一步加深了网络结构
- 另一个是使用 FPN 架构实现多尺度检测。<span style="color:red;">什么是 FPN 架构？</span>

**YOLOv3 有哪些创新点？**

1. 新网络结构：DarkNet-53
2. 融合 FPN
3. 用逻辑回归替代 softmax 作为分类器。<span style="color:red;">为什么使用逻辑回归代替 softmax？</span>

**1. YOLOv3 对网络结构做了哪些改进？**

YOLOv3 在之前 Darknet-19 的基础上引入了残差块，并进一步加深了网络，改进后的网络有 53 个卷积层，取名为 Darknet-53，网络结构如下图所示（以 256*256 的输入为例）。

<center>

![](http://images.iterate.site/blog/image/20190722/LGcLacmVdnYg.png?imageslim){ width=38% }

</center>


为了比较 Darknet-53 与其它网络结构的性能，作者在 TitanX 上，采用相同的实验设置，将 256x256 的图片分别输入以 Darknet-19，ResNet-101，ResNet-152 和 Darknet-53 为基础网络的分类模型中，实验得到的结果如下图所示。可以看到 Darknet-53 比 ResNet-101 的性能更好，而且速度是其 1.5 倍，Darknet-53 与 ResNet-152 性能相似但速度几乎是其 2 倍。注意到，Darknet-53 相比于其它网络结构实现了每秒最高的浮点计算量，说明其网络结构能更好的利用 GPU。<span style="color:red;">为什么每秒浮点计算量会有不同？</span>

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/DHrjnVtPGTy1.png?imageslim">
</p>


**2.YOLOv3 中怎样实现多尺度检测？**

YOLOv3 借鉴了 FPN 的思想，从不同尺度提取特征。相比 YOLOv2，YOLOv3 提取最后 3 层特征图，不仅在每个特征图上分别独立做预测，同时通过将小特征图上采样到与大的特征图相同大小，然后与大的特征图拼接做进一步预测。<span style="color:red;">怎么拼接？</span>

用维度聚类的思想聚类出 9 种尺度的 anchor box，将 9 种尺度的 anchor box 均匀的分配给 3 种尺度的特征图。

如下图是在网络结构图的基础上加上多尺度特征提取部分的示意图（以在 COCO 数据集(80 类)上 256x256 的输入为例）：

<center>

![](http://images.iterate.site/blog/image/20190722/RGzMRK2wqm8X.png?imageslim){ width=65% }

</center>


从 YOLOv1 到 YOLOv2 再到 YOLO9000、YOLOv3，YOLO 经历三代变革，在保持速度优势的同时，不断改进网络结构，同时汲取其它优秀的目标检测算法的各种 trick，先后引入 anchor box 机制、引入 FPN 实现多尺度检测等。<span style="color:red;">嗯。</span>






# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
