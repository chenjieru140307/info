
# 可以补充进来的

- 基本没什么新的。拆掉。


# 卷积神经网络

卷积神经网络是近年发展起来，并引起广泛重视的一种高效识别方法。

卷积神经网络是人工神经网络的一种，是深度学习的一个重要算法，它在很多应用上表现出卓越的效果。特别是在模式分类领域，由于该网络避免了对图像的复杂前期预处理，可以直接输入原始图像，因而得到了更为广泛的应用。

20世纪 60 年代，Hubel和 Wiesel 在研究猫脑皮层中用于局部敏感和方向选择的神经元时，发现其独特的网络结构可以有效地降低反馈神经网络的复杂性，继而提出了卷积神经网络（Convolutional Neural Networks，简称 CNN）。

由于 CNN 的特征检测层通过训练数据进行学习，因此可以隐式地从训练数据中进行学习。

CNN主要用来识别位移、缩放及其他形式扭曲不变性的二维图形。

在图像处理过程中，由于图像像素可以看作是多维输入向量，同一特征映射面上的神经元权值相同，权值共享减少了权值的数量，降低了网络的复杂性，因此卷积神经网络以其局部权值共享的特殊结构在语音识别和图像处理方面有着独特的优越性。

同时卷积神经网络对输入图片的平移、比例缩放、倾斜或者其他形式的变形具有高度不变性。

神经网络的基本组成包括输入层、隐藏层、输出层。卷积神经网络也不例外，包括输入层、隐藏层和输出层。但是卷积神经网络的隐藏层可分为卷积层和池化层。

卷积神经网络具有特殊深层的神经网络模型结构，它的特殊性体现在两个方面：

- 一方面神经元之间的连接是非全连接的
- 另一方面同一层中某些神经元之间的连接的权重是共享的。

它的非全连接和权值共享的网络结构使之更类似于生物神经网络，降低了网络模型的复杂度，减少了权值的数量。

从卷积神经网络的构造上来看，卷积神经网络的基本结构包括两层：

- 其一为特征提取层，每个神经元的输入与前一层的局部接受域相连，并提取该局部的特征。一旦该局部特征被提取后，它与其他特征间的位置关系也随之确定下来。
- 其二为特征映射层，网络的每个计算层由多个特征映射组成，每个特征映射是一个平面，平面上所有神经元的权值相等。一般采用 Sigmoid 函数作为卷积网络的激活函数，这使得特征映射具有位移不变性。

卷积神经网络的基本流程结构：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190615/A2WvujIdu5iQ.png?imageslim">
</p>

我们用文字简单描述一下卷积神经网络的基本流程。

一个卷积神经网络由若干卷积层、池化层、全连接层组成。

- 输入图像到输入层。
- 第一个卷积层的输入图像通过三个可训练的卷积核加偏置进行卷积操作，得到了三个特征图。
- 在第一个卷积层之后，池化层对三个特征图做了下采样，得到了三个更小的特征图。
- 第二个卷积层，每个卷积核 Filter 都把前面下采样之后的特征图卷积在一起，得到一个新的特征图，然后得到了 5 个特征图。
- 第二个池化层，对 5 个特征图进行下采样，得到了 5 个更小的特征图。
- 卷积神经网络的最后两层是全连接层。这些像素值连接成一个向量输入到传统的神经网络中，得到输出。




# 相关

- 《深度学习框架 Pytorch 快速开发与实战》
