
# PyTorch

分布式的配置和应用也要补充进来。




现在很多论文的实现发出来的都是 Pytorch 的实现，因此，这个是必须要掌握的。

Caffe 现在已经合并到 PyTorch 里面了，怪不得现在这么厉害。嗯，这个是必须要掌握的。

张量是 PyTorch 的一个完美组件，和 NumPy 类似。将张量从 NumPy 转换至 PyTorch 非常容易。可以把它作为 NumPy 的替代品。PyTorch 这种框架可以获得 GPU 加速，以便快速进行数据预处理，或其他任务。PyTorch 同时也提供了变量，我们在构建神经网络的时候，在张量之上的封装，构建自己的计算图，并自动计算梯度。

PyTorch 建立的是动态图，TensorFlow 建立的是静态图。PyTorch 更加符合一般的编程习惯，而不是像 TensorFlow 那样需要先定义计算图。<span style="color:red;">PyTorch 建立的是动态图吗？Tensorflow 是静态图吗？这两者有什么不同？那种好？</span>


利用 PyTorch 开源平台快速实现经典卷积神经网络、循环神经网络、自编码模型、对抗生成网络等模型。开启海绵模式，尽可能多学原理知识，掌握机器学习的基础理论知识，然后针对性地训练。通常从收集数据，预处理和清洗数据，到搭建模型，训练和调试模型，再到最后评估模型。逐渐培养出对于什么样的数据适合用什么类型的模型的判断能力，并增强实践能力。经过学习，逐渐从“小白”，慢慢到专业人士。



## 主要内容

- 基本使用
- 实践
- 源代码的学习


## 需要消化的


- 《深度学习框架 PyTorch 快速开发与实战》
- 《深度学习框架 PyTorch：入门与实践》


- [浅谈 Pytorch 与 Torch 的关系](https://cloud.tencent.com/developer/article/1142510)
- [Awesome-pytorch-list](https://github.com/bharathgs/Awesome-pytorch-list)

## 可以补充进来的

- 大部分不涉及 PyTorch 基础的，而是涉及 Pytorch 应用的要拆分出去。这里面只保留一些基本的实现以及基础的东西。



- [Github项目推荐 | 基于 PyTorch 以用户为中心的可微概率推理包 Brancher](http://mp.weixin.qq.com/s?__biz=MjM5ODU3OTIyOA==&mid=2650677438&idx=2&sn=5d70def612e4d42fc1835cca39071d8d&chksm=bec21dcd89b594dbee3e48482d5cfe3e01f83539af664eca8bb57333700c6f14ecb7e22dbc05&mpshare=1&scene=1&srcid=#rd)
- [Brancher](https://github.com/AI-DI/Brancher)
