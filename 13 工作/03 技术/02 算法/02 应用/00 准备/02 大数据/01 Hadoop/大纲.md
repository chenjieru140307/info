

# 大纲

hadoop是个生态系统，上面有大数据分析很多组件，适合事后大数据分析任务。


写一个 Hadoop 版本的 wordcount。

Hadoop是怎么读入很大的数据的？ 接受HDFS？


Hadoop（HDFS+MapReduce+Yarn ）

书籍：





4）Hadoop （《Hadoop 权威指南》）—80小时

**1、HDFS**

1. HDFS的概念和特性。
2. HDFS的shell操作。
3. HDFS的工作机制。
4. HDFS的Java应用开发。

**2、MapReduce**

1. 运行WordCount示例程序。
2. 了解MapReduce内部的运行机制。
   1. MapReduce程序运行流程解析。
   2. MapTask并发数的决定机制。
   3. MapReduce中的combiner组件应用。
   4. MapReduce中的序列化框架及应用。
   5. MapReduce中的排序。
   6. MapReduce中的自定义分区实现。
   7. MapReduce的shuffle机制。
   8. MapReduce利用数据压缩进行优化。
   9. MapReduce程序与YARN之间的关系。
   10. MapReduce参数优化。

**3、MapReduce的Java应用开发**

官网：<http://hadoop.apache.org/>
中文文档：<http://hadoop.apache.org/docs/r1.0.4/cn/>
中文社区：<http://www.aboutyun.com/forum-143-1.html>




## 可以补充进来的


- 《Hadoop 权威指南》
- 《Hive编程指南》


- 《Hadoop + Spark 大数据巨量分析与机器学习整合开发实战》


- [基于 Hadoop 集群的大规模分布式深度学习](http://www.voidcn.com/article/p-aslkhsxb-qa.html)
