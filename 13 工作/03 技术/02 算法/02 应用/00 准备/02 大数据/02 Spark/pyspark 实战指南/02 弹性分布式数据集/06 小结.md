
2.6 小结
RDD是 Spark 的核心；这些无 schema 数据结构是在 Spark 中处理的最基本的数据结构。
这一章中，我们展示了从文本文件创建 RDD 的方式，通过.parallelize（……）方法以及从文本文件中读取数据。另外，一些非结构化数据的处理方法也在此展示。
Spark中的转化是惰性的，它们只在操作被调用时应用。这一章中，我们讨论并展示了最通用的转换和操作；更多的 PySpark 文档包含在 http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD。
Scala和 python RDD之间一个主要的区别是速度：python RDD比 Scala 慢很多。
下一章，我们将引导你完成使 PySpark 应用程序与 Scala 中编写的数据结构相符的数据结构——DataFrame。
