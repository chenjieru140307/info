
9.5 小结
本章介绍的概念只是使用 Blaze 的开始。还有许多其他的方法和可连接的数据源可以使用。你可以以此为起点，构建你对混合持久化的理解。
但是请注意，在这几天中提到的本章中大部分概念之所以都可以在 Spark 内部实现，是因为你可以直接在 Spark 中使用 SQLAlchemy 来轻松处理各种数据源。这样做的好处是，尽管学习 SQLAlchemy 的 API 会需要初始投资，但是将返回的数据存储在 Spark DataFrame中，你将可以访问 PySpark 提供的所有内容。但是这绝对不意味着永远不要使用 Blaze：像往常一样，选择权在你手中。
在下一章中，你将了解流媒体以及如何使用 Spark 来做到这一点。最近流媒体已成为越来越重要的话题，就像每天（2016年）一样，世界产生大约 2.5EB的数据（数据来源：http://www.northeastern.edu/levelblog/2016/05/13/how-much-data-produced-every-day/）需要被获取、处理和分析。
