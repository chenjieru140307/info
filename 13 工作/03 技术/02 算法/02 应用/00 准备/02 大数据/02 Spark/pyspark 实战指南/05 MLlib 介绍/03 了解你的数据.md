
5.3 了解你的数据
为了清晰地建造一个统计模型，需要深入了解数据集的知识。不了解数据便来建造一个成功的模型是有可能的，但是接下来的任务会更艰巨，其需要更多的技术资源来测试所有可能的特征组合。因此在花了 80％的时间清理数据后，我们接下来会用 15％的时间来了解数据。
5.3.1 描述性统计
我通常从描述性统计开始。虽然 DataFrame 公开了.describe（）方法，但由于我们正在使用 MLlib，所以我们将采取.colStats（……）方法。注意：.colStats（……）是根据一个样本来计算描述性统计的。对于真实世界的数据集，这并不重要，但如果您的数据集少于 100 个观察结果，您可能会得到一些奇怪的结果。
该方法使用 RDD 的数据来计算 MultivariateStatisticalSummary 对象的描述性统计信息，并返回 MultivariateStatisticalSummary 对象，该对象包含如下描述性统计信息：
·count（）：行数
·max（）：列中的最大值
·mean（）：列的所有值的平均值
·min（）：列中的最小值
·normL1（）：列中值的 L1-Norm值
·normL2（）：列中值的 L2-Norm值
·numNonzeros（）：列中非零值的数量
·variance（）：列中值的方差值了解更多关于 L1-norm和 L2-norm的信息请访问 http://bit.ly/2jJJPJ0。
建议您查看 Spark 文档以了解更多相关信息。以下是计算数字特征描述性统计信息的代码片段：
上述代码产生以下结果：


正如你所看到的，与父亲相比，母亲年龄更小：母亲的平均年龄是 28 岁，而父亲的平均年龄则超过 44 岁。一个好的现象（至少对于一些婴儿来说）是许多母亲怀孕后开始戒烟；而令人吃惊的是，有些母亲还是持续吸烟。
对于分类变量，我们将计算其值的频率：
结果如下：
大部分的生产是在医院里（BIRTH_PLACE等于 1）。大约 550 例的生产是在家里：有些是计划好的（BIRTH_PLACE等于 3），而有些不是（BIRTH_PLACE等于 4）。
5.3.2 相关性
相关性有助于识别共线数字特征并适当处理它们。接下来我们检查一下其特征之间的相关性。
前面的代码将计算相关性矩阵，并且只打印那些相关性系数大于 0.5的特征，即 corrs>0.5所限制的部分。
得到的结果如下：


如你所见，“CIG_……”特征是高度相关的，所以它们中的大部分我们用不到。由于我们要尽快预测婴儿的生存机会，所以我们只会保留“CIG_1_TRI”。另外，如预期的那样，重量特征也是高度相关的，我们只会保留“MOTHER_PRE_WEIGHT”：
5.3.3 统计测试
我们无法计算分类特征的相关性。然而，我们可以进行卡方检验来确定是否存在显著差异。
以下是如何使用 MLlib 的.chiSqTest（……）方法：
我们循环遍历所有的分类变量，并通过“INFANT_ALIVE_AT_REPORT”特征进行转换，以获得计数。接下来，我们将它们转换为 RDD，因此我们可以使用 pyspark.mllib.linalg模块将它们转换成矩阵。
.Matrices.dense（……）方法的第一个参数指定矩阵的行数，在我们的例子中，这是分类特征的不同值的长度。
第二个参数指定列数：因为我们的“INFANT_ALIVE_AT_REPORT”目标变量只有两个值，所以列数为二。
最后一个参数是要转换为矩阵的值的列表。
这是一个更清楚的例子：
上述代码生成以下矩阵：

一旦我们以矩阵形式存放我们的计数，我们可以使用.chiSqTest（……）来计算我们的测试。
得到结果如下：
我们的测试表明，所有的特征应该是显著不同的，应该有助于我们预测婴儿的生存机会。5.
