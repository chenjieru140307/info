

## 6.7 为什么 RNN 训练的时候 Loss 波动很大

由于 RNN 特有的 memory 会影响后期其他的 RNN 的特点，梯度时大时小，learning rate 没法个性化的调整，<span style="color:red;">为什么梯度会时大时小？为什么 learning rate 没法个性化调整？</span>导致 RNN 在 train 的过程中，Loss 会震荡起伏，为了解决 RNN 的这个问题，在训练的时候，可以设置临界值，当梯度大于某个临界值，直接截断，用这个临界值作为梯度的大小，防止大幅震荡。<span style="color:red;">怎么进行截断？要设置多少为好？一定会出现这个问题吗？</span>








# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
