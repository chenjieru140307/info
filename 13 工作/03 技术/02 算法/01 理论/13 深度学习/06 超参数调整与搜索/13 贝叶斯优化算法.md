


**贝叶斯优化算法**

<span style="color:red;">不是很理解。</span>

贝叶斯优化算法在寻找最优最值参数时，采用了与网格搜索、随机搜索完全不同的方法。

网格搜索和随机搜索在测试一个新点时，会忽略前一个点的信息；而贝叶斯优化算法则充分利用了之前的信息。

贝叶斯优化算法通过对目标函数形状进行学习，找到使目标函数向全局最优值提升的参数。<span style="color:red;">这句话是什么意思？通过对目标偶函数形状进行学习，找到使目标函数向全局最优值提升的参数。</span>

具体来说，它学习目标函数形状的方法是，

1. 首先根据先验分布，假设一个搜集函数；
2. 然后，每一次使用新的采样点来测试目标函数时，利用这个信息来更新目标函数的先验分布；
3. 最后，算法测试由后验分布给出的全局最值最可能出现的位置的点。

对于贝叶斯优化算法，有一个需要注意的地方，一旦找到了一个局部最优值，它会在该区域不断采样，所以很容易陷入局部最优值。

为了弥补这个缺陷，贝叶斯优化算法会在探索和利用之间找到一个平衡点，“探索”就是在还未取样的区域获取采样点；而“利用”则是根据后验分布在最可能出现全局最值的区域进行采样。<span style="color:red;">怎么进行平衡的？怎么进行探索和利用的？代码是怎么实现的？原理是什么？</span>
