

### 3.6.10 批归一化（BN）算法流程

下面给出 BN 算法在训练时的过程

输入：上一层输出结果 $X = {x_1, x_2, ..., x_m}$，学习参数 $\gamma, \beta$

算法流程：

1. 计算上一层输出数据的均值

$$
\mu_{\beta} = \frac{1}{m} \sum_{i=1}^m(x_i)
$$

其中，$m​$ 是此次训练样本 batch 的大小。<span style="color:red;">看到这个想问下，$x_i$ 到底指的是什么？是所有的 [batch,height,width,channel] 吗？</span>

2. 计算上一层输出数据的标准差

$$
\sigma_{\beta}^2 = \frac{1}{m} \sum_{i=1}^m (x_i - \mu_{\beta})^2
$$

3. 归一化处理，得到

$$
\hat x_i = \frac{x_i + \mu_{\beta}}{\sqrt{\sigma_{\beta}^2} + \epsilon}
$$

<span style="color:red;">这个地方不是应该 $x_i - \mu_{\beta}$ 吗？</span>

其中 $\epsilon$ 是为了避免分母为 $0$ 而加进去的接近于 $0$ 的很小值

4. 重构，对经过上面归一化处理得到的数据进行重构，得到

$$
y_i = \gamma \hat x_i + \beta
$$

其中，$\gamma, \beta$ 为可学习参数。<span style="color:red;">这个参数是怎么学习的？</span>

注：上述是 BN 训练时的过程，但是当在投入使用时，往往只是输入一个样本，没有所谓的均值 $\mu_{\beta}$ 和标准差 $\sigma_{\beta}^2$。此时，均值 $\mu_{\beta}$ 是计算所有 batch $\mu_{\beta}$ 值的平均值得到，标准差 $\sigma_{\beta}^2$ 采用每个 batch $\sigma_{\beta}^2$  的无偏估计得到。<span style="color:red;">没有明白，这个所有 batch 的平均值是会保存在权重文件里面吗？如果是，那么当加载预训练权重进行训练的时候，这个平均值会怎么更新？</span>
