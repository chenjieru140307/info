---
title: 1.12 VAE
toc: true
date: 2019-09-03
---

### 7.3.2 什么是 VAE？

<span style="color:red;">感觉很厉害呀，这个就是想要的那个感觉 </span>

PixelCNN/RNN 定义了一个易于处理的密度函数，我们可以直接优化训练数据的似然；<span style="color:red;">什么是密度函数？</span>

对于变分自编码器我们将定义一个不易处理的密度函数，通过附加的隐变量 $z$ 对密度函数进行建模。

VAE原理图如下[6]：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/WJ8Mf6839A7y.png?imageslim">
</p>

在 VAE 中，真实样本 $X$ 通过神经网络计算出均值方差（假设隐变量服从正太分布），然后通过采样得到采样变量 $Z$ 并进行重构。VAE和 GAN 均是学习了隐变量 $z$ 到真实数据分布的映射。但是和 GAN 不同的是：

- GAN 的思路比较粗暴，使用一个判别器去度量分布转换模块（即生成器）生成分布与真实数据分布的距离。
- VAE 则没有那么直观，VAE 通过约束隐变量 $z$ 服从标准正太分布以及重构数据实现了分布转换映射 $X=G(z)$

**生成式模型对比**

- 自回归模型通过对概率分布显式建模来生成数据
- VAE 和 GAN 均是：假设隐变量 $z$ 服从某种分布，并学习一个映射 $X=G(z)$，实现隐变量分布 $z$ 与真实数据分布 $p_{data}(x)$ 的转换。
- GAN 使用判别器去度量映射 $X=G(z)$ 的优劣，而 VAE 通过隐变量 $z$ 与标准正太分布的 KL 散度和重构误差去度量。









# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
