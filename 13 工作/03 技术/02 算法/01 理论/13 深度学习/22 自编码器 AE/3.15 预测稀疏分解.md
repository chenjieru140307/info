

# 预测稀疏分解


预测稀疏分解是稀疏编码和参数化自编码器的混合模型。


参数化编码器被训练为能预测迭代推断的输出。PSD 被应用于图片和视频中对象识别的无监督特征学习，在音频中也有所应用。这个模型由一个编码器 $f(\boldsymbol x)$ 和一个解码器 $g(\boldsymbol h)$ 组成，并且都是参数化的。在训练过程中，$\boldsymbol h$ 由优化算法控制。优化过程是最小化


$$\begin{aligned}
 \| \boldsymbol x - g(\boldsymbol h) \| ^2 + \lambda | \boldsymbol h |_1 + \gamma \| \boldsymbol h - f(\boldsymbol x) \|^2.
\end{aligned}$$


就像稀疏编码，训练算法交替地相对 $\boldsymbol h$ 和模型的参数最小化上述目标。相对 $\boldsymbol h$ 最小化较快，因为 $f(\boldsymbol x)$ 提供 $\boldsymbol h$ 的良好初始值以及损失函数将 $\boldsymbol h$ 约束在 $f(\boldsymbol x)$ 附近。简单的梯度下降算法只需 10 步左右就能获得理想的 $\boldsymbol h$。


PSD 所使用的训练程序不是先训练稀疏编码模型，然后训练 $f(\boldsymbol x)$ 来预测稀疏编码的特征。PSD 训练过程正则化解码器，使用 $f(\boldsymbol x)$ 可以推断出良好编码的参数。


预测稀疏分解是学习近似推断的一个例子。在\sec?中，这个话题将会进一步展开。\chap?中展示的工具能让我们了解到，PSD 能够被解释为通过最大化模型的对数似然下界训练有向稀疏编码的概率模型。



在 PSD 的实际应用中，迭代优化仅在训练过程中使用。模型被部署后，参数编码器 $f$ 用于计算已经习得的特征。相比通过梯度下降推断 $\boldsymbol h$，计算 $f$ 是很容易的。因为 $f$ 是一个可微带参函数，PSD 模型可堆叠，并用于初始化其他训练准则的深度网络。



# 相关

- 《深度学习》花书
