

## 偏差

估计的偏差被定义为：

$$
\operatorname{bias}\left(\hat{\boldsymbol{\theta}}_{m}\right)=\mathbb{E}\left(\hat{\boldsymbol{\theta}}_{m}\right)-\boldsymbol{\theta}
$$

其中期望作用在所有数据(看作从随机变量采样得到的)上，$\boldsymbol{\theta}$ 是用于定义数据生成分布的 $\boldsymbol{\theta}$ 的真实值。如果 $\operatorname{bias}\left(\hat{\boldsymbol{\theta}}_{m}\right)=0$，那么估计量 $\hat{\boldsymbol{\theta}}_{m}$ 被称为是无偏(unbiased)，这意味着 $\mathbb{E}\left(\hat{\boldsymbol{\theta}}_{m}\right)=\boldsymbol{\theta}$。如果 $\lim _{m \rightarrow \infty} \operatorname{bias}\left(\hat{\boldsymbol{\theta}}_{m}\right)=0$ ，那么估计量 $\hat{\theta}_{m}$ 被称为是渐近无偏(asymptotically unbiased)，这意味着 $\lim _{m \rightarrow \infty} \mathbb{E}\left(\hat{\boldsymbol{\theta}}_{m}\right)=\boldsymbol{\theta}$。<span style="color:red;">嗯，无偏估计和渐进无偏</span>


### 示例：伯努利分布

考虑一组服从均值为 $\theta$ 的伯努利分布的独立同分布的样本 $\left\{x^{(1)}, \ldots, x^{(m)}\right\}$：

$$
P\left(x^{(i)} ; \theta\right)=\theta^{x^{(i)}}(1-\theta)^{\left(1-x^{(i)}\right)}\tag{5.21}
$$


这个分布中参数 $\theta$ 的常用估计量是训练样本的均值：

$$
\hat{\theta}_{m}=\frac{1}{m} \sum_{i=1}^{m} x^{(i)}\tag{5.22}
$$

判断这个估计量是否有偏，我们将式(5.22)代入式(5.20)：



$$
\begin{aligned}
\operatorname{bias}\left(\hat{\theta}_{m}\right)&=\mathbb{E}\left[\hat{\theta}_{m}\right]-\theta\\&=\mathbb{E}\left[\frac{1}{m} \sum_{i=1}^{m} x^{(i)}\right]-\theta\\&=\frac{1}{m} \sum_{i=1}^{m} \mathbb{E}\left[x^{(i)}\right]-\theta\\&=\frac{1}{m} \sum_{i=1}^{m} \sum_{x^{(i)}=0}^{1}\left(x^{(i)} \theta^{x^{(i)}}(1-\theta)^{\left(1-x^{(i)}\right)}\right)-\theta\\&=\frac{1}{m} \sum_{i=1}^{m}(\theta)-\theta\\&=\theta-\theta=0
\end{aligned}
$$


因为 $\operatorname{bias}(\hat{\theta})=0$ ，我们称估计 $\hat{\theta}$ 是无偏的。

### 示例：均值的高斯分布估计

现在，考虑一组独立同分布的样本 $\left\{x^{(1)}, \ldots, x^{(m)}\right\}$ 服从高斯分布 $p\left(x^{(i)}\right)=\mathcal{N}\left(x^{(i)} ; \mu, \sigma^{2}\right)$ ，其中 $i \in\{1, \ldots, m\}$ 。回顾高斯概率密度函数如下：

$$
p\left(x^{(i)} ; \mu, \sigma^{2}\right)=\frac{1}{\sqrt{2 \pi \sigma^{2}}} \exp \left(-\frac{1}{2} \frac{\left(x^{(i)}-\mu\right)^{2}}{\sigma^{2}}\right)\tag{5.29}
$$



高斯均值参数的常用估计量被称为样本均值(sample mean)：

$$
\hat{\mu}_{m}=\frac{1}{m} \sum_{i=1}^{m} x^{(i)}\tag{5.30}
$$



判断样本均值是否有偏，我们再次计算它的期望：

$$
\begin{aligned}
\operatorname{bias}\left(\hat{\mu}_{m}\right)&=\mathbb{E}\left[\hat{\mu}_{m}\right]-\mu\\&=\mathbb{E}\left[\frac{1}{m} \sum_{i=1}^{m} x^{(i)}\right]-\mu\\&=\left(\frac{1}{m} \sum_{i=1}^{m} \mathbb{E}\left[x^{(i)}\right]\right)-\mu\\&=\left(\frac{1}{m} \sum_{i=1}^{m} \mu\right)-\mu\\&=\mu-\mu=0
\end{aligned}
$$


因此我们发现样本均值是高斯均值参数的无偏估计量。

### 示例：高斯分布方差估计

本例中，我们比较高斯分布方差参数 $\sigma^{2}$ 的两个不同估计。我们探讨是否有一个是有偏的。

我们考虑的第一个方差估计被称为样本方差(sample variance)：

$$
\hat{\sigma}_{m}^{2}=\frac{1}{m} \sum_{i=1}^{m}\left(x^{(i)}-\hat{\mu}_{m}\right)^{2}\tag{5.36}
$$

其中 $\hat{\mu}_{m}$ 是样本均值。更形式化地，我们对计算感兴趣:

$$
\operatorname{bias}\left(\hat{\sigma}_{m}^{2}\right)=\mathbb{E}\left[\hat{\sigma}_{m}^{2}\right]-\sigma^{2}\tag{5.37}
$$

我们首先估计项 $\mathbb{E}\left[\hat{\sigma}_{m}^{2}\right]$:

$$
\begin{aligned}
\mathbb{E}\left[\hat{\sigma}_{m}^{2}\right]&=\mathbb{E}\left[\frac{1}{m} \sum_{i=1}^{m}\left(x^{(i)}-\hat{\mu}_{m}\right)^{2}\right]\\&=\frac{m-1}{m} \sigma^{2}
\end{aligned}\tag{5.38}
$$



回到式(5.37)，我们可以得出 $\hat{\sigma}_{m}^{2}$ 的偏差是 $-\sigma^{2} / m$ 。因此样本方差是有偏估计。

无偏样本方差(unbiased sample variance)估计：

$$
\tilde{\sigma}_{m}^{2}=\frac{1}{m-1} \sum_{i=1}^{m}\left(x^{(i)}-\hat{\mu}_{m}\right)^{2}\tag{5.40}
$$

提供了另一种可选方法。正如名字所言，这个估计是无偏的。换言之，我们会发现 $\mathbb{E}\left[\tilde{\sigma}_{m}^{2}\right]=\sigma^{2}$ ：


$$
\begin{aligned}
\mathbb{E}\left[\tilde{\sigma}_{m}^{2}\right]&=\mathbb{E}\left[\frac{1}{m-1} \sum_{i=1}^{m}\left(x^{(i)}-\hat{\mu}_{m}\right)^{2}\right]\\&=\frac{m}{m-1} \mathbb{E}\left[\hat{\sigma}_{m}^{2}\right]\\&=\frac{m}{m-1}\left(\frac{m-1}{m} \sigma^{2}\right)\\&=\sigma^{2}
\end{aligned}
$$

我们有两个估计量：一个是有偏的，另一个是无偏的。尽管无偏估计显然是令人满意的，但它并不总是“最好”的估计。我们将看到，经常会使用其他具有重要性质的有偏估计。<span style="color:red;">为什么呢？为什么无偏估计不是最好的估计？</span>



# 相关

- 《深度学习》花书
