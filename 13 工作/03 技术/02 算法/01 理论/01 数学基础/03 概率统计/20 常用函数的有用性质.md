
# 可以补充进来的

- 后面的式子没怎么清楚理解，想知道这些式子在什么时候使用的。补充下。

# 常用函数的有用性质

某些函数在处理概率分布时经常会出现，尤其是深度学习的模型中用到的概率分布。

## logistic sigmoid 函数

其中一个函数是 logistic sigmoid 函数：

$$
\sigma(x)=\frac{1}{1+\exp (-x)}\tag{3.30}
$$


logistic sigmoid 函数通常用来产生 Bernoulli 分布中的参数 $\phi$，因为它的范围是 $(0,1)$，处在 $\phi$ 的有效取值范围内。

图 3.3给出了 sigmoid 函数的图示。sigmoid 函数在变量取绝对值非常大的正值或负值时会出现饱和(saturate)现象，意味着函数会变得很平，并且对输入的微小改变会变得不敏感：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190515/PJwRdNlPXW80.png?imageslim">
</p>


## softplus 函数

另外一个经常遇到的函数是 softplus 函数(softplus function)(Dugas et al.,2001)：

$$
\zeta(x)=\log (1+\exp (x))\tag{3.31}
$$

<span style="color:red;">之前好像没有看到过这个 softplus 函数，一般用在什么地方？</span>

softplus 函数可以用来产生正态分布的 $\beta$ 和 $\sigma$ 参数，因为它的范围是 $(0, \infty)$。<span style="color:red;">为什么要用这个来产生？</span>

当处理包含 sigmoid 函数的表达式时，它也经常出现。softplus 函数名来源于它是另外一个函数的平滑(或“软化”)形式，这个函数是：

$$
x^{+}=\max (0, x)\tag{3.32}
$$


图 3.4给出了 softplus 函数的图示。

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190516/M4OTFcmLusVa.png?imageslim">
</p>

## 关于 logistic sigmoid 和 softplus 函数

下面一些性质非常有用，你可能要记下来。


$$
\sigma(x)=\frac{\exp (x)}{\exp (x)+\exp (0)}\tag{3.33}
$$

$$
\frac{d}{d x} \sigma(x)=\sigma(x)(1-\sigma(x))\tag{3.34}
$$



$$
1-\sigma(x)=\sigma(-x)\tag{3.35}
$$

$$
\log \sigma(x)=-\zeta(-x)\tag{3.36}
$$

$$
\frac{d}{d x} \zeta(x)=\sigma(x)\tag{3.37}
$$

$$
\forall x \in(0,1), \sigma^{-1}(x)=\log \left(\frac{x}{1-x}\right)\tag{3.38}
$$


$$
\forall x>0, \zeta^{-1}(x)=\log (\exp (x)-1)\tag{3.39}
$$

$$
\zeta(x)=\int_{-\infty}^{x} \sigma(y) d y\tag{3.40}
$$


$$
\zeta(x)-\zeta(-x)=x\tag{3.41}
$$

<span style="color:red;">对于上面这些式子，为什么重要？一般在什么时候使用？要补充下。</span>



函数 $\sigma^{-1}(x)$ 在统计学中被称为分对数(logit)，但这个函数在机器学习中很少用到。



式(3.41)为函数名 “softplus” 提供了其他的正当理由。softplus 函数被设计成正部函数(positive partfunction)的平滑版本，这个正部函数是指 $x^{+}=\max \{0, x\}$ 。<span style="color:red;">没明白为什么这个叫正部函数？</span>与正部函数相对的是负部函数(negative part function)，即 $x^{-}=\max \{0,-x\}$。为了获得类似负部函数的一个平滑函数，我们可以使用 $\zeta(-x)$ 。就像 $x$ 可以用它的正部和负部通过等式 $x^{+}-x^{-}=x$ 恢复一样，<span style="color:red;">这也可以。。</span>我们也可以用同样的方式对 $\zeta(x)$ 和 $\zeta(-x)$ 进行操作，就像式 (3.41) 中那样。<span style="color:red;">嗯，挺有意思的，一般什么时候会用到呢？</span>


# 相关

- 《深度学习》花书
