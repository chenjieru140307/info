---
title: 概率统计-常见概率分布
toc: true
date: 2018-08-21 18:16:23
---

# 可以补充进来的

- 很多还是不清楚
- 将原来的图片都替换为文字


# 常见概率分布

因为总是涉及到二项分布，而且后面如果学各种似然估计的话，这个分布是必须的。


复习各种常见分布本身的统计量，统计量是属于数学统计的。

在复习各种分布的同时，重温积分、Taylor展式等前序知识

常见分布是可以完美统一为一类分布。**怎么统一？**


## 两点分布


一个硬币投掷 1 次


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/FD1A7jBjAa.png?imageslim">
</p>




## 二项分布：


**这两种求法都要掌握。**

一个硬币投掷 n 次


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/Hkli1mD7ab.png?imageslim">
</p>

也可以用二项展开式去做：


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/HJIE70HCE1.png?imageslim">
</p>



<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/Ag1iI4JA9H.png?imageslim">
</p>

**上面这两种方法都要清楚，没有仔细看**


## 泰勒展开式 与 泊松分布




<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/BH18Fb77ce.png?imageslim">
</p>

某一项长的就是这个样子。

最后的一个东西就是泊松分布。可见泰勒展开式可以推出泊松分布。也可见，如果我们知道泊松分布，那么可以反推出\(e^x\)的 taylor 展开式是对的。


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/beL5EL4AHm.png?imageslim">
</p>

离散的情况叫做分布率。


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/Kj5eiIE4K0.png?imageslim">
</p>

可见，泊松分布的期望和方差都是λ。

那么怎么去理解泊松分布呢？


在实际事例中，当一个随机事件，以固定的平均瞬时速率λ(或称密度)随机且独立地出现时，那么这个事件在单位时间(面积或体积)内出现的次数或个数就近似地服从泊松分布 P(λ)。




* 某一服务设施在一定时间内到达的人数
* 电话交换机接到呼叫的次数
* 汽车站台的候客人数
* 机器出现的故障数
* 自然灾害发生的次数
* 一块产品上的缺陷数
* 显微镜下单位分区内的细菌分布数
* 某放射性物质单位时间发射出的粒子数


刚才的二项分布里面，如果 n 比较大，p比较小的时候，n*p是等于\(\lambda\)的，可以近似成泊松分布。

泊松分布是离散分布的一个非常重要的东西。

**理解的不够，不知道应用的时候是什么样子的？**



上面全是离散情况，下面将连续情况。


## 均匀分布

设 $\boldsymbol{X} \sim \boldsymbol{U}(a, \boldsymbol{b})$，其概率密度为：

$$
f(x)=\left\{\begin{array}{c}{\frac{1}{b-a},a<x<b} \\ {0，其他}\end{array}\right.
$$

则有：

$$
E(X)=\int_{-\infty}^{\infty} x f(x) \mathrm{d} x=\int_{a}^{b} \frac{1}{b-a} x \mathrm{d} x=\frac{1}{2}(a+b)
$$

则：

$$
\begin{aligned}
D(X)&=E\left(X^{2}\right)-[E(X)]^{2}\\&=\int_{a}^{b} x^{2} \frac{1}{b-a} d x-\left(\frac{a+b}{2}\right)^{2}\\&=\frac{(b-a)^{2}}{12}
\end{aligned}
$$



## 指数分布

设随机变量 X 俯冲指数分布，其概率密度为：

$$
f(x)=\left\{\begin{array}{ll}{\frac{1}{\theta} \mathrm{e}^{-x / \theta},} & {x>0} \\ {0,} & {x \leq 0}\end{array}\right.
$$

其中 $\theta>0$，则有：

$$
\begin{aligned}
E(X)&=\int_{-\infty}^{+\infty} x f(x) \mathrm{d} x\\&=\int_{0}^{+\infty} x \cdot \frac{1}{\theta} \mathrm{e}^{-x / \theta} \mathrm{d} x\\&=-x\left.\mathrm{e}^{-x / \theta}\right|_{0} ^{+\infty}+\int_{0}^{+\infty} \mathrm{e}^{-x / \theta} \mathrm{d} x\\&=\theta
\end{aligned}
$$

$$
\begin{aligned}
D(X)&=E\left(X^{2}\right)-[E(X)]^{2}\\&=\int_{0}^{+\infty} x^{2} \cdot \frac{1}{\theta} \mathrm{e}^{-x / \theta} \mathrm{d} x-\theta^{2}\\&=2 \theta^{2}-\theta^{2}\\&=\theta^{2}
\end{aligned}
$$


指数分布怎么去理解？事件间隔就是指数分布，这样的话，就与泊松分布的例子感觉比较像，<span style="color:red;">泊松分布与指数分布到底有什么关系？</span>


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/baaaaaimmF.png?imageslim">
</p>

等车是服从指数分布的，平均下来是等 20 分钟车就来了，但是今天我等 10 分钟，车没来，那么我在等 20 分钟等到车的概率跟之前是一样的。所以是无记忆性的。


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/A8ihJlFhdD.png?imageslim">
</p>




## 正态分布


<span style="color:red;">很奇怪的一个分布。这个在线性回归里面会讲。正态分布最后会推出线性回归，二项分布会推出 logistic 回归。</span>

正态分布是一个连续变化的，是一个回归问题。而二项分布是 0-1变化的，因此解决的是分类问题。因此线性回归解决的是连续变化的，logistic回归解决的是分类问题。

<span style="color:red;">这一段还是没有很理解。</span>


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/fK9Ij4IDBh.png?imageslim">
</p>



<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/58HjcGf7EK.png?imageslim">
</p>



<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/AgdF1h8kmI.png?imageslim">
</p>




## 二元正态分布


左边的是标准的，如果方差变小，就变成中间上的，方差变大，就变成 3-1的

均值做一个旋转，得到下面两个


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/L2mle6097l.png?imageslim">
</p>




# 一个问题： 集合 Hash 问题：


某 Hash 函数将任一字符串非均匀映射到正整数 k，概率为\(2^{-k}\)，如下所示，现在有字符串集合 S，其元素经映射后，得到的最大整数为 10，试估计 S 的元素个数。

\[P\{Hash(<string>)=k\}=2^{-k},\, k\in Z^+\]

由于 Hash 映射成整数是指数级衰减的，“最大整数为 10”这一条件可近似考虑成“整数 10 曾经出现”，继续近似成“整数 10 出现过一次”。**应该说：整数 10 曾经出现过 1 次，整数 10 以上的从来没有出现过吧？嗯，应该是整数 10 曾经出现过 1 次，整数 10 以上有出现的可能性，但是没有出现。还不是很确定**

字符串被映射成 10 的概率为\(p=2^{-10}=\frac{1}{1024}\)，从而，一次映射即两点分布：**这里没明白？为什么 0 的概率是 1023？比 10 大的数不是没法被映射到吗？感觉应该是 1022 吧？而且没明白为什么一次映射是两点分布？嗯如果是说整数 10 以上有出现的可能性，但是没有出现，那么感觉亮点分布是合理的，1023也是合理的。**

\[\left\{\begin{matrix}P(X=1)=\frac{1}{1024}\\P(X=0)=\frac{1023}{1024}\end{matrix}\right.\]


从而 n 个字符串的映射，即二项分布：


\[P\{X=k\}=C_n^kp^k(1-p)^{n-k},\; 其中 p=\frac{1}{1024}

二项分布的期望为：

\[E(P\{X=k\})=np,\; 其中 p=\frac{1}{1024}\]

而期望表示 n 次事件发生的次数，当前问题中发生了 1 次，从而：

\[np=1\Rightarrow n=\frac{1}{p}\Rightarrow n=1024\]




# 关于分布的总结：




<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/CLekHHcla0.png?imageslim">
</p>




# 指数族分布


刚才的内容都可以归成一个指数族分布。


### \(\eta\)是自然常数，不用管。但是\(T(y)\)叫做充分统计量




<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/2jJ268CFA4.png?imageslim">
</p>




## 如 Bernoulli 分布和高斯分布




<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/Lhb4Gf42Gc.png?imageslim">
</p>




## Bernoulli 分布属于指数族


\(\Phi\)比如是投一次硬币，朝上的概率，y是投掷的次数，


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/mFL5f0B0HE.png?imageslim">
</p>




### 考察参数Φ


注意在推导过程中，出现了 Logistic 方程。下面这个 f(x)就是 Logistic 方程，或者叫 Sigmoid 方程，也叫做 S 曲线。

\[\Phi =\frac{1}{1+e^{-\eta} }\]

\[f(x)=\frac{1}{1+e^{-x} }\]


这个 f(x)就是我们通过二项分布和充分统计量这个概念得到的。曲线是如下的样子：




<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/Hj4hm4G8jk.png?imageslim">
</p>

对它求导数，是下面这个样子：

\[\begin{align*}f'(x)&=(\frac{1}{1+e^{-x} })'\\&=\frac{e^{-x} }{(1+e^{-x})^2}\\&=\frac{1}{1+e^{-x} }\cdot \frac{e^{-x} }{1+e^{-x} }\\&=\frac{1}{1+e^{-x} }\cdot (1-\frac{1}{1+e^{-x} })\\&=f(x)\cdot (1-f(x))\end{align*}\]

这个结论在后面做 Logistic 回归的时候会用到，因为 logistic 要求梯度下降的时候要求导数。


## Gaussian分布也属于指数族分布




<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/CcE07JCG73.png?imageslim">
</p>




# Gamma分布


\[p(x;\alpha,\beta)=\frac{\beta^\alpha x^{\alpha-1}e^{-\beta x} }{\Gamma (\alpha)},\; x\geq 0(常系数\alpha,\beta >0)\]

其中的 Gamma 函数\(\Gamma (\alpha)\)就是一个常数，就是一个规划因子：

\[\Gamma (\alpha)=\int_{0}^{\infty}t^{\alpha-1}e^{-t}dt\]

而且\(\Gamma(n)=(n-1)!\)

这个 Gamma 分布怎么理解呢？就把泊松分布的\(\lambda\)替换为成 \(\beta^\alpha x^{\alpha-1}\)。**未证实。要再看下。**

Gamma分布的期望为：

\[E(x)=\frac{\alpha}{\beta}\]

这个期望在后面谈主题模型的时候会遇到。当然，那里面不是 Gamma 分布了，不只涉及\(\alpha\)、\(\beta\)两个参数，而是涉及 k 个参数。那么这个时候就从 Gamma 分布变成 Dirichlet 分布。也就是 LDA 的 D 对应的。**什么是主题模型？什么是 Dirichlet 分布？什么是 LDA？**




# 由基本分类器得到高级分类器：


**为什么这个放在这里？因为后面会谈到 MCMC 的一些东西，带拒绝的采样？这个后续要补充下，不然这个放在这里感觉不是很恰当。**

给定一个分类器 p，它有 0.5的概率输出 1，0.5的概率输出 0。

如何生成一个分类器使该分类器输出 1 的概率为 0.25，输出 0 的概率为 0.75？做两回即可。**即怎么由一个基本的分类器得到一个高级的分类器呢？**

如何生成一个分类器使该分类器输出 1 的概率为 0.3，输出 0 的概率为 0.7？这个到后面会谈到 MCMC 的东西，马尔科夫链的..。的模拟。




# 一定接受率的采样


已知有个 rand7() 的函数，返回 1 到 7 随机自然数，让利用这个 rand7() 构造 rand10() 等概率返回 1~10 。

解：因为 rand7 仅能返回 1~7的数字，少于 rand10 的数目。因此，多调用一次，从而得到 49 种组合。

伪代码如下：

```cpp
int rand10()
{
    int a1,a2,r;
    do{
        a1=rand7()-1;
        a2=rand7()-1;
        r=a1*7+a2;
    }while (r>=40)
    return r/4+1
}
```

如果是 rand7()+rand7()+...+rand7()这样 7 个加起来的话来代替 a1*7，这样是不对的，因为任何的分布这样加起来在求平均，最后会退化为高斯分布。**为什么会退化为高斯分布？什么是高斯分布？上面讲的分布里面好像没有高斯分布？**





# 相关

- 七月在线 机器学习
- 《机器学习》周志华
