
# 可以补充进来的

- 回归问题中的 KNN 算法是什么样子的？



# K 近邻介绍

k-近邻 kNN k-NearestNeighbor

有以下几种特质：

- 非参数学习算法
- 非概率算法
- 监督学习算法
- 可用于分类和回归


K 近邻算法的：

* 输入为实例的特征向量，对应于特征空间的点；
* 输出为实例的类别，可以取多类。


它的分类过程是这样的：假设我们已经给定一个训练数据集，其中的实例类别已定。OK，那么，对于一个新的实例，我们可以知道离它最近的 k 个样本的类别，然后，我们就可以通过多数表决等方式进行预测。**等方式？除了多数表决还有什么方式？**

因此，k近邻算法不具有显式的学习过程，它实际上是直接使用的训练集的数据来对特征空间进行划分，并作为它分类的“模型”。**这个还是比较特别的。这句好像不是很通顺。**




K 近邻 (K-Nearest Neighbor  KNN)

k 近邻是一种常用的监督学习方法，它的工作机制非常简单：

- 给定测试样本，基于某种距离度量找出训练集中与其最靠近的  $k$ 个训练样本，然后基于这 $k$ 个“邻居”的信息来进行预测。

通常：

- 在分类任务中可使用“投票法”，即选择这 $k$ 个样本中出现最多的类别标记作为预测结果；
- 在回归任务中可使用“平均法”，即将这 $k$ 个样本的实值输出标记的平均值作为预测结果；

还可基于距离远近进行加权平均或加权投票，距离越近的样本权重越大。

$k$ 近邻学习相比别的学习方法有一个明显的不同之处：它似乎没有显式的训练过程！<span style="color:red;">是的。</span>

事实上，它是“懒惰学习”(lazy learning)的著名代表<span style="color:red;">原来这个就是懒惰学习</span>， 此类学习技术在训练阶段仅仅是把样本保存起来，训练时间开销为零，待收到 测试样本后再进行处理；相应的，那些在训练阶段就对样本进行学习处理的方法，称为“急切学习” (eager learning)。<span style="color:red;">嗯。</span>




# 相关

- 《机器学习》周志华
