

## 岭回归求解

岭回归不抛弃任何一个特征，缩小了回归系数。

岭回归求解与一般线性回归一致。

（1）如果采用梯度下降法：
$$
\frac{\partial J(w)}{\partial w_{j}}=\frac{1}{m} \sum_{i=1}^{m}\left(w^{T} x_{i}-y_{i}\right) x_{i j}+2 \lambda w_{j}
$$

迭代公式如下：

$$
\begin{array}{l}{w_{j+1}=w_{j}-\frac{\alpha}{m} \sum_{i=1}^{m}\left(w^{T} x_{i}-y_{i}\right) x_{i j}-2 \lambda w_{j}} \\ {=(1-2 \lambda) w_{j}-\frac{\alpha}{m} \sum_{i=1}^{m}\left(w^{T} x_{i}-y_{i}\right) x_{i j}}\end{array}
$$

（2）如果采用正规方程：

最优解为：
$$
w^{*}=\left(X^{T} X+\lambda I\right)^{-1} X^{T} y
$$

最后，将学得的线性回归模型为：
$$
\widehat{y}=w^{T} X=X^{T} w=\left(X^{T} X+\lambda I\right)^{-1} X^{T} y
$$








# 相关

- [【机器学习】一文读懂正则化与 LASSO 回归，Ridge回归](https://blog.csdn.net/pxhdky/article/details/82960659)
