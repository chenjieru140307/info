

# 偏差与方差


我们经常用过拟合、欠拟合来定性地描述模型是否很好地解决了特定的问题。从定量的角度来说，可以用模型的偏差（Bias）与方差（Variance）来描述模型的性能。


集成学习往往能够“神奇”地提升弱分类器的性能。

本节将从偏差和方差的角度去解释这背后的机理。<span style="color:red;">嗯，想知道。</span>


什么是模型的偏差和方差，Boosting 和 Bagging 方法与偏差和方差的关系是什么，通过回答这些问题，我们将介绍如何根据偏差和方差这两个指标来指导模型的优化和改进。

偏差，方差，重采样，Boosting，Bagging


## 什么是偏差和方差？

在有监督学习中，模型的泛化误差来源于两个方面-偏差和方差，具体来讲偏差和方差的定义如下：


### 偏差

偏差指的是由所有采样得到的大小为 $m$ 的训练数据集训练出的所有模型的输出的平均值和真实模型输出之间的偏差。

偏差通常是由于我们对学习算法做了错误的假设所导致的，比如真实模型是某个二次函数，但我们假设模型是一次函数。

由偏差带来的误差通常在训练误差上就能体现出来。<span style="color:red;">是的，应该是训练的时候准确率就无法上去。</span>

### 方差

方差指的是由所有采样得到的大小为 $m$ 的训练数据集训练出的所有模型的输出的方差。

方差通常是由于模型的复杂度相对于训练样本数 $m$ 过高导致的，比如一共有 $100$ 个训练样本，而我们假设模型是阶数不大于 $200$ 的多项式函数。

由方差带来的误差通常体现在测试误差相对于训练误差的增量上。<span style="color:red;">是的。</span>


上面的定义很准确，但不够直观，为了更清晰的理解偏差和方差，我们用一个射击的例子来进一步描述这二者的区别和联系：

假设一次射击就是一个机器学习模型对一个样本进行预测。射中靶心位置代表预测准确，偏离靶心越远代表预测误差越大。我们通过 $n$ 次采样得到 $n$ 个大小为 $m$ 的训练样本集合，训练出 $n$ 个模型，对同一个样本做预测，相当于我们做了 $n$ 次射击，射击结果如图 12.4所示：


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190420/8HoVvi8vXCeT.png?imageslim">
</p>

- 我们最期望的结果就是左上角的结果，射击结果又准确又集中，说明模型的偏差和方差都很小；
- 右上图虽然射击结果的中心在靶心周围，但分布比较分散，说明模型的偏差较小但方差较大；
- 同理，左下图说明模型方差较小，偏差较大；
- 右下图说明模型方差较大，偏差也较大。

<span style="color:red;">是的，还是比较好理解这个概念的。</span>
