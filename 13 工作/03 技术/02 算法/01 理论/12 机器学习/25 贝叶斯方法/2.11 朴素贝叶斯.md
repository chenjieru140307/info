---
title: 2.11 朴素贝叶斯
toc: true
date: 2018-07-28 20:44:00
---


# 相关


* 七月在线 机器学习


# 朴素贝叶斯


朴素贝叶斯 Naive Bayes 曾经的十大算法之一。 **哪十大算法？现在还有十大算法吗？**

朴素贝叶斯时间复杂度比较低。


## 朴素贝叶斯的假设

- 假设一个特征出现的概率，与其他特征(条件)独立(特征独立性)。其实是：对于给定分类的条件下，特征独立
- 而且每个特征同等重要(特征均衡性)


朴素贝叶斯分类器通常有两种实现方式:

- 一种基于伯努利模型实现
- 一种基于多项式模型实现

<span style="color:red;">这句是什么意思？</span>


## 举个例子：以为本分类为例


用朴素贝叶斯方法完成垃圾邮件和非垃圾邮件的分类：

- 样本：10000封邮件，每个邮件被标记为垃圾邮件或者非垃圾邮件
- 分类目标：给定第 10001 封邮件，确定它是垃圾邮件还是非垃圾邮件


分析：


![](http://images.iterate.site/blog/image/180728/iCbhIC8g1i.png?imageslim){ width=55% }

分解：
![](http://images.iterate.site/blog/image/180728/0IAI6GH0Fc.png?imageslim){ width=55% }

注意：


![](http://images.iterate.site/blog/image/180728/67DmFCDaI0.png?imageslim){ width=55% }中的第二个等号用的就是特征是条件独立的。




![](http://images.iterate.site/blog/image/180728/EHbGccB8Jk.png?imageslim){ width=55% }第二个等号成立的条件也是特征是独立的。




![](http://images.iterate.site/blog/image/180728/EgaGD86C5d.png?imageslim){ width=55% }就算出了这个邮件是垃圾的还是非垃圾的。


之所以叫做朴素贝叶斯，因为它的假设：提特征独立，特征条件独立。

因为实际中可能不是这么独立的。

但是这并不影响这种算法在实践中的重大应用

其实还是 OK 的，但是如果遇到生词呢？

## 遇到生词怎么办？

拉普拉斯平滑


![](http://images.iterate.site/blog/image/180728/Bc2ekkdcJI.png?imageslim){ width=55% }

是的呀，![](http://images.iterate.site/blog/image/180728/b30951C8H0.png?imageslim){ width=55% }如果 n_1=0，说明这个是新词，那么


![](http://images.iterate.site/blog/image/180728/EeAFCl5G8L.png?imageslim)也就等于 0 了，而且 img_5ae1b51d41bac也等于 0，所以这个时候![](http://images.iterate.site/blog/image/180728/lGdmB1h5GC.png?imageslim){ width=55% }就是 0/0.




这个怎么解决呢？最简单的思路就是每个字出现的次数加上 1，![](http://images.iterate.site/blog/image/180728/7k6cE7E1ei.png?imageslim){ width=55% }

这样的变化还是很厉害的的，这样的思路叫做拉普拉斯平滑。

这个地方给 1 还是几，这个就是所谓的先验分布了。

实际上可以想象成：加个文档，所有的词都出现一次。

后面遇到主题模型的 LDA 的时候仍然会谈到拉普拉斯平滑。到时候会如何计算平滑。


## 对朴素贝叶斯的思考

![](http://images.iterate.site/blog/image/180728/AahDDj0898.png?imageslim){ width=55% }

小数乘积下溢出怎么办？直接取对数来解决。

**交叉验证还是不知道？**




## 朴素贝叶斯

输入属性是 A, B, C，输出属性是 Y。若使用朴素贝叶斯分类(Naive Bayes Classifier)，下面哪张图能表示朴素贝叶斯分类的假设。

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190915/mS0VHTMFKHC5.jpg?imageslim">
</p>


**C** 朴素贝叶斯分类器是机器学习一个特别质朴而深刻的模型：当要根据多个特征而非一个特征对数据进行分类时，假设这些特征相互独立，然后利用条件概率乘法法则得到每一个分类的概率，选择概率最大的那个作为输出。

回顾一下贝叶斯公式 P(Y|A,B,C) = P(A,B,C|Y) * P(Y) / P(A,B,C)，如果需要求在 A,B,C条件下 Y 的概率，则需要知道先验概率 P(A,B,C)和 P(Y)，和在 Y 条件下，A,B,C的概率。
