

## 10.8 多智能体深度强化学习算法

在一些复杂场景中，涉及到多智能体的感知决策问题，这时需要将单一模型扩展为多个智能体之间相互合作、通信及竞争的多智能体深度强化学习系统。

- Foerster等提出了一种称为分布式深度递归 Q 网络(deep distributed recurrent Q-networks，DDRQN) 的模型，解决了状态部分可观测状态下的多智能体通信与合作的挑战性难题[54]。实验表明，经过训练的 DDRQN 模型最终在多智能体之间达成了一致的通信协 1536 控制理论与应用第 34 卷议，成功解决了经典的红蓝帽子问题。让智能体学会合作与竞争一直以来都是人工智能领域内的一项重要研究课题，也是实现通用人工智能的必要条件。
- Lowe等提出了一种用于合作–竞争混合环境的多智能体 actor-critic 算法(multi-agent deepdeterministic policy gradient，MADDPG)[55]。MADDPG对 DDPG 强化学习算法进行了延伸，可实现多智能体的集中式学习和分布式执行，让智能体学习彼此合作和竞争。在多项测试任务中，MADDPG 的表现都优于 DDPG。





# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
