# CTR 预估模型

1. `CTR` 预估模型主要用于搜索、推荐、计算广告等领域的 `CTR` 预估，其发展经历了传统 `CTR` 预估模型、神经网络`CTR` 预估模型。

   传统 `CTR` 预估模型包括：逻辑回归`LR` 模型、因子分解机`FM` 模型、梯度提升树 `GBDT` 模型等。其优点是：可解释性强、训练和部署方便、便于在线学习。

   本章主要介绍传统 `CTR` 预估模型。

## 一、LR 模型

1. 在 `cost-per-click:CPC` 广告中广告主按点击付费。为了最大化平台收入和用户体验，广告平台必须预测广告的 `CTR` ，称作 `predict CTR: pCTR` 。对每个用户的每次搜索`query`，有多个满足条件的广告同时参与竞争。只有 `pCTR x bid price`最大的广告才能竞争获胜，从而最大化 `eCPM` ：

  $\text{eCPM} = \text{pCTR} \times \text{bid}$

   基于最大似然准则可以通过广告的历史表现得统计来计算 `pCTR` 。假设广告曝光了 100次，其中发生点击 5 次，则 `pCTR = 5%`。其背后的假设是：忽略表现出周期性行为或者不一致行为的广告，随着广告的不断曝光每个广告都会收敛到一个潜在的真实点击率$\text{CTR}_{\text{true}}$。

   这种计算 `pCTR` 的方式对于新广告或者刚刚投放的广告问题较大：

   - 新广告没有历史投放信息，其曝光和点击的次数均为 0 。

   - 刚刚投放的广告，曝光次数和点击次数都很低，因此这种方式计算的 `pCTR` 波动非常大。

     如：一个真实 `CTR` 为 `5%` 的广告必须曝光 1000次才有 `85%` 的信心认为 `pCTR` 与真实 `CTR` 的绝对误差在`1%` 以内。真实点击率越低，则要求的曝光次数越多。

   为解决这个问题，论文 `《Predicting Clicks: Estimating the Click-Through Rate for New Ads》` 提出利用 `LR` 模型来预测新广告的`CTR`。

2. 从经验上来看：广告在页面上的位置越靠后，用户浏览它的概率越低。因此广告被点击的概率取决于两个因素：广告被浏览的概率、广告浏览后被点击的概率。

   因此有：

  $p(\text{click} \mid \text{ad},\text{pos}) = p(\text{click} \mid \text{ad},\text{pos},\text{seen}) \times p(\text{seen} \mid \text{ad}, \text{pos})$

   假设：

   - 在广告被浏览（即：曝光）到的情况下，广告被点击的概率与其位置无关，仅与广告内容有关。

   - 广告被浏览的概率与广告内容无关，仅与广告位置有关。

     > 广告可能被拉取（推送到用户的页面），但是可能未被曝光（未被用户浏览到）。

   则有：

  $p(\text{click} \mid \text{ad},\text{pos}) = p(\text{click} \mid \text{ad}, \text{seen}) \times p(\text{seen} \mid \text{pos})$

   - 第一项$p(\text{click} \mid \text{ad}, \text{seen})$就是我们关注和预测的 `CTR` 。

   - 第二项与广告无关，是广告位置（即：广告位）的固有属性。

     可以通过经验来估计这一项：统计该广告位的总拉取次数$\text{impress}(\text{pos} )$，以及总曝光次数$\text{seen}(\text{pos})$，则：

    $p(\text{seen} \mid \text{pos}) = \frac{\text{seen}(\text{pos} )}{\text{impress}(\text{pos} )}$

     这也称作广告位的曝光拉取比。

### 1.1 数据集构造

1. 通常广告主会为一个订单 `order` 给出多个竞价词 `term`，如：

   ```
   xxxxxxxxxx
   ```

   4

   1

   ```
   Title: Buy shoes now,
   ```

   2

   ```
   Text: Shop at our discount shoe warehouse!
   ```

   3

   ```
   Url: shoes.com
   ```

   4

   ```
   Terms: {buy shoes, shoes, cheap shoes}.
   ```

   此时广告系统会为每个竞价 `Term` 生成一个广告，每个广告对应相同的`Title/Text/Url`、但是不同的竞价 `Term`。

2. 数据集包含 1万个广告主，超过 1百万个广告、超过 50万竞价词（去重之后超过 10万个竞价词）。

   - 样本的特征从广告基本属性中抽取（抽取方式参考后续小节）。广告的基本属性包括：

     - `landing page` 落地页：点击广告之后将要跳转的页面的 `url`
     - `bid term`：广告的竞价词
     - `title`：广告标题
     - `body`：广告的内容正文
     - `display url`：位于广告底部的、给用户展示的 `url`

   - 将每个广告的真实点击率 `CTR` 来作为 `label` 。

     考虑到真实点击率 `CTR` 无法计算，因此根据每个广告的累计曝光次数、累计点击次数从而得到其经验点击率$\overline{\text{CTR}}$来作为 `CTR` 。

3. 为了防止信息泄露，训练集、验证集、测试集按照广告主维度来拆分。最终训练集包含 `70%` 广告主、验证集包含 `10%` 广告主、测试集包含 `20%` 广告主。每个广告主随机选择它的 1000 个广告，从而确保足够的多样性。

   > 因为同一个广告主的广告之间的内容、素材、风格相似度比较高，点击率也比较接近。

4. 对于有专业投放管理的那些优质广告主，在数据集中剔除它们。因为：

   - 优质广告主的广告通常表现出不同于普通广告主的行为：
     - 两种广告主的广告具有不同的平均点击率
     - 优质广告主的广告的点击率方差较低（表现比较稳定）、普通广告主的广告的点击率方差较高（表现波动大）
   - 广告平台更关注于普通广告主，因为这些普通广告主的数量远远超过优质广告主的数量，而且这些普通广告主更需要平台的帮助。

5. 对于曝光量少于100的广告，在数据集中剔除它们。因为我们使用经验点击率$\overline{\text{CTR}}$来近似真实 `CTR` 来作为 `label` ，对于曝光次数较少的广告二者可能相差很远，这将导致整个训练和测试过程中产生大量噪音。

   曝光阈值的选取不能太大，也不能太小：

   - 阈值太小，则导致 `label` 中的噪音太多。
   - 阈值太大，则离线训练样本（大曝光的广告）和在线应用环境（大量新广告和小曝光广告）存在`gap`，导致在线预测效果较差。

### 1.2 LR模型

1. 论文将 `CTR` 预估问题视作一个回归问题，采用逻辑回归 `LR` 模型来建模，因为 `LR` 模型的输出是在 `0` 到 `1` 之间。

  $\text{pCTR} = \frac{1}{1+\exp(-\sum_{i} w_i\times f_i)}$

   其中$f_i$表示从广告中抽取的第$i$个特征（如广告标题的单词数量），$w_i$为该特征对应的权重。采用负号的原因是使得权重、特征和 `pCTR` 正相关：权重越大则 `pCTR` 越大。

   - 模型通过 `limited-memory Broyden-Fletcher-Goldfarb-Shanno:L-BFGS` 算法来训练。

   - 模型的损失函数为交叉熵：

    $\mathcal L = -[\text{pCTR}\times \log (\overline{\text{CTR}}) + (1-\text{pCTR})\times\log (1-\overline{\text{CTR}})]$

   - 权重通过均值为零、方差为$\sigma$的高斯分布来随机初始化。其中$\sigma$为超参数，其取值集合为`[0.01,0.03,0.1,0.3,1,3,10,30,100]`，并通过验证集来选取最佳的值。

     通过实验发现，$\sigma = 0.1$的效果最好。

2. 论文采取了一些通用的特征预处理方法：

   - 模型添加了一个`bias feature`，该特征的取值恒定为 1。即：将偏置项$b$视为$b\times 1$。

    $\sum_{i} w_i\times f_i + b \rightarrow \sum_{i} w_i\times f_i + b\times 1 = \sum_{i^\prime} w_{i^\prime}\times f_{i^\prime}$

   - 对于每个特征$f_i$，人工构造额外的两个非线性特征：：$\log(f_i+1)$，$f_i^2$。加 `1` 是防止$f_i$取值为 0 。

   - 对所有特征执行标准化，标准化为均值为0、方差为1 。

     注意：对于验证集、测试集的标准化过程中，每个特征的均值、方差使用训练集上的结果。

   - 对所有特征执行异常值截断：对于每个特征，任何超过均值 5 个标准差的量都被截断为 5 个标准差。

     如：特征$f_1$的均值为 `20`，方差为 `2` 。则该特征上任何大于`30` 的值被截断为 `30`、任何小于 `10` 的值被截断为 `10` 。

     注意：对于验证集、测试集的异常值截断过程中，每个特征的均值、方差使用训练集上的结果。

3. 评价标准：

   - `baseline` ：采用训练集所有广告的平均 `CTR` 作为测试集所有广告的 `pCTR` 。

     即：测试集里无论哪个广告，都预测其 `CTR` 为一个固定值，该值就是训练集所有广告的平均 `CTR` 。

   - 评估指标：测试集上每个广告的 `pCTR` 和真实点击率的平均 `KL` 散度。

    $\overline{\mathbb D_{KL}} = \frac 1T \sum_{i=1}^T \left(\text{pCTR}(\text{ad}_i) \times \log \frac{\text{pCTR}(\text{ad}_i)}{\overline{\text{CTR}}(\text{ad}_i)} + (1-\text{pCTR}(\text{ad}_i)) \times \log \frac{1-\text{pCTR}(\text{ad}_i)}{1-\overline{\text{CTR}}(\text{ad}_i)}\right)$

     `KL` 散度衡量了$\text{pCTR}$和真实点击率之间的偏离程度。一个理想的模型，其 `KL` 散度为 0 ，表示预估点击率和真实点击率完全匹配。

     为了更好的进行指标比较，论文实验中也给出了测试集的 `MSE` （均方误差）指标。

4. 模型不仅可以用于预测新广告的 `pCTR` ，还可以为客户提供优化广告的建议。

   可以根据模型特征及其重要性来给广告主提供创建广告的建议，如：广告标题太短建议增加长度。

### 1.3 特征工程

#### 1.3.1 Term CTR Feature Set

1. 不同竞价词的平均点击率存在明显的差异，因此在预测某个广告的点击率时，相同竞价词的其它类似广告可能有所帮助。

   因此论文对此提出两个特征，称作相同竞价词特征集 `Term CTR Feature Set` 。

   对于广告 `ad` 的竞价词 `term` （记作$\text{ad}_\text{term}$)

   - 针对该 `term` 竞价的其它广告主所有广告的数量：

    $f_0 = N(\text{ad}_\text{term})$

     > 由于同一个广告主的不同广告之间相关性比较强，因此这里用其它广告主的广告作为特征来源。否则容易出现信息泄露。

   - 针对该 `term` 竞价的其它广告主的广告点击率（经过归一化）：

    $f_1 = \frac{\alpha \overline{\text{CTR}} +N(\text{ad}_\text{term})\times \text{CTR}(\text{ad}_\text{term})}{\alpha + N(\text{ad}_\text{term})}$

     其中：

     -$\overline{\text{CTR}}$是训练集上所有广告的平均点击率

     -$N(\text{ad}_\text{term})$是针对该 `term` 竞价的其它广告主所有广告的数量

     -$\text{CTR}(\text{ad}_\text{term})$是针对该 `term` 竞价的其它广告主所有广告的平均点击率

     -$\alpha$是平滑系数，为了防止某些新的 `term`出现导致$N(\text{ad}_\text{term}) =0$。如果不采取平滑，则有$f_1 = \text{CTR}(\text{ad}_\text{term})$。

      $\alpha$代表了`term` 竞价的广告数量的先验强度，默认取值为 1 。

       > 实验发现，结果对$\alpha$的取值不敏感。

   模型新增这两个特征的实验结果如下图所示，可见 `term ctr feature set` 使得评估指标 “平均 `KL` 散度” 提升了 `13.28%`。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603191920.png?imageslim">
   </p>
   

#### 1.3.2 Related Term CTR Feature Set

1. 预测某个广告的点击率时，相关竞价词的其它类似广告可能也有所帮助。

   如：广告 `a` 的竞价词是 `电脑`，广告 `b` 的竞价词是 `买电脑`，则广告 `b` 的点击率对于预测广告 `a` 的点击率是有帮助的。

2. 考虑竞价词的子集/超集。

   给定一个竞价词 `t`，定义其相关广告集合为$\mathbf R_{m,n}(t)$（一个竞价词`term` 可能包含多个单词`word`，这里不考虑`word` 之间的词序）：

   如：`t` 是 `red shoes`

   - 如果广告的竞价词是`buy red shoes`，则该广告属于`t` 的$\mathbf R_{0,1}$
   - 如果广告的竞价词是 `shoes`，则该广告属于 `t` 的$\mathbf R_{1,0}$
   - 如果广告的竞价词是`red shoes`，则该广告属于`t` 的$\mathbf R_{0,0}$
   - 如果广告的竞价词是`blue shoes`，则该广告属于`t` 的$\mathbf R_{1,1}$

3. 由$\mathbf R_{m,n}(t)$的定义可知：

   - 广告集合$\mathbf R_{0,0}$代表广告的竞价 `term` 和 `t` 完全匹配。
   - 广告集合$\mathbf R_{m,0}$代表广告的竞价 `term` 比 `t` 少了$m$个单词之外其它单词完全相同（不考虑词序）。
   - 广告集合$\mathbf R_{0,n}$代表广告的竞价 `term` 比 `t` 多了$n$个单词之外其它单词完全相同（不考虑词序）。

   假设 `*` 为任意数值，则定义：

   -$\mathbf R_{0,*}(t)$表示 `t`的任何超集（不考虑词序）作为竞价`term` 的广告的集合。
   -$\mathbf R_{*,0}(t)$表示 `t`的任何子集（不考虑词序）作为竞价`term` 的广告的集合。

4. 定义相关竞价词的一组特征，它们称为相关竞价词特征集 `Related Term CTR Feature Set`：

   - 在 `term` 相关的竞价词上竞价的其它广告主所有广告的数量：

    $v_{m,n}(\text{term}) = |\mathbf R_{m,n}(\text{term})|$

   - 在 `term` 相关的竞价词上竞价的其它广告主所有广告的平均点击率:

    $\overline{\text{CTR}_{m,n}}(\text{term}) = \frac{1}{|\mathbf R_{m,n}(\text{term})|}\sum_{x\in \mathbf R_{m,n}(\text{term})}\text{CTR}_x$

     其中$\text{CTR}_x$表示广告 `x` 的真实点击率。

     和 `Term CTR Feature Set` 一样，这里也采用平滑：

    $\text{CTR}_{m,n}(\text{term}) = \frac{\beta \overline{\text{CTR}} +|\mathbf R_{m,n}(\text{term})|\times \overline{\text{CTR}_{m,n}}(\text{term})}{\beta + |\mathbf R_{m,n}(\text{term})|}$

     其中$\beta$表示平滑系数。

   论文中采取了$m,n\in \{0,1,2,3,*\}$一共 `5x5=25` 种组合，得到 `25 x 2 =50` 个 `related term ctr`特征。测试集的 “平均 `KL` 散度” 表明：采用这一组特征之后，取得了接近 `20%` 的提升。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603191937.png?imageslim">
   </p>
   

#### 1.3.3 Ad Quality Feature Set

1. 即使是同一个竞价`term`，不同广告的点击率也存在显著差异。从经验来看，至少有五种粗略的要素影响用户是否点击：

   - 外观 `Appearance`：外观是否美观。

   - 吸引力 `Attention Capture`：广告是否吸引眼球。

   - 声誉 `Reputation`：广告主是否知名品牌。

   - 落地页质量 `Landing page quality`：点击广告之后的落地页是否高质量。

     > 虽然用户只有点击之后才能看到落地页，但是我们假设这些落地页是用户熟悉的广告主（如 ebay, amazon ），因此用户在点击之前就已经熟知落地页的信息。

   - 相关性 `Relevance`：广告与用户`query` 词是否相关。

   针对每个要素，论文给出一些特征：

   - 外观`Appearance`：

     - 广告标题包含多少个单词
     - 广告标题是在广告体内还是在广告体外
     - 标题是否正确的大小写首字母
     - 广告标题是否包含了太多的感叹号、美元符号或其它标点符号
     - 广告标题用的是短词还是长词

   - 吸引力 `Attention Capture`：

     - 标题是否包含暗示着转化的单词，如`购买 buy`、`加入join`、`订阅subscribe` 等等
     - 这些转化词是否出现在广告体内还是广告体外
     - 标题是否包含数字（如折扣率，价格等）

   - 声誉`Reputation`：

     - 底部展示的 `URL` 是否以 `.com/.net/.org/.edu` 结尾

     - 底部展示的的 `url` 多长

     - 底部展示的`url` 分为几个部分

       > 如 `books.com` 只有两部分，它比 `books.something.com` 更好

     - 底部展示的`url` 是否包含破折号或者数字

     因为好的、短的 `.com` 域名比较贵，因此 `url` 体现了广告主的实力。

   - 落地页质量`Landing page quality`：

     - 落地页是否包含 `flash`
     - 落地页页面哪部分采用大图
     - 落地页是否符合 `W3C`
     - 落地页是否使用样式表
     - 落地页是否弹出广告

   - 相关性 `Relevance`：

     - 竞价词是否出现在标题
     - 竞价词的一部分是否出现在标题
     - 竞价词或者竞价词的一部分是否出现在广告体内
     - 如果出现，则竞价词或者竞价词的一部分占据广告体的几分之一

   最终在这 5 个因素种抽取了 81 个特征。

2. 某些特征可以出现在多个要素里，如：广告内容中美元符号数量。该特征可能会增加吸引力，但是会降低外观。

3. 除了以上5个内容要素，还有一个重要的内容要素：广告文本的单词。

   我们统计广告标题和正文中出现的 `top 10000` 个单词，将这1万个单词出现与否作为 `unigram` 特征。因为某些单词更容易吸引用户点击，因此`unigram` 特征能够弥补注意力要素遗漏的特征。

   > 注意：构造特征时，标题和正文的 `unigram` 分别进行构造。即：单词是否出现在标题中、单词是否出现在正文中。

   如下所示：单词 `shipping` 更倾向于在高 `CTR` 广告中出现，这意味着 `shipping` 更容易吸引用户点击。图中的三条曲线从上到下依次代表：

   - 每个单词在高 `CTR` 广告中出现的平均频次
   - 每个单词在所有广告中出现的平均频次
   - 每个单词在低 `CTR` 广告中出现的平均频次

  <p align="center">
     <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603191948.png?imageslim">
  </p>
  

4. 以上5个内容要素，以及 `unigram` 特征一起构成了广告质量特征集 `Ad Quality Feature Set`。结果表明：

   - 该组特征能够显著提升性能，将测试集的 “平均 `KL` 散度” 提升约 3.8 % 。
   - 考虑去掉 `unigram` 特征，结果表明：
     - 仅仅 `5` 个因素的 `81` 个特征能够提升约 `1.1 %`
     - `unigram` 特征能够提升约 `2.7 %`

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603192007.png?imageslim">
   </p>
   

#### 1.3.4 Order Specificity Feature Set

1. 有的订单定向比较窄。如：

   ```
   xxxxxxxxxx
   ```

   4

   1

   ```
   Title: Buy shoes now,
   ```

   2

   ```
   Text: Shop at our discount shoe warehouse!
   ```

   3

   ```
   Url: shoes.com
   ```

   4

   ```
   Terms: {buy shoes, shoes, cheap shoes}.
   ```

   该订单的竞价词都和 `shoes` 相关，定向比较狭窄。

   而有的订单定向比较宽，如：

   ```
   xxxxxxxxxx
   ```

   4

   1

   ```
   Title: Buy [term] now,
   ```

   2

   ```
   Text: Shop at our discount warehouse!
   ```

   3

   ```
   Url: store.com
   ```

   4

   ```
   Terms: {shoes, TVs, grass, paint}.
   ```

   该订单的竞价词不仅包含`shoes`，还包括 `TV`、`grass` 等等。

   我们预期：定向越宽的订单，其平均`CTR`越低；定向越窄的订单，其平均`CTR` 越高。

2. 为了考虑捕捉同一个订单内不同广告的联系，论文提出了订单维度特征集 `Order Specificity Feature Set` 。

   - 同一个订单中，去重之后不同竞价词`term` 的数量。

    $Num(\text{order}_{\text{unique_term}})$

   - 同一个订单中，竞价词 `term` 的类别分布。分布越集中，定向越窄；分布越分散，定向越宽。

     - 利用搜索引擎搜索每个竞价词 `term` ，并通过文本分类算法对搜索结果进行分类，将每个竞价词`term` 划分到 74 个类别中。
     - 计算每个订单的竞价词`term`的类别熵，并将类别熵作为特征。

   采用该特征集之后，测试集的 “平均 `KL` 散度” 提升约 5.5 % 。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603192041.png?imageslim">
   </p>
   

#### 1.3.5 Search Data Feature Set

1. 事实上可以通过使用外部数据来构造特征。

   如：给定一个竞价词`term`，可以通维基百科来判断它是否是一个众所周知的词，也可以通过同义词词库来查找其同义词等等。

   因此构建外部搜索数据特征集 `Search Data Feature Set`，其中包括：

   - 每个竞价词`term`，网络上该 `term`出现的频率。

     这可以利用搜索引擎的搜索结果中包含该 `term` 的网页数量来初略估计。

   - 每个竞价词`term`，搜索引擎的`query` 中出现该`term` 的频率。

     这可以用近三个月搜索引擎的搜索日志中，`query` 里出现该 `term` 的数量来粗略估计。

   这两个特征离散化为 20 个桶，仔细划分桶边界使得每个桶具有相同数量的广告。

   单独采用该特征集之后，测试集的 “平均 `KL` 散度” 提升约 `3.1 %` 。但是融合了前面提到的特征之后没有任何改进，这意味着该特征集相比前面的几个特征集是冗余的。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603192049.png?imageslim">
   </p>
   

#### 1.3.6 更多特征

1. 当独立的考虑每个`feature set` 时，测试集的 “平均 `KL` 散度” 提升效果如下：

   - `related term ctr feature set`：`19.67%`
   - `ad quality feature set`：`12.0%`
   - `unigram features along`：`10.2%`
   - `order specificity feature set`：`8.9%`
   - `search data feature set` ：`3.1%`

2. 有几个特征探索方向：

   - 可以将广告的竞价词 `term` 进行聚类，从而提供广告之间的关系。这是从语义上分析竞价词`term` 的相似性。这组特征称作 `Related Term Feature Set` 。

   - 可以基于用户的 `query` 来构造特征。

     在完全匹配条件下竞价词和用户搜索词完全相同，但是在更宽松的匹配下竞价词和搜索词可能存在某种更广义的关联。此时了解搜索词的内容有助于预测广告的点击率。

     因此可以基于用户的搜索词 `query term` 来构建特征，如： `query term` 和 `bid term` 相似度、 `query term` 的单词数、`query term` 出现在广告标题/广告正文/落地页的频次。

   - 可以将落地页的静态排名和动态排名信息加入特征。如：用户访问落地页或者域名的频率、用户在落地页停留的时间、用户在落地页是否点击回退等等。

3. 一个推荐的做法是：在模型中包含尽可能多的特征。这带来两个好处：

   - 更多的特征带来更多的信息，从而帮助模型对于广告点击率预测的更准。

   - 更多的特征带来一定的冗余度，可以防止对抗攻击。

     广告主有动力来攻击特征来欺骗模型，从而提升广告的 `pCTR` ，使得他的广告每次排名都靠前。

     假设模型只有一个特征，该特征是 ”竞价词`term` 是否出现在标题“ 。广告主可以刻意将竞价词放置到广告标题，从而骗取较高的 `pCTR` 。

     一旦模型有多个特征，那么广告主必须同时攻击这些特征才能够欺骗模型。这种难度要大得多。

### 1.4 特征重要性

1. 由于模型采用逻辑回归，因此可以直观的通过模型权重看到哪些特征具有最高权重、哪些特征具有最低权重。

   模型的`top 10` 和 `bottom 10` 权重对应的特征如下：

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603192102.png?imageslim">
   </p>
   

2. **特征的权重不一定直接表示其重要性，因为特征之间不是独立的**。

   假设有一个重要的特征是文本中每个单词的平均长度（即：平均多少个字符）$\text{word_len}$，但我们并没有直接给出这个特征，而是给出相关的两个特征：文本总字符数$\text{text_len}$、文本总单词数$\text{word_count}$。那么我们会发现：特征$\text{text_len}$具有一个较大的正权重、特征$\text{word_count}$有一个较大的负权重。

   因为$\text{word_len} = \text{text_len}/ \text{word_count}$，所以特征$\text{word_len}$和特征$\text{text_len}$正相关，而特征$\text{word_len}$和特征$\text{word_count}$负相关。

3. 在 `unigram features` 中，`top 10` 和 `bottom 10` 权重对应的特征如下。

   可以看到：

   - 排在前面的是更为成熟`established` 的实体词，如 `official,direct,latest,version`
   - 排在后面的是更为吸引眼球的实体词，如 `quotes, trial, deals, gift, compare`

   从经验上看：用户似乎更愿意点击声誉更好的、更成熟的广告，而不愿意点击免费试用、优惠类的广告。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603192113.png?imageslim">
   </p>
   

### 1.5 曝光量

1. 假设模型能准确预估广告的点击率，一个问题是：广告经过多少次曝光之后，观察到的点击率和预估的点击率接近。

   定义观察到的点击率为：

  $\text{CTR}^* = \frac{ \text{click}}{\text{expo}}$

   定义预测的点击率为：

  $\hat p = \frac{\alpha p_0+ \text{click}}{\alpha + \text{expo}}$

   其中：

   -$\text{expo}$是广告的曝光次数，$\text{click}$为广告的点击次数，$p_0$为先验`CTR`，$\alpha$是先验曝光次数。

   -$p_0$是模型预估得到的 `pCTR` ，而$\alpha$是一个超参数。

   -$\hat p$是结合了模型预估的 `pCTR` 和广告已经产生的曝光、点击之后，预测的点击率。

     > 模型预测的 `pCTR` 没有考虑广告当前的曝光、点击，因此需要修正。

   定义期望绝对损失 `expected absolute error:EAE`：

  $\mathbb E[\text{err}\mid \text{expo} ] = \sum_{\text{click}=1}^\text{expo} p(\text{click}\mid \text{expo} )\times |\hat p -\text{CTR}^*|$

   其中：$p(\text{click}\mid \text{expo} )$表示给定曝光的条件下，点击`click` 次的概率。它通过统计其它广告得到。

   `EAE` 刻画了在不同曝光量的条件下，模型给出的$\hat p$和 `CTR` 的绝对误差。这和模型优化目标平均`KL` 散度不同。

2. `baseline` 和 `LR` 模型的 `EAE` 结果如下所示。可以看到：

   - 在广告的曝光量超过 100时，`baseline` 和 `LR` 模型的 `EAE` 几乎相同。
   - 在广告的曝光量小于 50 时，`LR` 模型的`EAE` 更低。

   因此模型对于曝光量100以内的广告具有明显优势。这也是前面预处理将 100 次曝光作为阈值截断的原因。

   对于百万级别广告的广告系统，如果在广告曝光的前100次期间对广告的`CTR` 预估不准，则导致这些广告以错误的顺序展示，从而导致收入减少和用户体验下降。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603204525.png?imageslim">
   </p>
   

3. 预处理选择 100 次曝光作为截断阈值，是希望样本的观察 `CTR` 具有合理的置信水平。

   事实上有一些广告系统更关注于曝光量更大的广告，希望对这些广告能够预测更准确。更大曝光量意味着`label` 中更少的噪音，模型会学习得效果更好。

   但是这也意味着广告样本不包含那些被系统判定为低价值的广告，因为系统没有给这些低价值广告足够多的曝光机会。

   当曝光阈值提升到 1000次时，模型效果如下。可以看到：曝光量超过1000的广告比曝光量100的广告，模型预测效果（以测试集的平均`KL` 散度为指标）提升了 40%左右（ `(41.88-29.47)/29.47` ）。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603204612.png?imageslim">
   </p>
   

## 二、POLY2 模型

1. `LR` 模型只考虑特征之间的线性关系，而`POLY2` 模型考虑了特征之间的非线性关系。

   - 捕获非线性特征的一个常用方法是采用核技巧，如高斯核`RBF`，将原始特征映射到一个更高维空间。在这个高维空间模型是线性可分的，即：只需要考虑新特征之间的线性关系。

     但是核技巧存在计算量大、内存需求大的问题。

   - 论文 `Training and Testing Low-degree Polynomial Data Mappings via Linear SVM` 提出多项式映射 `polynomially mapping` 数据的方式来提供非线性特征，在达到接近核技巧效果的情况下大幅度降低内存和计算量。

2. 设低维样本空间为$n$维度，低维样本$\mathbf{\vec x} = [x_1,\cdots,x_n]^T$。

   多项式核定义为：$K(\mathbf{\vec x}_i,\mathbf{\vec x}_j) = (\gamma \mathbf{\vec x}_i\cdot \mathbf{\vec x}_j +r)^d$。其中$\gamma,r$为超参数，$d$为多项式的度`degree` 。

   根据定义，多项式核等于样本在高维空间向量的内积：

  $K(\mathbf{\vec x}_i,\mathbf{\vec x}_j) = \phi(\mathbf{\vec x}_i) \cdot \phi(\mathbf{\vec x}_j)$

   其中$\phi$是映射函数。

   当$d=2$时，有：

  $\phi(\mathbf{\vec x}) = [1,\sqrt{2\gamma}x_1,\cdots,\sqrt{2\gamma}x_n,\gamma x_1^2,\cdots,\gamma x_n^2,\sqrt2 \gamma x_1x_2,\cdots,\sqrt 2 \gamma x_{n-1}x_n ]^T$

   使用$\sqrt 2$是为了$\phi(\mathbf{\vec x}_i) \cdot \phi(\mathbf{\vec x}_j)$的表达更简洁。

3. 如果不用核技巧，仅仅考虑使用一个多项式映射，则我们得到：

  $\phi(\mathbf{\vec x}) = [1,x_1,\cdots,x_n,x_1^2,\cdots,x_n^2,x_1x_2,\cdots,x_{n-1}x_n]^T$

   结合`LR` 模型，则得到 `POLY2` 模型：

   新增的组合特征一共有$\frac{n\times (n-1)}{2}$个。

4. `POLY2` 模型的优缺点：

   - 优点：除了线性特征之外，还能够通过特征组合自动捕获二阶特征交叉产生的非线性特征。

   - 缺点：

     - 参数太多导致计算量和内存需求发生爆炸性增长。

       如计算广告场景中，原始样本特征可能达到上万甚至百万级别，则特征的交叉组合达到上亿甚至上万亿。

     - 数据稀疏导致二次项参数训练困难，非常容易过拟合。

       参数$w_{i,j}$的训练需要大量的$x_i,x_j$都非零的样本。而大多数应用场景下，原始特征本来就稀疏（非零的样本数很少），特征交叉之后更为稀疏（非零的样本数更少）。这使得训练$w_{i,j}$的样本明显不足，很容易发生过拟合。

## 三、FM模型

1. 推荐系统面临的问题是评分预测问题。给定用户集合$\mathbb U=\{u_1,u_2,\cdots,u_M\}$、物品集合$\mathbb I = \{i_1,i_2,\cdots,i_N\}$，模型是一个评分函数：

  $f:\mathbb U\times \mathbb I\rightarrow \mathbb R$

  $y=f(u,i)$表示用户$u$对物品$i$的评分。

   其中已知部分用户在部分物品上的评分：$\mathbb S \in \mathbb U\times \mathbb I, \forall (u,i)\in \mathbb S,\tilde y=f(u,i)$。目标是求解剩余用户在剩余物品上的评分：

  $\hat y = f(u,i) ,\;\forall(u,i) \in \complement_\mathbb S$

   其中$\complement_\mathbb S$为$\mathbb S$的补集。

   - 通常评分问题是一个回归问题，模型预测结果是评分的大小。此时损失函数采用`MAE/MSE` 等等。

     也可以将其作为一个分类问题，模型预测结果是各评级的概率。此时损失函数是交叉熵。

   - 当评分只有 `0` 和 `1` 时，这表示用户对商品 “喜欢/不喜欢”，或者 “点击/不点击”。这就是典型的点击率预估问题。

2. 事实上除了已知部分用户在部分物品上的评分之外，通常还能够知道一些有助于影响评分的额外信息。如：用户画像、用户行为序列等等。这些信息称作上下文 `context` 。

   对每一种上下文，我们用变量$c \in \mathbb C$来表示，$\mathbb C$为该上下文的取值集合。假设所有的上下文为$\mathbb C_3,\cdots,\mathbb C_K$，则模型为：

  $f:\mathbb U\times \mathbb I \times \mathbb C_3\times\cdots\times\mathbb C_K\rightarrow \mathbb R$

   上下文的下标从 `3` 开始，因为可以任务用户$u$和商品$i$也是上下文的一种。

   如下图所示为评分矩阵，其中：

   所有离散特征都经过特征转换。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603204631.png?imageslim">
   </p>
   

3. 上下文特征 `context` 类似属性 `property`特征，它和属性特征的区别在于：

   - 属性特征是作用到整个用户（用户属性）或者整个物品（物品属性），其粒度是用户级别或者物品级别。

     如：无论用户 “张三” 在在评分矩阵中出现多少次，其性别属性不会发生改变。

   - 上下文特征是作用到用户的单个评分事件上，粒度是事件级别，包含的评分信息更充足。

     如：用户 ”张三“ 在评价某个电影之前已经看过的电影，该属性会动态改变。

   事实上属性特征也称作静态画像，上下文特征也称作动态画像。业界主流的做法是：融合静态画像和动态画像。

   另外，业界的经验表明：动态画像对于效果的提升远远超出静态画像。

### 3.1 模型

1. `Multiverse Recommendation` 基于矩阵分解技术求解该问题，它将原始的评分矩阵分解为一个小的矩阵$\mathbf B$和$K$个因子矩阵$\mathbf V^{(k)}$：

  $\hat y =f(u,i,c_3,\cdots,c_K) = \sum_{l_1=1}^{d_1}\cdots\sum_{l_K=1}^{d_K}b_{l_1,\cdots,l_K} \times\left[ v_{u,l_1}^{(U)}\times v_{i,l_2}^{(I)}\times \prod_{k=3}^Kv_{c_k,l_k}^{(C_k)}\right]$

   其中：

   这种方式存在三个问题：

   - 计算复杂度太高：假设每个特征的维度都是$d$，则计算复杂度为$O(d^K)$。一旦上下文特征数量$K$增加，则计算复杂度指数型增长。
   - 仅能对离散型 `categorical` 上下文特征建模：无法处理数值型特征、离散集合型 `categorical set`特征。
   - 交叉特征高度稀疏：这里执行的是 `K` 路特征交叉（前面的 `POLY2` 模型是两路特征交叉），由于真实应用场景中单个特征本身就已经很稀疏，`K` 路特征交叉使得数据更加稀疏，难以准确的预估模型参数。

2. `Fast Context-aware Recommendations with Factorization Machines` 论文提出了 `FM` 算法来解决该问题。

   和 `POLY2` 相同`FM` 也是对二路特征交叉进行建模，但是`FM` 的参数要比 `POLY2` 少得多。

   将样本重写为：

  $\mathbf{\vec x} =(x_1,x_2,x_3,\cdots,x_K)^T =(u,i,c_3,\cdots,c_K)^T$

   则 `FM` 模型为：

  $\hat y(\mathbf{\vec x}) = w_0 + \sum_{i=1}^K w_i\times x_i + \sum_{i=1}^K\sum_{j=i+1}^K \hat w_{i,j}\times x_i\times x_j$

   其中$\hat w_{i,j}$是交叉特征的参数，它由一组参数定义：

  $\hat w_{i,j} = <\mathbf{\vec v}_i,\mathbf{\vec v}_j> = \sum_{l=1}^d v_{i,l}\times v_{j,l}$

   即：

   模型待求解的参数为：

   其中：

   -$w_0$表示全局偏差
   -$w_i$用于捕捉第$i$个特征和目标之间的关系
   -$\hat w_{i,j}$用于捕捉$(i,j)$二路交叉特征和目标之间的关系。
   -$\mathbf{\vec v}_i$代表特征$i$的`representation vector`，它是$\mathbf V$的第$i$列。

3. `FM` 模型的计算复杂度为$O(K\times K\times d) = O(K^2d)$，但是经过数学转换之后其计算复杂度可以降低到$O(Kd)$：

   因此有：

  $\hat y(\mathbf{\vec x}) = w_0 + \sum_{i=1}^K w_i\times x_i +\frac 12 \sum_{l=1}^d\left(\left(\sum_{i=1}^Kv_{i,l}\times x_i\right)^2 - \sum_{i=1}^K v_{i,l}^2\times x_{i}^2\right)$

   其计算复杂度为$O(Kd)$。

4. `FM` 模型可以用于求解分类问题（预测各评级的概率），也可以用于求解回归问题（预测各评分大小）。

   - 对于回归问题，其损失函数为`MSE`均方误差：

    $\mathcal L = \sum_{(\mathbf{\vec x},y)\in \mathbb S} \left(\hat y(\mathbf{\vec x}) - y\right)^2 + \sum_{\theta\in \mathbf \Theta} \lambda_{\theta} \times \theta^2$

   - 对于二分类问题，其损失函数为交叉熵：

     其中：

     - 评级集合为$y\in \{-1,1 \}$一共两个等级
     -$p(\hat y=y\mid \mathbf{\vec x})$为样本$\mathbf{\vec x}$预测为评级$y$的概率，满足：

   损失函数最后一项是正则化项，为了防止过拟合，$\mathbf \Theta = \{w_0,\mathbf{\vec w}, \mathbf V\}$。其中$\lambda_\theta$为参数$\theta$的正则化系数，它是模型的超参数。

   可以针对每个参数配置一个正则化系数，但是选择合适的值需要进行大量的超参数选择。论文推荐进行统一配置：

   - 对于$w_0$，正则化系数为$\lambda_{w_0} = 0$，这表示不需要对全局偏差进行正则化。
   - 对于$w_i$，统一配置正则化系数为$\lambda_w$
   - 对于$v_{i,l}$，统一配置正则化系数为$\lambda_v$

5. `FM` 模型可以处理不同类型的特征：

   - 离散型特征 `categorical`：`FM` 对离散型特征执行 `one-hot` 编码。

     如，性别特征：“男” 编码为 `(0,1)`，“女” 编码为 `(1,0)` 。

   - 离散集合特征 `categorical set`：`FM` 对离散集合特征执行类似 `one-hot` 的形式，但是执行样本级别的归一化。

     如，看过的历史电影。假设电影集合为：“速度激情9，战狼，泰囧，流浪地球”。如果一个人看过 “战狼，泰囧，流浪地球”， 则编码为`(0,0.33333,0.33333,0.33333)`。

   - 数值型特征 `real valued`：`FM`直接使用数值型特征，不做任何编码转换。

6. `FM` 的优势：

   - 给定特征 `representation` 向量的维度时，预测期间计算复杂度是线性的。

   - 在交叉特征高度稀疏的情况下，参数仍然能够估计。

     因为交叉特征的参数不仅仅依赖于这个交叉特征，还依赖于所有相关的交叉特征。这相当于增强了有效的学习数据。

   - 能够泛化到未被观察到的交叉特征。

     设交叉特征 `“看过电影 A 且 年龄等于20”` 从未在训练集中出现，但出现了 `“看过电影 A”`相关的交叉特征、以及 `“年龄等于20”`相关的交叉特征。

     于是可以从这些交叉特征中分别学习 `“看过电影 A”` 的 `representation` 、`“年龄等于20”`的 `representation`，最终泛化到这个未被观察到的交叉特征。

### 3.2 ALS 优化算法

#### 3.2.1 最优化解

1. `FM` 的目标函数最优化可以直接采用随机梯度下降 `SGD` 算法求解，但是采用 `SGD` 有个严重的问题：需要选择一个合适的学习率。

   - 学习率必须足够大，从而使得 `SGD`能够尽快的收敛。学习率太小则收敛速度太慢。

   - 学习率必须足够小，从而使得梯度下降的方向尽可能朝着极小值的方向。

     由于 `SGD` 计算的梯度是真实梯度的估计值，引入了噪音。较大的学习率会放大噪音的影响，使得前进的方向不再是极小值的方向。

   论文提出了一种新的交替最小二乘 `alternating least square:ALS` 算法来求解 `FM` 目标函数的最优化问题。

   与 `SGD` 相比`ALS` 优点在于无需设定学习率，因此调参过程更简单。

2. 根据定义：

  $\hat y(\mathbf{\vec x};\mathbf \Theta) = w_0 + \sum_{i=1}^K w_i\times x_i +\frac 12 \sum_{l=1}^d\left(\left(\sum_{i=1}^Kv_{i,l}\times x_i\right)^2 - \sum_{i=1}^K v_{i,l}^2\times x_{i}^2\right)$

   对每个$\theta \in \mathbf \Theta = \{w_0,\mathbf{\vec w}, \mathbf V\}$，可以将$\hat y$分解为$\theta$的线性部分和偏置部分：

  $\hat y(\mathbf{\vec x};\mathbf \Theta) = h_{\theta}(\mathbf{\vec x}) \times \theta +g_\theta(\mathbf{\vec x})$

   其中$g_\theta(\mathbf{\vec x}), h_\theta(\mathbf{\vec x})$与$\theta$无关。如：

   - 对于$w_0$有：
   - 对于$w_i,i=1,2\cdots,K$有：
   - 对于$v_{i,l}, i=1,2,\cdots,K,l=1,2,\cdots,d$有：

   因此有：

  $\frac{\partial \hat y(\mathbf{\vec x};\mathbf \Theta)}{\partial \theta} = h_\theta(\mathbf{\vec x})$

   考虑均方误差损失函数：

  $\mathcal L = \sum_{(\mathbf{\vec x},y)\in \mathbb S} \left(\hat y(\mathbf{\vec x};\mathbf \Theta) - y\right)^2 + \sum_{\theta\in \mathbf \Theta} \lambda_{\theta} \times \theta^2$

   最小值点的偏导数为 0 ，有：

  $\frac{\partial L}{\partial \theta} = 2\sum_{(\mathbf{\vec x},y)\in \mathbb S} \left(\hat y(\mathbf{\vec x};\mathbf \Theta) - y\right)\times \frac{\partial \hat y(\mathbf{\vec x};\mathbf \Theta)}{\partial \theta} + 2\times \lambda_{\theta} \times \theta = 0$

   则有：

  $\theta = - \frac{\sum_{(\mathbf{\vec x},y)\in \mathbb S}(g_\theta(\mathbf{\vec x})-y)\times h_\theta(\mathbf{\vec x}) }{\left(\sum_{(\mathbf{\vec x},y)\in \mathbb S} h^2_\theta(\mathbf{\vec x})\right)+\lambda_\theta }$

3. `ALS` 通过多轮次、轮流迭代求解$\theta \in \mathbf \Theta = \{w_0,\mathbf{\vec w}, \mathbf V\}$即可得到模型的最优解。

   - 在迭代之前初始化参数，其中：$w_0,\mathbf{\vec w}$通过零初始化，$\mathbf V$的每个元素通过均值为0、方差为$\sigma$的正太分布随机初始化。

   - 每一轮迭代时：

     - 首先求解$w_0,\mathbf{\vec w}$，因为相对于二阶交叉的高阶特征，低阶特征有更多的数据来估计其参数，因此参数估计更可靠。

     - 然后求解$\mathbf V$。这里按照维度优先的准确来估计：先估计所有 `representation` 向量的第 `1` 维度，然后是第 `2` 维，... 最后是第 `d` 维。

       这是为了计算优化的考量。

#### 3.2.2 计算优化

1. 直接求解 `ALS` 的解时复杂度较高：在每个迭代步中计算每个训练样本的$g_\theta(\mathbf{\vec x})$和$h_\theta(\mathbf{\vec x})$。

   对于每个样本，求解$g_\theta(\mathbf{\vec x})$和$h_\theta(\mathbf{\vec x})$的计算复杂度为：

   - 计算$h_{w_0}(\mathbf{\vec x})$的复杂度为$O(1)$，计算$g_{w_0}(\mathbf{\vec x})$的复杂度为$O(Kd)$
   - 计算$h_{w_i}(\mathbf{\vec x})$的复杂度为$O(1)$，计算$g_{w_i}(\mathbf{\vec x})$的复杂度为$O(Kd)$
   - 计算$h_{v_{i,l}}(\mathbf{\vec x})$的复杂度为$O(K)$，计算$g_{v_{i,l}}(\mathbf{\vec x})$的复杂度为$O(K^2d)$

   因此求解$\theta$的计算复杂度为$O(|\mathbb S|\times K^2\times d)$。

2. 有三种策略来降低求解$\theta$的计算复杂度，从$O(|\mathbb S|\times K^2\times d)$降低到$O(|\mathbb S|\times \bar K\times d)$，其中$\bar K$表示平均非零特征的数量：

   - 利用预计算的误差项$e$降低$(g_\theta(\mathbf{\vec x})-y)$的计算代价 。
   - 利用预计算的$q$项降低交叉特征的$h_\theta$的计算代价。
   - 利用数据集$\mathbb S$的稀疏性降低整体计算代价。

3. 预计算误差项$e$：

   定义误差项：

  $e(\mathbf{\vec x},y;\mathbf \Theta) := \hat y(\mathbf{\vec x}; \mathbf \Theta) - y$

   考虑到$\hat y(\mathbf{\vec x};\mathbf \Theta) = h_{\theta}(\mathbf{\vec x}) \times \theta +g_\theta(\mathbf{\vec x})$，则有：

  $g_\theta(\mathbf{\vec x})-y = e(\mathbf{\vec x},y;\mathbf \Theta) - \theta\times h_\theta(\mathbf{\vec x})$

   因此如果计算$e(\mathbf{\vec x},y;\mathbf \Theta)$的计算代价较低，则计算$(g_\theta(\mathbf{\vec x})-y)$的计算复杂度也会降低。

   - 首先对每个样本，计算其初始误差：

    $\mathbf{\vec e} = \left(e(\mathbf{\vec x}_1,y_1;\mathbf \Theta ),\cdots,e(\mathbf{\vec x}_{|\mathbb S|},y_{|\mathbb S|};\mathbf \Theta )\right)^T \in \mathbb R^{|\mathbb S|}$

     考虑到$\hat y$的计算复杂度为$O(K\times d)$，因此$\mathbf{\vec e}$的计算复杂度为$O(|\mathbb S|\times K\times d)$。

   - 当参数$\theta$更新到$\theta^*$时，重新计算误差：

     计算代价由$h_\theta(\mathbf{\vec x})$决定 （根据下面的讨论，其计算复杂度为$O(1)$）。

4. 预计算$q$值：

   如果能够降低计算$h_\theta(\mathbf{\vec x})$的代价，则整体计算复杂度可以进一步降低。由于$h_{w_0}(\mathbf{\vec x}),h_{w_i}(\mathbf{\vec x})$的复杂度为$O(1)$，因此重点考虑$h_{v_{i,l}}(\mathbf{\vec x})$的计算复杂度。

   重写$h_{v_{i,l}} (\mathbf{\vec x})$，有：

  $h_{v_{i,l}}(\mathbf{\vec x}) = \sum_{j=1,j\ne i}^K v_{j,l} \times x_j\times x_i = x_i\times \left[\sum_{j=1 }^K v_{j,l} \times x_j\right] - v_{i,l}\times x_i^2$

   定义：

  $q(\mathbf{\vec x},l;\mathbf\Theta) := \sum_{j=1}^Kv_{j,l}\times x_j$

   因此如果计算$q(\mathbf{\vec x},l;\mathbf\Theta)$的计算代价较低，则$h_{v_{i,l}}(\mathbf{\vec x})$的计算复杂度也会降低。

   - 对每个样本、每个`representation` 向量维度计算初始$q$值：

     计算复杂度为$O(|\mathbb S|\times K\times d)$。

   - 当参数$v_{j,l}$更新到$v_{j,l}^*$时，重新$q$值：

    $q(\mathbf{\vec x},l;\mathbf\Theta ^*)= q(\mathbf{\vec x},l;\mathbf\Theta) +(v_{j,l}^* - v_{j,l})\times x_l$

     计算代价为$O(1)$。

   - 一旦得到$q(\mathbf{\vec x},l;\mathbf\Theta)$，则有：

    $h_{v_{i,l}}(\mathbf{\vec x}) = q(\mathbf{\vec x},l;\mathbf\Theta) - v_{i,l}\times x_i^2$

     计算代价为$O(1)$

5. 数据集$\mathbb S$的稀疏性：

   根据：

  $\theta = - \frac{\sum_{(\mathbf{\vec x},y)\in \mathbb S}(g_\theta(\mathbf{\vec x})-y)\times h_\theta(\mathbf{\vec x}) }{\left(\sum_{(\mathbf{\vec x},y)\in \mathbb S} h^2_\theta(\mathbf{\vec x})\right)+\lambda_\theta }$

   - 对于$w_0$，其计算复杂度为$O(|\mathbb S|\times K)$

    $w_0\leftarrow \frac{\sum_{(\mathbf{\vec x},y)\in \mathbb S}\left[e(\mathbf{\vec x},y;\mathbf \Theta)-w_0\right] }{|\mathbb S|+\lambda_{w_0} }$

   - 对于$w_i,v_{i,l}$， 我们只需要迭代$\mathbb S$中$h_\theta(\mathbf{\vec x}) \ne 0$的样本，即$x_i \ne 0$的样本。

     因此每次更新只需要使用部分样本。总体而言，整体复杂度为$O(|\mathbb S|\times \bar K\times d)$，其中$\bar K$表示平均非零特征的数量。

#### 3.2.3 算法

1. `ALS` 优化算法：

   - 输入：

     - 训练样本$\mathbb S$
     -$\mathbf V$随机初始化的方差$\sigma$

   - 输出：模型参数$w_0,\mathbf{\vec w},\mathbf V$

   - 算法步骤：

     - 参数初始化：

     - 初始化$\mathbf{\vec e},\mathbf Q$：

     - 迭代直至目标函数收敛或者达到指定步数，每一轮迭代过程为：

       - 更新$w_0$：

       - 更新$w_i,i=1,2\cdots,K$：

       - 更新$v_{i,l},i=1,\cdots,K;l=1,\cdots,d$：

         外层循环为$l$，内层循环为$i$。这是为了充分利用$q(\mathbf{\vec x},l;\mathbf \Theta)$。

2. 论文实验给出了 `SGD` 和 `ALS` 优化算法的比较结果。可以看到：

   - `SGD` 的优化效果很大程度上取决于学习率和迭代次数。

     当精心挑选合适的学习率、足够大的迭代次数（根据验证集执行早停策略从而防止过拟合），`SGD` 可以达到 `ALS` 的效果。

   - `ALS` 不需要精心的、耗时的搜索合适的学习率，就可以达到很好的效果。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205150.png?imageslim">
   </p>
   

## 四、FFM模型

1. 考虑一组特征：“性别、年龄、城市”。为简化讨论，假设：“年龄”取值集合为 `[18,19,20]`， “城市” 取值集合为 `[北京,上海,广州,深圳]` 。

   把离散特征 `one-hot` 编码，设各 `binary`特征分别记作：`male,female,age18,age19,age20,bj,sh,gz,sz`， `y` 表示样本标签（`-1` 表示不感兴趣，`+1` 表示感兴趣）。

   记作：

   - `POLY2` 模型为：

     参数个数为$O(K^2)$，计算复杂度为$O(K^2)$。

   - `FM` 模型为：

     参数个数为$O(K\times d)$，计算复杂度为$O(K\times d)$。

     - `FM` 要优于 `POLY2` ，原因是：交叉特征非零的样本过于稀疏使得无法很好的估计$w_{i,j}$；但是在 `FM` 中，交叉特征的参数可以从很多其它交叉特征中学习，使得参数估计更准确。

       如：交叉特征$(\text{male}=1,\text{age19=1})$从未出现过，因此在 `POLY2` 模型中参数$w_{\text{male=1,age19=1}}$根本无法学习。

       而在 `FM` 模型中 `male=1` 的 `representation` 向量可以从以下交叉特征的样本中学习：

       `age19=1` 的 `representation` 向量可以从交叉特征$(\text{age19=1}=1,\text{gz=1})$的样本中学习。

     - 另外 `FM` 还可以泛化到没有见过的交叉特征。

       如：交叉特征$(\text{male}=1,\text{age19=1})$从未在训练样本中出现过，但是在预测阶段 `FM` 模型能够较好的预测该交叉特征的测试样本。

2. 在 `FM` 模型中，每个特征的 `representation` 向量只有一个。如：计算$\hat w_{\text{male=1,age=18}},\hat w_{\text{male=1,age=20}},\hat w_{\text{male=1,sh=1}}$用到的是同一个向量$\mathbf{\vec v}_{\text{male=1}}$。

   论文`Field-aware Factorization Machines for CTR Prediction` 提出的 `FFM` 算法认为：`age=18` 和 `sh=1` 之间的区别，远远大于 `age=18` 和 `age=20` 之间的区别。

   因此，`FFM` 算法将特征划分为不同的域`field`。其中：

   - 特征$\text{male=1,female=1}$属于性别域 `gender field` 。
   - 特征$\text{age18=1,age19=1,age20=1}$属于年龄域 `age field` 。
   - 特征$\text{bj=1,sh=1,gz=1,sz=1}$属于城市域 `city field` 。

   `FFM` 中每个特征的 `representation` 向量有多个，用于捕捉该特征在不同`field` 中的含义。

   如：特征 `male=1` 具有两个 `representation` 向量：

   - 当用于计算 `age field` 域的交叉特征时，采用$\mathbf{\vec v}_{\text{male=1,age}}$
   - 当用于计算 `city field` 域的交叉特征时，采用$\mathbf{\vec v}_{\text{male=1,city}}$

   其它特征依次类推。

   注意：`male=1` 没有 `gender field` 域的交叉特征。因为 `one-hot` 编码的原因 ，交叉特征`male=1,female=1` 一定不能同时存在，所以不用计算$\hat w_{\text{male=1,female=1}}$。

### 4.1 模型

1. `FFM` 模型用数学语言描述为：

   其中：$f_i$表示第$i$个特征所属的 `field` ，一共有$F$个`field` （$1\le F\le K$）。

   参数数量为$O(K\times d\times F)$，计算复杂度为$O(\bar K^2\times d)$，其中$\bar K$是样本中平均非零特征数。

2. 和 `FM` 相比，通常 `FFM` 中 `representation` 向量的维度要低的多。即：

  $d_{\text{FFM}} \ll d_{\text{FM}}$

3. `FFM` 每个`representation` 向量的学习只需要特定 `field` 中的样本。

   如：学习$\mathbf{\vec v}_{\text{male=1,age}}$时，只需要考虑交叉特征$(\text{male=1,age18=1}),(\text{male=1,age20=1})$的样本，而不需要考虑交叉特征$(\text{male}=1,\text{sh=1}),\;(\text{male}=1,\text{sz=1})$的样本。

   > 因为上面的示例中，交叉特征$(\text{male=1,age19=1})$未出现；如果该交叉特征出现，则也需要考虑该交叉特征的样本。

4. 和 `FM` 相同，`FFM` 模型也可以用于求解分类问题（预测各评级的概率），也可以用于求解回归问题（预测各评分大小）。

   - 对于回归问题，其损失函数为`MSE`均方误差：

   - 对于二分类问题（分类标签为 `-1,+1` ），其损失函数为交叉熵：

     .

### 4.2 优化算法

1. `FFM` 模型采用随机梯度下降算法来求解，使用 `AdaGrad` 优化算法。

   在每个迭代步随机采样一个样本$(\mathbf{\vec x},y)$来更新参数，则$\mathcal L$退化为：

  $\mathcal L = \log (1+\exp(-y\phi(\mathbf{\vec x}))) + \sum_{\theta\in \mathbf \Theta} \lambda_{\theta} \times \frac 12 \theta^2$

   统一所有的$\lambda_\theta=\lambda$，则有：

   其中：$\sum_{f_j= f}$表示`field f` 内的所有特征；$\kappa$表示：

  $\kappa = \frac{\partial \log(1+\exp(-y\phi))}{\partial \phi} = -\frac{y}{1+\exp(y\phi(\mathbf{\vec x}))}$

   - 对梯度的每个维度，计算累积平方：

     其中$g_{w_i}$是$\mathbf{\vec g}_{\mathbf w}$的第$i$个分量，$i=1,2,\cdots,K$；$g_{v_{i,f,l}}$是$\mathbf{\vec g}_{\mathbf{ v}_{i,f}}$的第$l$个分量，$l=1,2,\cdots,d$。

   - 更新参数：

    $\theta \leftarrow \theta - \frac{\eta}{\sqrt{G_\theta}} g_{\theta}$

     其中$\eta$是用户指定的学习率，$\theta \in \{w_0,\mathbf {\vec w},\mathbf{\vec v}_{i,f}\}$。

2. 模型参数需要合适的初始化。论文推荐：

   -$\mathbf{\vec v}_{i,f}$从均匀分布$[0,1/\sqrt d]$中随机初始化
   -$G_\theta$初始值为1，这是为了防止在迭代开始时$\frac {1}{\sqrt{G_\theta}}$太大，从而导致前进方向较大的偏离损失函数降低的方向。

   原始论文并没有$w_0,\mathbf {\vec w}$的项，因此个人推荐采用 零均值、方差为$\sigma$的正态分布来初始化它们。

3. 论文推荐采用样本级别的归一化，这可以提升模型泛化能力。

   > 注：如果采用 `Batch normalization` 效果可能会更好。论文未采用 `BN`，是因为论文发表时 `BN` 技术还没有诞生。

4. `FFM` 的 `AdaGrad` 优化算法：

   - 输入：

     - 训练集$\mathbb S$
     - 学习率$\eta$
     - 最大迭代步$T$
     - 初始化$w_0,\mathbf{\vec w }$的参数$\sigma$

   - 输出：极值点参数$\mathbf \Theta^*$

   - 算法步骤：

     - 初始化参数和$G_{\theta}$：

     - 迭代$T$步，每一步的过程为：

       - 随机从$\mathbb S$中采样一个样本$(\mathbf{\vec x},y)$

       - 计算$\kappa$：

        $\kappa = -\frac{y}{1+\exp(y\phi(\mathbf{\vec x}))}$

       - 计算$g_{w_0},G_{w_0}$，更新$w_0$

       - 遍历所有的项：$i=1,\cdots,K$：

         - 计算$g_{w_i},G_{w_i}$，更新$w_i$
         - 遍历所有的项：$j=i+1,\cdots,K$
           - 计算$\mathbf{\vec g}_{v_{i,f}}$
           - 遍历所有的维度：$l=1,\cdots,d$：计算$G_{i,f,l}$，并更新$v_{i,f,l}$

### 4.3 field 分配

1. `FFM` 模型需要为每个特征分配一个 `field`。

   - 离散型特征 `categorical` ：通常对离散型特征进行 `one-hot` 编码，编码后的所有二元特征都属于同一个 `field` 。

   - 数值型特征 `numuerical`：数值型特征有两种处理方式：

     - 不做任何处理，简单的每个特征分配一个`field` 。

       此时$F=K$， `FFM`退化为 `POLY2` 模型。

     - 数值特征离散化之后，按照离散型特征分配 `field` 。

       论文推荐采用这种方式，缺点是：

       - 难以确定合适的离散化方式。如：多少个分桶？桶的边界如何确定？
       - 离散化会丢失一些信息。

   - 离散集合特征`categorical set`（论文中也称作 `single-field`特征）：所有特征都属于同一个`field`，此时$F=1$， `FFM` 退化为 `FM` 模型。

     如 `NLP` 情感分类任务中，特征就是单词序列。

     - 如果对整个`sentence` 赋一个`field`，则没有任何意义。
     - 如果对每个`word` 赋一个 `field`，则$F$等于词典大小，计算复杂度$O(FKd)$无法接受。

### 4.4 实验效果

1. 实验效果的评估指标是负的对数似然，该指标越小越好：

  $\log\text{loss} = \frac 1N \sum_{i=1}^N \log(1+\exp(-y_i\phi(\mathbf{\vec x}_i)))$

   其中$N$为训练集或者验证集的样本数。

2. 论文研究了超参数$d$（`representation` 向量维度）、$\lambda$（正则化项系数）、$\eta$（学习率）的影响。所有结果都是在验证集上得到。

   - 超参数$d$的实验效果如下图所示。

     第一列为不同$d$的取值（论文中用 `k` 这个不同的符号），第二列为平均每个`epoch` 的计算时间，第三列为验证集的 `logloss` 。

     可以看到：不同的`representation` 向量维度，对模型的预测能力影响不大，但是对计算代价影响较大。

     - 由于采用了 `SSE` 指令集，所以$d=1,2,3$时每个 `epoch` 计算时间几乎相同。
     - 所以在 `FFM` 中，通常选择一个较小的$d$值。

     <p align="center">
        <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205206.png?imageslim">
     </p>
     

   - 超参数$\lambda$的实验效果如下图所示。

     可以看到：

     - 如果正则化系数太小，则模型太复杂，容易陷入过拟合。
     - 如果正则化系数太大，则模型太简单，容易陷入欠拟合。

     一个合适的正则化系数不大不小，需要精心挑选。

     <p align="center">
        <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205212.png?imageslim">
     </p>
     

   - 学习率$\eta$的实验效果如下图所示：

     可以看到：

     - 如果学习率较小，虽然模型可以获得一个较好的性能，但是收敛速度很慢。
     - 如果学习率较大，则目标函数很快下降，但是目标函数不会收敛到一个较低的水平。

     <p align="center">
        <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205218.png?imageslim">
     </p>
     

3. `FFM` 对于训练 `epoch` 次数很敏感。为解决该问题，论文推荐对 `FFM` 执行早停策略：

   - 首先将数据集拆分为训练集、验证集。
   - 在通过训练集训练的每个 `epoch` 结束时，计算验证集的 `logloss` 。
   - 如果验证集的 `logloss` 上升，则：
     - 记录当前已训练的 `epoch` 次数$\text{epoch}_{best}$
     - 停止当前训练
     - 用全量训练数据重新训练模型$\text{epoch}_{best}$个 `epoch` 。

   该方案存在一个潜在的缺点：`logloss` 对 `epoch` 次数高度敏感，以及验证集上的最佳 `epoch` 不一定是测试集上的最佳 `epoch`。因此早停得到的模型无法保证在测试集上取得最小的 `logloss` 。

4. 论文在 `Criteo` 和 `Avazu` 数据集上比较了不同算法、不同优化方式、不同参数的结果。

   `Criteo` 和 `Avazu` 数据集是`Kaggle` 提供的，其中有两个测试集：

   - `public test`：当提交模型时，模型在该测试集上的得分和排名立即计算出来。

   - `private test` ：当提交模型时，模型在该测试集上的得分和排名必须等竞赛结束时刻才揭晓。

     这是为了防止选手的模型对 `public test` 过拟合。

   论文选择了四种算法：`LM` 模型（线性模型）、`POLY2` 模型、`FM` 模型、`FFM` 模型；选择了三种优化算法：`SG` （随机梯度下降）、`CD`（坐标下降）、`Newton`（牛顿法）、`ALS` ；选择了不同参数。

   - `LIBFM` 支持`SG,ALS,MCMC` 三种优化算法，但是论文发现 `ALS` 效果最好。因此这里 `LIBFM` 使用 `ALS` 优化算法。
   - `FM`、`FFM` 都是论文基于 `SG` 优化算法来实现的。同时对于 `SG` 优化算法采取早停策略。
   - 对于非 `SG` 优化算法，停止条件由各算法给出合适的停止条件。

   从实验结果可以看到：

   - `FFM` 模型 效果最好，但是其训练时间要比 `LM` 和 `FM` 更长； `LM` 效果比其它模型都差，但是它的训练要快得多； `FM` 是一种较好的平衡了预测效果和训练速度的模型。

     因此这就是效果和速度的平衡。

   - `POLY2` 比所有模型都慢，因为其计算代价太大。

   - 从两种 `FM` 的优化方法可见，`SG` 要比 `ALS` 优化算法训练得快得多。

   - 逻辑回归是凸优化问题，理论上 `LM`和 `POLY2` 的不同优化算法应该收敛到同一个点，但实验表明并非如此。

     原因是：我们并没有设置合适的停止条件，这使得训练过程并没有到达目标函数极值点就提前终止了。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205228.png?imageslim">
   </p>
   

5. 论文比较了其它数据集上不同模型的表现。其中：

   - `KDD2010-bridge,KDD2012,adult`数据集包含数值特征和离散特征，论文将数值特征执行了离散化。
   - `cod-rna,ijcnn` 数据集仅仅包含数值特征 ，论文将数值特征进行两种处理从而形成对比：
     - 将数值特征离散化
     - 每个数值特征作为一个`field` （称作 `dummy fields` ）
   - `phishing` 数据集仅仅包含离散特征。

   实验结果表明：

   - `FFM` 模型几乎在所有数据集上都占优。这些数据集的特点是：

     - 大多数特征都是离散的
     - 经过 `one-hot` 编码之后大多数特征都是稀疏的

   - 在 `phishing,adult` 数据集上 `FFM`几乎没有优势。原因可能是：这两个数据集不是稀疏的，导致 `FFM,FM,POLY2` 这几个模型都具有几乎相同的表现。

   - 在 `adult` 数据集上`LM` 的表现和 `FFM,FM,POLY2` 几乎完全相同，这表明在该数据集上特征交叉几乎没有起到什么作用。

   - 在 `dummy fields` 的两个数据集上 `FFM` 没有优势，说明 `field` 不包含任何有用的信息。

   - 在数值特征离散化之后，尽管 `FFM`比 `FM` 更有优势，但还是不如使用原始数值特征的 `FM` 模型。

     这说明数值特征的离散化会丢失一些信息。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205233.png?imageslim">
   </p>
   

6. 从实验中总结的 `FFM` 应用场景：

   - 数据集包含离散特征，且这些离散特征经过`one-hot` 编码。
   - 经过编码后的数据集应该足够稀疏，否则 `FFM` 无法获取较大收益（相对于 `FM` ）。
   - 不应该在连续特征的数据集上应用 `FFM`，此时最好使用 `FM` 。

## 五、GBDT-LR 模型

1. 论文 `Practical Lessons from Predicting Clicks on Ads at Facebook` 提出了 `GBDT-LR` 模型，该模型利用 `GBDT` 作为特征抽取器来抽取特征、利用 `LR` 作为分类器来执行分类预测。

   实验结果表明：`GBDT-LR` 比单独的 `GBDT`模型，或者单独的 `LR` 模型都要好。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205255.png?imageslim">
   </p>
   

2. 传统的搜索广告根据用户`query` 来检索候选广告，检索依据是：广告是否显式的或隐式的匹配用户 `query` 。

   而 `Facebook` 中的广告不是和用户 `query`关联，而是和广告主指定的人群定向（如：年龄、性别、城市等统计特性，体育、财经、游戏等兴趣特性）相关联。这使得每个用户能够匹配大量的候选广告。

   如果每次用户的广告请求都对这些候选广告做预测，则时间成本太高（广告检索有时间约束，时间太长则不可接受）。因此 `Facebook` 构建了一组分类器：

   - 前期的分类器比较简单，处理候选广告多，计算成本低，同时预测准确率较差。
   - 后期的分类器比较复杂，处理候选广告少，计算成本高，同时预测准确率较好。
   - 每个分类器都将它们预测的低 `pCTR`广告截断，从而降低下游分类器的处理数据量

   通过这种分类器级联的方式层层过滤，最终每个用户只需要对少量广告的点击率进行预测。

   本论文关注的是最后一个分类器，它为最终候选广告集合生成点击率预估。

### 5.1 评估指标

1. 论文提出归一化熵 `Normalized Entropy:NE` 来评估模型。

2. 假设样本集合有$N$个样本，样本集合的经验`CTR` 为$\bar p$（它等于所有正类样本数量除以总样本数量）。

   假设第$i$个样本预测为正类的概率为$p_i$，其真实标签为$y_i\in \{-1,+1\}$。

   - 定义背景点击率 `background CTR`为样本集合经验 `CTR` ，它的熵定义为背景熵：

    $H_{bg} = - p\log p - (1-p)\log(1-p)$

     背景熵衡量了样本集合的类别不平衡程度，也间接的衡量了样本集合的预测难度。

     类别越不均衡预测难度越简单，因为只需要将所有样本预测为最大的类别即可取得非常高的准确率。

   - 定义模型在样本集合熵的损失函数为：

    $\mathcal L = - \sum_{i=1}^N\left(\frac{1+y_i}{2}\log p_i + \frac{1-y_i}{2}\log (1-p_i)\right)$

     每个样本的损失为交叉熵。

   - 定义归一化熵 `NE` 为：模型在所有样本的平均损失函数除以背景熵。

    $\text{NE} = \frac{\mathcal L /N}{H_{bg}}$

     - 分子需要除以$N$是为了剔除样本集合大小的影响。

     - `NE` 相对损失函数的优势在于：`NE` 考虑了样本集预测的难易程度。

       在平均损失相同的情况下，样本集越不均衡则越容易预测，此时 `NE` 越低。

3. `AUC` 也是评估模型能力的一个很好的指标，但是 `AUC` 反应的模型对样本的排序能力：`auc=0.8` 表示 80% 的情况下，模型将正样本预测为正类的概率大于模型将负样本预测为正类的概率。

   假设我们预估的 `pCTR`$p_i$是有偏的（相比较经验 `CTR`），此时我们需要乘以一个系数$\gamma$来校准 `calibration` 。

   - 在校准前后，模型的 `AUC` 保持不变。因为对所有正负样本的 `pCTR`乘以一个系数不改变它们的排序 `rank` 。
   - 在校准前后，模型的 `NE` 得到改善。因为校准后的 `pCTR` 分布与样本的标签分布距离更近。

### 5.2 GBDT 特征抽取

1. 有两种最简单的特征转换方式：

   - 连续特征离散化：将连续特征的取值映射到一个个分散的分桶里，从而离散化。

     这里桶的数量和边界难以确定，通常有两种方法：

     - 通过人工根据经验来设定分桶规则
     - 利用后续的分类器来显式的学习这个非线性映射，从而学习出有意义的分桶数量和边界。

   - 离散特征交叉：类似 `FM` 模型采用二路特征交叉（或者更高阶）来学习高阶非线性特征。

     对于连续特征可以先离散化之后再执行特征交叉，如 `kd` 树就是典型的代表。

   `Boosted decisition tree:BDT` 就是结合了上述两种方式的一个强大的特征提取器。

2. 对于 `BDT`，我们将每棵子树视为一个离散特征，其叶结点的编号为特征的取值并执行 `one-hot` 编码。

   假设 `BDT` 有两棵子树，第一棵有 `3` 个叶结点，第二棵有`2` 个叶结点。则样本提取后有两个特征：第一个特征取值为 `{1,2,3}`，第二个特征取值为 `{1,2}` 。

   假设某个样本被划分到第一棵子树的叶结点 `2`，被划分到第二棵子树的叶结点 `1`，则它被转换后的特征为：`[0,1,0,1,0]`。其中：前三项对应于第一个离散特征的 `one-hot`，后两项对应于第二个离散特征的 `one-hot` 。

3. 论文采用梯度提升树 `Gradient Boosting Machine:GBM` 来训练每棵子树，因此这种特征提取方式可以视为基于决策树的有监督特征编码：

   - 它将一组实值向量 `real-valued vector` 转换为一组二元向量`binary-valued vector` 。
   - 每棵子树从根节点到叶节点的遍历表示某些特征转换规则。
   - 在转换后的二元向量上拟合线性分类器本质上是学习每个规则的权重。

4. 实验结果表明：采用 `GBDT-LR` 的模型相比于单独的 `GBDT` 提升了 3.4%。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205313.png?imageslim">
   </p>
   

### 5.3 数据新鲜度freshness

1. `CTR` 预估模型通常部署在数据分布随时间变化的动态环境中。训练数据和测试数据的时间距离越近，二者的数据分布差距越小，效果也越好。

   论文用某一天的样本数据训练一个模型，然后用该模型评估当天、一天后、两天后、... 六天后的测试数据。

   结果表明：模型需要每天根据最新的样本进行重新训练。与每周训练一个模型相比，每天训练一个模型可以提升模型效果大约 1%（以 `NE` 为指标）。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205324.png?imageslim">
   </p>
   

2. 考虑数据新鲜度，我们需要用最新的样本更新模型。有两种更新策略：

   - 每天用最新的数据重新训练模型。当模型比较大时，可能要花费几个小时甚至24个小时以上来训练。
   - 每天或者每隔几天来训练特征提取器 `BDT` ，但是用最新的数据在线训练 `LR` 线性分类器。

### 5.4 学习率

1. 当通过`mini-batch` 梯度下降法来训练在线 `LR` 分类器时，学习率的设定非常关键。有几种学习率设定方式：

   - `per-coordinate` 基于特征的学习率：在第$t$次迭代特征$i$的学习率为：

    $\eta_{t,i} = \frac{\alpha}{\beta +\sqrt{\sum_{j=1}^t (\mathbf{\vec g}_j)_i^2}}$

     其中：$\alpha,\beta$为模型的超参数；$(\mathbf{\vec g}_j)_i$为第$j$次迭代的梯度在特征$i$的分量。

     - 特征$i$的梯度越大，说明该特征方向波动较大，则学习率越小，学习速度放慢。
     - 特征$i$的梯度越小，说明该特征方向波动较小，则学习率越大，学习速度加快。

   - `per-weight` 维度加权学习率：在第$t$次迭代特征$i$的学习率为：

    $\eta_{t,i} = \frac{\alpha}{ {n_{t,i}}}$

     其中：$\alpha$为模型的超参数，$n_{t,i}$为截至到第$t$次迭代特征$i$上有取值的所有样本数量。在特征上有取值表示：`one-hot` 之后的取值为 1 。

     设样本为$(\mathbf{\vec x},y)$，模型参数为$\mathbf{\vec w}$。 其中：

    $\mathbf{\vec x}=(x_1,\cdots,x_n)^T, \mathbf{\vec w}=(w_1,\cdots,w_n)^T$

     对于广义线性模型：

    $\hat y=f(z),z = \sum_{i=1}^n x_i \times w_i$

     设损失函数为$L(y,\hat y)$。则有：

     因此可以看到，对于罕见特征由于大多数情况下特征取值$x_i = 0$，因此特征权重$w_i$几乎很难有更新的机会。

     - 特征$i$上有取值的样本越多，则可供学习的样本也多，则学习率越小，学习速度放慢。
     - 特征$i$上有取值的样本越少，则可用学习的样本也少，则学习率越大，学习速度加快。

   - `per-weight square root` 基于权重开方的学习率：在第$t$次迭代特征$i$的学习率为：

    $\eta_{t,i} = \frac{\alpha}{\sqrt{n_{t,i}}}$

- `global` 全局学习率：在第$t$次迭代所有特征的学习率都为：

 $\eta_{t,i} = \frac{\alpha}{\sqrt t}$

- `constant` 常量学习率：在第$t$次迭代所有特征的学习率都为：

 $\eta_{t,i} = \alpha$

1. 论文验证了这几种学习率的效果，其中超参数$\alpha,\beta$通过`grid search` 来得到。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205333.png?imageslim">
   </p>
   

   实验结果如下表所示。结果表明：`per-coordinate` 方法获得最好的表现，而 `per-weight` 效果最差。

   - 全局学习率表现不佳，其主要原因是：每个特征上训练样本数量不平衡。

     一些常见特征上（如：“是否男性” 特征）的样本数量较多，而另一些罕见特征（如：“是否明星” ）上的样本数量较少。在全局学习率策略下，罕见特征学习率太快降低到很小的值，使得最优化难以收敛到最优点。

   - 虽然 `per-weight` 策略解决了该问题，但是它仍然表现不佳。主要原因是：虽然它对罕见特征的学习率控制较好，但是它对常见特征的学习率控制较差。它太快的降低了常见特征的学习率到一个很小的值，在算法收敛到最优点之前训练就过早终止了。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205343.png?imageslim">
   </p>
   

### 5.5 在线训练框架

1. 在线训练框架最重要的是为模型提供在线学习的标注样本。

   点击行为比较好标记，但是“不点击”行为难以标记。因为广告并没有一个“不点击”按钮来获取不点击的信息。

   因此，如果一个曝光在一个时间窗内未发生点击行为，则我们标记该次曝光是未点击的。

   之所以要设定一个时间窗，是因为广告曝光和用户点击之间存在时间差。这里有两个原因：

   - 给用户曝光一个广告后，用户不会立即点击。如：用户会简单浏览广告的内容再决定是否点击。对于视频类广告，用户甚至会观看完整视频之后再决定是否点击。

     因此曝光事件和点击事件这两个事件存在时间差。

   - 广告系统的曝光日志和点击日志通常都是分开的、独立的实时数据流。这两个数据流回传到在线训练系统可能并不是同步的，存在数据回传时间差。

2. 给定一个曝光，我们需要等待一段时间来确认它是否被用户点击。

   - 如果等待时间内收到了曝光的点击信息，则该曝光标记为正样本。
   - 如果等待时间内未收到曝光的点击信息，则该曝光标记为负样本。

   等待的时长需要精心选择：

   - 如果时间太长则实时训练数据延迟较大，数据 `freshness` 较差。

     同时，为了存储更长时间的曝光数据内存代价也较高。

   - 如果时间太短则因为没有等到点击信息回传，部分正样本被误判为负样本。这会导致实时样本集的经验 `CTR` 比真实 `CTR` 偏低。

     这种经验`CTR` 的偏差也可以检测并矫正。

   因此，需要在数据的 `freshness` 和点击覆盖率（能匹配上曝光的点击的数量占总点击数量之比） 之间平衡。

   通过挑选合适的时长，可以降低经验的 `CTR` 偏差到百分之1以下，同时内存代价也可以接受。

3. `Facebook` 在线训练框架如下图所示：

   - 用户浏览 `Facebook` 时向 `Ranker`模块发送一个广告请求，请求中包含 `request ID` 。
   - `Ranker` 模块根据在线模型的预测结果，向用户返回一个广告，同时在曝光实时数据流中增加一条曝光日志。
   - 如果用户点击广告，则前端打点系统上报点击事件，在后台点击实时数据流中增加一条点击日志。
   - 通过 `Oneline Joiner` 模块实时获取最近一个时间窗的曝光、点击日志，并拼接样本特征来构造训练集。
   - `Trainer` 模块根据构造的训练集执行在线训练，训练好的模型部署到线上供 `Ranker` 模块使用。

   这会形成一个数据闭环，使得模型能够捕捉到最新的数据分布。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205353.png?imageslim">
   </p>
   

4. 在线训练需要增加对实时训练数据的异常保护。

   假设实时训练数据出现问题（如：前端打点上报出现异常、`Online Joiner` 工作异常等），导致大量的点击数据丢失。那么这批实时训练样本存在缺陷，它们的经验 `CTR` 非常低甚至为 0 。

   如果模型去学习这样一批样本，则模型会被带偏：对任何测试样本，模型都会预测出非常低、甚至为零的点击率。

   根据广告点击价值 `eCPM = BID x pCTR`，一旦预估点击率 `pCTR` 为零则广告的 `eCPM` 为零。那么这些广告几乎没有竞争力，竞争失败也就得不到曝光机会。

   因此需要增加实时训练数据的异常检测机制。如：一旦检测到实时训练数据的分布突然改变，则自动断开在线训练流程。

### 5.6 优化技巧

1. 论文提出了一些优化技巧来降低数据规模，从而节省训练代价，加快训练速度。

#### 5.6.1 子树规模

1. 在 `GBDT-LR` 模型中，子树的数量越大模型表现越好，但是计算代价、内存代价越高。

   但是随着子树的增多，每增加一棵子树获得的效益是递减的。这就存在平衡：新增子树的代价和效益的平衡。

   如下图所示，可以看到：`NE` 随着子树数量的增加而下降，但是最后增加的1000棵子树获得的效益很低。

   - `NE submodel0, NE submodel1`使用全量训练数据，不同的超参数来训练
   - `NE submodel2` 使用 `1/4` 的训练数据，模型在 `1000` 棵子树之后出现过拟合（损失函数增加）。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205404.png?imageslim">
   </p>
   

#### 5.6.2 特征数量

1. 在 `GBDT-LR` 模型中，样本特征越大模型表现越好，但是计算代价、内存代价越高。

   但是随着特征的增多，尤其是无效特征的增多，每增加一个特征获得的效益是递减的。这就存在平衡：新增特征的代价和效益的平衡。

2. 为衡量特征数量的影响，我们首先对特征重要性进行排序，然后考察 `topK` 重要性特征的效果。

   可以通过 `Boosting Feature Importance` 来衡量特征重要性。有三种度量方法（如 `XGBoolst/LightGBM` ）：

   - `weight`：特征在所有子树中作为分裂点的总次数
   - `gain`：特征在所有子树中作为分裂点带来的损失函数降低总数
   - `cover`：特征在所有子树中作为分裂点包含的总样本数

   通常少数特征贡献了较多的重要性，大多数特征贡献了较少的重要性。如下图所示，`top 10` 特征贡献了大于一半的重要性，最后 300 个特征贡献了不到 1% 的重要性。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205412.png?imageslim">
   </p>
   

3. 论文考察了`top10,top20,top50,top100,top200` 重要性的特征，结果如下图。

   可以看到，随着特征增加模型的 `NE` 在降低。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205418.png?imageslim">
   </p>
   

#### 5.6.3 降采样

1. `Facebook` 每天的广告曝光量非常大。即使是每个小时，数据样本也可能上亿。在线学习需要对样本进行采样来降低数据量，从而提升训练速度。

2. 有两种降采样技术：

   - 均匀降采样：所有样本都以同一个概率$p_{sample}$来随机采样。

     该方法容易实现，且采样后的样本分布和采样前保持不变。这样使得训练数据集的分布基本和线上保持一致。

     论文考察了几种采样率 ： `0.001,0.01,0.1,0.5,1` 。结果表明：更多的数据带来更好的模型。但是采用 `10%` 的训练样本相对于全量样本仅仅损失了 1% 的预测能力（经过模型校准之后甚至没有降低），而训练代价降低一个量级。

     <p align="center">
        <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205454.png?imageslim">
     </p>
     

   - 负降采样：保留所有的正样本，仅负样本以概率$p_{sample}$来随机采样。

     该方法可以缓解类别不平衡问题。但是，采样后的样本分布和采样前不再相同，导致训练集的分布和线上不再保持一致。因此需要对模型进行校准。

     论文考察了几种采样率 ： `0.1,0.01,0.001,0.0001,...` 。结果表明：最佳负采样率在 `0.025`。

     <p align="center">
        <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205505.png?imageslim">
     </p>
     

### 5.7 历史统计特征

1. 模型中用到的特征分类两类：上下文特征和历史统计特征。

   - 上下文特征：曝光广告的当前上下文信息。如：用户设备、用户所在页面的信息等等。
   - 历史统计特征：广告的历史统计行为，或者用户的历史统计行为。如：广告的上周平均点击率，用户的历史平均点击率。

2. 取 `top K` 重要性的特征，通过查看历史统计特征的占比来评估这两类特征的重要程度。

   结果表明：历史统计特征比上下文特征更重要。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205513.png?imageslim">
   </p>
   

3. 训练三种模型：仅仅包含上下文特征、仅仅包含历史统计特征、包含完整的特征。

   这三种模型的表现如下。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205519.png?imageslim">
   </p>
   

4. 虽然实验结果表明：历史统计特征要重要得多。但是，上下文特征对于解决冷启动问题非常重要。

   对新广告和新用户，上下文特征对于点击率预测是必不可少的。

5. 训练两种模型来评估模型对数据的`freshness` 依赖性：仅仅包含上下文特征、仅仅包含历史统计特征。

   实验结果表明：上下文特征比历史统计特征更为依赖数据 `freshness` 。这比较符合直觉：上下文特征刻画了事件发生的瞬间用户的行为，历史统计特征刻画了更长期的用户累积行为，因此历史统计特征更稳定。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603205746.png?imageslim">
   </p>
   

### 5.8 模型校准 calibration

1. 模型校准分为两类：

   - 模型预测能力不足导致的校准
   - 训练数据分布和线上数据分布不一致导致的校准

   相比较第一类情况，第二类情况的校准系数偏离 `1.0` 更为严重，因此也更需要执行校准。

2. 给定样本集$\mathbb D = \{(\mathbf{\vec x}_1,y_1),\cdots,(\mathbf{\vec x}_N,y_N)\}$，假设模型预估的 `pCTR` 分别为：$(\hat y_1,\cdots,\hat y_N)$。则样本集的经验 `CTR` 为：

  $\overline{\text{CTR}} = \frac{\sum_{i=1}^N \mathbb I(y_i =1)}{N}$

   样本集的预估平均 `CTR` 为：

  $\overline{\text{CTR}}_{pred} = \frac{\sum_{i=1}^N\hat y_i}{N}$

   定义校准系数为：预估平均 `CTR` 和经验 `CTR` 之比：

  $ratio = \frac{\overline{\text{CTR}}_{pred}}{\overline{\text{CTR}}}$

   它衡量了模型预期点击次数和实际观察到的点击次数之比，它的值与 1 的差异越小，则模型的表现越好。

   假设模型预估的结果为$\hat y$，则校准后的预估结果为：

  $\hat y_{new} = \frac{\hat y}{ratio}$

3. 负降采样可以加快训练速度，改善模型能力。但是负采样中的训练数据分布和线上数据分布不一致，因此必须对模型进行校准。

   假设采样之前样本集的平均 `CTR` 为 `0.1%`。当执行采样率为 `0.01` 的负降采样之后，由于正样本数量不变、负样本数量降低到之前的 `0.01` ，因此采样后的样本集的平均 `CTR` 为 `10%` 。

   此时需要校准模型，使得模型的预估平均 `CTR` 尽可能与线上的平均 `CTR` 一致。假设模型预估的结果为$\hat y$，则校准后的预估结果为：

  $\hat y_{new} = \frac{\hat y}{\hat y + (1-\hat y)/s}$

   其中$s$为负采样比例。

## 六、FTRL模型

1. 谷歌2013年发表的论文 `Ad Click Prediction: a View from the Trenches` 并不关注于如何解决 `CTR` 预估本身，而是关注`CTR` 预估相关的问题，如：内存优化策略、模型性能分析、预测置信度、模型校准等问题。

   系统整体框架如图所示。

   - `Probalistic Feature Inclusion`：概率性特征引入模块，主要用于降低特征数量来优化内存。
   - `Parallelized Model Training`：多模型并行训练模块，主要用于超参数选择中，提高多模型并行训练的效率。
   - `Calibration`：模型校准模块，主要用于对校准模型的系统性预测偏差。
   - `Progressive Validation Metrics`：模型性能分析模块，主要用于分析模型在验证集上的性能。
   - `Model Serving Replicas`：模型部署模块，主要用于部署模型到线上。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603210036.png?imageslim">
   </p>
   

### 6.1 内存优化

#### 6.1.1 稀疏解

1. 在2013年左右，大多数在线学习框架使用逻辑回归模型并采用在线梯度下降 `Oneline gradient descent:OGD` 算法来训练。

   > `OGD` 就是单个样本的随机梯度下降算法。

   设样本$\mathbf{\vec x} = (x_1,x_2,\cdots,x_d)^T$，其标记为$y \in \{0,1 \}$；模型参数为$\mathbf{\vec w} =(w_1,\cdots,w_d)^T$。则：

   - 逻辑回归预测的点击概率为：

   - 交叉熵损失函数为：

    $l = -y\log p - (1-y)\log(1-p)$

   - 损失函数的梯度为：

    $\nabla_{\mathbf{\vec w}} l = (p-y) \mathbf{\vec x}$

   当采用 `OGD` 时，设第$t$轮迭代的样本为$(\mathbf{\vec x}_t,y_t)$，模型参数为$\mathbf{\vec w}_t$，则有：

2. 在线训练算法需要关注三个方面的因素：

   - 训练速度快。如果训练速度太慢，无法保证在线训练的实时性。
   - 参数稀疏性。模型参数稀疏，即大量的参数为零。这带来两个好处：
     - 内存代价低，因为只需要存储非零的参数值。
     - 推断时，计算速度快，因为只需要计算参数非零对应的特征。
   - 模型表现好。如果模型预测能力严重下降，则没有应用价值。

3. `OGD` 算法的训练速度很快，但是它并不能产生稀疏解。由于随机梯度下降中采用的梯度不再是真实梯度的方向，因此即使增加了 `L1` 正则化项也无法得到稀疏解。

   - `FOBOS` 、梯度截断等方法能够产生稀疏解，但是它们降低了模型的预测能力。
   - `RDA` 在模型的预测能力和稀疏解之间取得平衡。
   - `Follow The (Proximally) Regularized Leader: FTRL` 既取得稀疏解，又能保证模型的预测能力。

   下表中，`aucloss = 1 - auc` 。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603210630.png?imageslim">
   </p>
   

4. 记参数的梯度为$\mathbf{\vec g} = (g_1,\cdots,g_d)^T$。设第$t$轮迭代的参数梯度为$\mathbf{\vec g}_t$，其第$i$维分量为$g_{t,i}$。

   - 在 `OGD` 中，参数更新方程为：

    $\mathbf{\vec w}_{t+1} = \mathbf{\vec w}_t - \eta_t\times \mathbf {\vec g}_t$

   - 在 `FTRL` 中，参数更新方程为：

     其中$\sigma_s =\frac{1}{\eta_s} - \frac{1}{\eta_{s-1}}$，$\mathbf{\vec z}_t = \sum_{s=1}^t\left(\mathbf{\vec g}_s - \mathbf{\vec w}_s\right)$。

#### 6.1.2 特征优化

1. 在超高维度领域（如：计算广告、推荐、搜索）中，特征规模可以达到上亿甚至百亿。

   事实上，绝大多数特征都是非常罕见的。论文提到：谷歌的一些模型中，在数十亿样本中约一半的特征仅仅出现一次。

   而且，这些罕见特征永远不会有任何实际应用价值。因为它出现的频次极为稀疏，没有任何统计意义。

2. 一种简单的操作是将这些罕见特征剔除。问题是：我们事先并不知道有哪些特征是罕见特征。

   可以统计样本中的特征，当特征出现次数低于指定阈值$k$次（如：3次）时，判定为罕见特征。

   - 这种操作需要读取全部数据（数十亿级），并进行特征统计。对于在线训练，这种操作的代价较大。
   - 如果直接剔除罕见特征，我们永远无法获知这种简单丢弃对于模型预测能力带来的影响。因为这些罕见特征从未在模型中出现过。

3. 论文提出 `Probabilistic Feature Includsion`：当特征首次出现时，以一定的概率导入。这实现了罕见特征预处理的效果，但是避免了其缺陷。

   有两种导入方式：

   - 泊松导入`Poisson Inclusion`：当遇到一个新特征时，以概率$p$添加到模型中。

     - 一旦添加了一个新特征，我们在随后步骤中更新其统计计数、更新其 `OGD` 系数。
     - 任何新特征被添加到模型之前，期望看到特征出现的次数为$1/p$。

   - `Bloom Filter Inclusion`：使用布隆过滤器来检测一个特征首次出现了$n$次。一旦发现，则将该特征添加到模型中。

     > 该方法也是概率性的，因为布隆过滤器可能会误报。

   两种方式的实验结果如下。可以看到：二者都可以降低模型大小，但是 `Bloom Filter Inclusion` 在模型大小和模型预测能力下降之间取得平衡。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603210639.png?imageslim">
   </p>
   

#### 6.1.3 固定精度浮点数

1. 通常我们用32位或者64位浮点数来存储模型参数。实际中发现：几乎所有的参数取值都在 `[-2, +2]` 之间。同时，分析表明：对模型参数取如此高的精度完全没有必要。

   论文抛弃了32位/64位浮点数，采用 16 位固定精度的 `q2.13` 格式来表示模型参数：1个`bit` 表示正负、2个 `bit` 表示整数部分、13 个 `bit` 表示小数部分。

2. 采用16位浮点数带来的精度下降会导致 `OGD` 过程中产生累积舍入误差。

   事实上在使用32位浮点数（而不是64位浮点数）时，我们也能够观察到舍入误差。

   一个简单的随机舍入策略可以缓解该问题：

  $\tilde w_i = 2^{-13}\lfloor 2^{13} w_i +R \rfloor$

   其中：

   -$w_i$为原始的参数。
   -$\tilde w_i$为引入随机舍入策略调整后的参数，它以 `q2.13`格式存储。
   -$R$为一个随机数，它从 `0~1` 均匀分布随机采样。

   最终在没有损失模型预测能力的情况下，相比于64位双精度浮点数，采用 `q2.13` 精度之后模型大小降低了 75%。

#### 6.1.4 多模型并行训练

1. 有时候我们需要训练多个模型，这些模型采用相同的算法但是不同的超参数来训练，这些模型称作变种模型。最后选择最佳的超参数及对应的模型。

   一个简单的方式是：先用给定的算法训练好一个模型，然后用该模型作为变种模型的初始化点来训练变种模型。

   这种方式比较简单，容易实现。但是缺点是：无法处理特征裁剪等改变模型结构的超参数调整。

2. 实际上有一些数据可以在多个模型之间共享，如：训练样本。另一些数据无法在多个模型之间共享，如：每个模型的参数值。

   我们可以在同一张表中存储每个模型的参数值，然后在每次迭代中同时更新所有模型的参数。这使得我们可以同时并行训练多个模型。

   - 对于被裁剪特征的模型，对应参数表的位置恒为0。 这是通过设定该模型该维度的学习率为 0 来实现的。
   - 一些通用的计数(如：特征索引、特征计数) 可以在多个模型之间共享，从而降低了大量内存。
   - 通过这种方式不仅节省了内存，还节省了网络带宽（因为每个样本只需要读取一次）

3. 更进一步的，我们可以为每个维度仅存储一个参数，而不是为维度在每个模型上存储一个参数。

   此时该参数由包含该特征的所有变种模型共享，称作 `Single Value Structure`。

   设维度$A$由所有变种模型共享，则训练期间：

   - 计算所有变种模型在该维度的参数更新值：

    $w^{(m)}_{t+1,A} = w_{t,A} - \eta_{t,A} ^{(m)}\times g_{t,A}^{(m)},m=1,2,\cdots,M$

     其中$M$为模型数量，$w_{t,A}$为所有模型在特征$A$上共享的参数，$[]^{(m)}$表示模型$m$的具体参数。

   - 计算最新的共享参数值：

    $w_{t+1,A} = \frac{\sum_{m=1}^M w^{(m)}_{t+1,A} }{M}$

   实验结果显示：这种方式和上一点提到方法的模型预测能力几乎相同，但是这里的参数存储量降低了一个量级。

### 6.2 维度独立的学习率

1. 如果某些特征的数据较多，则它应该学习速度快一点，因此需要给它一个较快的学习率衰减；如果某些特征的数据较少，则它应该学习速度慢一点，因此需要给它一个较慢的学习率衰减。

   因此定义学习率：

  $\eta_{t,i} = \frac{\alpha}{\beta + \sqrt{\sum_{s=1}^t g_{s,i}^2}}$

   其中$\alpha,\beta$为超参数。

   -$\beta$是为了保证初始阶段的学习率不会太高，其取值通常选择为 1 。
   -$\alpha$取值由具体的数据集和特征来决定，变化很大。
   -$\alpha,\beta$通过超参数搜索来获取最佳的值，其中重点搜索$\alpha$。因为算法对$\alpha$取值比较敏感，而对$\beta$取值不敏感。

   通过实验表明：相较于全局学习率，基于维度的学习率可以将 `aucloss` 降低 `11.2%` 。

2. 为计算每个维度的学习率我们需要计算梯度的累积平方。

   假设特征$A$出现时，点击事件和不点击事件是相互独立的（虽然实际上很难成立，但是不影响下面的推导过程）。

   设特征$A$出现时，有$P$次点击、$N$次未点击。则点击概率为：

  $p = \frac{P}{N + P}$

   设我们采用逻辑回归模型。则有梯度：

  $g_{w_A} = (p-y) \times x_A$

   考虑到特征$A$出现，即：$x_A = 1$，则有：

   - 样本$(\mathbf{\vec x},y)$点击时，梯度：

    $g_{w_A} = p -1$

   - 样本$(\mathbf{\vec x},y)$未点击时，梯度：$g_{w_A} = p$

   则维度$A$的累积梯度平方为：

   其中第二步是假设：每次点击的概率$p_t$都是相同的，等于$p$。

   因此可以基于每个特征上发生的点击/不点击计数来近似梯度的累积平方，从而调整学习率。

   - 允许这样做的原因：学习率是模型的超参数，其取值不必非常精确。

     实验表明：这种方式得到的学习率，与采用梯度平方和得到的学习率，二者表现相当。

   - 在多模型并行训练中，由于所有变种模型都具有相同的特征点击/不点击计数，因此存储$N,P$的成本被摊销，总的存储成本较低。

### 6.3 降采样

1. 在典型的推荐、搜索等场景中，点击率`CTR` 通常远低于 50%。这意味着正样本非常少。因此，正样本在 `CTR` 预估任务的学习中更具有价值。

   因此我们可以通过负降采样来显著减少训练集大小，同时保证对模型预测能力的影响降到最低。

   - 所有正类样本被保留。
   - 负类样本保留$r$比例，其中$r\in (0,1]$。

2. 负降采样会导致模型产生预测偏差。这种偏差可以通过为每个样本赋予一个权重来解决：

   - 正样本权重为 `1`
   - 负样本权重为$1/r$

   这种权重放大了每个样本的损失，因此也同步地放大了梯度。

   实验表明：即使是非常大比例的负降采样（$r$值非常小），对最终模型的准确率的影响也是微乎其微的。而且和具体的$r$值无关。

### 6.4 模型评估

1. 虽然可以直接利用实时流量来评估模型效果，但是这种评估的代价太大：在实时流量中上新模型可能会降低这些流量的收入，因为新模型的效果在评估之前是未知的，可能更好，但是大多数情况下是更坏。

2. 可以通过历史日志来评估模型效果。由于不同的评估指标衡量了模型在不同方面的能力，因此我们评估了一组指标：`aucloss`（即：`1-auc`）、`logloss`、平方误差。

3. 论文使用`progressive validation` 渐进式验证（也称为在线损失`online loss`），而未采用交叉验证。

   假设当前待学习的样本为$(\mathbf{\vec x}_t,y_t)$， 为了学习该样本，`oneline learning` 模型会首先预测该样本，得到预测值$p_t$。然后基于预测值计算损失$l_t$和参数梯度$\mathbf{\vec g}_t$。最后根据参数梯度来更新参数。

   在这个过程中，我们可以很容易的将样本的预测值$p_t$记录下来供后续的模型评估。

   - 我们每个小时汇总一次，得到该小时内每个样本的真实值、预测值。基于这些数据得到小时级别的模型评估指标。

     因此可以得到随时间推进的模型能力变化趋势。

   - 这种方式中，每个样本都被用来训练，同时每个样本也被用来预测：训练完$(\mathbf{\vec x}_{t-1},y_{t-1})$来预测$(\mathbf{\vec x}_t,y_t)$、训练完$(\mathbf{\vec x}_{t},y_{t})$来预测$(\mathbf{\vec x}_{t+1},y_{t+1})$、...

     这使得我们可以将 `100%` 的数据用于训练和验证。相比较于传统的交叉验证只有部分数据用于验证，这里的验证集更大，得到的验证结果也更具有统计意义。

     这很重要，因为某些性能的改进可能需要在大规模的验证集上评估才有意义（如：改进可能很小，比如千分之五），置信度才比较高。

4. 用绝对值来评估模型能力可能会产生误导。

   假如某个场景点击率是 `50%`，另一个场景点击率是 `2%` 。事实上前者的 `logloss` 的绝对值可能会超过后者。因为 `logloss`及其它指标可能会根据问题的难度（即贝叶斯风险）而变化。

   这个问题非常重要。因为 `CTR` 会根据不同国家/地区，以及 `query` 而不同。`query`在一天中的不同时段的分布不同，因此评估指标的均值会在一天之内发生变化。

   因此我们更关注相对变化：模型的评估指标相对于 `baseline` 的变化。根据论文的经验，随着时间的推进，相对变化会更加稳定。

5. 需要注意的是：我们必须在同一批数据上产生的同一个指标才有比较意义。

   如：`A` 模型在某个时间段上得到的模型指标，和 `B` 模型在另一个时间段上得到的模型指标之间不可比较。因为 `A` 模型和 `B` 模型的评估数据都不同。

6. 大规模机器学习的一个隐藏陷阱是：统计指标可能受到数据中某些属性分布的影响。

   如：给定一个验证集，模型 `A` 的准确率比模型 `B` 更高。很有可能该验证集中 “女性” 用户非常多，而模型 `A` 对于 “女性” 用户的预测比模型 `B` 更准。

   因此我们不仅要给出模型在整体验证集上的评估指标，还要再验证集数据的每个分区上给出评估指标。如：模型在每个国家上的评估指标、模型在每个性别上的评估指标、模型在每个主题上的评估指标 ....

### 6.5 置信度

1. 在很多应用场景中，我们不仅要预估 `CTR`，还要衡量预估结果的置信度。

   通常采用置信区间来评估不确定性，但是在这里不适用。

   - 标准的方法用于评估完全收敛的 `batch` 学习模型，且没有正则化。

     而 `FTRL` 模型是在线学习，不再满足独立同分布 `IID` 的样本假设，因此甚至无法定义收敛性。并且模型是经过正则化的。

   - 标准的方法需要求解一个 `n x n` 矩阵的逆，这里 `n` 的规模达到数十亿甚至百亿，因此无法计算。

2. 论文提出不确定性得分来评估结果的置信度。

   假设我们对样本进行归一化，使得样本每个特征的取值都归一化到 1 以内。即：$|x_i| \le 1$。

   对于逻辑回归模型，损失函数的梯度为：$g_i = (p_t - y_t)\times x_i$。 考虑到$y_t\in \{0,1\}, 0\le p_t \le 1$因此有：$|g_i| \le 1 \times 1 = 1$。

   当采用维度独立的学习率时，有：$\eta_{t,i} = \frac{\alpha}{\beta + \sqrt{\sum_{s=1}^t g_{s,i}^2}}$。

   因此给定样本$\mathbf{\vec x}$，其预估的不确定性为：

  $|\mathbf{\vec x}\cdot \mathbf{\vec w}_t - \mathbf{\vec x}\cdot \mathbf{\vec w}_{t+1} | \le \sum_{i:|x_i| \ne 0} \eta_{t,i} |g_{t,i}|\times x_i\le \sum_{i:|x_i| \ne 0} \eta_{t,i} \times x_i = \vec\eta \times \mathbf{\vec x}$

   因此对于样本$\mathbf{\vec x}$，定义模型预测的不确定性得分为：

  $u(\mathbf{\vec x}) = \mathbf{\vec \eta} \times \mathbf{\vec x}$

   其物理意义是：由于学习的不充分导致预测结果的不确定性。因为一旦学习充分，则模型参数$\mathbf{\vec w}$非常稳定，在前后两次迭代之间的变化几乎为零。

   这种方式定义的置信度指标计算非常方便。

3. 为验证这种置信度指标的有效性，论文执行以下实验：

   - 首先在真实数据集$\mathbb D$上训练模型 `A`

   - 然后丢弃真实数据的标记$y$，用模型 `A` 的预测结果$p(\mathbf{\vec x})$来代替$y$，从而产生了替代数据集$\mathbb D_p$

   - 在数据集$\mathbb D_p$上用 `FTRL` 算法训练模型 `B` 。

   - 对于样本$\mathbf {\vec x}$，假设模型 `A` 的预测结果为 `p`，模型 `B` 的预测结果为$\tilde p$。

     则得分误差为：

    $e(\mathbf{\vec x}) = |\sigma^{-1}(p) - \sigma^{-1}(\tilde p) |$

     其中$\sigma^{-1}$是$\sigma(z) = \frac{1}{1+\exp(-z)}$的反函数，它根据预测概率计算得分$\mathbf{\vec x} \times \mathbf{\vec w}$。

    $e(\mathbf{\vec x})$的物理意义为：由于标记噪声的引入，导致模型预测的波动范围。

   - 最后计算$u(\mathbf{\vec x})$，观察该指标是否和得分误差$e(\mathbf{\vec x})$相符。

   实验结果表明：$u(\mathbf{\vec x})$和得分误差$e(\mathbf{\vec x})$比较比配，而且置信度指标计算量非常小。

   如下图所示：

   - 横坐标表示每一个样本的得分误差$e$，纵坐标表示每个样本的不确定性分$u$。

     其中每一种得分都归一化成 `0~1` 之间。

   - 曲线分别代表：`25%, 50%, 75%` 百分位的得分误差对应的样本连接而成的曲线。

     可以看到：得分误差$e$和不确定性分$u$成正向关系：得分误差越大，不确定性分越大。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603210650.png?imageslim">
   </p>
   

### 6.6 模型校准

1. 很多因素可能会导致模型产生系统性偏差，如：模型的前提假设不成立、优化算法本身的缺陷、训练或预测期间无法获取某些重要特征。

   为解决该问题，论文提出模型校准模块来校准预测的 `CTR` ，使得预测 `CTR` 和经验 `CTR` 适配。

2. 假设模型在数据集$\mathbb D$上的平均预测 `CTR` 为$p$，数据集$\mathbb D$的经验 `CTR` 为$q$，其中$p \simeq q$。预测偏差 `bias` 为$q-p$。

   模型校准是提供一个校准函数$\pi_{\mathbb D} (p)$，使得校准后的平均预测 `CTR` 尽可能接近$q$。

   - 一个简单方法是基于泊松回归来矫正。定义：

    $\pi_{\mathbb D}(p) = \gamma\times p^{\kappa}$

     其中$\gamma,\kappa$都是待学习的参数，通过泊松回归在数据集$\mathbb D$上学习。

   - 一个通用的方法是：利用分段线性函数来拟合 `bias` 曲线，其中必须满足$\pi(\cdot)$是单调递增函数。如：采用 `isotonic` 回归。

     这种方式的优点是：通用性更强。无论平均预测 `CTR` 较高还是较低，它都能很好的校准。

3. 对于数据集，我们通常需要对不同数据区间对应的子集进行校准。因为很有可能模型对 “女性” 用户预测的平均 `CTR` 偏高，对“男性”用户预测的平均 `CTR` 偏低，但是整体预测的平均 `CTR` 较好。

   这时我们需要分别针对 “女性” 用户、“男性” 用户分别进行模型校准。

### 6.7 无效的探索

1. 论文还研究了一些探索方向，但是这些方向是无效的，并不能带来很好的效果。

   - 基于特征哈希`feature hasing` 技术可以大规模降低训练的内存代价。

     但是实验发现：这种方式会带来模型预测能力的明显下降，因此无法应用。

   - 基于 `dropout` 的正则化并不会带来任何好处，甚至会降低模型预测能力。

     其根本原因是：数据特征非常稀疏，经过 `dropout` 之后更为稀疏。

     - 在计算机视觉任务中，输入特征是非常密集的，且标签是比较干净的。

       此时 `dropout` 将高度相关的特征分离开，从而产生更健壮的分类器。

     - 而在 `CTR` 预估任务中，输入特征是非常稀疏的，且标签是带噪音的。

       此时 `dropout` 会显著降低学习的数据量，降低学习效果。

   - `bagging`：通过$k$折交叉来获取$k$个训练样本子集，然后基于这些样本子集训练$k$个模型。对于未知样本，最终这$k$个模型的预测均值为该样本的预测结果。

     该方法略微降低模型预测能力，大约损失 `AucLoss` 的 `0.1%`到 `0.6%`。

   - 样本归一化：论文尝试将样本归一化$\frac{\mathbf{\vec x} }{ ||\mathbf{\vec x}||}$，最终效果不理想。

     猜测的原因：维度独立的学习率和样本归一化相互作用，导致效果下降。

## 七、LS-PLM 模型

1. 论文 `“Learning Piece-wise Linear Models from Large Scale Data for Ad Click Prediction”` 提出了 `“Large Scale Piece-wise Linear Model:LS-PLM”` 模型来求解 `CTR` 预估问题，并给出了有效的优化算法来训练 `LS-PLM` 模型。

   该模型自2012年以来作为阿里巴巴在线展示广告系统中的主要 `CTR` 预测模型。

### 7.1 模型

1. `LS-PLM` 模型基于分而治之的策略：

   - 首先将特征空间划分为几个局部区域
   - 然后在每个区域中建立一个广义线性模型
   - 最后将每个广义线性模型加权作为最终输出

2. `LS-PLM` 具有非线性、可扩展性、稀疏性的优点。

   - 非线性：如果特征空间划分区域足够多，则 `LS-PLM` 模型将拟合任何复杂的非线性函数。
   - 可扩展性：`LS-PLM` 可以扩展到超大规模和超高维特征。
   - 稀疏性：带有$L_1$和$L_{2,1}$正则化的 `LS-PLM`模型具有很好的稀疏性。

3. 给定数据集$\mathbb D = \{(\mathbf{\vec x}_1,y_1),\cdots,(\mathbf{\vec x}_N,y_N)\}$，其中：

  $\mathbf{\vec x}_i = (x_{i,1},\cdots,x_{i,d})^T\in \mathbb R^d\\y_i\in \{0,1\}$

   `LS-PLM` 算法基于分而治之的策略，将整个特征空间划分为一些局部区域，对每个区域采用广义线性分类模型：

  $p(y=1\mid \mathbf{\vec x}) = g\left(\sum_{j=1}^m \sigma(\mathbf{\vec u}_j\cdot \mathbf{\vec x})\times \eta(\mathbf{\vec w}_j\cdot \mathbf{\vec x})\right)$

   其中：

   -$\mathbf\Theta=\{\mathbf{\vec u}_1,\cdots,\mathbf{\vec u}_m,\mathbf{\vec w}_1,\cdots,\mathbf{\vec w}_m\},\mathbf{\vec u}_j\in \mathbb R^d,\mathbf{\vec w}_j\in \mathbb R^d$为模型参数。

     因此$\mathbf \Theta$有 两种表示方法：

     - 列向量：$\mathbf\Theta = (\vec\theta_1,\vec\theta_2,\cdots,\vec\theta_{2m})$。其中：

      $\vec\theta_j$表示第$j$列。

     - 行向量：$\Theta = (\vec\Theta^{(1)},\cdots,\vec\Theta^{(d)}) ^T$。其中：

      $\vec\Theta^{(i)} = (u_{1,i},u_{2,i},\cdots ,u_{m,i},w_{1,i},w_{2,i},\cdots,w_{m,i})^T$

      $\vec\Theta^{(i)}$表示第$i$行。

     因此我们有：$(\mathbf\Theta)_{i,j} = (\vec\theta_j)_i = (\vec\Theta^{(i)})_j = \Theta_{i,j}$，其中$i$为行索引、$j$为列索引：

   -$\sigma (\mathbf{\vec u}_j\cdot \mathbf{\vec x})$将样本划分到$m$个区域

   -$\eta(\mathbf{\vec w}_j\cdot \mathbf{\vec x})$对每个空间进行预测

   -$g(\cdot)$用于对结果进行归一化

4. 一种简单的情形是：

   此时有：

  $p(y=1\mid \mathbf{\vec x}) = \sum_{j=1}^m \frac{\exp(\mathbf{\vec u}_j\cdot \mathbf{\vec x})}{\sum_{j^\prime=1}^m \mathbf{\vec u}_{j^\prime}\cdot \mathbf{\vec x}} \times \frac{1}{1+ \exp(-\mathbf{\vec w}_j\cdot \mathbf{\vec x})}$

   这可以被认为是一种混合模型：

  $p(y = 1\mid \mathbf{\vec x}) = \sum_{j=1}^m p(z=j\mid {\mathbf{\vec x}}) \times p(y = 1\mid z=j,\mathbf{\vec x})$

   其中：

   -$p(z=j\mid {\mathbf{\vec x}}) = \frac{\exp(\mathbf{\vec u}_j\cdot \mathbf{\vec x})}{\sum_{j^\prime=1}^m \mathbf{\vec u}_{j^\prime}\cdot \mathbf{\vec x}}$表示样本划分到区域$j$的概率。它满足：
   -$p(y = 1\mid z=j,\mathbf{\vec x}) = \frac{1}{1+ \exp(-\mathbf{\vec w}_j\cdot \mathbf{\vec x})}$表示在区域$j$中，样本$\mathbf{\vec x}$属于正类的概率。

   论文主要研究这种简单的模型。

5. `LS-PLM` 模型的目标函数为：

  $\mathcal J = \text{loss}(\mathbf \Theta) + \lambda ||\mathbf \Theta||_{2,1} + \beta ||\mathbf \Theta||_1$

   其中：

   - `loss` 是负的对数似然损失函数：

    $\text{loss}(\mathbf\Theta) = -\sum_{i=1}^N\left[y_i\log p(y_i = 1 \mid \mathbf{\vec x}_i;\mathbf\Theta) + (1-y_i)\log p(y_i = 0 \mid \mathbf{\vec x}_i;\mathbf\Theta) \right]$

   -$||\mathbf \Theta||_{2,1}$和$||\mathbf\Theta||_1$是$L_{2,1}$和$L_1$正则化项：

     - 该正则化先计算每个维度在各区域的正则化，然后将所有维度的正则化直接累加。
     -$||\mathbf \Theta||_{2,1}$正则化主要用于特征选择；$||\mathbf\Theta||_1$主要用于模型稀疏性，但是它也有助于特征选择。

### 7.2 优化算法

1. 由于$L_1$和$L_{2,1}$正则化项是非凸、非光滑的函数，因此 `LS-PLM` 的目标函数$\mathcal J$采用传统的算法（如：随机梯度下降）难以优化。

   论文提出了一种有效的基于方向导数和拟牛顿法的优化算法。

2. 定义方向导数为：

  $f^\prime(\mathbf \Theta;\mathbf{ v}) = \lim_{\alpha \rightarrow 0} \frac{f(\mathbf\Theta+\alpha\mathbf{ v}) - f(\mathbf\Theta)}{\alpha}$

   当$f^\prime(\mathbf \Theta;\mathbf{ v} ) \lt 0$时，$\mathbf{ v}$就是使得函数值$f(\mathbf \Theta)$下降的方向。其中

  $v_{i,j}$对应于参数$\Theta_{i,j}$的方向。

   可以证明：对于任意的参数$\mathbf \Theta$和任意方向$\mathbf{ v}$，$\mathcal J(\mathbf\Theta)$的方向导数都存在。

   证明过程：

   - 第一项：因为$\text{loss}(\mathbf\Theta)$是光滑的、可微的，所以有：

    $\lim_{\alpha\rightarrow 0 } \frac{\text{loss}(\mathbf\Theta + \alpha \mathbf{ v})-\text{loss}(\mathbf\Theta)}{\alpha} = (\nabla_{\mathbf\Theta}\text{loss}) \cdot \mathbf{ v}$

     这里的向量点积是将两个张量展平为两个一维向量，再进行点积。

   - 第二项：

     根据：

     其中$\mathbf{\vec v}^{(i)}$是$\mathbf v$的第$i$行组成的向量。

     则有：

    $\lim_{\alpha\rightarrow 0 }\lambda \frac{||\mathbf\Theta + \alpha \mathbf{ v}||_{2,1}-||\mathbf\Theta||_{2,1}}{\alpha} = \lambda \left( \sum_{\substack{1\le i\le d\\|| \vec\Theta^{(i)}||_{2 }\ne 0}}\frac{\vec\Theta^{(i)}\cdot \mathbf{\vec v}^{(i)}}{ || \vec\Theta^{(i)}||_{2 }} +\sum_{\substack{1\le i\le d\\|| \vec\Theta^{(i)}||_{2 } = 0}} ||\mathbf{\vec v}^{(i)}||_{2 }\right)$

   - 第三项：

     考虑到：

     因此有：

    $\lim_{\alpha\rightarrow 0 }\beta \frac{||\mathbf\Theta + \alpha \mathbf{ v}||_{1}-||\mathbf\Theta||_{1}}{\alpha} = \beta \left(\sum_{\substack{1\le i \le d\\
     1\le j\le m\\
     \Theta_{i,j} \ne 0}} \text{sgn}(\Theta_{i,j})v_{i,j}+\sum_{\substack{1\le i \le d\\
     1\le j\le m\\
     \Theta_{i,j} = 0}} |v_{i,j}| \right)$

   最终得到方向导数：

  $\mathcal J^\prime(\mathbf \Theta;\mathbf{ v}) = (\nabla_{\mathbf\Theta}\text{loss}) \cdot \mathbf{ v} + \lambda \left( \sum_{\substack{1\le i\le d\\|| \vec\Theta^{(i)}||_{2 }\ne 0}}\frac{\vec\Theta^{(i)}\cdot \mathbf{\vec v}^{(i)}}{ || \vec\Theta^{(i)}||_{2 }} +\sum_{\substack{1\le i\le d\\|| \vec\Theta^{(i)}||_{2 } = 0}} ||\mathbf{\vec v}^{(i)}||_{2 }\right) +\\
   \beta \left(\sum_{\substack{1\le i \le d\\
   1\le j\le m\\
   \Theta_{i,j} \ne 0}} \text{sgn}(\Theta_{i,j})v_{i,j}+\sum_{\substack{1\le i \le d\\
   1\le j\le m\\
   \Theta_{i,j} = 0}} |v_{i,j}| \right)$

   其中$\vec\Theta^{(i)},\mathbf{\vec v}^{(i)}$分别表示$\mathbf\Theta,\mathbf v$的第$i$行的行向量；$\Theta_{i,j},v_{i,j}$分别表示$\mathbf \Theta,\mathbf v$的第$i$行第$j$列。$||\cdot||_2$表示向量长度。

3. 既然代价函数的方向导数存在，则可以求得代价函数降低最多的那个方向作为梯度下降的方向。

   由于代价函数降低的幅度与方向$\mathbf{ v}$的长度有关，因此给定长度约束$||\mathbf v ||\le C$，其中 `C` 是一个常数。即：

   这是一个带约束的最优化问题，最终解得：

   其中：

4. 给定方向向量$\mathbf v^{}$，我们可以通过 `LBFGS` 算法估计出海森矩阵的逆矩阵$\mathbf H^{}$，其中用到辅助向量$\mathbf{ y}^{},\mathbf{ s}^{}$。最后得到参数更新的方向$\mathbf H^{} \mathbf v^{}$。

   但是论文采用了两个技巧：

   - 保证参数更新的方向和方向向量$\mathbf v$一致。

   - 由于目标函数$\mathcal J$是非凸的，因此不能保证$\mathbf H^{}$是正定的。因此：

     - 当$\mathbf{ y}^{}\cdot \mathbf{ s}^{} \gt 0$时，采用$\mathbf H^{}$来更新
     - 当$\mathbf{ y}^{}\cdot \mathbf{ s}^{} \le 0$时，采用$\mathbf v^{}$来更新

     其中$\mathbf p^{}$为参数更新方向，$\pi(\cdot)$函数用于确保参数更新的方向和$\mathbf v^{}$的方向一致。

5. 当得到参数更新方向$\mathbf p^{}$，我们通过线性搜索来查找最佳步长$\alpha$，则得到参数更新：

  $\mathbf\Theta ^{}_{tmp} = \mathbf\Theta ^{} + \alpha\times \mathbf p^{}$

   但是论文还添加了约束条件：每轮迭代前后，参数的正负号保持不变。因此有：

   其中：

   -$\xi^{}$存放$\mathbf \Theta^{}$每个参数的正负号（如果$Q_{i,j} ^{} = 0$则使用$v_{i,j}^{}$的正负号）。

   -$\pi(\cdot)$确保$\mathbf \Theta^{}$的正负号和$\xi^{}$一致，也即和$\mathbf Q^{}$的正负号一致。

     因此要想参数$\Theta_{i,j}$符号发生改变，唯一的机会是当$\Theta_{i,j} =0$时基于$v_{i,j}$的符号来改变。

6. `LS-PLM` 模型优化算法：

   - 输入：训练集$\mathbb D = \{(\mathbf{\vec x}_1,y_1),\cdots,(\mathbf{\vec x}_N,y_N)\}$
   - 输出：模型参数$\mathbf \Theta$
   - 步骤：
     - 随机初始化参数$\mathbf\Theta^{<0>}$
     - 迭代：$t=0,1,2,\cdots, T$，其中$T$为最大迭代步数。迭代步骤为：
       - 计算$\mathbf v^{}$
       - 计算$\mathbf p^{}$
       - 更新$\mathbf\Theta^{}$
       - 判断停止条件：
         - 如果$\mathbf \Theta^{}$满足停止条件（如$||\mathbf \Theta^{} - \mathbf \Theta^{}||_2\le \epsilon$，或者$|\mathcal J(\mathbf \Theta^{}) - \mathcal J(\mathbf \Theta^{})|\le \epsilon$），则停止迭代并返回$\mathbf \Theta^{}$。
         - 否则继续迭代，并更新$\mathbf{ y} , \mathbf{ s}$：

   .

### 7.3 模型实现

1. 为了在工业场景中应用 ，论文基于分布式学习框架来实现 `LS-PLM` 模型。框架中包含两种类型的计算单元：

   - `server`：每个 `server` 结点分别独立的存储全局模型中的一部分。
   - `worker`：每个 `worker` 结点存储部分训练样本，以及一个局部模型。该局部模型仅仅保存用于训练本地样本的模型参数。

   其中每个计算结点包含一个 `server` 结点和一个 `worker` 结点。这种方式充分利用了 `server` 结点的计算能力，又可以和 `worker` 结点很方便的共享内存。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603210715.png?imageslim">
   </p>
   

   在每次迭代过程中：

   - 每个 `worker` 首先用本地数据和局部模型计算损失和下降方向（数据并行）
   - 然后 `server` 将损失 `loss`、方向$\mathbf v^{}$、以及其它需要用于计算$\mathbf \Theta^{}$的项汇总，从而计算$\mathbf\Theta^{}$(模型并行)
   - 最终 `worker` 同步最新的$\mathbf{\Theta}^{}$

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603210721.png?imageslim">
   </p>
   

2. 为了提高训练速度，论文优化了特征计算过程。

   如图所示：用户 `U1` 在一个 `session` 中看到三条广告，因此产生三个样本。事实上，这三个样本共享 `U1` 的画像特征（如：年龄、性别、城市、兴趣爱好等）。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603210729.png?imageslim">
   </p>
   

   由于大量的计算几种在$\mathbf{\vec u}_j\cdot \mathbf{\vec x}$和$\mathbf{\vec w}_j\cdot \mathbf{\vec x}$， 因此可以将计算拆解成样本共享特征和样本非共享特征：

   其中$\mathbf{\vec x}_c$表示样本的共享特征，$\mathbf{\vec x}_{nc}$为样本的非共享特征。对于共享特征，每个用户只需要计算一次并保存起来，后续该用户的所有样本都可以直接复用该计算结果。

   因此共享特征计算优化步骤为：

   - 将训练样本根据共享特征分组（如：`年龄、城市、性别` ），共享特征相同的样本划分到同一个 `worker` 中。
   - 每组共享特征仅需要存放一次，从而节省内存。如：`年龄 = 20, 城市 = 北京，性别 = 女` 这组特征只需要存放一次，该组的所有样本不需要重复存储该组特征。
   - 在更新损失函数和梯度时，每组共享特征只需要计算一次，从而提高计算速度。

   由于阿里巴巴的生产数据具有共享特征的模式，因此该技巧可以大幅度提高训练速度。在 `100` 个 `worker` 、每个 `worker` 12个 `CPU core, 11GB` 内存的条件下，实验结果表明：内存显著降低到 `1/3`，计算速度加快 `12` 倍左右。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603210736.png?imageslim">
   </p>
   

### 7.4 实验结论

1. 论文使用了阿里巴巴移动展示广告的 7 个数据集，它们是在不同日期收集的，但是数据集各自的收集时间是连续的。

   每个数据集的训练集、验证集、测试集的比例约为 7: 1 : 1 。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603210743.png?imageslim">
   </p>
   

2. 区域数量$m$：参数$m$的物理意义是区域数量，它控制了模型的容量。

  $m$越大则模型容量越大，拟合能力越强，但是模型训练代价也越大。因此实际应用中必须在模型的拟合能力和训练成本之间平衡。

   模型在数据集 `1` 上的结果如下图所示。

   - 当$m=12$时，模型测试 `AUC` 明显强于$m=6$。

   - 当$m=24,36$时，模型测试 `AUC` 相对于$m=12$虽然有所提升，但是提升幅度很小。

     因此后续采用$m=12$。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603210750.png?imageslim">
   </p>
   

3. 正则化可以缓解模型过拟合，除此之外$L_1$和$L_{2,1}$正则化都会使得模型更稀疏。如结果所示：

   - 仅采用$L_{2,1}$正则化，最终保留了 `9.4%` 的非零权重，从而保留了 `18.7%` 的特征。

     > 这是因为特征数量时参数数量的一半，因此非零特征比例是非零参数比例的一倍。

   - 仅采用$L_1$正则化，最终保留了 `1.9%` 的非零特征，从而保留了 `12.7%` 的特征（谨慎怀疑这里有问题）。

   - 联合采用$L_1$正则化和$L_{2,1}$正则化，最终得到更稀疏的模型，以及泛化能力更强的模型。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603210758.png?imageslim">
   </p>
   

4. `LS-PLM` 和 `LR` 模型在 7 个数据集上的对比如下图所示（评估指标为测试 `auc` ）：

   所有超参数通过 `grid search` 搜索。其中：

   - `LS-PLM` 的超参数$\beta \in \{0.01,0.1,1,10\},\lambda \in \{0.01,0.1,1,10\}$， 最佳超参数为$\lambda = 1,\beta = 1$
   - `LR` 采用$L_1$正则化，超参数$\beta \in \{0.01,0.1,1,10\}$，最佳超参数为$\beta = 1$

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603210807.png?imageslim">
   </p>
   

 