
# 常见概率分布

## 均匀分布

1. 离散随机变量的均匀分布：假设$X$有$k$个取值：$x_1,x_2,\cdots,x_k$，则均匀分布的概率密度函数(`probability mass function:PMF`)为：

   $$p(X=x_i) =\frac 1k,\quad i=1,2,\cdots,k$$

2. 连续随机变量的均匀分布： 假设$X$在 `[a,b]`上均匀分布，则其概率密度函数(`probability density function：PDF`)为：

   $$p(X=x)=\begin{cases} 0,&x\notin [a,b]\\ \frac{1}{b-a},&x \in [a,b]\\ \end{cases}$$

   .

## 伯努利分布

1. 伯努利分布：参数为$\phi\in [0,1]$。随机变量$X \in \{0,1\}$。

   - 概率分布函数为：$p(X=x)=\phi^{x}(1-\phi)^{1-x}\;,x \in \{0,1\}$。
   - 期望：$\mathbb E[X]=\phi$。方差：$Var[X]=\phi(1-\phi)$。

2. `categorical` 分布：它是二项分布的推广，也称作`multinoulli`分布。假设随机变量$X \in \{1,2,\cdots,K\}$，其概率分布函数为：

   $$p(X=1)=\theta_1\\ p(X=2)=\theta_2\\ \vdots\\ p(X=K-1)=\theta_{K-1}\\ p(X=K)=1-\sum_{i=1}^{K-1}\theta_i \\$$

   其中$\theta_i$为参数，它满足$\theta_i \in [0,1]$，且$\sum_{i=1}^{K-1}\theta_i \in [0,1]$。

## 二项分布

1. 假设试验只有两种结果：成功的概率为$\phi$，失败的概率为$1-\phi$。 则二项分布描述了：独立重复地进行$n$次试验中，成功$x$次的概率。

   - 概率质量函数：

     $$p(X=x)=\frac{n!}{x!(n-x)!}\phi^{x}(1-\phi)^{n-x},x\in \{0,1,\cdots,n\}$$

   - 期望：$\mathbb E[X]=n\phi$。 方差：$Var[X]=n\phi(1-\phi)$。

## 高斯分布

1. 正态分布是很多应用中的合理选择。如果某个随机变量取值范围是实数，且对它的概率分布一无所知，通常会假设它服从正态分布。有两个原因支持这一选择：
   - 建模的任务的真实分布通常都确实接近正态分布。中心极限定理表明，多个独立随机变量的和近似正态分布。
   - 在具有相同方差的所有可能的概率分布中，正态分布的熵最大（即不确定性最大）。

### 一维正态分布

1. 正态分布的概率密度函数为 :

   $$p(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-(x-\mu)^{2}/ (2\sigma^{2})}, -\infty \lt x \lt \infty$$

   其中$\mu,\sigma(\sigma \gt 0)$为常数。

   - 若随机变量$X$的概率密度函数如上所述，则称$X$服从参数为$\mu,\sigma$的正态分布或者高斯分布，记作$X \sim N(\mu,\sigma^{2})$。
   - 特别的，当$\mu=0,\sigma=1$时，称为标准正态分布，其概率密度函数记作$\varphi(x)$，分布函数记作$\Phi(x)$。
   - 为了计算方便，有时也记作：$\mathcal N(x;\mu,\beta^{-1}) =\sqrt{\frac{\beta}{2\pi}}\exp\left(-\frac{1}{2}\beta(x-\mu)^{2}\right)$，其中$\beta \in (0,\infty)$。

2. 正态分布的概率密度函数性质：

   - 曲线关于$x=\mu$对称。
   - 曲线在$x=\mu$时取最大值。
   - 曲线在$x=\mu \pm \sigma$处有拐点。
   - 参数$\mu$决定曲线的位置；$\sigma$决定图形的胖瘦。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603/RDMqeYyEjERD.png?imageslim">
   </p>
   

3. 若$X \sim N(\mu,\sigma^{2})$则：

   -$\frac{X-\mu}{\sigma} \sim N(0,1)$
   - 期望：$\mathbb E[X] = \mu$。方差：$Var[X]=\sigma^2$。

4. 有限个相互独立的正态随机变量的线性组合仍然服从正态分布：若随机变量$X_i \sim N(\mu_i,\sigma_i^{2}),i=1,2,\cdots,n$且它们相互独立，则它们的线性组合：$C_1X_1+C_2X_2+\cdots+C_nX_n$仍然服从正态分布（其中$C_1,C_2,\cdots,C_n$不全是为 0 的常数），且：$C_1X_1+C_2X_2+\cdots+C_nX_n \sim N(\sum_{i=1}^{n}C_i\mu_i,\sum_{i=1}^{n}C_i^{2}\sigma_i^{2})$。

### 多维正态分布

1. 二维正态随机变量$(X,Y)$的概率密度为：

   $$p(x,y)=\frac{1}{2\pi\sigma_1\sigma_2\sqrt{1-\rho^{2}}}\exp\{\frac{-1}{2(1-\rho^{2})}[\frac{(x-\mu_1)^{2}}{\sigma_1^{2}}\\ -2\rho\frac{(x-\mu_1)(y-\mu_2)}{\sigma_1\sigma_2}+\frac{(y-\mu_2)^{2}}{\sigma_2^{2}}]\}$$

   根据定义，可以计算出:

   $$p_X(x)=\frac{1}{\sqrt{2\pi}\sigma_1}e^{-(x-\mu_1)^{2}/ (2\sigma_1^{2})}, -\infty \lt x \lt \infty \\ p_Y(y)=\frac{1}{\sqrt{2\pi}\sigma_2}e^{-(y-\mu_2)^{2}/ (2\sigma_2^{2})}, -\infty \lt y \lt \infty\\ \mathbb E[X] =\mu_1 \\ \mathbb E[Y] =\mu_2 \\ Var[X] =\sigma_1^{2} \\ Var[Y]=\sigma_2^{2}\\ Cov[X,Y]=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}(x-\mu_1)(y-\mu_2)p(x,y)dxdy=\rho \sigma_1\sigma_2\\ \rho_{XY}=\rho$$

2. 引入矩阵：

   $$\mathbf{\vec x}=\begin{bmatrix} x \\ y \end{bmatrix} \quad \mathbf{\vec \mu}=\begin{bmatrix} \mu_1 \\ \mu_2 \end{bmatrix}\quad \mathbf{\Sigma}=\begin{bmatrix} c_{11} &c_{12}\\ c_{21} &c_{22} \end{bmatrix} = \begin{bmatrix} \sigma_1^{2} & \rho \sigma_1 \sigma_2 \\ \rho \sigma_1 \sigma_2 & \sigma_2^{2} \end{bmatrix}$$

  $\mathbf \Sigma$为$(X,Y)$的协方差矩阵。其行列式为$\det \mathbf{\Sigma} =\sigma_1^{2}\sigma_2^{2}(1-\rho^{2})$，其逆矩阵为：

   $$\mathbf{\Sigma}^{-1}=\frac{1}{\det\mathbf \Sigma}\begin{bmatrix} \sigma_2^{2} & -\rho \sigma_1 \sigma_2 \\ -\rho \sigma_1 \sigma_2 & \sigma_1^{2} \end{bmatrix}$$

   于是$(X,Y)$的概率密度函数可以写作$( \mathbf {\vec x}- \mathbf {\vec \mu})^{T}$表示矩阵的转置：

   $$p(x,x)=\frac{1}{(2\pi)(\det \mathbf \Sigma)^{1/ 2}}\exp\{- \frac 12 ( \mathbf {\vec x}- \mathbf {\vec \mu})^{T} \mathbf \Sigma^{-1}( \mathbf {\vec x}- \mathbf {\vec \mu})\}$$

   其中：

   - 均值$\mu_1,\mu_2$决定了曲面的位置（本例中均值都为0）。

   - 标准差$\sigma_1,\sigma_2$决定了曲面的陡峭程度（本例中方差都为1）。

   - $\rho$ 定了协方差矩阵的形状，从而决定了曲面的形状。

     - $\rho=0$ 时，协方差矩阵对角线非零，其他位置均为零。此时表示随机变量之间不相关。

       此时的联合分布概率函数形状如下图所示，曲面在 $z=0$ 平面的截面是个圆形：

      <p align="center">
         <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603/C0LYj4xMewIF.png?imageslim">
      </p>
      

     - $\rho=0.5$ 时，协方差矩阵对角线非零，其他位置非零。此时表示随机变量之间相关。

       此时的联合分布概率函数形状如下图所示，曲面在 $z=0$ 平面的截面是个椭圆，相当于圆形沿着直线 $y=x$ 方向压缩 ：

      <p align="center">
         <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603/qlXy8POufbkA.png?imageslim">
      </p>
      

   - $\rho=1$ 时，协方差矩阵对角线非零，其他位置非零。

     此时表示随机变量之间完全相关。此时的联合分布概率函数形状为：曲面在 $z=0$ 平面的截面是直线 $y=x$ ，相当于圆形沿着直线 $y=x$ 方向压缩成一条直线 。

     由于 $\rho=1$ 会导致除数为 0，因此这里给出 $\rho=0.9$：

      <p align="center">
         <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603/cf6rM7xRRSWx.png?imageslim">
      </p>
     

3. 多维正态随机变量 $(X_1,X_2,\cdots,X_n)$，引入列矩阵：

   $$\mathbf{\vec x}=\begin{bmatrix} x_1 \\ x_2 \\ \vdots\\ x_n \end{bmatrix} \quad \mathbf{\vec \mu}=\begin{bmatrix} \mu_1 \\ \mu_2\\ \vdots\\ \mu_n \end{bmatrix}=\begin{bmatrix} \mathbb E[X_1] \\ \mathbb E[X_2] \\ \vdots\\ \mathbb E[X_n] \end{bmatrix}$$

  $\mathbf \Sigma$ 为 $(X_1,X_2,\cdots,X_n)$ 的协方差矩阵。则：

   $$p(x_1,x_2,x_3,\cdots,x_n)=\frac {1}{(2\pi)^{n/2}(\det \mathbf \Sigma)^{1/2}} \exp \{- \frac 12( \mathbf {\vec x}- \mathbf {\vec \mu})^{T}\mathbf \Sigma^{-1}( \mathbf {\vec x}- \mathbf {\vec \mu})\}$$

   记做 ：$\mathcal N(\mathbf{\vec x};\mathbf{\vec \mu},\mathbf\Sigma) =\sqrt{\frac{1}{(2\pi)^{n}det(\mathbf\Sigma)}}\exp\left(-\frac 12(\mathbf{\vec x-\vec \mu})^{T}\mathbf\Sigma^{-1}(\mathbf{\vec x-\vec \mu})\right)$。

4. $n$ 维正态变量具有下列四条性质：

   -$n$维正态变量的每一个分量都是正态变量；反之，若$X_1,X_2,\cdots,X_n$都是正态变量，且相互独立，则$(X_1,X_2,\cdots,X_n)$是$n$维正态变量。

   -$n$维随机变量$(X_1,X_2,\cdots,X_n)$服从$n$维正态分布的充要条件是：$X_1,X_2,\cdots,X_n$的任意线性组合：$l_1X_1+l_2X_2+\cdots+l_nX_n$服从一维正态分布，其中$l_1,l_2,\cdots,l_n$不全为 0 。

   - 若$(X_1,X_2,\cdots,X_n)$服从$n$维正态分布，设$Y_1,Y_2,\cdots,Y_k$是$X_j,j=1,2,\cdots,n$的线性函数，则$(Y_1,Y_2,\cdots,Y_k)$也服从多维正态分布。

     这一性质称为正态变量的线性变换不变性。

   - 设$(X_1,X_2,\cdots,X_n)$服从$n$维正态分布，则$X_1,X_2,\cdots,X_n$相互独立$\Longleftrightarrow$$X_1,X_2,\cdots,X_n$两两不相关。

## 拉普拉斯分布

1. 拉普拉斯分布：

   - 概率密度函数：$p(x;\mu,\gamma)=\frac{1}{2\gamma}\exp\left(-\frac{|x-\mu|}{\gamma}\right)$。
   - 期望：$\mathbb E[X]=\mu$。方差：$Var[X]=2\gamma^{2}$。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603/7pkpEuIRVqKg.png?imageslim">
   </p>
   

## 泊松分布

1. 假设已知事件在单位时间（或者单位面积）内发生的**平均**次数为$\lambda$，则泊松分布描述了：事件在单位时间（或者单位面积）内发生的具体次数为$k$的概率。

   - 概率质量函数：$p(X=k;\lambda)=\frac{e^{-\lambda}\lambda^{k}}{k!}$。
   - 期望：$\mathbb E[X]=\lambda$。 方差：$Var[X]=\lambda$。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603/RyPUn4slXRp1.jpeg?imageslim">
   </p>
   

2. 用均匀分布模拟泊松分布：

```py
import numpy as np
from sklearn.utils import stats


def make_poisson(lmd, tm):
    '''
    用均匀分布模拟泊松分布。 lmd为 lambda 参数； tm 为时间
    '''
    t = np.random.uniform(0, tm, size=lmd * tm)  # 获取 lmd*tm 个事件发生的时刻
    count, tm_edges = np.histogram(t, bins=tm, range=(0, tm))  # 获取每个单位时间内，事件发生的次数
    max_k = lmd * 2  # 要统计的最大次数
    dist, count_edges = np.histogram(count, bins=max_k, range=(0, max_k), density=True)
    x = count_edges[:-1]
    return x, dist, stats.poisson.pmf(x, lmd)
```

   该函数：

   - 首先随机性给出了 `lmd*tm`个事件发生的时间（时间位于区间`[0,tm]`）内。
   - 然后统计每个单位时间区间内，事件发生的次数。
   - 然后统计这些次数出现的频率。
   - 最后将这个频率与理论上的泊松分布的概率质量函数比较。

### 5.7 指数分布

1. 若事件服从泊松分布，则该事件前后两次发生的时间间隔服从指数分布。由于时间间隔是个浮点数，因此指数分布是连续分布。

   - 概率密度函数：（$t$为时间间隔）

     $$p(t;\lambda)=\begin{cases} 0,& t\lt0\\ \frac{\lambda}{\exp(\lambda t)},& t\ge0\\ \end{cases}$$

   - 期望：$\mathbb E[t] = \frac 1\lambda$。方差：$Var[t]=\frac{1}{\lambda^2}$。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603/qRO87iQqn8Up.jpeg?imageslim">
   </p>
   

2. 用均匀分布模拟指数分布：

```py
import numpy as np
from sklearn.utils import stats


def make_expon(lmd, tm):
    '''
    用均匀分布模拟指数分布。 lmd为 lambda 参数； tm 为时间
    '''
    t = np.random.uniform(0, tm, size=lmd * tm)  # 获取 lmd*tm 个事件发生的时刻
    sorted_t = np.sort(t)  # 时刻升序排列
    delt_t = sorted_t[1:] - sorted_t[:-1]  # 间隔序列
    dist, edges = np.histogram(delt_t, bins="auto", density=True)
    x = edges[:-1]
    return x, dist, stats.expon.pdf(x, loc=0, scale=1 / lmd)  # scale 为 1/lambda
```

### 5.8 伽马分布

1. 若事件服从泊松分布，则事件第$i$次发生和第$i+k$次发生的时间间隔为伽玛分布。由于时间间隔是个浮点数，因此指数分布是连续分布。

   - 概率密度函数：$p(t;\lambda,k)=\frac{t^{(k-1)}\lambda^{k}e^{(-\lambda t)}}{\Gamma(k)}$，$t$为时间间隔 。
   - 期望：$\mathbb E[t]=\frac {k}{\lambda}$。方差：$Var[t]=\frac{k}{\lambda^2}$。

2. 上面的定义中$k$必须是整数。事实上，若随机变量$X$服从伽马分布，则其概率密度函数为：

   $$p(X;\alpha,\beta)=\frac{\beta^{\alpha}}{\Gamma(\alpha)}X^{\alpha-1}e^{-\beta X},\quad X\gt 0$$

   记做$\Gamma(\alpha,\beta)$。其中$\alpha$称作形状参数，$\beta$称作尺度参数。

   - 期望$\mathbb E[X]=\frac \alpha\beta$，方差$Var[X]=\frac{\alpha}{\beta^2}$。
   - 当$\alpha\le 1$时，$p(X;\alpha,\beta)$为递减函数。
   - 当$\alpha \gt 1$时，$p(X;\alpha,\beta)$为单峰函数。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603/N28K6gesFPGv.jpeg?imageslim">
   </p>
   

3. 性质：

   - 当$\beta=n$时， 为 `Erlang`分布。
   - 当$\alpha=1,\beta=\lambda$时，就是参数为$\lambda$的指数分布。
   - 当$\alpha=\frac n2,\beta=\frac 12$时，就是常用的卡方分布。

4. 伽马分布的可加性：设随机变量$X_1,X_2,\cdots,X_n$相互独立并且都服从伽马分布：$X_i \sim \Gamma(\alpha_i,\beta)$，则：

   $$X_1+X_2+\cdots+X_n\sim \Gamma(\alpha_1+\alpha_2+\cdots+\alpha_n,\beta)$$

5. 用均匀分布模拟伽玛分布：

```py
import numpy as np
from sklearn.utils import stats


def make_gamma(lmd, tm, k):
    '''
    用均匀分布模拟伽玛分布。 lmd为 lambda 参数； tm 为时间；k 为 k 参数
    '''
    t = np.random.uniform(0, tm, size=lmd * tm)  # 获取 lmd*tm 个事件发生的时刻
    sorted_t = np.sort(t)  # 时刻升序排列
    delt_t = sorted_t[k:] - sorted_t[:-k]  # 间隔序列
    dist, edges = np.histogram(delt_t, bins="auto", density=True)
    x = edges[:-1]
    return x, dist, stats.gamma.pdf(x, loc=0, scale=1 / lmd, a=k)  # scale 为 1/lambda,a 为 k
```

### 5.9 贝塔分布

1. 贝塔分布是定义在$(0,1)$之间的连续概率分布。

   如果随机变量$X$服从贝塔分布，则其概率密度函数为：

   $$p(X,\alpha,\beta) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}X^{\alpha-1}(1-X)^{\beta-1}=\frac{1}{B(\alpha,\beta)}X^{\alpha-1}(1-X)^{\beta-1},\quad 0\le X\lt 1$$

   记做$Beta(\alpha,\beta)$。

   - 众数为：$\frac{\alpha-1}{\alpha+\beta-2}$。
   - 期望为：$\mathbb E[X] = \frac{\alpha}{\alpha+\beta}$，方差为：$Var[X]=\frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}$。

   <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200603/77i95A53TpM5.jpeg?imageslim">
   </p>
  

### 5.10 狄拉克分布

1. 狄拉克分布：假设所有的概率都集中在一点$\mu$上，则对应的概率密度函数为：$p(x)=\delta(x-\mu)$。

   其中$\delta(\cdot)$为狄拉克函数，其性质为：

   $$\delta(x)=0,\forall x\neq 0\\ \int_{-\infty}^{\infty}\delta(x)dx=1$$

2. 狄拉克分布的一个典型用途就是定义连续型随机变量的经验分布函数。假设数据集中有样本$\mathbf{\vec x}_1,\mathbf{\vec x}_2,\cdots,\mathbf{\vec x}_N$，则定义经验分布函数：

   $$\hat p(\mathbf{\vec x})=\frac 1N\sum_{i=1}^{N}\delta(\mathbf{\vec x}-\mathbf{\vec x}_i)$$

   它就是对每个样本赋予了一个概率质量$\frac 1N$。

3. 对于离散型随机变量的经验分布，则经验分布函数就是`multinoulli`分布，它简单地等于训练集中的经验频率。

4. 经验分布的两个作用：

   - 通过查看训练集样本的经验分布，从而指定该训练集的样本采样的分布（保证采样之后的分布不失真）。
   - 经验分布就是使得训练数据的可能性最大化的概率密度函数。

### 5.11 多项式分布与狄里克雷分布

1. 多项式分布的质量密度函数：

   $$Mult(m_1,m_2,\cdots,m_K;\vec\mu,N)=\frac{N!}{m_1!m_2!\cdots m_K!}\prod_{k=1}^{K}\mu_k^{m_k}$$

   它是$(\mu_1+\mu_2+\cdots+\mu_K)^{m_1+m_2+\cdots+m_K}$的多项式展开的形式。

2. 狄利克雷分布的概率密度函数：

   $$Dir(\vec\mu;\vec\alpha)=\frac{\Gamma(\sum_{k=1}^{K}\alpha_k)}{\sum_{k=1}^{K}\Gamma(\alpha_k)}\prod_{k=1}^{K}\mu_k^{\alpha_k-1}$$

3. 可以看到，多项式分布与狄里克雷分布的概率密度函数非常相似，区别仅仅在于前面的归一化项：

   - 多项式分布是针对离散型随机变量，通过求和获取概率。
   - 狄里克雷分布时针对连续型随机变量，通过求积分来获取概率。

### 5.12 混合概率分布

1. 混合概率分布：它组合了其他几个分量的分布来组成。

   - 在每次生成样本中，首先通过`multinoulli`分布来决定选用哪个分量，然后由该分量的分布函数来生成样本。

   - 其概率分布函数为：

     $$p(x)=\sum_{i}P(c=i)p(x\mid c=i)$$

     其中$p(c=i)$为一个`multinoulli`分布，$c$的取值范围就是各分量的编号。

2. 前面介绍的连续型随机变量的经验分布函数就是一个混合概率分布的例子，此时$p(c=i)=\frac 1N$。

3. 混合概率分布可以通过简单的概率分布创建更复杂的概率分布。一个常见的例子是混合高斯模型，其中$p(x\mid c=i)$为高斯模型。每个分量都有对应的参数$(\mathbf{\vec \mu}_i,\mathbf \Sigma_i)$。

   - 有些混合高斯模型有更强的约束，如$\forall i,\mathbf \Sigma_i=\mathbf\Sigma$，更进一步还可以要求$\mathbf\Sigma$为一个对角矩阵。
   - 混合高斯模型是一个通用的概率密度函数逼近工具。任何平滑的概率密度函数都可以通过足够多分量的混合高斯模型来逼近。
