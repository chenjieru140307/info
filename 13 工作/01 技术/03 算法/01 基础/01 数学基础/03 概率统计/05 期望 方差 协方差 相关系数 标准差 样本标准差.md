
# 期望 方差 协方差 相关系数 标准差 样本标准差


## 期望


期望：

- 是试验中每次可能结果的概率乘以其结果的总和。
- 它反映随机变量平均取值的大小。


函数的期望：

- 设 $f(x)$ 为 $x$ 的函数，则 $f(x)$ 的期望为
  - 离散函数： $E(f(x))=\sum_{k=1}^{n}{f(x_k)P(x_k)}$
  - 连续函数： $E(f(x))=\int_{-\infty}^{+\infty}{f(x)p(x)dx}$


运算：

- 线性运算： $E(ax+by+c) = aE(x)+bE(y)+c$
- 推广形式： $E(\sum_{k=1}^{n}{a_ix_i+c}) = \sum_{k=1}^{n}{a_iE(x_i)+c}$
- 如果 $X$ 和 $Y$ 相互独立，则 $E(xy)=E(x)E(y)​$。

注意：

- 函数的期望大于等于期望的函数（Jensen不等式），即 $E(f(x))\geqslant f(E(x))$ （没有很清楚）
- 一般情况下，乘积的期望不等于期望的乘积。





## 方差

方差

- 用来度量随机变量和其数学期望（即均值）之间的偏离程度。
- 方差是一种特殊的期望。

计算：

$$
\begin{aligned}
Var(x) =& E((x-E(x))^2)
\\=& E(x^2) -E(x)^2
\end{aligned}
$$

说明：

- 常数的方差为 0;
- 方差不满足线性性质;
- 如果 $X$ 和 $Y$ 相互独立，$Var(ax+by)=a^2Var(x)+b^2Var(y)$



## 协方差

协方差：

- 可以衡量两个变量线性相关性强度与变化尺度。
- 注意，是线性相关性强度。


定义：

$$
Cov(x,y)=E((x-E(x))(y-E(y)))
$$


说明：

- 方差是一种特殊的协方差。当 $X=Y$ 时，$Cov(x,y)=Var(x)=Var(y)$。
- 独立变量的协方差为 0。
- $Cov(\sum_{i=1}^{m}{a_ix_i}, \sum_{j=1}^{m}{b_jy_j}) = \sum_{i=1}^{m} \sum_{j=1}^{m}{a_ib_jCov(x_iy_i)}$
- $Cov(a+bx, c+dy) = bdCov(x, y)$
- 协方差的绝对值如果很大，则意味着变量值变化很大，并且它们同时距离各自的均值很远。
- 如果协方差是正的，那么两个变量都倾向于同时取得相对较大的值。
- 如果协方差是负的，那么其中一个变量倾向于取得相对较大的值的同时，另一个变量倾向于取得相对较小的值，反之亦然。



协方差和相关性：

- 协方差和相关性是有联系的，但实际上是不同的概念。
- 如果两个变量相互独立，那么它们的协方差为零；如果两个变量的协方差不为零，那么它们一定是相关的。


独立性和协方差：

- 两个变量如果协方差为零，它们之间一定没有线性关系。
- 而独立性是比零协方差的要求更强，因为独立性还排除了非线性的关系。
- 两个变量相互依赖，但是具有零协方差是可能的。
  - 例如，假设我们首先从区间 $[-1,1]$ 上的均匀分布中采样出一个实数 $x$ ，然后对一个随机变量 $s$ 进行采样。$s$ 以 $\frac{1}{2}$ 的概率值为 $1$，否则为 $-1$。我们可以通过令 $y=sx$ 来生成一个随机变量 $y$。显然，$x$ 和 $y$ 不是相互独立的，因为 $x$ 完全决定了 $y$ 的尺度。然而，$\operatorname{Cov}(x, y)=0$。

协方差矩阵：（没明白）

- 随机向量 $\boldsymbol{x} \in \mathbb{R}^{n}$ 的协方差矩阵 (covariance matrix) 是一个 $n \times n$ 的矩阵，并且满足：

$$
\operatorname{Cov}(\mathbf{x})_{i, j}=\operatorname{Cov}\left(\mathrm{x}_{i}, \mathrm{x}_{j}\right)
$$

- 协方差矩阵的对角元是方差：

$$
\operatorname{Cov}\left(\mathrm{x}_{i}, \mathrm{x}_{i}\right)=\operatorname{Var}\left(\mathrm{x}_{i}\right)
$$


## 相关系数


相关系数：

- 相关系数是用来研究变量之间线性相关程度的量。
- 注意：是线性相关程度
- 相关系数将每个变量的贡献归一化，为了只衡量变量的相关性而不受各个变量尺度大小的影响。

定义：

$$
Corr(x,y) = \frac{Cov(x,y)}{\sqrt{Var(x)Var(y)}}
$$

说明：

- 有界性。相关系数的取值范围是 $[-1,1]$，可以看成无量纲的协方差。
  - 值越接近 $1$，说明两个变量正相关性（线性）越强。
  - 越接近 $-1$，说明负相关性越强。
  - 当为 $0$ 时，表示两个变量没有相关性。



## 标准差 样本标准差

- 方差 $S^2_{N}=\frac{1}{N}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}​$
- 标准差 $S_{N}=\sqrt{\frac{1}{N}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}}​$
- 样本标准差 $S_{N}=\sqrt{\frac{1}{N-1}\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}}​$


说明：

- 样本标准差为什么除以 n-1
  - 相对于总体来说，样本是比较少的，它有可能把较为极端的数值排除在外了，这时候，数值可能以更紧密的方式聚集在均值周围。如图：
    <p align="center">
        <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190902/w4jRFl4SBDv0.png?imageslim">
    </p>
  - 因此，为了更好的用样本估计总体的标准差，统计学家就将标准差的公式做了改造：将 $n$ 改为 $n-1$。这样，使得标准差略大。弥补了样本的标准差小于总体标准差的不足。
  - 所以，这个样本标准差 实际上应该是，使用样本估计整体的标准差。
- 那么，平时使用时，我们是除以 $n$ 还是 $n-1$ 呢？
  - 只与一点有关：我们使用标准差的目的。
    - 如果是单纯的想计算一个数据集的标准差，那么就除以 $n$。
    - 如果是想用这些样本来估计总体的标准差，那就用除以 $n-1$
  - 举例：
    - 例如你有 100 个毕业与清华人的收入，只是想了解这 100 个人构成的数据集的波动大小，那你就使用除以 $n$ 的标准差公式。
    - 如果想把刚才例子中这 100 个人当成一个样本，用这个样本来估计出总体（所有毕业与清华人的收入）的标准差，那么就使用除以 $n-1$ 的标准差公式。
- 使用标准差来表示数据点的离散程度，与与方差相比，有那些好处：
  - 表示离散程度的数字与样本数据点的数量级一致，更适合对数据样本形成感性认知。
  - 表示离散程度的数字单位与样本数据的单位一致，更方便做后续的分析运算。
  - 在样本数据大致符合正态分布的情况下，标准差具有方便估算的特性：68% 的数据点落在平均值前后 1 个标准差的范围内、95% 的数据点落在平均值前后 2 个标准差的范围内，而 99% 的数据点将会落在平均值前后 3 个标准差的范围内。

