# 分布

- 伯努利分布
- 正态分布
- 指数分布
- 拉普拉斯分布
- 狄拉克分布和经验分布
- 分布的混合
  - 混合模型
  - 高斯混合模型

## 伯努利分布

伯努利分布 Bernoulli


- 是单个二值随机变量分布， 单参数 $\phi \in[0,1]$ 控制，$\phi​$ 给出随机变量等于 $1$ 的概率。（没有很清楚）
- 主要性质有:

$$
\begin{aligned}
P(x=1) &= \phi \\
P(x=0) &= 1-\phi  \\
P(x=x) &= \phi^x(1-\phi)^{1-x} \\
\end{aligned}
$$

- 期望和方差为：

$$
\begin{aligned}
E_x[x] &= \phi \\
Var_x(x) &= \phi{(1-\phi)}
\end{aligned}
$$


应用：

- 伯努利分布适合对离散型随机变量建模。


范畴分布 Multinoulli

- 是单个 $k$ 值随机分布，经常用来表示**对象分类的分布**。 <span style="color:red;">嗯，多分类问题中常用。</span>$k$ 为有限值。
- Multinoulli 分布由向量 $\vec{p} \in[0,1]^{k-1}$ 参数化，每个分量 $p_i$ 表示第 $i$ 个状态的概率， 且 $p_{k}=1-1^{T} p$。


应用：

- Bernoulli 分布和 Multinoulli 分布足够用来描述在它们领域内的任意分布。它们能够描述这些分布，不是因为它们特别强大，而是因为它们的领域很简单。
- 它们可以对那些能够将所有的状态进行枚举的离散型随机变量进行建模。当处理的是连续型随机变量时，会有不可数无限多的状态，所以任何通过少量参数描述的概率分布都必须在分布上加以严格的限制。



## 正态分布

正态分布 Normal distribution

又名高斯分布 Gaussian distribution


概率度函数

$$
N(x;\mu,\sigma^2) = \sqrt{\frac{1}{2\pi\sigma^2}}exp\left ( -\frac{1}{2\sigma^2}(x-\mu)^2 \right )
$$

正态分布的概率密度函数：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190518/EIpT5taNOzDl.png?imageslim">
</p>

说明：

- 正态分布由两个参数控制，$\mu \in \mathbb{R}$ 和 $\sigma \in(0, \infty)$ 。参数 $\mu$ 给出了中心峰值的坐标，这也是分布的均值：$\mathbb{E}[\mathrm{x}]=\mu$ 。分布的标准差用 $\sigma$ 表示，方差用 $\sigma^{2}$ 表示。
- $\mu​$ 和 $\sigma​$ 分别是均值和方差
- 中心峰值 $x$ 坐标由 $\mu​$ 给出， 峰的宽度受 $\sigma​$ 控制， 最大点在 $x=\mu​$ 处取得， 拐点为 $x=\mu\pm\sigma​$

令 $\mu=0,\sigma=1​$ 高斯分布即简化为标准正态分布:

$$
N(x;\mu,\sigma^2) = \sqrt{\frac{1}{2\pi}}exp\left ( -\frac{1}{2}x^2 \right )
$$


说明：

- 正态分布中，$\pm 1 \sigma$、$\pm 2 \sigma$、$\pm 3 \sigma$ 下的概率分别是 68.3%、95.5%、99.73%，这 3 个数最好记住。

对概率密度函数高效求值:（没明白？）

$$
N(x;\mu,\beta^{-1})=\sqrt{\frac{\beta}{2\pi}}exp\left(-\frac{1}{2}\beta(x-\mu)^2\right)
$$


其中：

- $\beta=\frac{1}{\sigma^2}$ 通过参数 $\beta \in(0, \infty)$ 来控制分布精度。


应用：

- 当缺乏实数上分布的先验知识，不知选择何种形式时，默认选择正态分布。理由：
  - 中心极限定理告诉我们，很多独立随机变量均近似服从正态分布，现实中很多复杂系统都可以被建模成正态分布的噪声，即使该系统可以被结构化分解。
  - 正态分布是具有相同方差的所有概率分布中，不确定性最大的分布， 换句话说，正态分布是对模型加入先验知识最少的分布。

多维正态分布：

- 正态分布可以推广到 $R^n$ 空间， 为**多维正态分布**， 其参数是一个正定对称矩阵 $\Sigma​$:

$$
N(x;\vec\mu,\Sigma)=\sqrt{\frac{1}{(2\pi)^ndet(\Sigma)}}exp\left(-\frac{1}{2}(\vec{x}-\vec{\mu})^T\Sigma^{-1}(\vec{x}-\vec{\mu})\right)
$$

对多维正态分布概率密度高效求值:

$$
N(x;\vec{\mu},\vec\beta^{-1}) = \sqrt{det(\vec\beta)}{(2\pi)^n}exp\left(-\frac{1}{2}(\vec{x}-\vec\mu)^T\beta(\vec{x}-\vec\mu)\right)
$$

说明：

- $\vec\beta$ 是一个精度矩阵。


## 指数分布


深度学习中，指数分布用来描述在 $x=0​$ 点处取得边界点的分布。

定义：

$$
p(x;\lambda)=\lambda I_{x\geq 0}exp(-\lambda{x})
$$

指数分布用指示函数 $I_{x\geq 0}​$ 来使 $x​$ 取负值时的概率为零。

疑问：

- 什么是 在 $x=0​$ 点处取得边界点的分布？




## 拉普拉斯分布

拉普拉斯分布 Laplace 

它允许我们在任意一点 $\mu$ 处设置概率质量的峰值：


$$
\operatorname{Laplace}(x ; \mu, \gamma)=\frac{1}{2 \gamma} \exp \left(-\frac{|x-\mu|}{\gamma}\right)
$$

疑问：

- 怎么设定概率质量的峰值？在什么时候使用？为什么要使用？





## 狄拉克分布和经验分布


狄拉克分布 Dirac

狄拉克分布可保证概率分布中所有质量都集中在一个点上。狄拉克分布的狄拉克 $\delta​$ 函数(也称为**单位脉冲函数**)定义如下:

$$
p(x)=\delta(x-\mu), x\neq \mu
$$

$$
\int_{a}^{b}\delta(x-\mu)dx = 1, a < \mu < b
$$

Dirac 分布经常作为 经验分布（empirical distribution）的一个组成部分出现

$$
\hat{p}(\vec{x})=\frac{1}{m}\sum_{i=1}^{m}\delta(\vec{x}-{\vec{x}}^{(i)})
$$

其中， $m$ 个点 $x^{1},...,x^{m}$ 是给定的数据集， **经验分布**将概率密度 $\frac{1}{m}​$ 赋给了这些点。

当我们在训练集上训练模型时，可以认为从这个训练集上得到的经验分布指明了**采样来源**。<span style="color:red;">什么是指明了采样来源？</span>

应用：

- 狄拉克 $\delta$ 函数适合对连续型随机变量的经验分布。




## 分布的混合

### 混合模型

混合分布：

- 可以通过组合一些简单的概率分布来定义新的概率分布，一种通用的组合方法是构造混合分布 (mixture distribution)。
- 混合分布由一些组件 (component) 分布构成。每次实验，样本是由哪个组件分布产生的取决于从一个 Multinoulli 分布中采样的结果：

公式：

$$
P(\mathrm{x})=\sum_{i} P(\mathrm{c}=i) P(\mathrm{x} | \mathrm{c}=i)
$$

说明：

- 这里 $P(\mathrm{c})$ 是对各组件的一个 Multinoulli 分布。


举例：

- 实际上，实值变量的经验分布对于每一个训练实例来说，就是以 Dirac 分布为组件的混合分布。


潜变量：

- 在混合模型中，我们涉及到了一个非常重要的概念-潜变量(latent variable)。
- 潜变量是我们不能直接观测到的随机变量。
  - 混合模型的组件标识变量 $\mathrm{c}$ 就是其中一个例子。潜变量在联合分布中可能和  $\mathrm{x}$  有关，在这种情况下，$P(\mathrm{x}, \mathrm{c})=P(\mathrm{x} | \mathrm{c}) P(\mathrm{c})$ 。潜变量的分布 $P(\mathrm{c})$ 以及关联潜变量和观测变量的条件分布 $P(\mathrm{x} | \mathrm{c})$ ，共同决定了分布 $P(\mathrm{x})$ 的形状，尽管描述 $P(\mathrm{x})$ 时可能并不需要潜变量。

### 高斯混合模型


高斯混合模型：Gaussian Mixture Model

- 高斯混合模型是一个非常强大且常见的混合模型是高斯混合模型。
- 它的组件 $p(\mathbf{x} | \mathbf{c}=i)$ 是高斯分布。每个组件都有各自的参数，均值 $\mu^{(i)}$ 和协方差矩阵 $\Sigma^{(i)}$ 。
- 有一些混合可以有更多的限制。例如，协方差矩阵可以通过 $\boldsymbol{\Sigma}^{(i)}=\boldsymbol{\Sigma}, \forall i$ 的形式在组件之间共享参数。和单个高斯分布一样，高斯混合模型有时会限制每个组件的协方差矩阵为对角的或者各向同性的(标量乘以单位矩阵)。
- 除了均值和协方差以外，高斯混合模型的参数指明了给每个组件 $i$ 的先验概率(prior probability) $\alpha_{i}=P(\mathrm{c}=i)$ 。“先验”一词表明了在观测到 $\mathbf{x}$ 之前传递给模型关于 $\mathrm{c}$ 的信念。作为对比，$P(\mathrm{c} | \boldsymbol{x})$ 是后验概率(posterior probability)，因为它是在观测到 $\mathrm{x}$ 之后进行计算的。

作用：

- 高斯混合模型是概率密度的万能近似器(universal approximator)，在这种意义下，任何平滑的概率密度都可以用具有足够多组件的高斯混合模型以任意精度来逼近。<span style="color:red;">怎么这么厉害呢！看到这句话，想起了双层神经网络可以用来逼近任何函数。</span>

举例：

- 下图展示了某个高斯混合模型生成的样本：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190518/pylDDJQJrzn5.png?imageslim">
</p>

说明：

- 在这个示例中，有 $3$ 个组件。从左到右：
  - 第 $1$ 个组件具有各向同性的协方差矩阵，这意味着它在每个方向上具有相同的方差。
  - 第 $2$ 个组件具有对角的协方差矩阵，这意味着它可以沿着每个轴的对齐方向单独控制方差。该示例中，沿着 $x_2$ 轴的方差要比沿着 $x_1$ 轴的方差大。
  - 第 $3$ 个组件具有满秩的协方差矩阵，使它能够沿着任意基的方向单独地控制方差。<span style="color:red;">满秩的概念要补充下。</span>

疑问：

- 高斯混合模型一般使用在什么场景下呢？各组件什么时候需要共享参数？各组件的参数要怎么更新和设定？