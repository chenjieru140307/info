

# 可以补充进来的



## 条件概率

公式：

$$P(A\mid B)=\frac{P(AB)}{P(B)}$$

说明：

- 即，落在集合 A 和 B 的交集的概率与 落在 B 集合的概率的比值。为在 B 条件下，落在 A 集合中的概率。即条件概率。

## 全概率公式

- 假设 $\{B_n:n=1,2,3,\cdots \}$ 是一个概率空间的有限或者可数无限的分割，且每个集合 $B_n$ 是一个可测集和。
- 则对任意事件 $A$ 有全概率公式：

$$
\begin{aligned}
P(A)=&\sum_{n}P(A\cap B_n)
\\=& \sum_{n}P(A\mid B_{n})P(B_{n})
\end{aligned}
$$

说明：

- 第一行到第二行：条件概率公式。

作用：

- 全概率公式将求解 $A$ 的概率问题，转化为了在不同情况或不同原因 $B_n$ 下发生的 $A$ 的求和问题。




## 贝叶斯公式

贝叶斯公式 Bayes

由条件概率：

$$

\begin{aligned}
P(AB)=&P(A\mid B)P(B)
\\=&P(B\mid A)P(A)
\end{aligned}
$$

所以：（贝叶斯公式）


$$
P(A|B)=\frac{P(B|A)P(A)}{P(B)}
$$
$$
P(B|A)=\frac{P(A|B)P(B)}{P(A)}
$$

对于上面第二个式子，将全概率公式带入，得到：


$$P(B_n\mid A)=\frac{P(A\mid B_n)P(B_n)}{\sum_{n}P(A\mid B_{n})P(B_{n})}$$


作用：

- 本来是 $A$ 发生的时候 $B_n$ 发生的概率，即 $B_n$ 是原因，$A$是结果，但是现在 $A$ 是原因，$B_n$ 是结果，感觉相当于把因果关系搞乱。**是这样吗？**因此，后面谈到贝叶斯网络里面，会用自然语言说因果，但是实际上都说有关联，至于谁是因谁是果不考虑。

<span style="color:red;">这个地方对贝叶斯公式没怎么讲，实际上我是非常想知道贝叶斯公式的来龙去脉的。再补充下</span>




## 贝叶斯公式的应用：


支步枪中有 5 支已校准过，3支未校准。一名射手用校准过的枪射击，中靶概率为 0.8；用未校准的枪射击，中靶概率为 0.3；现从 8 支枪中随机取一支射击，结果中靶。求该枪是已校准过的概率。

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/mjCfbIgj36.png?imageslim">
</p>




## 由贝叶斯公式引发的，频率学派与贝叶斯学派：


给定某系统的若干样本，求该系统的参数。怎么求？




  * 可以用：矩估计/MLE/MaxEnt/EM等：即假定参数是某个/某些未知的定值，求这些参数如何取值，能够使得某目标函数取极大/极小。 这种就属于频率学派。**什么是 MLE？MaxEnt？EM？**

  * 也可以用：贝叶斯模型来求：假定参数本身是变化的，服从某个分布。求在这个分布约束下使得某目标函数极大/极小。这种就属于贝叶斯学派。


这两种方式没有高低好坏之分，都是认识自然的手段。只是，在当前人们掌握的数学工具和需解决的实践问题中，贝叶斯学派的理论体系往往能够比较好的解释目标函数、分析相互关系等。**为什么可以比较好的解释和分析？**


前面章节的内容，大多是频率学派的思想；下面的推理，使用贝叶斯学派的观点。

<span style="color:red;">还是没明白什么时频率学派，什么是贝叶斯学派？</span>





## 先验概率，后验概率，似然函数


<span style="color:red;">这个是我一直没有明白清楚的</span>

给定某系统的若干样本 x，计算该系统的参数，即：

$$P(\theta \mid x)=\frac{P(x\mid \theta)P(\theta )}{P(x)}$$

那么，先验概率是什么呢？

就是没有给定任何信息，你想猜这个概率，没有任何东西可言，比如没有任何信息猜一个人姓什么。对应式子中就是：P(\theta)，即在没有数据支持的情况下，$\theta$发生的概率。

后验概率是什么呢？

有了一些知识之后猜的概率，比如某人来自牛家村，那么姓牛的概率就比较大，这个就是后验概率，但是他虽然来自牛家村也可能姓马，所以不管先验后验都可能出错的，不是一定对的。对应式子中就是：$P(\theta\mid x)$：在数据 x 的支持下，$\theta$发生的概率。

那么什么是似然函数呢？

式子中的 P(x\mid\theta)$：给定某参数$\theta$的概率分布就是似然函数。即：在某一个参数的情况下，样本的发生概率就是似然函数，**样本像那个样子得到了。****这个似然这个词到底是什么意思？确认下。**




<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/LhhIFe0dEc.png?imageslim">
</p>

<span style="color:red;">这个地方是在讲贝叶斯网络的时候讲到的。在琢磨下。</span>


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/fkKFkH8HlF.png?imageslim">
</p> 这个地方我们假定了 $P(A_i)$ 是相等的。要注意。


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/7G5D8Di30l.png?imageslim">
</p>指的是：在给定数据的时候，我们想去看一下那一条结论是最有可能发生的。但是我们往往算的是反方向，在 A_i给定的时候这个数据出现的极大值。而这个


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180727/ad45g7Flcm.png?imageslim">
</p>就是极大似然估计。再理解下。


所以极大似然估计其实是先验性的假定了 A_1,A_2,A_n  出现的概率是相同的。

但是在贝叶斯学派中，最多的是探讨先验概率 $P(A_i)$ 如果是不相等的时候如何进行建模的问题。<span style="color:red;">那么先验概率怎么知道是不是相等的？</span>

怎么理解 P(D)是常数呢，仅为归一化因子？P(D)其实是似然，它是表示样本已经出现了。<span style="color:red;">还是没有很理解？</span>



# 补充

- 关于似然，没讲，而且关于贝叶斯，还想知道更多更系统。
