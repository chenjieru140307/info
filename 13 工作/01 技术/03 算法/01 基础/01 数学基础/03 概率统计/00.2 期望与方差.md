# 期望和方差

## 期望

1. 期望描述了随机变量的平均情况，衡量了随机变量$X$的均值。它是概率分布的泛函（函数的函数）。

   - 离散型随机变量$X$的期望：$\mathbb E[X]=\sum_{i=1}^{\infty}x_ip_i$。

     若右侧级数不收敛，则期望不存在。

   - 连续性随机变量$X$的期望：$\mathbb E[X]=\int_{-\infty}^{\infty}xp(x)dx$。

     若右侧极限不收敛，则期望不存在。

2. 定理：对于随机变量$X$，设$Y=g(X)$也为随机变量，$g(\cdot)$是连续函数。

   - 若$X$为离散型随机变量，若$Y$的期望存在，则：$\mathbb E[Y]=\mathbb E[g(X)]=\sum_{i=1}^{\infty}g(x_i)p_i$。

     也记做：$\mathbb E_{X\sim P(X)}[g(X)]=\sum_{x}g(x)p(x)$。

   - 若$X$为连续型随机变量，若$Y$的期望存在，则 ：$\mathbb E[Y]=\mathbb E[g(X)]=\int_{-\infty}^{\infty}g(x)p(x)dx$。

     也记做：$\mathbb E_{X\sim P(X)}[g(X)]=\int g(x)p(x)dx$。

   该定理的意义在于：当求$\mathbb E(Y)$时，不必计算出$Y$的分布，只需要利用$X$的分布即可。

   该定理可以推广至两个或两个以上随机变量的情况。对于随机变量$X,Y$，假设$Z=g(X,Y)$也是随机变量，$g(\cdot)$为连续函数，则有：$\mathbb E[Z]=\mathbb E[g(X,Y)]=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}g(x,y)p(x,y)dxdy$。也记做：$\mathbb E_{X,Y\sim P(X,Y)}[g(X,Y)\int g(x,y)p(x,y)dxdy$。

1. 期望性质：

   - 常数的期望就是常数本身。

   - 对常数$C$有 ：$\mathbb E[CX]=C\mathbb E[X]$。

   - 对两个随机变量$X,Y$，有：$\mathbb E[X+Y]=\mathbb E[X]+\mathbb E[Y]$。

     该结论可以推广到任意有限个随机变量之和的情况。

   - 对两个相互独立的随机变量，有：$\mathbb E[XY]=\mathbb E[X]\mathbb E[Y]$。

     该结论可以推广到任意有限个相互独立的随机变量之积的情况。

## 方差

1. 对随机变量$X$，若$\mathbb E[(X-\mathbb E[X])^{2}]$存在，则称它为$X$的方差，记作$Var[X]$。

  $X$的标准差为方差的开平方。即：

   $$Var[X]=\mathbb E[(X-\mathbb E[X])^{2}] \\ \sigma=\sqrt{Var[X]}$$

   - 方差度量了随机变量$X$与期望值偏离的程度，衡量了$X$取值分散程度的一个尺度。

   - 由于绝对值$|X-\mathbb E[X] |$带有绝对值，不方便运算，因此采用平方来计算。

     又因为$|X-\mathbb E[X]|^2$是一个随机变量，因此对它取期望，即得$X$与期望值偏离的均值。

2. 根据定义可知：

   $$Var[X]=\mathbb E[(X-\mathbb E[X])^{2}]=\mathbb E[X^{2}]-(\mathbb E[X])^{2}\\ Var [f(X)]=\mathbb E[(f(X)-\mathbb E[f(X)])^{2}]$$

3. 对于一个期望为$\mu$， 方差为$\sigma^{2},\sigma \ne 0$的随机变量$X$，随机变量$X^{*}=\frac {X-\mu}{\sigma}$的数学期望为0，方差为1。 称$X^{\ast}$为$X$的标准化变量。

4. 方差的性质：

   - 常数的方差恒为 0 。

   - 对常数$C$，有$Var[CX]=C^{2}Var[X]$。

   - 对两个随机变量$X,Y$，有：$Var[X+Y]=Var[X] +Var[Y] +2\mathbb E[(X-\mathbb E[X])(Y-\mathbb E[Y])]$

     当$X$和$Y$相互独立时，有$Var[X+Y] = Var[X] +Var[Y]$。这可以推广至任意有限多个相互独立的随机变量之和的情况。

   -$Var [X] =0$的充要条件是$X$以概率1取常数。

## 协方差与相关系数

1. 对于二维随机变量$(X,Y)$，可以讨论描述$X$与$Y$之间相互关系的数字特征。

   - 定义$\mathbb E[(X-\mathbb E[X])(Y-\mathbb E [Y])]$为随机变量$X$与$Y$的协方差，记作$Cov[ X,Y]=\mathbb E[(X-\mathbb E[X])(Y-\mathbb E [Y])]$。
   - 定义$\rho_{XY}=\frac {Cov[X,Y]}{\sqrt{Var[X] }\sqrt{Var[Y]}}$为随机变量$X$与$Y$的相关系数，它是协方差的归一化。

2. 由定义可知：

   $$Cov[ X,Y] =Cov[ Y,X] \\ Cov [X,X] =Var [X] \\ Var [X+Y] =Var [X] +Var [Y] +2Cov [X,Y]$$

3. 协方差的性质：

   -$Cov [aX,bY] =abCov [X,Y]$，$a,b$为常数。
   -$Cov[ X_1+X_2,Y ]=Cov [X_1,Y] +Cov [X_2,Y]$
   -$Cov [f(X),g(Y)]=\mathbb E[(f(X)-\mathbb E[f(X)])(g(Y)-\mathbb E[g(Y)])]$
   -$\rho[f(X),g(Y)]=\frac {Cov[f(X),g(Y)]}{\sqrt{Var[f(X)] }\sqrt{Var[g(Y)]}}$

4. 协方差的物理意义：

   - 协方差的绝对值越大，说明两个随机变量都远离它们的均值。

   - 协方差如果为正，则说明两个随机变量同时趋向于取较大的值或者同时趋向于取较小的值；如果为负，则说明一个随变量趋向于取较大的值，另一个随机变量趋向于取较小的值。

   - 两个随机变量的独立性可以导出协方差为零。但是两个随机变量的协方差为零无法导出独立性。

     因为独立性也包括：没有非线性关系。有可能两个随机变量是非独立的，但是协方差为零。如：假设随机变量$X\sim U[-1,1]$。定义随机变量$S$的概率分布函数为：

     $$P(S=1)= \frac 12P(S=-1)= \frac 12$$

     定义随机变量$Y=SX$，则随机变量$X,Y$是非独立的，但是有：$Cov[X,Y]=0$。

5. 相关系数的物理意义：考虑以随机变量$X$的线性函数$a+bX$来近似表示$Y$。以均方误差

   $$e=\mathbb E[(Y-(a+bX))^{2}]=\mathbb E[Y^{2}] +b^{2}\mathbb E[X^{2}] +a^{2}-2b\mathbb E[XY] +2ab\mathbb E[X] -2a\mathbb E [Y]$$

   来衡量以$a+bX$近似表达$Y$的好坏程度。$e$越小表示近似程度越高。

   为求得最好的近似，则对$a,b$分别取偏导数，得到：

   $$a_0=\mathbb E[Y] -b_0\mathbb E[X] =\mathbb E[Y] -\mathbb E[X] \frac{Cov [X,Y]}{Var [X] }\\ b_0=\frac{Cov[ X,Y] }{Var[ X] }\\ \min(e)=\mathbb E[(Y-(a_0+b_0X))^{2}]=(1-\rho^{2}_{XY})Var [Y]$$

   因此有以下定理：

   -$|\rho_{XY}| \le 1$（$|\cdot|$是绝对值）。
   -$|\rho_{XY}| = 1$的充要条件是：存在常数$a,b$使得$P\{Y=a+bX\}=1$。

6. 当$|\rho_{XY}|$较大时，$e$较小，意味着随机变量$X$和$Y$联系较紧密。于是$\rho_{XY}$是一个表征$X$、$Y$之间线性关系紧密程度的量。

7. 当$\rho_{XY}=0$时，称$X$和$Y$不相关。

   - 不相关是就线性关系来讲的，而相互独立是一般关系而言的。
   - 相互独立一定不相关；不相关则未必独立。

## 协方差矩阵

1. 设$X$和$Y$是随机变量。

   - 若$\mathbb E[X^{k}] ,k=1,2,\cdots$存在，则称它为$X$的$k$阶原点矩，简称$k$阶矩。
   - 若$\mathbb E[(X-\mathbb E[X])^{k}] ,k=2,3,\cdots$存在，则称它为$X$的$k$阶中心矩。
   - 若$\mathbb E[X^{k}Y^{l}] ,k,l=1,2,\cdots$存在，则称它为$X$和$Y$的$k+l$阶混合矩。
   - 若$\mathbb E[(X-\mathbb E[X])^{k}(Y-\mathbb E[Y])^{l}] ,k,l=1,2,\cdots$存在，则称它为$X$和$Y$的$k+l$阶混合中心矩。

   因此：期望是一阶原点矩，方差是二阶中心矩，协方差是二阶混合中心矩。

2. 协方差矩阵：

   - 二维随机变量$(X_1,X_2)$有四个二阶中心矩（假设他们都存在），记作：

     $$c_{11}=\mathbb E[(X_1-\mathbb E[X_1])^{2}] \\ c_{12}=\mathbb E[(X_1-\mathbb E[X_1])( X_2-\mathbb E[X_2]) ] \\ c_{21}=\mathbb E[( X_2-\mathbb E[X_2])(X_1-\mathbb E[X_1] ) ] \\ c_{22}=\mathbb E[(X_2-\mathbb E[X_2])^{2}]$$

     称矩阵

     $$\mathbf C=\begin{bmatrix} c_{11}&c_{12}\\ c_{21}&c_{22} \end{bmatrix}$$

     为随机变量$(X_1,X_2)$的协方差矩阵。

   - 设$n$维随机变量$(X_1,X_2,\cdots,X_n)$的二阶混合中心矩$c_{ij}=Cov [X_i,X_j] =\mathbb E[(X_i-\mathbb E[X_i] )( X_j-\mathbb E[X_j] ) ]$都存在，则称矩阵

     $$\mathbf C= \begin{bmatrix} c_{11} & c_{12} & \cdots & c_{1n} \\ c_{21} & c_{22} & \cdots & c_{2n} \\ \vdots &\vdots &\ddots &\vdots \\ c_{n1} & c_{n2} & \cdots & c_{nn} \\ \end{bmatrix}$$

     为$n$维随机变量$(X_1,X_2,\cdots,X_n)$的协方差矩阵。

     由于$c_{ij}=c_{ji}, i\ne j, i,j=1,2,\cdots,n$因此协方差矩阵是个对称阵。

3. 通常$n$维随机变量的分布是不知道的，或者太复杂以致数学上不容易处理。因此实际中协方差矩阵非常重要。