# 向量



## 向量的范数

向量 $\vec{x}=(x_1,x_2,...,x_N)$

-  1 范数：$\Vert\vec{x}\Vert_1=\sum_{i=1}^N\vert{x_i}\vert$
-  2 范数：$\Vert\vec{x}\Vert_2=\sqrt{\sum_{i=1}^N{\vert{x_i}\vert}^2}$
-  负无穷范数：$\Vert\vec{x}\Vert_{-\infty}=\min{|{x_i}|}$
-  正无穷范数：$\Vert\vec{x}\Vert_{+\infty}=\max{|{x_i}|}$
-  p 范数：$L_p=\Vert\vec{x}\Vert_p=\sqrt[p]{\sum_{i=1}^{N}|{x_i}|^p}$

举例：

- 向量 $\vec{a}=[-5, 6, 8, -10]$
- 1 范数 29
- 2 范数 15。
- 负无穷范数 5。
- 正无穷范数 10。
- 向量的 p 范数：



## 向量运算

线性相关：

- 一组向量 $\mathbf{\vec v}_1,\mathbf{\vec v}_2,\cdots,\mathbf{\vec v}_n$ 是线性相关的：指存在一组不全为零的实数 $a_1,a_2,\cdots,a_n$ ，使得：$\sum_{i=1}^{n}a_i\mathbf{\vec v}_i=\mathbf{\vec 0}$ 。
- 一组向量 $\mathbf{\vec v}_1,\mathbf{\vec v}_2,\cdots,\mathbf{\vec v}_n$ 是线性无关的，当且仅当 $a_i=0,i=1,2,\cdots,n$ 时，才有：$\sum_{i=1}^{n}a_i\mathbf{\vec v}_i=\mathbf{\vec 0}$


向量空间的维数：

- 一个向量空间所包含的最大线性无关向量的数目，称作该向量空间的维数。


点积与叉积：

- 三维向量的点积：$\mathbf{\vec u}\cdot\mathbf{\vec v} =u _ xv_x+u_yv_y+u_zv_z = |\mathbf{\vec u}| | \mathbf{\vec v}| \cos(\mathbf{\vec u},\mathbf{\vec v})$
 。

   <p align="center">
      <img width="30%" height="70%" src="http://images.iterate.site/blog/image/20190218/VTy4fmgh3lBG.png?imageslim">
   </p>

- 三维向量的叉积：$\mathbf{\vec w}=\mathbf{\vec u}\times \mathbf{\vec v}=\begin{bmatrix}\mathbf{\vec i}& \mathbf{\vec j}&\mathbf{\vec k}
\\    u_x&u_y&u_z\\    v_x&v_y&v_z\\    \end{bmatrix}$
  - $\mathbf{\vec i}, \mathbf{\vec j},\mathbf{\vec k}$ 分别为 $x,y,z$ 轴的单位向量。
    - $\mathbf{\vec u}=u_x\mathbf{\vec i}+u_y\mathbf{\vec j}+u_z\mathbf{\vec k},$
    - $\mathbf{\vec v}=v_x\mathbf{\vec i}+v_y\mathbf{\vec j}+v_z\mathbf{\vec k}$

   - $\mathbf{\vec u}$ 和 $\mathbf{\vec v}$ 的叉积垂直于 $\mathbf{\vec u},\mathbf{\vec v}$ 构成的平面，其方向符合右手规则。
   <p align="center">
    <img width="50%" height="70%" src="http://images.iterate.site/blog/image/20190218/QhK8pFRSVeNv.png?imageslim">
   </p>

   - 叉积的模等于 $\mathbf{\vec u},\mathbf{\vec v}$ 构成的平行四边形的面积
   - $\mathbf{\vec u}\times \mathbf{\vec v}=-\mathbf{\vec v}\times \mathbf{\vec u}$
   - $\mathbf{\vec u}\times( \mathbf{\vec v} \times \mathbf{\vec w})=(\mathbf{\vec u}\cdot \mathbf{\vec w})\mathbf{\vec v}-(\mathbf{\vec u}\cdot \mathbf{\vec v})\mathbf{\vec w}$
- 三维向量的混合积：$[\mathbf{\vec u} \;\mathbf{\vec v} \;\mathbf{\vec w}]=(\mathbf{\vec u}\times \mathbf{\vec v})\cdot \mathbf{\vec w}= \mathbf{\vec u}\cdot (\mathbf{\vec v} \times \mathbf{\vec w})\\    =\begin{vmatrix} u_x&u_y&u_z\\    v_x&v_y&v_z\\    w_x&w_y&w_z \end{vmatrix} =\begin{vmatrix} u_x&v_x&w_x\\    u_y&v_y&w_y\\    u_z&v_z&w_z\end{vmatrix}$
  - 其物理意义为：以 $\mathbf{\vec u} ,\mathbf{\vec v} ,\mathbf{\vec w}$ 为三个棱边所围成的平行六面体的体积。 当 $\mathbf{\vec u} ,\mathbf{\vec v} ,\mathbf{\vec w}$ 构成右手系时，该平行六面体的体积为正号。
- 两个向量的并矢：给定两个向量 $\mathbf {\vec x}=(x_1,x_2,\cdots,x_n)^{T},   \mathbf {\vec y}= (y_1,y_2,\cdots,y_m)^{T}$ ，则向量的并矢记作：$\mathbf {\vec x}\mathbf {\vec y}  =\begin{bmatrix}x_1y_1&x_1y_2&\cdots&x_1y_m\\    x_2y_1&x_2y_2&\cdots&x_2y_m\\    \vdots&\vdots&\ddots&\vdots\\    x_ny_1&x_ny_2&\cdots&x_ny_m\\    \end{bmatrix}$
  - 也记作 $\mathbf {\vec x}\otimes\mathbf {\vec y}$ 或者 $\mathbf {\vec x} \mathbf {\vec y}^{T}$。（并矢之前接触过，补充下）




## 向量求导

**向量对标量求导：**


$${\frac {\partial \mathbf {y} }{\partial x}}={\begin{bmatrix}{\frac {\partial y_{1}}{\partial x}}\\{\frac {\partial y_{2}}{\partial x}}\\\vdots \\{\frac {\partial y_{m}}{\partial x}}\\\end{bmatrix}}$$

其中：

- 向量 $\mathbf {y} ={\begin{bmatrix}y_{1}&y_{2}&\cdots &y_{m}\end{bmatrix}}^{\mathsf {T}}$ 
- 标量 $x$


**标量对向量求导：**


$${\frac {\partial y}{\partial \mathbf {x} }}={\begin{bmatrix}{\frac {\partial y}{\partial x_{1}}}&{\frac {\partial y}{\partial x_{2}}}&\cdots &{\frac {\partial y}{\partial x_{n}}}\end{bmatrix}}$$

其中：

- 标量 $y$
- 向量 $\mathbf {x} ={\begin{bmatrix}x_{1}&x_{2}&\cdots &x_{n}\end{bmatrix}}^{\mathsf {T}}$

亦即：


$$
\nabla f(\mathbf{x})=\frac{\partial f(\mathbf{x})}{\partial \mathbf{x}}=\left[\begin{array}{c}{\frac{\partial f(\mathbf{x})}{\partial x_{1}}} \\ {\vdots} \\ {\frac{\partial f(\mathbf{x})}{\partial x_{n}}}\end{array}\right]
$$

**向量对向量求导：**


$${\frac {\partial \mathbf {y} }{\partial \mathbf {x} }}={\begin{bmatrix}{\frac {\partial y_{1}}{\partial x_{1}}}&{\frac {\partial y_{1}}{\partial x_{2}}}&\cdots &{\frac {\partial y_{1}}{\partial x_{n}}}\\{\frac {\partial y_{2}}{\partial x_{1}}}&{\frac {\partial y_{2}}{\partial x_{2}}}&\cdots &{\frac {\partial y_{2}}{\partial x_{n}}}\\\vdots &\vdots &\ddots &\vdots \\{\frac {\partial y_{m}}{\partial x_{1}}}&{\frac {\partial y_{m}}{\partial x_{2}}}&\cdots &{\frac {\partial y_{m}}{\partial x_{n}}}\\\end{bmatrix}}$$

说明：

- 向量 $\mathbf {y} ={\begin{bmatrix}y_{1}&y_{2}&\cdots &y_{m}\end{bmatrix}}^{\mathsf {T}}$ 
- 向量 $\mathbf {x} ={\begin{bmatrix}x_{1}&x_{2}&\cdots &x_{n}\end{bmatrix}}^{\mathsf {T}}$


也称为**雅可比矩阵**。


## 向量的导数

- $\frac{\partial A \overrightarrow{x} }{\partial \overrightarrow{x} }=A^T$
- $\frac{\partial A^T \overrightarrow{x} }{\partial \overrightarrow{x} }=A$
- $\frac{\partial A \overrightarrow{x} }{\partial \overrightarrow{x}^T}=A$




## 标量对向量的导数


$A$ 为 $n\times n$ 的矩阵，$x$ 为 $n\times 1$ 的列向量，记  $y=\overrightarrow{x}^T\cdot A\cdot \overrightarrow{x}$

这个时候 y 是一个数。这时可得：

$$
\frac{\partial y}{\partial \vec{x}}=\frac{\partial\left(\vec{x}^{T} \cdot A \cdot \vec{x}\right)}{\partial \vec{x}}=\left(A^{T}+A\right) \cdot \vec{x}
$$

如果 A 为对称阵，则有：

$$
\frac{\partial y}{\partial \vec{x}}=\frac{\partial\left(\vec{x}^{T} \cdot A \cdot \vec{x}\right)}{\partial \vec{x}}=2 A \cdot \vec{x}
$$
