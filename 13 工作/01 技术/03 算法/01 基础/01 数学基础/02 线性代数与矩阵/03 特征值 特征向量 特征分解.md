

# 特征值 特征向量 特征分解

## 特征值 特征向量


特征向量 eigenvector

特征向量与特征值：

- 方阵 $\boldsymbol{A}$ 的特征向量是指与 $\boldsymbol{A}$ 相乘后相当于对该向量进行缩放的非零向量 $\boldsymbol{v}$：

$$
\boldsymbol{A} \boldsymbol{v}=\lambda \boldsymbol{v}
$$

说明：

- 标量 $\lambda$ 称为这个特征向量对应的特征值(eigenvalue)。
- 类似地，我们也可以定义左特征向量(left eigenvector) $\boldsymbol{v}^{\top} \boldsymbol{A}=\lambda \boldsymbol{v}^{\top}$，但是通常我们更关注右特征向量(right eigenvector)。
- 如果 $\boldsymbol{v}$ 是 $\boldsymbol{A}$ 的特征向量，那么任何缩放后的向量 $s \boldsymbol{v}(s \in \mathbb{R}, \quad s \neq 0)$ 也是 $\boldsymbol{A}$ 的特征向量。而且，$s\boldsymbol{v}$ 和 $\boldsymbol{v}$ 有相同的特征值。基于这个原因，通常我们只考虑单位特征向量。




特征值与特征向量：

- 通过特征值分解，我们可以得到特征值(eigenvalues)与特征向量(eigenvectors)。
- 特征值表示的是这个特征到底有多重要，而特征向量表示这个特征是什么。

含义：

- 如果 $\nu$ 是方阵 $A$ 的特征向量
- $\lambda$ 为特征向量 $\nu$ 对应的特征值。
- 那么：$A\nu = \lambda \nu$




## 特征分解

特征分解 eigendecomposition



分解：

- 对于一个数学对象，我们可以通过将它们分解成多个组成部分或者找到它们的一些属性来更好地理解它们。
  - 举例：对于整数，我们可以分解为质因数。我们可以用十进制或二进制等不同方式表示整数 $12$，但是 $12=2×2×3$ 永远是对的。从这个表示中我们可以获得一些有用的信息，比如 $12$ 不能被 $5$ 整除，或者 $12$ 的倍数可以被 $3$ 整除。
  - 举例，对于矩阵，我们可以通过分解矩阵来发现矩阵表示成数组元素时不明显的函数性质。特征分解，就是一种矩阵分解方式，将矩阵分解成一组特征向量和特征值。

特征分解：

- 假设矩阵 $\boldsymbol{A}$ 有 $n$ 个线性无关的特征向量 $\left\{\boldsymbol{v}^{(1)}, \ldots, \boldsymbol{v}^{(n)}\right\}$，对应着特征值 $\left\{\lambda_{1}, \dots, \lambda_{n}\right\}$。我们将特征向量连接成一个矩阵，使得每一列是一个特征向量：$V=\left[\boldsymbol{v}^{(1)}, \ldots, \boldsymbol{v}^{(n)}\right]$。类似地，我们也可以将特征值连接成一个向量 $\boldsymbol{\lambda}=\left[\lambda_{1}, \ldots, \lambda_{n}\right]^{\top}$。因此 A 的特征分解可以记作：

$$
\boldsymbol{A}=\boldsymbol{V} \operatorname{diag}(\boldsymbol{\lambda}) \boldsymbol{V}^{-1}
$$


说明：

- $diag(\boldsymbol{v})$ 表示对角元素由向量 $\boldsymbol{v}$ 中元素给定的一个对角方阵。



后面这部分没有看：




是否可以分解：

- 不是每一个矩阵都可以分解成特征值和特征向量。在某些情况下，特征分解存在，但是会涉及复数而非实数。幸运的是，在本书中，我们通常只需要分解一类有简单分解的矩阵。具体来讲，每个实对称矩阵都可以分解成实特征向量和实特征值：<span style="color:red;">嗯。</span>


$$
\boldsymbol{A}=\boldsymbol{Q} \boldsymbol{\Lambda} \boldsymbol{Q}^{\top}
$$

其中 $\boldsymbol{Q}$ 是 $\boldsymbol{A}$ 的特征向量组成的正交矩阵，$\boldsymbol{\Lambda}$ 是对角矩阵。特征值 $\Lambda_{i, i}$ 对应的特征向量是矩阵 $\boldsymbol{Q}$ 的第 $i$ 列，记作 $\boldsymbol{Q}_{ :, i}$ 。因为  $\boldsymbol{Q}$ 是正交矩阵，我们可以将 $\boldsymbol{A}$ 看作沿方向 $\boldsymbol{v}^{(i)}$ 延展 $\lambda_{i}$ 倍的空间，如图 2.3所示。<span style="color:red;">嗯嗯，是的，这么一说还真的有点形象。</span>

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190507/bRqJscGmGXDF.png?imageslim">
</p>


> 图 2.3　特征向量和特征值的作用效果。特征向量和特征值的作用效果的一个实例。在这里，矩阵 $\boldsymbol{A}$ 有两个标准正交的特征向量，对应特征值为 $\lambda_{1}$ 的 $\boldsymbol{v}^{(1)}$ 以及对应特征值为 $\lambda_{2}$ 的 $\boldsymbol{v}^{(2)}$。(左)我们画出了所有单位向量 $\boldsymbol{u} \in \mathbb{R}^{2}$ 的集合，构成一个单位圆。(右)我们画出了所有 $\boldsymbol{A} \boldsymbol{u}$ 点的集合。通过观察 $\boldsymbol{A}$ 拉伸单位圆的方式，我们可以看到它将 $\boldsymbol{v}^{(2)}$ 方向的空间拉伸了 $\lambda_{i}$ 倍。<span style="color:red;">是的是的，很清晰，很形象。</span>

虽然任意一个实对称矩阵 $\boldsymbol{A}$ 都有特征分解，但是特征分解可能并不唯一。如果两个或多个特征向量拥有相同的特征值，那么在由这些特征向量产生的生成子空间中，任意一组正交向量都是该特征值对应的特征向量。因此，我们可以等价地从这些特征向量中构成 $\boldsymbol{Q}$ 作为替代。按照惯例，我们通常按降序排列 $\boldsymbol{\Lambda}$ 的元素。在该约定下，特征分解唯一，当且仅当所有的特征值都是唯一的。<span style="color:red;">对于这个理解的没有很深。</span>

矩阵的特征分解给了我们很多关于矩阵的有用信息。矩阵是奇异的，当且仅当含有零特征值。实对称矩阵的特征分解也可以用于优化二次方程 $f(x)=x^{\top} A x$ ，其中限制 $\|x\|_{2}=1$ 。当 $x$ 等于 $\boldsymbol{A}$ 的某个特征向量时，$f$ 将返回对应的特征值。在限制条件下，函数 $f$ 的最大值是最大特征值，最小值是最小特征值。<span style="color:red;">有些厉害，但是感觉没有理解很深。</span>

所有特征值都是正数的矩阵称为正定(positive definite)；所有特征值都是非负数的矩阵称为半正定(positive semidefinite)。同样地，所有特征值都是负数的矩阵称为负定(negative definite)；所有特征值都是非正数的矩阵称为半负定(negative semidefinite)。半正定矩阵受到关注是因为它们保证 $\forall \boldsymbol{x}, \boldsymbol{x}^{\top} \boldsymbol{A} \boldsymbol{x} \geq 0$ 。此外，正定矩阵还保证 $\boldsymbol{x}^{\top} \boldsymbol{A} \boldsymbol{x}=0 \Rightarrow \boldsymbol{x}=\mathbf{0}$。<span style="color:red;">没明白。</span>


疑问：

- 所有的矩阵都可以进行特征分解吗？