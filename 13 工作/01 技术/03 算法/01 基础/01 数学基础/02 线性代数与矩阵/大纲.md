
# 线性代数

线性代数在机器学习的几乎所有地方都有使用，具体用到的知识点有：

矩阵分析。

线性代数作为数学的一个分支，广泛应用于科学和工程中。然而，因为线性代数主要是面向连续数学，而非离散数学，所以很多计算机科学家很少接触它。掌握好线性代数对于理解和从事机器学习算法相关工作是很有必要的，尤其对于深度学习算法而言。

<span style="color:red;">感觉还是要找一本线性代数的书，仔细阅读，这样心里才踏实。</span>



1．向量和矩阵（Vectors and matrics）
2．矩阵的决定因素（determinant of a matrix）
3．特征向量和特征值（eigenvectors and eigenvalues）
4．矩阵分解（像SVD）（Matrix factorization）



## 主要内容

线性代数基本概念：

- 向量及其运算
- 矩阵及其运算
- 张量
- 行列式
- 二次型
- 特征值与特征向量


- 奇异值分解 SVD
- 常用的矩阵与向量求导公式





1）线性空间及线性变换
2）矩阵的基本概念
3）状态转移矩阵
4）特征向量
5）矩阵的相关乘法
6）矩阵的 QR 分解
7）对称矩阵、正交矩阵、正定矩阵
8）矩阵的 SVD 分解
9）矩阵的求导
10）矩阵映射/投影
11）矩阵的秩
12）矩阵的特征值和特征空间




1~24 是微积分和线性代数的
第 2 集数学知识-1
2.1 本集内容简介
2.2 学好机器学习需要哪些数学知识
2.3 推荐的参考书
2.4 本集所讲的知识点
2.5 机器学习算法所用的数学知识
2.6 导数
2.7 高阶导数
2.8 导数与函数的性质


2.9 一元函数的泰勒展开
2.10 向量
2.11 矩阵
2.12 行列式
2.13 偏导数
2.14 高阶偏导数
2.15 梯度

2.16 雅可比矩阵
2.17 Hessian 矩阵
2.18 极值判别法则
2.19 二次型
2.20 特征值与特征向量
2.21 特征值分解
2.22 多元函数的泰勒展开
2.23 矩阵和向量求导公式
2.24 奇异值分解




相比之下，线性代数用的更多。在机器学习的几乎所有地方都有使用，具体用到的知识点有：

- 向量和它的各种运算，包括加法，减法，数乘，转置，内积
- 向量和矩阵的范数，L1范数和 L2 范数
- 矩阵和它的各种运算，包括加法，减法，乘法，数乘
- 逆矩阵的定义与性质
- 行列式的定义与计算方法
- 二次型的定义
- 矩阵的正定性
- 矩阵的特征值与特征向量
- 矩阵的奇异值分解
- 线性方程组的数值解法，尤其是共轭梯度法



机器学习算法处理的数据一般都是向量、矩阵或者张量。经典的机器学习算法输入的数据都是特征向量，深度学习算法在处理图像时输入的 2 维的矩阵或者 3 维的张量。掌握这些知识会使你游刃有余。




## 需要消化的

- 《线性代数》同济 第六版
- 《线性代数》 史蒂文利恩 黄皮书 Steven Leon
- 如果想非常深入的理解线性代数里里面的思想和概念，可以去看数学系的教材，叫《高等代数》
- 清华大学张贤达的《矩阵分析与应用》，可以弥补绝大多数机器学习深度学习方面的矩阵/优化/分析相关知识。

- [ 用Python和NumPy学习《深度学习》中的线性代数基础](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650742247&idx=4&sn=04a0db41941d6e7b438149abcb17f86f&chksm=871ad999b06d508fabaeaed126925125f29c05c4e9cffc114f780312ee5cafeacb82bca22866&mpshare=1&scene=1&srcid=05158upcR4K5uQizD0RwbruL#rd) 看了下非常好，对于矩阵的理解非常有帮助，融入进来。

## 可以补充进来的

- 这里面的张量比矩阵里面的张量要简单很多，可以当成一个三维的数组。



1. 线性代数介绍
2. 标量、向量、矩阵和张量
3. 矩阵和向量相乘
4. 单位矩阵和逆矩阵
5. 线性相关和生成子空间
6. 范数
7. 特殊类型的矩阵和向量
8. 特征分解
9. 奇异值分解
10. Moore-Penrose 伪逆
11. 迹运算
12. 行列式
13. 实例：主成分分析
14.
15. 线性映射与矩阵
16. 矩阵变换与特征值
17. 奇异值分解
18. 向量求导


## 疑问


- 什么是数学归纳法？明确的是什么？
- [伪逆矩阵的意义及求法？](https://www.zhihu.com/question/47688307)