

# 损失函数

损失函数：

- 在大多数情况下，我们的参数模型定义了一个分布 $p(\boldsymbol y\mid\boldsymbol x;\boldsymbol \theta)$ 并且我们简单地使用最大似然原理。这意味着我们使用训练数据和模型预测间的交叉熵作为损失函数。
- 有时，我们使用一个更简单的方法，不是预测 $\boldsymbol y$ 的完整概率分布，而是仅仅预测在给定 $\boldsymbol x$ 的条件下 $\boldsymbol y$ 的某种统计量。某些专门的损失函数允许我们来训练这些估计量的预测器。（没明白）
- 注意：完整的损失函数，通常在基本的损失函数上结合一个正则项。






## 使用最大似然学习条件分布

代价函数由来：

- 大多数现代的神经网络使用最大似然来训练。
- 这意味着代价函数就是负的对数似然，它与训练数据和模型分布间的交叉熵等价。
- 这个代价函数表示为

$$
J(\boldsymbol \theta) = -\mathbb E_{\mathbf x, \mathbf y \sim \hat{p}_\text{data}} \log p_\text{model} (\boldsymbol y \mid \boldsymbol x).
$$

- 使用最大似然来导出代价函数的一个优势是：
  - 它减轻了为每个模型设计代价函数的负担。明确一个模型 $p(\boldsymbol y\mid\boldsymbol x)$ 则自动地确定了一个代价函数 $\log p(\boldsymbol y\mid\boldsymbol x)$。

随着模型的变化：

- 代价函数的具体形式随着模型而改变，取决于 $\log p_\text{model}$ 的具体形式。
- 上述方程的展开形式通常会有一些项不依赖于模型的参数，我们可以舍去。
  - 例如：
    - 如果 $p_\text{model}(\boldsymbol y\mid\boldsymbol x) = \mathcal N(\boldsymbol y;f(\boldsymbol x;\boldsymbol \theta), \boldsymbol I)$
    - 那么我们就重新得到了均方误差代价 $J(\theta) = \frac{1}{2} \mathbb E_{\mathbf x, \mathbf y \sim  \hat{p}_\text{data}} || \boldsymbol y - f(\boldsymbol x; \boldsymbol \theta) ||^2 + \text{const},$
    - 至少系数 $\frac{1}{2}$ 和常数项不依赖于 $\boldsymbol \theta$。舍弃的常数是基于高斯分布的方差，在这种情况下我们选择不把它参数化。
  - 之前，我们看到了对输出分布的最大似然估计和对线性模型均方误差的最小化之间的等价性<span style="color:red;">等价性这部分再看下。</span>，但事实上，这种等价性并不要求 $f(\boldsymbol x; \boldsymbol \theta)$ 用于预测高斯分布的均值。


对于代价函数的设计：

- 贯穿神经网络设计的一个反复出现的主题是代价函数的梯度必须足够的大和具有足够的预测性，来为学习算法提供一个好的指引。
- 饱和（变得非常平）的函数破坏了这一目标，因为它们把梯度变得非常小。这在很多情况下都会发生，因为用于产生隐藏单元或者输出单元的输出的激活函数会饱和。负的对数似然帮助我们在很多模型中避免这个问题。很多输出单元都会包含一个指数函数，这在它的变量取绝对值非常大的负值时会造成饱和。<span style="color:red;">输出单元包含一个指数函数，是指的 softmax 吗？还是 sigmoid？还是什么？</span>负对数似然代价函数中的对数函数消除了某些输出单元中的指数效果。我们将会在 节 输出单元 中讨论代价函数和输出单元的选择间的相互作用。


用于实现最大似然估计的交叉熵代价函数：

（没有很明白）

- 用于实现最大似然估计的交叉熵代价函数有一个不同寻常的特性，那就是：
  - 当它被应用于实践中经常遇到的模型时，它通常没有最小值。
  - 对于离散型输出变量，大多数模型以一种特殊的形式来参数化，即它们不能表示概率零和一，但是可以无限接近。逻辑回归是其中一个例子。对于实值的输出变量，如果模型可以控制输出分布的密度（例如，通过学习高斯输出分布的方差参数），<span style="color:red;">控制输出分布的密度是什么意思？</span>那么它可能对正确的训练集输出赋予极其高的密度，这将导致交叉熵趋向负无穷。<span style="color:red;">对正确的训练集输出赋予极其高的密度是什么意思？为什么会导致交叉熵趋向于负无穷？</span>第七章中描述的正则化技术提供了一些不同的方法来修正学习问题，使得模型不会通过这种方式来获得无限制的收益。<span style="color:red;">有哪些正则化技术来消除这个问题？</span>



## 学习条件统计量

缘由：

- 有时我们并不是想学习一个完整的概率分布 $p(\boldsymbol y\mid\boldsymbol x; \boldsymbol \theta)$，而仅仅是想学习在给定 $\boldsymbol x$ 时 $\boldsymbol y$ 的某个条件统计量。

举例：

- 我们可能有一个预测器 $f(\boldsymbol x; \boldsymbol \theta)$，我们想用它来预测 $\boldsymbol y$ 的均值。
- 如果我们使用一个足够强大的神经网络，我们可以认为这个神经网络能够表示一大类函数中的任何一个函数 $f$，这个类仅仅被一些特征所限制，例如连续性和有界，而不是具有特殊的参数形式。从这个角度来看，我们可以把代价函数看作是一个泛函而不仅仅是一个函数。
- 泛函是函数到实数的映射。我们因此可以将学习看作是选择一个函数而不仅仅是选择一组参数。我们可以设计代价泛函在我们想要的某些特殊函数处取得最小值。
- 例如，我们可以设计一个代价泛函，使它的最小值处于一个特殊的函数上，这个函数将 $\boldsymbol x$ 映射到给定 $\boldsymbol x$ 时 $\boldsymbol y$ 的期望值。对函数求解优化问题需要用到变分法这个数学工具。理解变分法对于理解本章的内容不是必要的。目前，只需要知道变分法可以被用来导出下面的两个结果。
  - 结果1：
    - 解优化问题

    $$
    f^* = \underset{f}{\arg \min }  \ \mathbb E_{\mathbf x, \mathbf y \sim  p_\text{data}} ||\boldsymbol y-f(\boldsymbol x)||^2
    $$

    - 得到

    $$
    f^*(\boldsymbol x) = \mathbb E_{\mathbf y\sim p_\text{data}(\boldsymbol y|\boldsymbol x)} [\boldsymbol y],
    $$

    - 要求这个函数处在我们要优化的类里。
    - 换句话说，如果我们能够用无穷多的、来源于真实的数据生成分布的样本进行训练，最小化均方误差代价函数将得到一个函数，它可以用来对每个 $\boldsymbol x$ 的值预测出 $\boldsymbol y$ 的均值。
  - 结果1：

    $$
    f^* = \underset{f}{\arg \min } \ \mathbb E_{\mathbf x, \mathbf y \sim  p_\text{data}} ||\boldsymbol y - f(\boldsymbol x)||_1
    $$

    - 将得到一个函数，可以对每个 $\boldsymbol x$ 预测 $\boldsymbol y$ 取值的**中位数**，只要这个函数在我们要优化的函数族里。这个代价函数通常被称为平均绝对误差。<span style="color:red;">中位数？为什么是预测中位数？</span>
  - 可惜的是，均方误差和平均绝对误差在使用基于梯度的优化方法时往往成效不佳。一些饱和的输出单元当结合这些代价函数时会产生非常小的梯度。这就是为什么交叉熵代价函数比均方误差或者平均绝对误差更受欢迎的原因之一了，即使是在没必要估计整个 $p(\boldsymbol y\mid\boldsymbol x)$ 分布时。




不同的代价函数给出不同的统计量。



## 交叉熵损失函数

交叉熵损失函数定义及其求导：


- 设：
  - $i_j$ 为输入
  - $z=\sum w_{j}i_{j}+b​$ 是输入的带权和。
  - 输出为 $\mathrm{a}=\sigma(\mathrm{z})$
  - $\sigma(z)=\frac{1}{1+e^{-z}}$
- 则，交叉熵为：

    $$
    C=-\frac{1}{n}\sum[y\ln a+(1-y)\ln (1-a)]
    $$

- 说明：
  - $n$ 是训练数据的总数
  - 求和是在所有的训练输入 $x$ 上进行的， $y$ 是对应的目标输出。






交叉熵为何能够解释成⼀个代价函数：

- 它是非负的。
  - 由于对数函数的定义域是 $(0，1)$，所以，$\ln a$ 和 $\ln (1-a)$ 均为负数。
- 如果对于所有的训练输入 $x$，神经元实际的输出接近目标值，那么交叉熵将接近 $0$。
  - 因为 $a$ 是 $(0,1)$ ，因此，$ln(a)$ 就是 $(-\infty,0)$ ，而 $y$ 的值是 $0$,$1$ ，所以 $C$ 接近 $0$。
- 综上所述：
  - 交叉熵是非负的，在神经元达到很好的正确率的时候会接近 $0$。这些其实就是我们想要的代价函数的特性。



交叉熵是否能够解决学习缓慢的问题：

- 计算交叉熵函数关于权重的偏导数：

$$
\begin{aligned}\frac{\partial C}{\partial w_{j}}&=-\frac{1}{n}\sum \frac{\partial }{\partial w_{j}}[ylna+(1-y)ln(1-a)]
\\&=-\frac{1}{n}\sum \frac{\partial }{\partial a}[ylna+(1-y)ln(1-a)]*\frac{\partial a}{\partial w_{j}}
\\&=-\frac{1}{n}\sum (\frac{y}{a}-\frac{1-y}{1-a})*\frac{\partial a}{\partial w_{j}}
\\&=-\frac{1}{n}\sum (\frac{y}{\sigma(z)}-\frac{1-y}{1-\sigma(z)})\frac{\partial \sigma(z)}{\partial w_{j}}
\\&=-\frac{1}{n}\sum (\frac{y}{\sigma(z)}-\frac{1-y}{1-\sigma(z)}){\sigma}'(z)x_{j}
\\&=\frac{1}{n}\sum x_{j}({\sigma}(z)-y)
\end{aligned}
$$

- 说明：
  - 第三行到第四行：将 $a={\sigma}(z)$ 代入
  - 第五行到第六行：根据 $\sigma(z)=\frac{1}{1+e^{-z}}$ 的定义，有： ${\sigma}'(z)=\sigma(z)(1-\sigma(z))$。带入。

- 类似的，可以计算出关于偏置的偏导数：

$$
\frac{\partial C}{\partial b}=\frac{1}{n}\sum ({\sigma}(z)-y)​
$$

- 可见：
  - 权重学习的速度受到 $\sigma(z)-y$，也就是输出中的误差的控制。
  - 也就是：越大的误差就会有越快的学习速度。这是我们直觉上期待的结果。
  - 特别地，与二次代价函数相比，这个代价函数还避免了像 ${\sigma}'(z)$ 导致的学习缓慢。当我们使用交叉熵的时候，${\sigma}'(z)$ 被约掉了，所以我们不再需要关心它是不是变得很小。也即：它避免了学习速度下降的问题。
    - 均方误差在 20 世纪 80 年代和 90 年代流行，但逐渐被交叉熵损失替代，并且最大似然原理的想法在统计学界和机器学习界之间广泛传播。
    - 使用交叉熵损失大大提高了具有 sigmoid  和 softmax 输出的模型的性能，而当使用均方误差损失时会存在饱和和学习缓慢的问题。
    - 实际上，这也并不是非常奇迹的事情。我们在后面可以看到，交叉熵其实只是满足这种特性的⼀种选择罢了。




### 平方误差损失函数和交叉熵损失函数对比：

- 平方损失函数更适合输出为连续，并且最后一层不含 Sigmoid 或 Softmax 激活函数的神经网络；
  - 原因：
    - 平方误差损失函数：
      - 权值 $w$ 和偏置 $b$ 的偏导数为：
        - $\frac{\partial J}{\partial w}=(a-y)\sigma'(z)x$
        - $\frac{\partial J}{\partial b}=(a-y)\sigma'(z)$
      - 可见：
        - 偏导数受激活函数的导数影响，sigmoid函数导数在输出接近 0 和 1 时非常小，会导致一些实例在刚开始训练时学习得非常慢。
    - 交叉熵损失函数：
      - 权值 $w$ 和偏置 $b$ 的梯度推导为：
        - $\frac{\partial J}{\partial w_j}=\frac{1}{n}\sum_{x}x_j(\sigma{(z)}-y)$
        - $\frac{\partial J}{\partial b}=\frac{1}{n}\sum_{x}(\sigma{(z)}-y)$
      - 可见：
        - 权重学习的速度受到 $\sigma{(z)}-y$ 影响，更大的误差，就有更快的学习速度，避免了二次代价函数方程中因 $\sigma'{(z)}$ 导致的学习缓慢的情况。
- 交叉熵损失则更适合二分类或多分类的场景。





