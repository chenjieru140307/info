
# 线性因子模型


- 缘由：
  - 之前总结的方法大部分是在有大量数据情况下的监督学习方法，而假如我们想减小数据量的要求，则需要一些无监督学习及半监督学习方法，
  - 虽然有很多无监督学习方法，但是目前还无法达到深度学习在监督学习问题中所达到的精度，这常常是由于我们需要解决的问题的维度过高或计算量过大造成的。
  - 无监督学习常常需要建立一种依赖于观察数据的概率模型 $p_{\text {model}}(x)$ ，但由于实际观察的数据 $x$ 常常比较杂乱没有规律，通常我们会用某种代表了更低维基本特征的隐性变量(latent variables) $h$ 来更好的表征数据，将问题转化为 $p_{\text {model}}(x)=E_{h} p_{\text {model}}(x | h)$
  - 而最基本的，利用隐性变量的概率模型 就是 线性因子模型(Linear Factor model)，即假定 $h$ 取自某种先验分布 $h \sim p(h)$ ，而我们观察到的数据是 $h$ 的线性变换与一些随机噪声的叠加，用式子表示为 $x=W h+b+$noise ，之后讨论的不同方法会选择不同的 $p(h)$ 和 noise 分布。


线性因子模型：

- 介绍：
  - 线性因子模型通过随机线性解码器函数来定义，该函数通过对 $\boldsymbol h$ 的线性变换以及添加噪声来生成 $\boldsymbol x$。
  - 线性解码器的简单性使得它们成为了最早被广泛研究的潜变量模型。

- 作用：
  - 这些模型有时被用来作为混合模型的组成模块**或者更大的深度概率模型**。


- 说明：
  - 线性因子模型描述如下的数据生成过程。
  - 首先，我们从一个分布中抽取解释性因子 $\boldsymbol h$：

    $$\begin{aligned}
    \mathbf h \sim p(\boldsymbol h),
    \end{aligned}$$
  - 其中：
    - $p(\boldsymbol h)$ 是一个因子分布，满足 $p(\boldsymbol h) = \prod_{i}^{}p(h_i)$，所以易于从中采样。
  - 接下来，在给定因子的情况下，我们对实值的可观察变量进行采样

    $$\begin{aligned}
    \boldsymbol x = \boldsymbol W \boldsymbol h + \boldsymbol b + \text{noise},
    \end{aligned}$$

  - 其中噪声通常是对角化的（在维度上是独立的）且服从高斯分布。
  - 如图：描述线性因子模型族的有向图模型

    <p align="center">
        <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/C9wpBfC2ccnA.png?imageslim">
    </p>

  - 说明：
    - 我们假设观察到的数据向量 $\boldsymbol x$ 是通过独立的潜在因子 $\boldsymbol h$ 的线性组合再加上一定噪声获得的。
    - 不同的模型，比如概率 PCA，因子分析或者是 ICA，都是选择了不同形式的噪声以及先验 $p(\boldsymbol h)$。