

## 3.8 权重偏差初始化

### 3.8.1 全都初始化为 0

<span style="color:red;">没理解。</span>

**偏差初始化陷阱**：都初始化为 0。

**产生陷阱原因**：因为并不知道在训练神经网络中每一个权重最后的值，但是如果进行了恰当的数据归一化后，我们可以有理由认为有一半的权重是正的，另一半是负的。令所有权重都初始化为 0，如果神经网络计算出来的输出值是一样的，神经网络在进行反向传播算法计算出来的梯度值也一样，并且参数更新值也一样。更一般地说，如果权重初始化为同一个值，网络就是对称的。<span style="color:red;">有一半的权重是正的。是什么意思？没懂这一段说的网络是对称的是什么意思。</span>

**形象化理解**：在神经网络中考虑梯度下降的时候，设想你在爬山，但身处直线形的山谷中，两边是对称的山峰。由于对称性，你所在之处的梯度只能沿着山谷的方向，不会指向山峰；你走了一步之后，情况依然不变。结果就是你只能收敛到山谷中的一个极大值，而走不到山峰上去。



# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
