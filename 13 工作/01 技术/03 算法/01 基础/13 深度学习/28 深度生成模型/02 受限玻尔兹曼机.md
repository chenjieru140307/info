

# 受限玻尔兹曼机

受限玻尔兹曼机以簧风琴之名面世之后，成为了深度概率模型中最常见的组件之一。我们之前在 节 实例：受限玻尔兹曼机 简要介绍了 RBM。在这里我们回顾以前的内容并探讨更多的细节。RBM 是包含一层可观察变量和单层潜变量的无向概率图模型。RBM 可以堆叠起来（一个在另一个的顶部）形成更深的模型。\fig?展示了一些例子。特别地， \fig?a显示 RBM 本身的图结构。它是一个二分图，观察层或潜层中的任何单元之间不允许存在连接。




<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/H4iOcLYXmh21.png?imageslim">
</p>
> 20.1 可以用受限玻尔兹曼机构建的模型示例。(a)受限玻尔兹曼机本身是基于二分图的无向图模型，在图的一部分具有可见单元，另一部分具有隐藏单元。可见单元之间没有连接，隐藏单元之间也没有任何连接。通常每个可见单元连接到每个隐藏单元，但也可以构造稀疏连接的 RBM，如卷积 RBM。(b)深度信念网络是涉及有向和无向连接的混合图模型。与 RBM 一样，它也没有层内连接。然而，DBN~具有多个隐藏层，因此隐藏单元之间的连接在分开的层中。深度信念网络所需的所有局部条件概率分布都直接复制 RBM 的局部条件概率分布。或者，我们也可以用完全无向图表示深度信念网络，但是它需要层内连接来捕获父节点间的依赖关系。(c)深度玻尔兹曼机是具有几层潜变量的无向图模型。与 RBM 和 DBN~一样，DBM 也缺少层内连接。DBM 与 RBM 的联系不如 DBN~紧密。当从 RBM 堆栈初始化 DBM 时，有必要对 RBM 的参数稍作修改。某些种类的 DBM 可以直接训练，而不用先训练一组 RBM。


我们从二值版本的受限玻尔兹曼机开始，但如我们之后所见，这还可以扩展为其他类型的可见和隐藏单元。

更正式地说，令观察层由一组 $n_v$ 个二值随机变量组成，我们统称为向量 $\mathbf v$。我们将 $n_h$ 个二值随机变量的潜在或隐藏层记为 $\boldsymbol h$。


就像普通的玻尔兹曼机，受限玻尔兹曼机也是基于能量的模型，其联合概率分布由能量函数指定：


$$\begin{aligned}
 P(\mathbf v = \boldsymbol v, \mathbf h = \boldsymbol h) = \frac{1}{Z} \exp(-E(\boldsymbol v, \boldsymbol h)).
\end{aligned}$$


RBM的能量函数由下给出

$$\begin{aligned}
 E(\boldsymbol v, \boldsymbol h) = -\boldsymbol b^\top \boldsymbol v - \boldsymbol c^\top \boldsymbol h - \boldsymbol v^\top \boldsymbol W \boldsymbol h,
\end{aligned}$$


其中 $Z$ 是被称为配分函数的归一化常数：

$$\begin{aligned}
 Z = \sum_{\boldsymbol v} \sum_{\boldsymbol h} \exp \{-E(\boldsymbol v, \boldsymbol h) \}
\end{aligned}$$

从配分函数 $Z$ 的定义显而易见，计算 $Z$ 的朴素方法（对所有状态进行穷举求和）计算上可能是难以处理的，除非有巧妙设计的算法可以利用概率分布中的规则来更快地计算 $Z$。在受限玻尔兹曼机的情况下， {long10rbm}正式证明配分函数 $Z$ 是难解的。难解的配分函数 $Z$ 意味着归一化联合概率分布 $P(\boldsymbol v)$ 也难以评估。



## 条件分布

虽然 $P(\boldsymbol v)$ 难解，但 RBM 的二分图结构具有非常特殊的性质，其条件分布 $P(\mathbf h \mid \mathbf v)$ 和 $P(\mathbf v\mid\mathbf h)$ 是因子的，并且计算和采样是相对简单的。



从联合分布中导出条件分布是直观的：


$$\begin{aligned}
 P(\boldsymbol h \mid \boldsymbol v) &= \frac{P(\boldsymbol h, \boldsymbol v)}{P(\boldsymbol v)} \\
 &= \frac{1}{P(\boldsymbol v)} \frac{1}{Z} \exp \big\{ \boldsymbol b^\top \boldsymbol v + \boldsymbol c^\top \boldsymbol h + \boldsymbol v^\top\boldsymbol W \boldsymbol h \big\} \\
 &=  \frac{1}{Z^\prime} \exp \big\{ \boldsymbol c^\top \boldsymbol h + \boldsymbol v^\top\boldsymbol W \boldsymbol h \big\} \\
 &=  \frac{1}{Z^\prime} \exp \Big\{ \sum_{j=1}^{n_h}\boldsymbol c_j^\top \boldsymbol h_j
 + \sum_{n_h}^{j=1} \boldsymbol v^\top\boldsymbol W_{:,j} \boldsymbol h_j \Big\} \\
 &=  \frac{1}{Z^\prime} \prod_{j=1}^{n_h} \exp \big\{ \boldsymbol c_j^\top \boldsymbol h_j + \boldsymbol v^\top\boldsymbol W_{:,j} \boldsymbol h_j \big\} .
\end{aligned}$$


由于我们相对可见单元 $\mathbf v$ 计算条件概率，相对于分布 $P(\mathbf h  \mid  \mathbf v)$ 我们可以将它们视为常数。条件分布 $ P(\mathbf h  \mid  \mathbf v) $ 因子相乘的本质，我们可以将向量 $\boldsymbol h$ 上的联合概率写成单独元素 $h_j$ 上（未归一化）分布的乘积。现在原问题变成了对单个二值 $h_j$ 上的分布进行归一化的简单问题。


$$\begin{aligned}
 P(h_j=1  \mid  \boldsymbol v) &= \frac{\tilde{P}(h_j=1 \mid \boldsymbol v)}{\tilde{P}(h_j=0 \mid \boldsymbol v) + \tilde{P}(h_j=1 \mid \boldsymbol v)} \\
 &= \frac{\exp \{ c_j + \boldsymbol v^\top \boldsymbol W_{:,j} \} }{\exp\{ 0 \} + \exp \{ c_j + \boldsymbol v^\top \boldsymbol W_{:,j}\}} \\
 &= \sigma (c_j + \boldsymbol v^\top \boldsymbol W_{:,j}).
\end{aligned}$$


现在我们可以将关于隐藏层的完全条件分布表达为因子形式：


$$\begin{aligned}
 P(\boldsymbol h  \mid  \boldsymbol v) = \prod_{j=1}^{n_h} \sigma \big( (2\boldsymbol h-1) \odot (\boldsymbol c + \boldsymbol W^\top \boldsymbol v) \big)_j .
\end{aligned}$$

类似的推导将显示我们感兴趣的另一条件分布，$P(\boldsymbol v  \mid  \boldsymbol h)$ 也是因子形式的分布：


$$\begin{aligned}
  P(\boldsymbol v  \mid  \boldsymbol h) = \prod_{i=1}^{n_v} \sigma \big( (2\boldsymbol v-1) \odot (\boldsymbol b + \boldsymbol W \boldsymbol h) \big)_i .
\end{aligned}$$



## 训练受限玻尔兹曼机


因为 RBM 允许高效计算 $\tilde{P}(\boldsymbol v)$ 的估计和微分，并且还允许高效地（以块吉布斯采样的形式）进行 MCMC 采样，所以我们很容易使用 章 直面配分函数 中训练具有难以计算配分函数的模型的技术来训练 RBM。这包括~CD、\,SML（PCD）、比率匹配等。与深度学习中使用的其他无向模型相比，RBM 可以相对直接地训练，因为我们可以以闭解形式计算 $P(\mathbf h  \mid  \boldsymbol v)$。其他一些深度模型，如深度玻尔兹曼机，同时具备难处理的配分函数和难以推断的难题。




# 相关

- 《深度学习》花书
