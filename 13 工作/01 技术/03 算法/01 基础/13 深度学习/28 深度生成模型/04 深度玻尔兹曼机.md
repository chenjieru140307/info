

# 深度玻尔兹曼机


深度玻尔兹曼机 是另一种深度生成模型。与深度信念网络不同的是，它是一个完全无向的模型。与 RBM 不同的是，DBM 有几层潜变量（RBM 只有一层）。但是像 RBM 一样，每一层内的每个变量是相互独立的，并条件于相邻层中的变量。见\fig?中的图结构。深度玻尔兹曼机已经被应用于各种任务，包括文档建模。




<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/LzY1Nzcs0CU5.png?imageslim">
</p>


> 具有一个可见层（底部）和两个隐藏层的深度玻尔兹曼机的图模型。仅在相邻层的单元之间存在连接。没有层内连接。



与 RBM 和 DBN~一样，DBM 通常仅包含二值单元 （正如我们为简化模型的演示而假设的），但很容易就能扩展到实值可见单元。

DBM 是基于能量的模型，这意味着模型变量的联合概率分布由能量函数 $E$ 参数化。在一个深度玻尔兹曼机包含一个可见层 $\boldsymbol v$ 和三个隐藏层 $\boldsymbol h^{(1)},\boldsymbol h^{(2)}$ 和 $\boldsymbol h^{(3)}$ 的情况下，联合概率由下式给出：


$$\begin{aligned}
P(\boldsymbol v, \boldsymbol h^{(1)},  \boldsymbol h^{(2)},  \boldsymbol h^{(3)}) = \frac{1}{Z(\boldsymbol \theta)}
\exp \big( -E(\boldsymbol v, \boldsymbol h^{(1)},  \boldsymbol h^{(2)},  \boldsymbol h^{(3)}; \boldsymbol \theta) \big).
\end{aligned}$$


为简化表示，下式省略了偏置参数。DBM 能量函数定义如下：


$$\begin{aligned}
E(\boldsymbol v, \boldsymbol h^{(1)}, \boldsymbol h^{(2)}, \boldsymbol h^{(3)}; \boldsymbol \theta)  = -\boldsymbol v^\top \boldsymbol W^{(1)}\boldsymbol h^{(1)}
- \boldsymbol h^{(1)^\top}\boldsymbol W^{(2)}\boldsymbol h^{(2)}- \boldsymbol h^{(2)^\top}\boldsymbol W^{(3)}\boldsymbol h^{(3)}.
\end{aligned}$$


与 RBM 的能量函数（ $E(\boldsymbol{v}, \boldsymbol{h})=-\boldsymbol{b}^{\top} \boldsymbol{v}-\boldsymbol{c}^{\top} \boldsymbol{h}-\boldsymbol{v}^{\top} \boldsymbol{W} \boldsymbol{h}$ ）相比，DBM 能量函数以权重矩阵（$\boldsymbol W^{(2)}$ 和 $\boldsymbol W^{(3)}$）的形式表示隐藏单元（潜变量）之间的连接。正如我们将看到的，这些连接对模型行为以及我们如何在模型中进行推断都有重要的影响。


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/0bi2M9pBhaL9.png?imageslim">
</p>
> 20.3 深度玻尔兹曼机，重新排列后显示为二分图结构。



与全连接的玻尔兹曼机（每个单元连接到其他每个单元）相比，DBM 提供了类似于 RBM 的一些优点。

具体来说， 如\fig?所示，DBM 的层可以组织成一个二分图，其中奇数层在一侧，偶数层在另一侧。容易发现，当我们条件于偶数层中的变量时，奇数层中的变量变得条件独立。当然，当我们条件于奇数层中的变量时，偶数层中的变量也会变得条件独立。



DBM 的二分图结构意味着我们可以应用之前用于 RBM 条件分布的相同式子来确定 DBM 中的条件分布。在给定相邻层值的情况下，层内的单元彼此条件独立，因此二值变量的分布可以由~Bernoulli~参数（描述每个单元的激活概率）完全描述。在具有两个隐藏层的示例中，激活概率由下式给出：


$$\begin{aligned}
P(v_i=1  \mid  \boldsymbol h^{(1)}) &= \sigma \big( \boldsymbol W_{i,:}^{(1)}\boldsymbol h^{(1)} \big), \\
P(h_i^{(1)}=1  \mid  \boldsymbol v, \boldsymbol h^{(2)}) &= \sigma \big( \boldsymbol v^\top  \boldsymbol W_{:,i}^{(1)}
+ \boldsymbol W_{i,:}^{(2)}\boldsymbol h^{(2)} \big) ,
\end{aligned}$$


和


$$\begin{aligned}
P(h_k^{(2)} =1  \mid  \boldsymbol h^{(1)}) = \sigma \big(\boldsymbol h^{(1)\top} \boldsymbol W_{:,k}^{(2)} \big).
\end{aligned}$$


二分图结构使 Gibbs采样能在深度玻尔兹曼机中高效采样。Gibbs采样的方法是一次只更新一个变量。RBM 允许所有可见单元以一个块的方式更新，而所有隐藏单元在另一个块上更新。我们可以简单地假设具有 $l$ 层的 DBM 需要 $l+1$ 次更新，每次迭代更新由某层单元组成的块。然而，我们可以仅在两次迭代中更新所有单元。Gibbs采样可以将更新分成两个块，一块包括所有偶数层（包括可见层），另一个包括所有奇数层。由于 DBM 二分连接模式，给定偶数层，关于奇数层的分布是因子的，因此可以作为块同时且独立地采样。类似地，给定奇数层，可以同时且独立地将偶数层作为块进行采样。高效采样对使用随机最大似然算法的训练尤其重要。



## 有趣的性质

深度玻尔兹曼机具有许多有趣的性质。

DBM 在 DBN~之后开发。与 DBN~相比，DBM 的后验分布 $P(\boldsymbol h  \mid  \boldsymbol v)$ 更简单。有点违反直觉的是，这种后验分布的简单性允许更加丰富的后验近似。在 DBN~的情况下，我们使用启发式的近似推断过程进行分类，其中我们可以通过 MLP（使用 sigmoid 激活函数并且权重与原始 DBN~相同）中的向上传播猜测隐藏单元合理的均匀场期望值。\emph{任何}分布 $Q(\boldsymbol h)$ 可用于获得对数似然的变分下界。因此这种启发式的过程让我们能够获得这样的下界。但是，该界没有以任何方式显式优化，所以该界可能是远远不紧的。特别地，$Q$ 的启发式估计忽略了相同层内隐藏单元之间的相互作用以及更深层中隐藏单元对更接近输入的隐藏单元自顶向下的反馈影响。因为 DBN~中基于启发式 MLP~的推断过程不能考虑这些相互作用，所以得到的 $Q$ 想必远不是最优的。DBM 中，在给定其他层的情况下，层内的所有隐藏单元都是条件独立的。这种层内相互作用的缺失使得通过不动点方程优化变分下界并找到真正最佳的均匀场期望（在一些数值容差内）变得可能的。



使用适当的均匀场允许 DBM 的近似推断过程捕获自顶向下反馈相互作用的影响。这从神经科学的角度来看是有趣的，因为根据已知，人脑使用许多自上而下的反馈连接。由于这个性质，DBM 已被用作真实神经科学现象的计算模型 。


DBM 一个不理想的特性是从中采样是相对困难的。在一次高效的原始采样过程中，DBN~只需要在其顶部的一对层中使用 MCMC 采样，而其他层仅在采样过程末尾参与。要从 DBM 生成样本，必须在所有层中使用 MCMC，并且模型的每一层都参与每个马尔可夫链转移。



## DBM均匀场推断

给定相邻层，一个 DBM 层上的条件分布是因子的。在有两个隐藏层的 DBM 的示例中，这些分布是 $P(\boldsymbol v  \mid  \boldsymbol h^{(1)}), P(\boldsymbol h^{(1)}  \mid  \boldsymbol v, \boldsymbol h^{(2)})$ 和 $P(\boldsymbol h^{(2)}  \mid  \boldsymbol h^{(1)})$。因为层之间的相互作用，\emph{所有}隐藏层上的分布通常不是因子的。在有两个隐藏层的示例中，由于 $\boldsymbol h^{(1)}$ 和 $\boldsymbol h^{(2)}$ 之间的交互权重 $\boldsymbol W^{(2)}$ 使得这些变量相互依赖， $P(\boldsymbol h^{(1)}  \mid  \boldsymbol v, \boldsymbol h^{(2)})$ 不是因子的。


与 DBN~的情况一样，我们还是要找出近似 DBM 后验分布的方法。然而，与 DBN~不同，DBM 在其隐藏单元上的后验分布（复杂的） 很容易用变分近似来近似（如 节 变分推断和变分学习 所讨论），具体是一个均匀场近似。均匀场近似是变分推断的简单形式，其中我们将近似分布限制为完全因子的分布。在 DBM 的情况下，均匀场方程捕获层之间的双向相互作用。在本节中，我们推导出由 {SalHinton09}最初引入的迭代近似推断过程。



在推断的变分近似中，我们通过一些相当简单的分布族近似特定目标分布——在这里指给定可见单元时隐藏单元的后验分布。在均匀场近似的情况下，近似族是隐藏单元条件独立的分布集合。


我们现在为具有两个隐藏层的示例推导均匀场方法。令 $Q(\boldsymbol h^{(1)}, \boldsymbol h^{(2)}  \mid  \boldsymbol v)$ 为 $P(\boldsymbol h^{(1)}, \boldsymbol h^{(2)}  \mid  \boldsymbol v)$ 的近似。均匀场假设意味着


$$\begin{aligned}
 Q(\boldsymbol h^{(1)}, \boldsymbol h^{(2)}  \mid  \boldsymbol v) = \prod_j Q(h_j^{(1)} \mid  \boldsymbol v) \prod_k Q(\boldsymbol h_k^{(2)}  \mid  \boldsymbol v).
\end{aligned}$$

均匀场近似试图找到这个分布族中最适合真实后验 $P(\boldsymbol h^{(1)}, \boldsymbol h^{(2)}  \mid  \boldsymbol v)$ 的成员。重要的是，每次我们使用 $\boldsymbol v$ 的新值时，必须再次运行推断过程以找到不同的分布 $Q$。


我们可以设想很多方法来衡量 $Q(\boldsymbol h  \mid  \boldsymbol v)$ 与 $P(\boldsymbol h  \mid  \boldsymbol v)$ 的拟合程度。均匀场方法是最小化

$$\begin{aligned}
 \text{KL}(Q \mid  \mid P) = \sum_{\boldsymbol h} Q(\boldsymbol h^{(1)}, \boldsymbol h^{(2)}  \mid  \boldsymbol v)
 \log \Big( \frac{Q(\boldsymbol h^{(1)}, \boldsymbol h^{(2)}  \mid  \boldsymbol v)}{P(\boldsymbol h^{(1)}, \boldsymbol h^{(2)}  \mid  \boldsymbol v)} \Big).
\end{aligned}$$

一般来说，除了要保证独立性假设，我们不必提供参数形式的近似分布。变分近似过程通常能够恢复近似分布的函数形式。然而，在二值隐藏单元（我们在这里推导的情况）的均匀场假设的情况下，不会由于预先固定模型的参数而损失一般性。

我们将 $Q$ 作为~Bernoulli分布的乘积进行参数化，即我们将 $\boldsymbol h^{(1)}$ 每个元素的概率与一个参数相关联。具体来说，对于每个 $j$，$\hat h_j^{(1)} = Q(h_j^{(1)}=1 \mid  \boldsymbol v)$，其中 $\hat h_j^{(1)} \in [0,1]$。另外，对于每个 $k$，$\hat h_k^{(2)} = Q(h_k^{(2)}=1 \mid  \boldsymbol v)$，其中 $\hat h_k^{(2)} \in [0,1]$。因此，我们有以下近似后验：

$$\begin{aligned}
 Q(\boldsymbol h^{(1)}, \boldsymbol h^{(2)}  \mid  \boldsymbol v) &=  \prod_j Q(h_j^{(1)} \mid  \boldsymbol v) \prod_k Q(h_k^{(2)}  \mid  \boldsymbol v) \\
 &= \prod_j (\hat h_j^{(1)})^{h_j^{(1)}}(1-\hat h_j^{(1)})^{(1-h_j^{(1)})} \times
 \prod_k (\hat h_k^{(2)})^{h_k^{(2)}}(1-\hat h_k^{(2)})^{(1-h_k^{(2)})} .
\end{aligned}$$


当然，对于具有更多层的 DBM，近似后验的参数化可以通过明显的方式扩展，即利用图的二分结构，遵循 Gibbs采样相同的调度，同时更新所有偶数层，然后同时更新所有奇数层。



现在我们已经指定了近似分布 $Q$ 的函数族，但仍然需要指定用于选择该函数族中最适合 $P$ 的成员的过程。最直接的方法是使用 $\tilde{q}\left(h_{i} | \boldsymbol{v}\right)=\exp \left(\mathbb{E}_{\mathbf{h}_{-i} \sim q\left(\mathbf{h}_{-i} | v\right)} \log \tilde{p}(\boldsymbol{v}, \boldsymbol{h})\right)$ 指定的均匀场方程。这些方程是通过求解变分下界导数为零的位置而导出。他们以抽象的方式描述如何优化任意模型的变分下界（只需对 $Q$ 求期望）。

应用这些一般的方程，我们得到以下更新规则（再次忽略偏置项）：


$$\begin{aligned}
\hat h_j^{(1)} &= \sigma  \Big(  \sum_i v_i \boldsymbol W_{i,j}^{(1)}
+ \sum_{k^{\prime}} \boldsymbol W_{j,k^{\prime}}^{(2)} \hat h_{k^{\prime}}^{(2)}  \Big), ~\forall j ,\\
\hat h_{k}^{(2)} &=  \sigma  \Big(  \sum_{j^{\prime}} \boldsymbol W_{j^{\prime},k}^{(2)}
\hat h_{j^{\prime}}^{(1)}  \Big), ~\forall k.
\end{aligned}$$


在该方程组的不动点处，我们具有变分下界 $\mathcal L(Q)$ 的局部最大值。因此，这些不动点更新方程定义了迭代算法，其中我们交替更新 $h_{j}^{(1)} $ （使用 $h_{j}^{(1)}=\sigma\left(\sum_{i} v_{i} \boldsymbol{W}_{i, j}^{(1)}+\sum_{k^{\prime}} \boldsymbol{W}_{j, k^{\prime}}^{(2)} \hat{h}_{k^{\prime}}^{(2)}\right), \forall j$ ）和 $h_{k}^{(2)} $ （使用 $\hat{h}_{k}^{(2)}=\sigma\left(\sum_{j^{\prime}} \boldsymbol{W}_{j^{\prime}, k}^{(2)} \hat{h}_{j^{\prime}}^{(1)}\right), \forall k$ ）。对于诸如 MNIST 的小问题，少至 10 次迭代就足以找到用于学习的近似正相梯度，而 50 次通常足以获得要用于高精度分类的单个特定样本的高质量表示。将近似变分推断扩展到更深的 DBM 是直观的。



## DBM 的参数学习


DBM 中的学习必须面对难解配分函数的挑战（使用 章 直面配分函数 中的技术），以及难解后验分布的挑战（使用 章 近似推断 中的技术）。

如 节 DBM均匀场推断 中所描述的，变分推断允许构建近似难处理的 $P(\boldsymbol h  \mid  \boldsymbol v)$ 的分布 $Q(\boldsymbol h \mid \boldsymbol v)$。然后通过最大化 $\mathcal L(\boldsymbol v, Q, \boldsymbol \theta)$（难处理的对数似然的变分下界 $\log P(\boldsymbol v; \boldsymbol \theta)$）学习。



对于具有两个隐藏层的深度玻尔兹曼机，$\mathcal L$ 由下式给出


$$\begin{aligned}
 \mathcal L(Q, \boldsymbol \theta) = \sum_i \sum_{j^{\prime}} v_i W_{i,j^{\prime}}^{(1)}
 \hat h_{j^{\prime}}^{(1)} +  \sum_{j^{\prime}} \sum_{k^{\prime}} \hat h_{j^{\prime}}^{(1)}
 W_{j^{\prime}, k^{\prime}}^{(2)} \hat h_{k^{\prime}}^{(2)} - \log Z(\boldsymbol \theta) + \mathcal H(Q).
\end{aligned}$$


该表达式仍然包含对数配分函数 $\log Z(\boldsymbol \theta)$。由于深度玻尔兹曼机包含受限玻尔兹曼机作为组件，用于计算受限玻尔兹曼机的配分函数和采样的困难同样适用于深度玻尔兹曼机。这意味着评估玻尔兹曼机的概率质量函数需要近似方法，如退火重要采样。同样，训练模型需要近似对数配分函数的梯度。见 章 直面配分函数 对这些方法的一般性描述。DBM 通常使用随机最大似然训练。章 直面配分函数 中描述的许多其他技术都不适用。诸如伪似然的技术需要评估非归一化概率的能力，而不是仅仅获得它们的变分下界。对于深度玻尔兹曼机，对比散度是缓慢的，因为它们不能在给定可见单元时对隐藏单元进行高效采样——反而，每当需要新的负相样本时，对比散度将需要磨合一条马尔可夫链。


非变分版本的随机最大似然算法已经在 节 随机最大似然和对比散度 讨论过。下图给出了应用于 DBM 的变分随机最大似然算法。回想一下，我们描述的是 DBM 的简化变体（缺少偏置参数）; 很容易推广到包含偏置参数的情况。


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/r1X0YgOfsdSX.png?imageslim">
</p>




## 逐层预训练


不幸的是，随机初始化后使用随机最大似然训练（如上所述）的 DBM 通常导致失败。在一些情况下，模型不能学习如何充分地表示分布。在其他情况下，DBM 可以很好地表示分布，但是没有比仅使用 RBM 获得更高的似然。除第一层之外，所有层都具有非常小权重的 DBM 与 RBM 表示大致相同的分布。

如 节 联合训练深度玻尔兹曼机 所述，目前已经开发了允许联合训练的各种技术。然而，克服 DBM 的联合训练问题最初和最流行的方法是贪心逐层预训练。在该方法中，DBM 的每一层被单独视为 RBM，进行训练。第一层被训练为对输入数据进行建模。每个后续 RBM 被训练为对来自前一 RBM 后验分布的样本进行建模。在以这种方式训练了所有 RBM 之后，它们可以被组合成 DBM。然后可以用~PCD~训练 DBM。通常，PCD~训练将仅使模型的参数、由数据上的对数似然衡量的性能、或区分输入的能力发生微小的变化。见\fig?展示的训练过程。




<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/gP2uWJj1r4iu.png?imageslim">
</p>
> 20.4 用于分类 MNIST 数据集的深度玻尔兹曼机训练过程~。(a)使用 CD 近似最大化 $\log P(\boldsymbol v)$ 来训练 RBM。(b)训练第二个 RBM，使用 CD-$k$ 近似最大化 $\log P(\boldsymbol h^{(1)}, \mathrm y)$ 来建模 $\boldsymbol h^{(1)}$ 和目标类 $\mathrm y$，其中 $\boldsymbol h^{(1)}$ 采自第一个 RBM 条件于数据的后验。 在学习期间将 $k$ 从 $1$ 增加到 $20$。(c)将两个 RBM 组合为 DBM。使用 $k = 5$ 的随机最大似然训练，近似最大化 $\log P(\mathbf v, \mathrm y)$。(d)将 $\mathrm y$ 从模型中删除。定义新的一组特征 $\boldsymbol h^{(1)}$ 和 $\boldsymbol h^{(2)}$，可在缺少 $\mathrm y$ 的模型中运行均匀场推断后获得。% ??使用这些特征作为 MLP 的输入，其结构与均匀场的额外轮相同，并且具有用于估计 $\mathrm y$ 的额外输出层。初始化 MLP 的权重与 DBM 的权重相同。使用随机梯度下降和 Dropout 训练 MLP 近似最大化 $\log P(\mathrm y \mid \mathbf v)$。



这种贪心逐层训练过程不仅仅是坐标上升。因为我们在每个步骤优化参数的一个子集，它与坐标上升具有一些传递相似性。这两种方法是不同的，因为贪心逐层训练过程中，我们在每个步骤都使用了不同的目标函数。


DBM 的贪心逐层预训练与 DBN 的贪心逐层预训练不同。每个单独的 RBM 的参数可以直接复制到相应的 DBN。在 DBM 的情况下，RBM 的参数在包含到 DBM 中之前必须修改。RBM 栈的中间层仅使用自底向上的输入进行训练，但在栈组合形成 DBM 后，该层将同时具有自底向上和自顶向下的输入。为了解释这种效应，{SalHinton09}提倡在将其插入 DBM 之前，将所有 RBM（顶部和底部 RBM 除外）的权重除 2。另外，必须使用每个可见单元的两个"副本"来训练底部 RBM，并且两个副本之间的权重约束为相等。这意味着在向上传播时，权重能有效地加倍。类似地，顶部 RBM 应当使用最顶层的两个副本来训练。

为了使用深度玻尔兹曼机获得最好结果，我们需要修改标准的 SML 算法，即在联合 PCD 训练步骤的负相期间使用少量的均匀场 。具体来说，应当相对于其中所有单元彼此独立的均匀场分布来计算能量梯度的期望。这个均匀场分布的参数应该通过运行一次均匀场不动点方程获得。{Goodfellow-et-al-NIPS2013}比较了在负相中使用和不使用部分均匀场的中心化 DBM 的性能。



## 联合训练深度玻尔兹曼机


经典 DBM 需要贪心无监督预训练，并且为了更好的分类，需要在它们提取的隐藏特征之上，使用独立的基于 MLP~的分类器。这种方法有一些不理想的性质。因为我们不能在训练第一个 RBM 时评估完整 DBM 的属性，所以在训练期间难以跟踪性能。因此，直到相当晚的训练过程，我们都很难知道我们的超参数表现如何。DBM 的软件实现需要很多不同的模块，如用于单个 RBM 的~CD~训练、完整 DBM 的~PCD~训练以及基于反向传播的 MLP~训练。最后，玻尔兹曼机顶部的 MLP~失去了玻尔兹曼机概率模型的许多优点，例如当某些输入值丢失时仍能够进行推断的优点。



主要有两种方法可以处理深度玻尔兹曼机的联合训练问题。第一个是 **中心化深度玻尔兹曼机**(centered deep Boltzmann machine) ，通过重参数化模型使其在开始学习过程时代价函数的 Hessian 具有更好的条件数。这个模型不用经过贪心逐层预训练阶段就能训练。这个模型在测试集上获得出色的对数似然，并能产生高质量的样本。不幸的是，作为分类器，它仍然不能与适当正则化的 MLP~竞争。联合训练深度玻尔兹曼机的第二种方式是使用多预测深度玻尔兹曼机 。该模型的训练准则允许反向传播算法，以避免使用 MCMC 估计梯度的问题。不幸的是，新的准则不会导致良好的似然性或样本，但是相比 MCMC 方法，它确实会导致更好的分类性能和良好的推断缺失输入的能力。

如果我们回到玻尔兹曼机的一般观点，即包括一组权重矩阵 $\boldsymbol U$ 和偏置 $\boldsymbol b$ 的单元 $\boldsymbol x$，玻尔兹曼机中心化技巧是最容易描述的。回顾 $E(\boldsymbol{x})=-\boldsymbol{x}^{\top} \boldsymbol{U} \boldsymbol{x}-\boldsymbol{b}^{\top} \boldsymbol{x}$ ，能量函数由下式给出


$$\begin{aligned}
E(\boldsymbol x) = -\boldsymbol x^\top \boldsymbol U \boldsymbol x - \boldsymbol b^\top \boldsymbol x.
\end{aligned}$$


在权重矩阵 $\boldsymbol U$ 中使用不同的稀疏模式，我们可以实现不同架构的玻尔兹曼机，如 RBM 或具有不同层数的 DBM。将 $\boldsymbol x$ 分割成可见和隐藏单元并将 $\boldsymbol U$ 中不相互作用的单元的归零可以实现这些架构。中心化玻尔兹曼机引入了一个向量 $\boldsymbol mu$，并从所有状态中减去：

$$\begin{aligned}
E^{\prime}(\boldsymbol x; \boldsymbol U, \boldsymbol b) = -(\boldsymbol x - \boldsymbol mu)^\top \boldsymbol U (\boldsymbol x - \boldsymbol mu) - (\boldsymbol x - \boldsymbol mu)^\top \boldsymbol b.
\end{aligned}$$


通常 $\boldsymbol mu$ 在开始训练时固定为一个超参数。当模型初始化时，通常选择为 $\boldsymbol x - \boldsymbol mu \approx 0$。这种重参数化不改变模型可表示的概率分布的集合，但它确实改变了应用于似然的随机梯度下降的动态。具体来说，在许多情况下，这种重参数化导致更好条件数的 Hessian 矩阵。{melchior2013center}通过实验证实了 Hessian 矩阵条件数的改善，并观察到中心化技巧等价于另一个玻尔兹曼机学习技术——**增强梯度**(enhanced gradient) 。即使在困难的情况下，例如训练多层的深度玻尔兹曼机，Hessian 矩阵条件数的改善也能使学习成功。


联合训练深度玻尔兹曼机的另一种方法是多预测深度玻尔兹曼机，它将均匀场方程视为定义一系列用于近似求解每个可能推断问题的循环网络~。模型被训练为使每个循环网络获得对相应推断问题的准确答案，而不是训练模型来最大化似然。训练过程如\fig?所示。它包括随机采一个训练样本、随机采样推断网络的输入子集，然后训练推断网络来预测剩余单元的值。



<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/2JTnyYdzPa1f.png?imageslim">
</p>
> 20.5 深度玻尔兹曼机多预测训练过程的示意图。每一行指示相同训练步骤内小批量中的不同样本。每列表示均匀场推断过程中的时间步。对于每个样本，我们对数据变量的子集进行采样，作为推断过程的输入。这些变量以黑色阴影表示条件。然后我们运行均匀场推断过程，箭头指示过程中的哪些变量会影响其他变量。在实际应用中，我们将均匀场展开为几个步骤。在此示意图中，我们只展开为两个步骤。虚线箭头表示获得更多步骤需要如何展开该过程。未用作推断过程输入的数据变量成为目标，以灰色阴影表示。我们可以将每个样本的推断过程视为循环网络。为了使其在给定输入后能产生正确的目标，我们使用梯度下降和反向传播训练这些循环网络。这可以训练 MP-DBM 均匀场过程产生准确的估计。图改编自 {Goodfellow-et-al-NIPS2013}。


这种用于近似推断，通过计算图进行反向传播的一般原理已经应用于其他模型~。在这些模型和 MP-DBM 中，最终损失不是似然的下界。相反，最终损失通常基于近似推断网络对缺失值施加的近似条件分布。这意味着这些模型的训练有些启发式。如果我们检查由 MP-DBM 学习出来的玻尔兹曼机表示 $p(\boldsymbol v)$，在 Gibbs采样产生较差样本的意义下，它倾向于有些缺陷。

通过推断图的反向传播有两个主要优点。首先，它以模型真正使用的方式训练模型 —— 使用近似推断。这意味着在 MP-DBM 中，进行如填充缺失的输入或执行分类（尽管存在缺失的输入）的近似推断比在原始 DBM 中更准确。原始 DBM 不会自己做出准确的分类器; 使用原始 DBM 的最佳分类结果是基于 DBM 提取的特征训练独立的分类器，而不是通过使用 DBM 中的推断来计算关于类标签的分布。MP-DBM 中的均匀场推断作为分类器，不需要进行特殊修改就获得良好的表现。通过近似推断反向传播的另一个优点是反向传播计算损失的精确梯度。对于优化而言，比~SML~训练中具有偏差和方差的近似梯度更好。这可能解释了为什么 MP-DBM 可以联合训练，而 DBM 需要贪心逐层预训练。近似推断图反向传播的缺点是它不提供一种优化对数似然的方法，而提供广义伪似然的启发式近似。

MP-DBM 启发了对 NADE 框架的扩展 NADE-$k$~ ，我们将在 节 NADE 中描述。


MP-DBM 与 Dropout 有一定联系。Dropout 在许多不同的计算图之间共享相同的参数，每个图之间的差异是包括还是排除每个单元。MP-DBM 还在许多计算图之间共享参数。在 MP-DBM 的情况下，图之间的差异是每个输入单元是否被观察到。当没有观察到单元时，MP-DBM 不会像 Dropout 那样将其完全删除。相反，MP-DBM 将其视为要推断的潜变量。我们可以想象将 Dropout 应用到 MP-DBM，即额外去除一些单元而不是将它们变为潜变量。




# 相关

- 《深度学习》花书
