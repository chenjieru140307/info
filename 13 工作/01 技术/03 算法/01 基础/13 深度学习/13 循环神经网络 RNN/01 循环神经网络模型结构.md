
# 可以补充进来的

- 拆掉

# 循环神经网络模型结构

下图是一个简单的循环神经网络，循环体中的神经网络的输入有两部分，一部分为上一时刻的状态，另一部分为当前时刻的输入样本。它由输入层、一个隐藏层和一个输出层组成。

<span style="color:red;">这个图画的不对吧？为什么左侧的隐层内的节点是互联的？顶多右边有个返回自身的圆弧吧？</span>

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190616/GAsnRhEtIHmi.png?imageslim">
</p>

展开图如下：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190616/OcaUNTCtVjso.png?imageslim">
</p>
- $x$ 是输入层的值
- $s$ 是隐藏层的值
- $o$ 表示输出层的值
- $U$ 是输入层到隐藏层的权重矩阵
- $V$ 是隐藏层到输出层的权重矩阵。
- $W$ 就是隐藏层上一次的值作为这一次的输入的权重。

循环神经网络的隐藏层的值 $s$ 不仅仅取决于当前这次的输入 $x$，还取决于上一次隐藏层的值 $s$。权重矩阵 $W$ 就是隐藏层上一次的值作为这一次的输入的权重。

对于一个序列数据，可以将这个序列上不同时刻的数据依次传入循环神经网络的输入层，而输出可以是对序列中下一个时刻的预测，也可以是对当前时刻信息的处理结果。如在机器翻译的任务中，对于源语言中的每个词向量，网络可以精准输出目标语言中的单词。<span style="color:red;">嗯。</span>


RNN 是根据下面的步骤来迭代和做计算的：

- $x_t$ 表示 $t=1,2,3…$ 步的输入。
- $s_t$ 是隐层第 $t$ 步的状态，$s_t$ 由当前步骤的输入和先前隐藏状态共同计算求得，$S_{t}=f\left(U x_{t}+W s_{t}-1\right)$。
- $O_t$ 是第 $t$ 步的输出。

循环神经网络的结构特征可以很容易得出它最擅长解决的问题是与时间序列相关的。循环神经网络也是处理这类问题时最自然的神经网络结构。

循环神经网络中由于输入时叠加了之前的信号，所以反向传导时不同于传统的神经网络，因为对于时刻 $t$ 的输入层，其残差不仅来自输出，还来自之后的隐藏层。通过反向传递算法，利用输出层的误差，求解各个权重的梯度，然后利用梯度下降法更新各个权重。

它的展开图中信息流向也是确定的，没有环流，循环神经网络是时间维度上的深度模型，可以对序列内容建模。但是需要训练的参数较多，容易出现梯度消散或梯度爆炸的问题，不具有特征学习能力。<span style="color:red;">什么是不具有特征学习能力？咋感觉这本书说话各种没有条理呢？</span>

RNN 已经在实践中被证明对 NLP 是非常成功的。如词向量表达、语句合法性检查、词性标注等。<span style="color:red;">大爷的。</span>



# 相关

- 《深度学习框架 Pytorch 快速开发与实战》
