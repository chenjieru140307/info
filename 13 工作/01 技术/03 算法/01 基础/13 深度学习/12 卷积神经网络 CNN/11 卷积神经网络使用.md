
卷积神经网络使用：

- 可以用于输出高维的结构化对象，而不仅仅是预测分类任务的类标签或回归任务的实数值。

举例：

- 使用模型标记图像中的每个像素，并绘制沿着单个对象轮廓的精确掩模。
  - 例如，模型可以由标准卷积层产生产生张量 $\boldsymbol S$，其中 $S_{i,j,k}$ 是网络的输入像素 $(j, k)$ 属于类 $i$ 的概率。
    - 经常出现的一个问题：
      - 输出平面可能比输入平面要小。
        - 用于对图像中单个对象分类的常用结构中，网络空间维数的最大减少来源于使用大步幅的池化层。
      - 为了产生与输入大小相似的输出映射，我们可以避免把池化放在一起。另一种策略是单纯地产生一张低分辨率的标签网格。最后，原则上可以使用具有单位步幅的池化操作。
    - 对图像逐个像素标记的一种策略：
      - 先产生图像标签的原始猜测，然后使用相邻像素之间的交互来修正该原始猜测。
      - 重复这个修正步骤数次对应于在每一步使用相同的卷积，该卷积在深层网络的最后几层之间共享权重。这使得在层之间共享参数的连续的卷积层所执行的一系列运算，形成了一种特殊的循环神经网络。
      - 下图给出了这样一个循环卷积网络的结构。用于像素标记的循环卷积网络的示例：
        <p align="center">
            <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/XdutTSvMnhdq.png?imageslim">
        </p>
      - 说明：（没有明白）
        - 输入是图像张量 $\boldsymbol X$，它的轴对应图像的行、列和通道（红，绿，蓝）。
        - 目标是输出标签张量 $\hat{Y}$，它遵循每个像素的标签的概率分布。该张量的轴对应图像的行、列和不同类别。
        - 循环网络通过使用 $\hat{Y}$ 的先前估计作为创建新估计的输入，来迭代地改善其估计，而不是单次输出 $\hat{Y}$，。
        - 每个更新的估计使用相同的参数，并且估计可以如我们所愿地被改善任意多次。
        - 每一步使用的卷积核张量 $\boldsymbol U$，是用来计算给定输入图像的隐藏表示的。核张量 $\boldsymbol V$ 用于产生给定隐藏值时标签的估计。
        - 除了第一步之外，核 $\boldsymbol W$ 都对 $\hat{Y}$ 进行卷积来提供隐藏层的输入。在第一步中，此项由零代替。因为每一步使用相同的参数，所以这是一个循环网络的例子。
    - 一旦对每个像素都进行了预测，我们就可以使用各种方法来进一步处理这些预测，以便获得图像在区域上的分割。
      - 一般的想法是假设大片相连的像素倾向于对应着相同的标签。图模型可以描述相邻像素间的概率关系。
      - 或者，卷积网络可以被训练来最大化地近似图模型的训练目标。
