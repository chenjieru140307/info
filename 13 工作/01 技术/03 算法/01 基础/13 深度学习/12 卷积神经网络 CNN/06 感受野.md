
感受野：

- 感受野被定义为卷积神经网络特征所能看到输入图像的区域，换句话说特征输出受感受野区域内的像素点的影响。

计算：

- $RF_{l+1}=RF_{l}+\left(kernel\_size_{l+1}-1\right)\times{feature\_stride}_{l}$
- 其中：
  - RF 表示特征感受野大小，
  - l表示层数,
  - $feature\_stride_{l}=\prod_{i=1}^{l}stride_{i}$ 表示输入层，
  - $R F_{0}=1$
  - $feature\_stride_{0}=1$
- 如果有 dilated conv 的话，计算公式
  - $R F_{l+1}=R F_{l}+\left(k e r n e l\_ s i z e_{l+1}-1\right) \times feature\_stride_{l} \times\left({dilation}_{l+1}-1\right)$

举例：

- 一个三层的神经卷积神经网络，每一层卷积核的 *kernel_size* = 3 ，*stride* = 1，为了方便，将二维简化为一维，
- 第一层特征，感受野为 3
  - 图像：
    <p align="center">
        <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200620/uwgiTuvG6mn0.png?imageslim">
    </p>
  - 计算：
    - $RF_{1}=RF_{0}+\left( {kernel\_size}_{1}-1\right) \times feature\_stride_{0}=1+(3-1) \times 1=3$




- 第二层特征，感受野为 5
  - 图像：
    <p align="center">
        <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200620/b8RahQUa6YO3.png?imageslim">
    </p>
  - 计算：
    - $R F_{2}=R F_{1}+\left(k e r n e l\_s i z e_{2}-1\right) \times feature\_stride_{1}=3+(3-1) \times 1=5$
- 第三层特征，感受野为 7
  - 图像：
    <p align="center">
        <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200620/KYyN1U5LfBBD.png?imageslim">
    </p>
  - 计算：
    - $R F_{3}=R F_{2}+\left(k e r n e l\_s i z e_{3}-1\right) \times feature\_stride_{2}=5+(3-1) \times 1=7$


说明：

- 上面所述的是理论感受野，而特征的有效感受野（实际起作用的感受野）实际上是远小于理论感受野的。
- 如下图所示，有效感受野示例：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200620/y9Yn0RBR22Me.png?imageslim">
</p>

- 有效感受野背后的原因：
  - 以一个两层的卷积神经网络为例
    - 每一层卷积核的 *kernel_size* = 3 ，*stride* = 1 的网络为例，
  - 则，该网络的理论感受野为 5，计算流程可以参加下图。
    <p align="center">
        <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200620/TwC2ESxTcL79.png?imageslim">
    </p>
  - 其中：
    - $x$ 为输入，$w$ 为卷积权重，$o$ 为经过卷积后的输出特征。
  - 说明：
    - 可见，$x_{1,1}$ 只影响第一层 feature map 中的 $o_{1,1}^{1}$ ；而 $x_{3,3}$ 会影响第一层 feature map 中的所有特征，即 $o_{1,1}^{1}, o_{1,2}^{1}, o_{1,3}^{1}, o_{2,1}^{1}, o_{2,2}^{1}, o_{2,3}^{1}, o_{3,1}^{1}, o_{3,2}^{1}, o_{3,3}^{1}$。
    - 第一层的输出全部会影响第二层的 $o_{1,1}^{2}$。
    - 于是 $x_{1,1}$ 只能通过 $o_{1,1}^{1}$ 来影响 $o_{1,1}^{2}$ ；而 $x_{3,3}$ 能通过 $o_{1,1}^{1}, o_{1,2}^{1}, o_{1,3}^{1}, o_{2,1}^{1}, o_{2,2}^{1}, o_{2,3}^{1}, o_{3,1}^{1}, o_{3,2}^{1}, o_{3,3}^{1}$ 来影响 $o_{1,1}^{2}$ 。
    - 显而易见，虽然 $x_{1,1}$ 和 $x_{3,3}$ 都位于第二层特征感受野内，但是二者对最后的特征 $o_{1,1}^{2}$ 的影响却大不相同，输入中越靠感受野中间的元素对特征的贡献越大。

应用：

- 目标检测中，anchor 的设定。
  - 一些目标检测网络基于anchor的，比如SSD系列，v2以后的yolo，还有faster rcnn系列。基于 anchor 的目标检测网络会预设一组大小不同的anchor，比如 32x32、64x64、128x128、256x256，这么多anchor，我们应该放置在哪几层比较合适呢？这个时候感受野的大小是一个重要的考虑因素。
  - 放置 anchor 层的特征感受野应该跟 anchor 大小相匹配，感受野比anchor 大太多不好，小太多也不好。如果感受野比 anchor 小很多，就好比只给你一只脚，让你说出这是什么鸟一样。如果感受野比 anchor 大很多，则好比给你一张世界地图，让你指出故宫在哪儿一样。（觉得，anchor 是不是不是很好，需要手动设定。）




