

# 使用图描述模型结构




结构化概率模型使用图（在图论中"结点"是通过"边"来连接的）来表示随机变量之间的相互作用。每一个结点代表一个随机变量。每一条边代表一个直接相互作用。这些直接相互作用隐含着其他的间接相互作用，但是只有直接的相互作用会被显式地建模。



使用图来描述概率分布中相互作用的方法不止一种。在下文中我们会介绍几种最为流行和有用的方法。图模型可以被大致分为两类：基于有向无环图的模型和基于无向图的模型。



## 有向模型


有向图模型是一种结构化概率模型，也被称为信念网络或者贝叶斯网络
 。

> 当我们希望"强调"从网络中计算出的值的"推断"本质，即强调这些值代表的是置信程度大小而不是事件的频率时，Judea Pearl建议使用"贝叶斯网络"这个术语。


之所以命名为有向图模型是因为所有的边都是有方向的，即从一个结点指向另一个结点。这个方向可以通过画一个箭头来表示。箭头所指的方向表示了这个随机变量的概率分布是由其他变量的概率分布所定义的。画一个从结点 $\mathrm a$ 到结点 $\mathrm b$ 的箭头表示了我们用一个条件分布来定义 $\mathrm b$，而 $\mathrm a$ 是作为这个条件分布符号右边的一个变量。换句话说，$\mathrm b$ 的概率分布依赖于 $\mathrm a$ 的取值。


我们继续 节 非结构化建模的挑战 所讲的接力赛的例子，我们假设 Alice 的完成时间为 $\mathrm t_0$，Bob的完成时间为 $\mathrm t_1$，Carol的完成时间为 $\mathrm t_2$。就像我们之前看到的一样，$\mathrm t_1$ 的估计是依赖于 $\mathrm t_0$ 的，$\mathrm t_2$ 的估计是直接依赖于 $\mathrm t_1$ 的，但是仅仅间接地依赖于 $\mathrm t_0$。我们用一个有向图模型来建模这种关系，如\fig?所示。


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/naB4VsLwQKWp.png?imageslim">
</p>
> 16.2 描述接力赛例子的有向图模型。Alice的完成时间 $\mathrm t_0$ 影响了 Bob 的完成时间 $\mathrm t_1$，因为 Bob 只能在 Alice 完成比赛后才开始。类似的，Carol也只会在 Bob 完成之后才开始，所以 Bob 的完成时间 $\mathrm t_1$ 直接影响了 Carol 的完成时间 $\mathrm t_2$。



正式地说，变量 $\mathbf x$ 的有向概率模型是通过有向无环图 $\mathcal G$ （每个结点都是模型中的随机变量）和一系列局部条件概率分布 $p(\mathrm x_i\mid Pa_{\mathcal G}(\mathrm x_i))$ 来定义的，其中 $Pa_{\mathcal G}(\mathrm x_i)$ 表示结点 $\mathrm x_i$ 的所有父结点。$\mathbf x$ 的概率分布可以表示为


$$\begin{aligned}
p(\mathbf x) = \prod_{i} p(\mathrm x_i\mid Pa_{\mathcal G}(\mathrm x_i)).
\end{aligned}$$





在之前所述的接力赛的例子中，参考\fig?，这意味着概率分布可以被表示为


$$\begin{aligned}
p(\mathrm t_0,\mathrm t_1,\mathrm t_2) = p(\mathrm t_0)p(\mathrm t_1\mid \mathrm t_0)p(\mathrm t_2\mid \mathrm t_1).
\end{aligned}$$



这是我们看到的第一个结构化概率模型的实际例子。我们能够检查这样建模的计算开销，为了验证相比于非结构化建模，结构化建模为什么有那么多的优势。



假设我们采用从第 $0$ 分钟到第 $10$ 分钟每 $6$ 秒一块的方式离散化地表示时间。这使得 $\mathrm t_0$，$\mathrm t_1$ 和 $\mathrm t_2$ 都是一个有 $100$ 个取值可能的离散变量。如果我们尝试着用一个表来表示 $p(\mathrm t_0, \mathrm t_1, \mathrm t_2)$，那么我们需要存储 $999,999$ 个值（100个 $\mathrm t_0$ 的可能取值 $\times$ 100个 $\mathrm t_1$ 的可能取值 $\times$ 100个 $\mathrm t_2$ 的可能取值 减去 1，由于存在所有的概率之和为 $1$ 的限制，所以其中有 $1$ 个值的存储是多余的）。反之，如果我们用一个表来记录每一种条件概率分布，那么表中记录 $\mathrm t_0$ 的分布需要存储 $99$ 个值，给定 $\mathrm t_0$ 情况下 $\mathrm t_1$ 的分布需要存储 9900 个值，给定 $\mathrm t_1$ 情况下 $\mathrm t_2$ 的分布也需要存储 $9900$ 个值。加起来总共需要存储 $19, 899$ 个值。这意味着使用有向图模型将参数的个数减少了超过 $50$ 倍！



通常意义上说，对每个变量都能取 $k$ 个值的 $n$ 个变量建模，基于建表的方法需要的复杂度是 $O(k^n)$，就像我们之前观察到的一样。现在假设我们用一个有向图模型来对这些变量建模。如果 $m$ 代表图模型的单个条件概率分布中最大的变量数目（在条件符号的左右皆可），那么对这个有向模型建表的复杂度大致为 $O(k^m)$。只要我们在设计模型时使其满足 $m\ll n$，那么复杂度就会被大大地减小。



换一句话说，只要图中的每个变量都只有少量的父结点，那么这个分布就可以用较少的参数来表示。图结构上的一些限制条件，比如说要求这个图为一棵树，也可以保证一些操作（例如求一小部分变量的边缘或者条件分布）更加地高效。
<!-- % 556 head   16.2 to here  -->



决定哪些信息需要被包含在图中而哪些不需要是很重要的。如果变量之间可以被假设为是条件独立的，那么这个图可以包含这种简化假设。当然也存在其他类型的简化图模型的假设。例如，我们可以假设无论 Alice 的表现如何，Bob总是跑得一样快（实际上，Alice的表现很大概率会影响 Bob 的表现，这取决于 Bob 的性格，如果在之前的比赛中 Alice 跑得特别快，这有可能鼓励 Bob 更加努力并取得更好的成绩，当然这也有可能使得 Bob 过分自信或者变得懒惰）。那么 Alice 对 Bob 的唯一影响就是在计算 Bob 的完成时间时需要加上 Alice 的时间。这个假设使得我们所需要的参数量从 $O(k^2)$ 降到了 $O(k)$。然而，值得注意的是在这个假设下 $\mathrm t_0$ 和 $\mathrm t_1$ 仍然是直接相关的，因为 $\mathrm t_1$ 表示的是 Bob 完成时的时间，并不是他跑的总时间。这也意味着图中会有一个从 $\mathrm t_0$ 指向 $\mathrm t_1$ 的箭头。"Bob的个人跑步时间相对于其他因素是独立的"这个假设无法在 $\mathrm t_0$，$\mathrm t_1$，$\mathrm t_2$ 的图中被表示出来。反之，我们只能将这个关系表示在条件分布的定义中。这个条件分布不再是一个大小为 $k\times k-1$ 的分别对应着 $\mathrm t_0$，  $\mathrm t_1$ 的表格，而是一个包含了 $k-1$ 个参数的略微复杂的公式。有向图模型的语法并不能对我们如何定义条件分布作出任何限制。它只定义了哪些变量可以作为其中的参数。





## 无向模型




有向图模型为我们提供了一种描述结构化概率模型的语言。而另一种常见的语言则是无向模型，也被称为马尔可夫随机场或者是马尔可夫网络 。就像它们的名字所说的那样，无向模型中所有的边都是没有方向的。



当存在很明显的理由画出每一个指向特定方向的箭头时，有向模型显然最适用。有向模型中，经常存在我们理解的具有因果关系以及因果关系有明确方向的情况。接力赛的例子就是一个这样的情况。之前运动员的表现会影响后面运动员的完成时间，而后面运动员却不会影响前面运动员的完成时间。


然而并不是所有情况的相互作用都有一个明确的方向关系。当相互的作用并没有本质性的指向，或者是明确的双向相互作用时，使用无向模型更加合适。



作为一个这种情况的例子，假设我们希望对三个二值随机变量建模：你是否生病，你的同事是否生病以及你的室友是否生病。就像在接力赛的例子中所作的简化假设一样，我们可以在这里做一些关于相互作用的简化假设。假设你的室友和同事并不认识，所以他们不太可能直接相互传染一些疾病，比如说感冒。这个事件太过罕见，所以我们不对此事件建模。然而，很有可能其中之一将感冒传染给你，然后通过你再传染给了另一个人。我们通过对你的同事传染给你以及你传染给你的室友建模来对这种间接的从你的同事到你的室友的感冒传染建模。



在这种情况下，你传染给你的室友和你的室友传染给你都是非常容易的，所以模型不存在一个明确的单向箭头。这启发我们使用无向模型。其中随机变量对应着图中的相互作用的结点。与有向模型相同的是，如果在无向模型中的两个结点通过一条边相连接，那么对应这些结点的随机变量相互之间是直接作用的。不同于有向模型，在无向模型中的边是没有方向的，并不与一个条件分布相关联。



我们把对应你健康状况的随机变量记作 $\mathrm h_y$，对应你的室友健康状况的随机变量记作 $\mathrm h_r$，你的同事健康的变量记作 $\mathrm h_c$。\fig?表示这种关系。




<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/6lxcY725mUFh.png?imageslim">
</p>
> 16.3 表示你室友健康状况的 $\mathrm h_r$、你健康状况的 $\mathrm h_y$ 和你同事健康状况的 $\mathrm h_c$ 之间如何相互影响的一个无向图。你和你的室友可能会相互传染感冒，你和你的同事之间也是如此，但是假设你室友和同事之间相互不认识，他们只能通过你来间接传染。}



正式地说，一个无向模型是一个定义在无向模型 $\mathcal G$ 上的结构化概率模型。对于图中的每一个团(注：图的一个团是图中结点的一个子集，并且其中的点是全连接的)$~\mathcal C$，一个因子 $\phi(\mathcal C)$(也称为团势能)，衡量了团中变量每一种可能的联合状态所对应的密切程度。这些因子都被限制为是非负的。它们一起定义了未归一化概率函数：


$$\begin{aligned}
\tilde{p}(\mathbf x) = \prod_{\mathcal C\in\mathcal G} \phi(\mathcal C).
\end{aligned}$$


只要所有团中的结点数都不大，那么我们就能够高效地处理这些未归一化概率函数。它包含了这样的思想，密切度越高的状态有越大的概率。然而，不像贝叶斯网络，几乎不存在团定义的结构，所以不能保证把它们乘在一起能够得到一个有效的概率分布。\fig? 展示了一个从无向模型中读取分解信息的例子。




<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/EY8wkQwfCUaF.png?imageslim">
</p>

> 16.4 这个图说明通过选择适当的 $\phi$，函数		$p(\mathrm a,\mathrm b,\mathrm c,\mathrm d,\mathrm e,\mathrm f)$ 可以写作		$\frac{1}{Z}\phi_{\mathrm a,\mathrm b}(\mathrm a,\mathrm b)\phi_{\mathrm b,\mathrm c}(\mathrm b,\mathrm c)\phi_{\mathrm a,\mathrm d}(\mathrm a,\mathrm d)\phi_{\mathrm b,\mathrm e}(\mathrm b,\mathrm e)\phi_{\mathrm e,\mathrm f}(\mathrm e,\mathrm f)$。



在你、你的室友和同事之间感冒传染的例子中包含了两个团。一个团包含了 $\mathrm h_y$ 和 $\mathrm h_c$。这个团的因子可以通过一个表来定义，可能取到下面的值：


| --                | $\mathrm h_y = 0$ | $\mathrm h_y = 1$ |
| ----------------- | ----------------- | ----------------- |
| $\mathrm h_c = 0$ | 2                 | 1                 |
| $\mathrm h_c = 1$ | 1                 | 10                |



状态为 $1$ 代表了健康的状态，相对的状态为 $0$ 则表示不好的健康状态（即感染了感冒）。你们两个通常都是健康的，所以对应的状态拥有最高的密切程度。两个人中只有一个人是生病的密切程度是最低的，因为这是一个很罕见的状态。两个人都生病的状态（通过一个人来传染给了另一个人）有一个稍高的密切程度，尽管仍然不及两个人都健康的密切程度。


为了完整地定义这个模型，我们需要对包含 $\mathrm h_y$ 和 $\mathrm h_r$ 的团定义类似的因子。



## 配分函数


尽管这个未归一化概率函数处处不为零，我们仍然无法保证它的概率之和或者积分为 $1$。为了得到一个有效的概率分布，我们需要使用对应的归一化的概率分布(注：一个通过归一化团势能乘积定义的分布也被称作是吉布斯分布)：



$$\begin{aligned}
p(\mathbf x) = \frac{1}{Z}\tilde{p}(\mathbf x),
\end{aligned}$$


其中，$Z$ 是使得所有的概率之和或者积分为 $1$ 的常数，并且满足：



$$\begin{aligned}
Z = \int \tilde{p}(\mathbf x)d\mathbf x.
\end{aligned}$$


当函数 $\phi$ 固定时，我们可以把 $Z$ 当成是一个常数。值得注意的是如果函数 $\phi$ 带有参数时，那么 $Z$ 是这些参数的一个函数。在相关文献中为了节省空间忽略控制 $Z$ 的变量而直接写 $Z$ 是一个常用的方式。归一化常数 $Z$ 被称作是配分函数，这是一个从统计物理学中借鉴的术语。


由于 $Z$ 通常是由对所有可能的 $\mathbf x$ 状态的联合分布空间求和或者求积分得到的，它通常是很难计算的。为了获得一个无向模型的归一化概率分布，模型的结构和函数 $\phi$ 的定义通常需要设计为有助于高效地计算 $Z$。在深度学习中，$Z$ 通常是难以处理的。由于 $Z$ 难以精确地计算出，我们只能使用一些近似的方法。这样的近似方法是 章 直面配分函数 的主要内容。


在设计无向模型时，我们必须牢记在心的一个要点是设定一些使得 $Z$ 不存在的因子也是有可能的。当模型中的一些变量是连续的，且 $\tilde{p}$ 在其定义域上的积分发散时这种情况就会发生。例如， 当我们需要对一个单独的标量变量 $\mathrm x\in\mathbb R$ 建模，并且单个团势能定义为 $\phi(x) = x^2$ 时。在这种情况下，


$$\begin{aligned}
Z = \int x^2 dx.
\end{aligned}$$


由于这个积分是发散的，所以不存在一个对应着这个势能函数 $\phi(x)$ 的概率分布。有时候 $\phi$ 函数某些参数的选择可以决定相应的概率分布是否能够被定义。例如，对 $\phi$ 函数 $\phi(x;\beta) = \text{exp}(-\beta x^2)$ 来说，参数 $\beta$ 决定了归一化常数 $Z$ 是否存在。正的 $\beta$ 使得 $\phi$ 函数是一个关于 $\mathrm x$ 的高斯分布，但是非正的参数 $\beta$ 则使得 $\phi$ 不可能被归一化。



有向建模和无向建模之间一个重要的区别就是有向模型是通过从起始点的概率分布直接定义的，反之无向模型的定义显得更加宽松，通过 $\phi$ 函数转化为概率分布而定义。这改变了我们处理这些建模问题的直觉。当我们处理无向模型时需要牢记一点，每一个变量的定义域对于一系列给定的 $\phi$ 函数所对应的概率分布有着重要的影响。举个例子，我们考虑一个 $n$ 维向量的随机变量 $\mathbf x$ 以及一个由偏置向量 $\boldsymbol b$ 参数化的无向模型。假设 $\mathbf x$ 的每一个元素对应着一个团，并且满足 $\phi^{(i)}(\mathrm x_i) = \exp(b_i\mathrm x_i)$。在这种情况下概率分布是怎样的呢？答案是我们无法确定，因为我们并没有指定 $\mathbf x$ 的定义域。如果 $\mathbf x$ 满足 $\mathbf x \in \mathbb R^n$，那么有关归一化常数 $Z$ 的积分是发散的，这导致了对应的概率分布是不存在的。如果 $\mathbf x\in\{0,1\}^n$，那么 $p(\mathbf x)$ 可以被分解成 $n$ 个独立的分布，并且满足 $p(\mathrm x_i=1) = \text{sigmoid}(b_i)$。如果 $\mathbf x$ 的定义域是基本单位向量 $(\{[1,0,\ldots,0],[0,1,\ldots,0],\ldots,[0,0,\ldots,1]\})$ 的集合，那么 $p(\mathrm x) = \text{softmax}(\boldsymbol b)$，因此对于 $j\neq i$，一个较大的 $b_i$ 的值会降低所有 $p(\mathrm x_j = 1)$ 的概率。通常情况下，通过仔细选择变量的定义域，能够从一个相对简单的 $\phi$ 函数的集合可以获得一个相对复杂的表达。我们会在 节 卷积玻尔兹曼机 中讨论这个想法的实际应用。




## 基于能量的模型




无向模型中许多有趣的理论结果都依赖于 $\forall \boldsymbol x,\ \tilde{p}(\boldsymbol x)>0$ 这个假设。使这个条件满足的一种简单方式是使用基于能量的模型，其中


$$\begin{aligned}
\tilde{p}(\mathbf x) = \exp(-E(\mathbf x)),
\end{aligned}$$

$E(\mathbf x)$ 被称作是能量函数。对所有的 $\mathrm z$， $\exp(\mathrm z)$ 都是正的，这保证了没有一个能量函数会使得某一个状态 $\mathbf x$ 的概率为 $0$。我们可以完全自由地选择那些能够简化学习过程的能量函数。如果我们直接学习各个团势能，我们需要利用约束优化方法来任意地指定一些特定的最小概率值。学习能量函数的过程中，我们可以采用无约束的优化方法(注：对于某些模型，我们可以仍然使用约束优化方法来确保 $Z$ 存在。)。基于能量的模型中的概率可以无限趋近于 $0$ 但是永远达不到 $0$。



服从 $\tilde{p}(\mathbf{x})=\exp (-E(\mathbf{x}))$ 形式的任意分布都是玻尔兹曼分布的一个实例。正是基于这个原因，我们把许多基于能量的模型称为玻尔兹曼机~。关于什么时候称之为基于能量的模型，什么时候称之为玻尔兹曼机不存在一个公认的判别标准。一开始玻尔兹曼机这个术语是用来描述一个只有二值变量的模型，但是如今许多模型，比如均值-协方差 RBM，也涉及到了实值变量。虽然玻尔兹曼机最初的定义既可以包含潜变量也可以不包含潜变量，但是时至今日玻尔兹曼机这个术语通常用于指拥有潜变量的模型，而没有潜变量的玻尔兹曼机则经常被称为马尔可夫随机场或对数线性模型。




无向模型中的团对应于未归一化概率函数中的因子。通过 $\exp(a+b) = \exp(a) \exp(b)$，我们发现无向模型中的不同团对应于能量函数的不同项。换句话说，基于能量的模型只是一种特殊的马尔可夫网络：求幂使能量函数中的每个项对应于不同团的一个因子。关于如何从无向模型结构中获得能量函数形式的示例可以参考\fig?。人们可以将能量函数中带有多个项的基于能量的模型视作是专家之积~。能量函数中的每一项对应的是概率分布中的一个因子。能量函数中的每一项都可以看作决定一个特定的软约束是否能够满足的"专家"。每个专家只执行一个约束，而这个约束仅仅涉及随机变量的一个低维投影，但是当其结合概率的乘法时，专家们一同构造了复杂的高维约束。




<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/DAeUrbAIAYDp.png?imageslim">
</p>
> 16.5 这个图说明通过为每个团选择适当的能量函数 $E(\mathrm a,\mathrm b,\mathrm c,\mathrm d,\mathrm e,\mathrm f)$ 可以写作 $E_{\mathrm a,\mathrm b}(\mathrm a,\mathrm b) + E_{\mathrm b,\mathrm c}(\mathrm b,\mathrm c) + E_{\mathrm a,\mathrm d}(\mathrm a,\mathrm d)+  E_{\mathrm b,\mathrm e}(\mathrm b,\mathrm e) + E_{\mathrm e,\mathrm f}(\mathrm e,\mathrm f)$。值得注意的是，我们令 $\phi$ 等于对应负能量的指数，可以获得图\?中的 $\phi$ 函数，比如，$\phi_{\mathrm a,\mathrm b}(\mathrm a,\mathrm b) = \exp(-E(\mathrm a,\mathrm b))$。


基于能量的模型定义的一部分无法用机器学习观点来解释：即 $\tilde{p}(\mathbf{x})=\exp (-E(\mathbf{x}))$ 中的"-"符号。这个"-"符号可以被包含在 $E$ 的定义之中。对于很多 $E$ 函数的选择来说，学习算法可以自由地决定能量的符号。这个负号的存在主要是为了保持机器学习文献和物理学文献之间的兼容性。概率建模的许多研究最初都是由统计物理学家做出的，其中 $E$ 是指实际的、物理概念的能量，没有任何符号。诸如"能量"和"配分函数"这类术语仍然与这些技术相关联，尽管它们的数学适用性比在物理中更宽。一些机器学习研究者（例如，{Smolensky86}将负能量称为 **harmony**）发出了不同的声音，但这些都不是标准惯例。



许多对概率模型进行操作的算法不需要计算 $p_{\text{model}}(\boldsymbol x)$，而只需要计算 $\log \tilde{p}_{\text{model}}(\boldsymbol x)$。对于具有潜变量 $\boldsymbol h$ 的基于能量的模型， 这些算法有时会将该量的负数称为自由能：


$$\begin{aligned}
\mathcal F (\boldsymbol x) = -\log \sum_{\boldsymbol h} \exp(-E(\boldsymbol x,\boldsymbol h)).
\end{aligned}$$


在本书中，我们更倾向于更为通用的基于 $\log \tilde{p}_{\text{model}}(\boldsymbol x)$ 的定义。




## 分离和 d-分离


图模型中的边告诉我们哪些变量直接相互作用。我们经常需要知道哪些变量\emph{间接}相互作用。某些间接相互作用可以通过观察其他变量来启用或禁用。更正式地，我们想知道在给定其他变量子集的值时，哪些变量子集彼此条件独立。



在无向模型中，识别图中的条件独立性是非常简单的。在这种情况下，图中隐含的条件独立性称为分离。如果图结构显示给定变量集 $\mathbb S$ 的情况下变量集 $\mathbb A$ 与变量集 $\mathbb B$ 无关，那么我们声称给定变量集 $\mathbb S$ 时，变量集 $\mathbb A$ 与另一组变量集 $\mathbb B$ 是分离的。<!-- %如果两个变量 $\mathrm a$ 和 $\mathrm b$ 通过涉及未观察变量的路径连接，那么这些变量不是分离的。 -->如果连接两个变量 $\mathrm a$ 和 $\mathrm b$ 的连接路径仅涉及未观察变量，那么这些变量不是分离的。如果它们之间没有路径，或者所有路径都包含可观测的变量，那么它们是分离的。我们认为仅涉及未观察到的变量的路径是"活跃"的，而包括可观察变量的路径称为"非活跃"的。



当我们画图时，我们可以通过加阴影来表示观察到的变量。\fig?用于描述当以这种方式绘图时无向模型中的活跃和非活跃路径的样子。\fig?描述了一个从无向模型中读取分离信息的例子。



<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/Pr0uNSNNRGhn.png?imageslim">
</p>
> 16.6 \emph{(a)}随机变量 $\mathrm a$ 和随机变量 $\mathrm b$ 之间穿过 $\mathrm s$ 的路径是活跃的，因为 $\mathrm s$ 是观察不到的。
这意味着 $\mathrm a$，$\mathrm b$ 之间不是分离的。\emph{(b)}图中 $\mathrm s$ 用阴影填充，表示它是可观察的。因为 $\mathrm a$ 和 $\mathrm b$ 之间的唯一路径通过 $\mathrm s$，并且这条路径是不活跃的，我们可以得出结论，在给定 $\mathrm s$ 的条件下 $\mathrm a$ 和 $\mathrm b$ 是分离的。



<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/glryw9T9NRsk.png?imageslim">
</p>

> 16.7 从一个无向图中读取分离性质的一个例子。这里 $\mathrm b$ 用阴影填充，表示它是可观察的。由于 $\mathrm b$ 挡住了从 $\mathrm a$ 到 $\mathrm c$ 的唯一路径，我们说在给定 $\mathrm b$ 的情况下 $\mathrm a$ 和 $\mathrm c$ 是相互分离的。观察值 $\mathrm b$ 同样挡住了从 $\mathrm a$ 到 $\mathrm d$ 的一条路径，但是它们之间有另一条活跃路径。因此给定 $\mathrm b$ 的情况下 $\mathrm a$ 和 $\mathrm d$ 不是分离的。





类似的概念适用于有向模型，只是在有向模型中，这些概念被称为 d-分离。"d"代表"依赖"的意思。有向图中 $d-$ 分离的定义与无向模型中分离的定义相同：如果图结构显示给定变量集 $\mathbb S$ 时 ，变量集 $\mathbb A$ 与变量集 $\mathbb B$ 无关， 那么我们认为给定变量集 $\mathbb S$ 时，变量集 $\mathbb A$~d-分离于变量集 $\mathbb B$。


与无向模型一样，我们可以通过查看图中存在的活跃路径来检查图中隐含的独立性。如前所述，如果两个变量之间存在活跃路径，则两个变量是依赖的，如果没有活跃路径，则为 d-分离。在有向网络中，确定路径是否活跃有点复杂。关于在有向模型中识别活跃路径的方法可以参考\fig?。\fig?是从一个图中读取一些属性的例子。



尤其重要的是要记住分离和 d-分离只能告诉我们\emph{图中隐含}的条件独立性。图并不需要表示所有存在的独立性。进一步的，使用完全图（具有所有可能的边的图）来表示任何分布总是合法的。事实上，一些分布包含不可能用现有图形符号表示的独立性。特定环境下的独立指的是取决于网络中一些变量值的独立性。例如，考虑三个二值变量的模型：$\mathrm a$，$\mathrm b $ 和 $\mathrm c$。假设当 $\mathrm a$ 是 0 时，$\mathrm b$ 和 $\mathrm c$ 是独立的， 但是当 $\mathrm a$ 是 1 时，$\mathrm b$ 确定地等于 $\mathrm c$。当 $\mathrm a = 1$ 时图模型需要连接 $\mathrm b$ 和 $\mathrm c$ 的边。但是图不能说明当 $\mathrm a = 0$ 时 $\mathrm b$ 和 $\mathrm c$ 不是独立的。

一般来说，当独立性不存在时，图不会显示独立性。然而，图可能无法编码独立性。



<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/09AM0hPMLxwp.png?imageslim">
</p>

> 16.8 两个随机变量 $\mathrm a$，$\mathrm b$ 之间存在的长度为 $2$ 的所有种类的活跃路径。<!-- %存在的所有种类的长度为 $2$ 的活跃路径。 -->\emph{(a)}箭头方向从 $\mathrm a$ 指向 $\mathrm b$ 的任何路径，反过来也一样。如果 $\mathrm s$ 可以被观察到，这种路径就是阻塞的。在接力赛的例子中，我们已经看到过这种类型的路径。\emph{(b)}变量 $\mathrm a$ 和 $\mathrm b$ 通过\emph{共因} $\mathrm s$ 相连。举个例子，假设 $\mathrm s$ 是一个表示是否存在飓风的变量，$\mathrm a$ 和 $\mathrm b$ 表示两个相邻气象监控区域的风速。如果我们在 $\mathrm a$ 处观察到很高的风速，我们可以期望在 $b$ 处也观察到高速的风。如果观察到 $\mathrm s$，那么这条路径就被阻塞了。如果我们已经知道存在飓风，那么无论 $\mathrm a$ 处观察到什么，我们都能期望 $\mathrm b$ 处有较高的风速。在 $\mathrm a$ 处观察到一个低于预期的风速（对飓风而言）并不会改变我们对 $\mathrm b$ 处风速的期望（已知有飓风的情况下）。然而，如果 $\mathrm s$ 不被观测到，那么 $\mathrm a$ 和 $\mathrm b$ 是依赖的，即路径是活跃的。\emph{(c)}变量 $\mathrm a$ 和 $\mathrm b$ 都是 $\mathrm s$ 的父节点。这称为 V-结构或者碰撞情况。根据相消解释作用，V-结构导致 $\mathrm a$ 和 $\mathrm b$ 是相关的。在这种情况下，当 $\mathrm s$ 被观测到时路径是活跃的。举个例子，假设 $\mathrm s$ 是一个表示你的同事不在工作的变量。变量 $\mathrm a$ 表示她生病了，而变量 $\mathrm b$ 表示她在休假。如果你观察到了她不在工作，你可以假设她很有可能是生病了或者是在度假，但是这两件事同时发生是不太可能的。如果你发现她在休假，那么这个事实足够\emph{解释}她的缺席了。你可以推断她很可能没有生病。\emph{(d)}即使 $\mathrm s$ 的任意后代都被观察到，相消解释作用也会起作用。举个例子，假设 $\mathrm c$ 是一个表示你是否收到你同事的报告的一个变量。如果你注意到你还没有收到这个报告，这会增加你估计的她今天不在工作的概率，这反过来又会增加她今天生病或者度假的概率。阻塞\,V-结构中路径的唯一方法就是共享子节点的后代一个都观察不到。


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/d4MnRaGmSK1k.png?imageslim">
</p>
> 16.9 从这张图中，我们可以发现一些 $d-$ 分离的性质。这包括了：

+ 给定空集的情况下，$\mathrm a$ 和 $\mathrm b$ 是 $d-$ 分离的。
+ 给定 $\mathrm c$ 的情况下，$\mathrm a$ 和 $\mathrm e$ 是 $d-$ 分离的。
+ 给定 $\mathrm c$ 的情况下，$\mathrm d$ 和 $\mathrm e$ 是 $d-$ 分离的。

我们还可以发现当我们观察到一些变量时，一些变量不再是 $d-$ 分离的：

+ 给定 $\mathrm c$ 的情况下，$\mathrm a$ 和 $\mathrm b$ 不是 $d-$ 分离的。
+ 给定 $\mathrm d$ 的情况下，$\mathrm a$ 和 $\mathrm b$ 不是 $d-$ 分离的。

}
\end{figure}



## 在有向模型和无向模型中转换


我们经常将特定的机器学习模型称为无向模型或有向模型。例如，我们通常将受限玻尔兹曼机称为无向模型， 而稀疏编码则被称为有向模型。这种措辞的选择可能有点误导，因为没有概率模型本质上是有向或无向的。但是，一些模型很适合使用有向图\emph{描述}，而另一些模型很适合使用无向模型描述。


有向模型和无向模型都有其优点和缺点。这两种方法都不是明显优越和普遍优选的。相反，我们根据具体的每个任务来决定使用哪一种模型。这个选择部分取决于我们希望描述的概率分布。根据哪种方法可以最大程度地捕捉到概率分布中的独立性，或者哪种方法使用最少的边来描述分布，我们可以决定使用有向建模还是无向建模。还有其他因素可以影响我们决定使用哪种建模方式。即使在使用单个概率分布时，我们有时也可以在不同的建模方式之间切换。有时，如果我们观察到变量的某个子集，或者如果我们希望执行不同的计算任务，换一种建模方式可能更合适。例如，有向模型通常提供了一种高效地从模型中抽取样本（在 节 从图模型中采样 中描述）的直接方法。而无向模型形式通常对于推导近似推断过程（我们将在 章 近似推断 中看到，$\tilde{q}\left(h_{i} | \boldsymbol{v}\right)=\exp \left(\mathbb{E}_{\mathbf{h}_{-i} \sim q\left(\mathbf{h}_{-i} | v\right)} \log \tilde{p}(\boldsymbol{v}, \boldsymbol{h})\right)$ 强调了无向模型的作用）是很有用的。



每个概率分布可以由有向模型或由无向模型表示。在最坏的情况下，我们可以使用"完全图"来表示任何分布。在有向模型的情况下，完全图是任意有向无环图，其中我们对随机变量排序，并且每个变量在排序中位于其之前的所有其他变量作为其图中的祖先。对于无向模型，完全图只是包含所有变量的单个团。\fig?给出了一个实例。





<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/SR9a5nHhD4at.png?imageslim">
</p>

> 16.10 完全图的例子，完全图能够描述任何的概率分布。这里我们展示了一个带有四个随机变量的例子。\emph{(左)}完全无向图。在无向图中，完全图是唯一的。\emph{(右)}一个完全有向图。在有向图中，并不存在唯一的完全图。我们选择一种变量的排序，然后对每一个变量，从它本身开始，向每一个指向顺序在其后面的变量画一条弧。因此存在着关于变量数阶乘数量级的不同种完全图。在这个例子中，我们从左到右从上到下地排序变量。


当然，图模型的优势在于图能够包含一些变量不直接相互作用的信息。完全图并不是很有用，因为它并不隐含任何独立性。


当我们用图表示概率分布时，我们想要选择一个包含尽可能多独立性的图，但是并不会假设任何实际上不存在的独立性。


从这个角度来看，一些分布可以使用有向模型更高效地表示，而其他分布可以使用无向模型更高效地表示。换句话说，有向模型可以编码一些无向模型所不能编码的独立性，反之亦然。


有向模型能够使用一种无向模型无法完美表示的特定类型的子结构。这个子结构被称为不道德。这种结构出现在当两个随机变量 $\mathrm a$ 和 $\mathrm b$ 都是第三个随机变量 $\mathrm c$ 的父结点，并且不存在任一方向上直接连接 $\mathrm a$ 和 $\mathrm b$ 的边时。（"不道德"的名字可能看起来很奇怪; 它在图模型文献中使用源于一个关于未婚父母的笑话。）为了将有向模型图 $\mathcal D$ 转换为无向模型，我们需要创建一个新图 $\mathcal U$。对于每对变量 $\mathrm x$ 和 $\mathrm y$，如果存在连接 $\mathcal D$ 中的 $\mathrm x$ 和 $\mathrm y$ 的有向边（在任一方向上），或者如果 $\mathrm x$ 和 $\mathrm y$ 都是图 $\mathcal D$ 中另一个变量 $\mathrm z$ 的父节点，则在 $\mathcal U$ 中添加连接 $\mathrm x$ 和 $\mathrm y$ 的无向边。得到的图 $\mathcal U$ 被称为是道德图。关于一个通过道德化将有向图模型转化为无向模型的例子可以参考\fig?。






<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/5H0Nx5Vkz6iA.png?imageslim">
</p>

> 16.11 通过构造道德图将有向模型（上一行）转化为无向模型（下一行）的例子。\emph{(左)}只需要把有向边替换成无向边就可以把这个简单的链转化为一个道德图。得到的无向模型包含了完全相同的独立关系和条件独立关系。\emph{(中)}这个图是在不丢失独立性的情况下是无法<!-- %不丢失独立性的情况下无法 -->转化为无向模型的最简单的有向模型。这个图包含了单个完整的不道德结构。因为 $\mathrm a$ 和 $\mathrm b$ 都是 $\mathrm c$ 的父节点，当 $\mathrm c$ 被观察到时，它们之间通过活跃路径相连。为了捕捉这个依赖，无向模型必须包含一个含有所有三个变量的团。这个团无法编码 $\mathrm a \perp \mathrm b$ 这个信息。\emph{(右)}一般来说，道德化的过程会给图添加许多边，因此丢失了一些隐含的独立性。举个例子，这个稀疏编码图需要在每一对隐藏单元之间添加道德化的边，因此也引入了二次数量级的新的直接依赖。



同样的，无向模型可以包括有向模型不能完美表示的子结构。具体来说，如果 $\mathcal U$ 包含长度大于 $3$ 的环，则有向图 $\mathcal D$ 不能捕获无向模型 $\mathcal U$ 所包含的所有条件独立性，除非该环还包含弦。环指的是由无向边连接的变量序列，并且满足序列中的最后一个变量连接回序列中的第一个变量。弦是定义环序列中任意两个非连续变量之间的连接。如果 $\mathcal U$ 具有长度为 $4$ 或更大的环，并且这些环没有弦，我们必须在将它们转换为有向模型之前添加弦。添加这些弦会丢弃在 $\mathcal U$ 中编码的一些独立信息。通过将弦添加到 $\mathcal U$ 形成的图被称为弦图或者三角形化图，因为我们现在可以用更小的、三角的环来描述所有的环。要从弦图构建有向图 $\mathcal D$，我们还需要为边指定方向。当这样做时，我们不能在 $\mathcal D$ 中创建有向循环，否则将无法定义有效的有向概率模型。为 $\mathcal D$ 中的边分配方向的一种方法是对随机变量排序，然后将每个边从排序较早的节点指向排序稍后的节点。一个简单的实例可以参考\fig?。




<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/ufSpLvS6YqGI.png?imageslim">
</p>

> 16.12 将一个无向模型转化为一个有向模型。\emph{(左)}这个无向模型无法转化为有向模型，因为它有一个长度为 $4$ 且不带有弦的环。具体说来，这个无向模型包含了两种不同的独立性，并且不存在一个有向模型可以同时描述这两种性质：$\mathrm a\perp \mathrm c \mid \{\mathrm b,\mathrm d\}$ 和 $\mathrm b \perp \mathrm d \mid \{\mathrm a,\mathrm c\}$。\emph{(中)}为了将无向图转化为有向图，我们必须通过保证所有长度大于 $3$ 的环都有弦来三角形化图。为了实现这个目标，我们可以加一条连接 $\mathrm a$ 和 $\mathrm c$ 或者连接 $\mathrm b$ 和 $\mathrm d$ 的边。在这个例子中，我们选择添加一条连接 $\mathrm a$ 和 $\mathrm c$ 的边。\emph{(右)}为了完成转化的过程，我们必须给每条边分配一个方向。执行这个任务时，我们必须保证不产生任何有向环。避免出现有向环的一种方法是赋予节点一定的顺序，然后将每个边从排序较早的节点指向排序稍后的节点。在这个例子中，我们根据变量名的字母进行排序。




## 因子图


因子图是从无向模型中抽样的另一种方法，它可以解决标准无向模型语法中图表达的模糊性。在无向模型中，每个 $\phi$ 函数的范围必须是图中某个团的\emph{子集}。我们无法确定每一个团是否含有一个作用域包含整个团的因子——比如说一个包含三个结点的团可能对应的是一个有三个结点的因子，也可能对应的是三个因子并且每个因子包含了一对结点，这通常会导致模糊性。通过显式地表示每一个 $\phi$ 函数的作用域，因子图解决了这种模糊性。<!-- %然而，$\phi$ 没有必要包含每个团的全部。 --><!-- %因子图明确表示每个 $\phi$ 函数的范围。 -->具体来说，因子图是一个包含无向二分图的无向模型的图形化表示。一些节点被绘制为圆形。就像在标准无向模型中一样，这些节点对应于随机变量。其余节点绘制为方块。这些节点对应于未归一化概率函数的因子 $\phi$。变量和因子可以通过无向边连接。当且仅当变量包含在未归一化概率函数的因子中时，变量和因子在图中存在连接。没有因子可以连接到图中的另一个因子，也不能将变量连接到变量。\fig?给出了一个例子来说明因子图如何解决无向网络中的模糊性。



<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190718/IuESftRG8wNC.png?imageslim">
</p>
> 16.13 因子图如何解决无向网络中的模糊性的一个例子。\emph{(左)}一个包含三个变量（$\mathrm a$、$\mathrm b$ 和 $\mathrm c$）的团组成的无向网络。\emph{(中)}对应这个无向模型的因子图。这个因子图有一个包含三个变量的因子。\emph{(右)}对应这个无向模型的另一种有效的因子图。这个因子图包含了三个因子，每个因子只对应两个变量。即使它们表示的是同一个无向模型，这个因子图上进行的表示、推断和学习相比于中图描述的因子图都要渐近地廉价。




# 相关

- 《深度学习》花书
