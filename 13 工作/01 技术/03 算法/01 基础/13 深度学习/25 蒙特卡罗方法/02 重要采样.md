

# 重要采样


如方程~\eq?所示，在蒙特卡罗方法中，对积分（或者和）分解，确定积分中哪一部分作为概率分布 $p(\boldsymbol x)$ 以及哪一部分作为被积的函数 $f(\boldsymbol x)$（我们感兴趣的是估计 $f(\boldsymbol x)$ 在概率分布 $p(\boldsymbol x)$ 下的期望）是很关键的一步。$p(\boldsymbol x)f(\boldsymbol x)$ 不存在唯一的分解，因为它总是可以被写成

$$\begin{aligned}
p(\boldsymbol x)f(\boldsymbol x) = q(\boldsymbol x) \frac{p(\boldsymbol x)f(\boldsymbol x)}{q(\boldsymbol x)},
\end{aligned}$$

在这里，我们从 $q$ 分布中采样，然后估计 $\frac{pf}{q}$ 在此分布下的均值。许多情况中，我们希望在给定 $p$ 和 $f$ 的情况下计算某个期望，这个问题既然是求期望，那么很自然地 $p$ 和 $f$ 是一种分解选择。然而，如果考虑达到某给定精度所需要的样本数量，这个问题最初的分解选择不是最优的选择。幸运的是，最优的选择 $q^*$ 可以被简单地推导出来。这种最优的采样函数 $q^*$ 对应所谓的最优重要采样。



从 $p(\boldsymbol{x}) f(\boldsymbol{x})=q(\boldsymbol{x}) \frac{p(\boldsymbol{x}) f(\boldsymbol{x})}{q(\boldsymbol{x})}$ 所示的关系中可以发现，任意蒙特卡罗估计


$$\begin{aligned}
\hat{s}_p = \frac{1}{n}\sum_{i=1,\boldsymbol x^{(i)}\sim p}^{n}f(\boldsymbol x^{(i)})
\end{aligned}$$


可以被转化为一个重要采样的估计


$$\begin{aligned}
\hat{s}_q = \frac{1}{n}\sum_{i=1,\boldsymbol x^{(i)}\sim q}^{n}\frac{p(\boldsymbol x^{(i)})f(\boldsymbol x^{(i)})}{q(\boldsymbol x^{(i)})}.
\end{aligned}$$


我们可以容易地发现估计的期望与 $q$ 分布无关：


$$\begin{aligned}
\mathbb E_q [\hat{s}_q] = \mathbb E_p [\hat{s}_p] = s.
\end{aligned}$$


然而，重要采样的方差可能对 $q$ 的选择非常敏感。这个方差可以表示为


$$\begin{aligned}
\boldsymbol ar [\hat{s}_q] = \boldsymbol ar \left[\frac{p(\mathbf x)f(\mathbf x)}{q(\mathbf x)}\right]/n.
\end{aligned}$$


方差想要取到最小值，$q$ 需要满足

$$\begin{aligned}
q^*(\boldsymbol x) = \frac{p(\boldsymbol x)\vert f(\boldsymbol x)\vert}{Z},
\end{aligned}$$



在这里 $Z$ 表示归一化常数，选择适当的 $Z$ 使得 $q^*(\boldsymbol x)$ 之和或者积分为 $1$。一个更好的重要采样分布会把更多的权重放在被积函数较大的地方。事实上，当 $f(\boldsymbol x)$ 的正负符号不变时，$\boldsymbol ar[\hat{s}_{q^*}]=0$， 这意味着当使用最优的 $q$ 分布时，\emph{只需要一个样本就足够了}。当然，这仅仅是因为计算 $q^*$ 时已经解决了原问题。所以在实践中这种只需要采样一个样本的方法往往是无法实现的。



对于重要采样来说任意 $q$ 分布都是可行的（从得到一个期望上正确的值的角度来说），$q^*$ 指的是最优的 $q$ 分布（从得到最小方差的角度上考虑）。从 $q^*$ 中采样往往是不可行的，但是其他仍然能降低方差的 $q$ 的选择还是可行的。



另一种方法是采用有偏重要采样，这种方法有一个优势，即不需要归一化的 $p$ 或 $q$ 分布。在处理离散变量时，有偏重要采样估计可以表示为


$$\begin{aligned}
\hat{s}_{\text{BIS}} & = \frac{\sum_{i=1}^{n} \frac{p(\boldsymbol x^{(i)})}{q(\boldsymbol x^{(i)})} f(\boldsymbol x^{(i)})}{\sum_{i=1}^{n}\frac{p(\boldsymbol x^{(i)})}{q(\boldsymbol x^{(i)})}} \\
& = \frac{\sum_{i=1}^{n} \frac{p(\boldsymbol x^{(i)})}{\tilde{q}(\boldsymbol x^{(i)})} f(\boldsymbol x^{(i)})}{\sum_{i=1}^{n}\frac{p(\boldsymbol x^{(i)})}{\tilde{q}(\boldsymbol x^{(i)})}} \\
& = \frac{\sum_{i=1}^{n} \frac{\tilde{p}(\boldsymbol x^{(i)})}{\tilde{q}(\boldsymbol x^{(i)})} f(\boldsymbol x^{(i)})}{\sum_{i=1}^{n}\frac{\tilde{p}(\boldsymbol x^{(i)})}{\tilde{q}(\boldsymbol x^{(i)})}},
\end{aligned}$$


其中 $\tilde{p}$ 和 $\tilde{q}$ 分别是分布 ${p}$ 和 ${q}$ 的未经归一化的形式，$\boldsymbol x^{(i)}$ 是从分布 ${q}$ 中抽取的样本。这种估计是有偏的，因为 $\mathbb E[\hat{s}_{\text{BIS}}]\neq s$，只有当 $n \to \infty$ 且方程 $\hat{s}_{\mathrm{BIS}}=\frac{\sum_{i=1}^{n} \frac{p\left(x^{(i)}\right)}{q\left(x^{(i)}\right)} f\left(x^{(i)}\right)}{\sum_{i=1}^{n} \frac{p\left(x^{(i)}\right)}{q\left(x^{(i)}\right)}}$ 的分母收敛到 $1$ 时，等式才渐近地成立。所以这一估计也被称为渐近无偏的。



一个好的 $q$ 分布的选择可以显著地提高蒙特卡罗估计的效率，而一个糟糕的 $q$ 分布选择则会使效率更糟糕。我们回过头来看看方程 $\operatorname{Var}\left[\hat{s}_{q}\right]=\operatorname{Var}\left[\frac{p(\mathbf{x}) f(\mathbf{x})}{q(\mathbf{x})}\right] / n$ 会发现，如果存在一个 $q$ 使得 $\frac{p(\boldsymbol x)f(\boldsymbol x)}{q(\boldsymbol x)}$ 很大，那么这个估计的方差也会很大。当 $q(\boldsymbol x)$ 很小，而 $f(\boldsymbol x)$ 和 $p(\boldsymbol x)$ 都较大并且无法抵消 $q$ 时，这种情况会非常明显。$q$ 分布经常会取一些简单常用的分布使得我们能够从 $q$ 分布中容易地采样。当 $\boldsymbol x$ 是高维数据时，$q$ 分布的简单性使得它很难与 $p$ 或者 $p\vert f\vert$ 相匹配。当 $q(\boldsymbol x^{(i)})\gg p(\boldsymbol x^{(i)}) \vert f(\boldsymbol x^{(i)})\vert $ 时，重要采样采到了很多无用的样本（很小的数或零相加）。另一种相对少见的情况是 $q(\boldsymbol x^{(i)})\ll p(\boldsymbol x^{(i)}) \vert f(\boldsymbol x^{(i)})\vert $，相应的比值会非常大。正因为后一个事件是很少发生的，这种样本很难被采到，通常使得对 $s$ 的估计出现了典型的欠估计，很难被整体的过估计抵消。这样的不均匀情况在高维数据屡见不鲜，因为在高维度分布中联合分布的动态域可能非常大。




尽管存在上述的风险，但是重要采样及其变种在机器学习的应用中仍然扮演着重要的角色，包括深度学习算法。例如，重要采样被应用于加速训练具有大规模词表的神经网络语言模型的过程中（见 节 重要采样）或者其他有着大量输出结点的神经网络中。此外，还可以看到重要采样应用于估计配分函数（一个概率分布的归一化常数），详见节 估计配分函数，以及在深度有向图模型比如变分自编码器中估计对数似然（详见 节 变分自编码器）。采用随机梯度下降训练模型参数时重要采样可以用来改进对代价函数梯度的估计，尤其是分类器这样的模型，其中代价函数的大部分代价来自于少量错误分类的样本。在这种情况下，更加频繁地抽取这些困难的样本可以减小梯度估计的方差~。





# 相关

- 《深度学习》花书
