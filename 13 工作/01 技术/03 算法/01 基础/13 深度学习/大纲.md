# 大纲

现在各种算法的分支很多，他们之间的关系是什么？有什么概括性的划分吗？比如 GAN 和 DRL 是什么关系？




诸如半监督学习、机器学习的神经符号方法、以及多任务和多模式学习之类的子领域，可能会在2020年迎来进步。



部分章节练习：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190819/gMegGj1DBriX.png?imageslim">
</p>


推导Kalman filter


## 主要内容

- 介绍
- 基本概念
- 模型正则化
- 优化方法
- 模型压缩

- 神经网络 nn
- 卷积神经网络 cnn
- 循环神经网络 rnn

- 线性因子模型
- 自编码器
- 表示学习
- 深度学习中的结构化概率模型
- 蒙特卡洛方法
- 直面配分函数
- 近似推断
- 深度生成模型

- 迁移学习
- 强化学习
- 生成对抗网络
- 图神经网络
- 元学习

- automl


## 需要消化的

- 《动手学深度学习》[Dive-into-DL-PyTorch](https://github.com/ShusenTang/Dive-into-DL-PyTorch) Dive into Deep Learning (动手学深度学习) with PyTorch.


- [《解析深度学习——卷积神经网络原理与视觉实践》（开源电子版）](http://lamda.nju.edu.cn/weixs/book/CNN_book.html) 后面以花书为主体合并进来。 京东上有电子书的。
- [d2l-zh](https://github.com/d2l-ai/d2l-zh)《动手学深度学习》：面向中文读者、能运行、可讨论。英文版即伯克利“深度学习导论（STAT 157）”教材。 http://zh.d2l.ai
- 《机器学习实践应用》
- [《神经网络与深度学习》](https://github.com/nndl/nndl.github.io) 有 pdf 版 没有 md 版，不过也是值得看的。
- 《神经网络设计(原书第 2 版) 》
- 《python神经网络编程》
- 《解析卷积神经网络》魏秀参

- [深度学习有哪些好玩的且易于实现的论文？](https://www.zhihu.com/question/41231774/answer/677109582)
- [(一)深度学习基础(基本概念、优化算法、初始化、正则化等)](https://zhuanlan.zhihu.com/p/31561570) 这个人还是不错的
- [深度学习](https://blog.csdn.net/app_12062011/article/category/6673389) 这个里面的内容还是很好的，要消化掉
- [深度学习中 Batch Normalization为什么效果好？](https://www.zhihu.com/question/38102762)
- [机器学习，深度学习，神经网络，深度神经网络之间有何区别？](https://www.zhihu.com/question/50191791)
- [目前深度学习的模型有哪几种，适用于哪些问题？](https://www.zhihu.com/question/38679133)
- [如何理解深度学习中的 deconvolution networks？](https://www.zhihu.com/question/43609045)

- [【更新于 12.29】深度学习论文汇总](https://blog.csdn.net/qq_21190081/article/details/69564634)
- [怎么及时掌握/把握深度学习的发展动向和状态？](https://www.zhihu.com/question/65646397)
- [深度学习和人工智能之间是什么样的关系？](https://www.zhihu.com/question/30545893)
- [如何理解深度学习中的 deconvolution networks？](https://www.zhihu.com/question/43609045)
- [深度学习会不会淘汰掉其他所有机器学习算法?](https://www.zhihu.com/question/42061396)
- [深度机器学习中的 batch 的大小对学习效果有何影响？](https://www.zhihu.com/question/32673260)
- [为什么深度学习对训练样本的数量要求较高？](https://www.zhihu.com/question/29633459)
- [如果有第谷的数据，现在的机器学习，深度学习有办法学出开普勒三定律吗？](https://www.zhihu.com/question/54349241)
- [数理逻辑和机器学习深度学习有什么关系？](https://www.zhihu.com/question/267047086)
- [深度学习应用在哪些领域让你觉得「我去，这也能行！」？](https://www.zhihu.com/question/47563637)
- [卷积神经网络提取图像特征时具有旋转不变性吗？](https://www.zhihu.com/question/30817011)
- [卷积神经网络里输入图像大小何时是固定，何时是任意？](https://www.zhihu.com/question/56688854)
- [深度学习 cnn 中，怎么理解图像进行池化（pooling）后的平移不变性？](https://www.zhihu.com/question/34898241)


- [卷积神经网络(CNN)中卷积层与池化层如何进行 BP 残差传递与参数更新？](https://www.zhihu.com/question/51244962)
- [卷积神经网络的卷积核大小、卷积层数、每层 map 个数都是如何确定下来的呢？](https://www.zhihu.com/question/38098038)
- [卷积层和分类层，哪个更重要？](https://www.zhihu.com/question/270245936)
- [卷积神经网络如何应用在彩色图像上？](https://www.zhihu.com/question/28832761)
- [什么是 end-to-end 神经网络？](https://www.zhihu.com/question/51435499)
- [什么是二值神经网络，它的前景如何？](https://www.zhihu.com/question/41957384)
- [人工神经网络与人类神经网络有关系吗？](https://www.zhihu.com/question/24988544)
- [神经网络中激活函数的真正意义？一个激活函数需要具有哪些必要的属性？还有哪些属性是好的属性但不必要的？](https://www.zhihu.com/question/67366051)
- [BP神经网络所谓的“前馈”体现在哪？](https://www.zhihu.com/question/39371451)
- [为什么都说神经网络是个黑箱？](https://www.zhihu.com/question/263672028)
- [RBF神经网络和 BP 神经网络有什么区别？](https://www.zhihu.com/question/44328472)



- [关于神经网络的调参顺序?](https://www.zhihu.com/question/29641737)
- [神经网络中隐层有确切的含义吗？](https://www.zhihu.com/question/60493121)
- [神经网络的损失函数为什么是非凸的?](https://www.zhihu.com/question/265516791)
- [梯度下降法是万能的模型训练算法吗？](https://www.zhihu.com/question/38677354)
- [梯度下降 or 拟牛顿法？](https://www.zhihu.com/question/46441403)
- [如何理解随机梯度下降(Stochastic gradient descent，SGD)？](https://www.zhihu.com/question/264189719)

- [为什么 feature scaling 会使 gradient descent 的收敛更好?](https://www.zhihu.com/question/37129350)
- [Gradient Reversal Layer指什么？](https://www.zhihu.com/question/266710153)

- [梯度消失问题为什么不通过 gradient scaling 来解决？](https://www.zhihu.com/question/275856902)

- [梯度下降为什么步长要乘以导数？](https://www.zhihu.com/question/37513411)
- [如何理解 natural gradient descent?](https://www.zhihu.com/question/266846405)
- [梯度下降法的步长到底怎么确定？](https://www.zhihu.com/question/37911687)



- [机器学习中梯度下降算法公式是不是有问题？](https://www.zhihu.com/question/38419853)
- [为什么共轭梯度法不适用于深度学习中的网络训练？](https://www.zhihu.com/question/268719846)
- [多类分类下为什么用 softmax 而不是用其他归一化方法?](https://www.zhihu.com/question/40403377)
- [神经网络中，为何不直接对损失函数求偏导后令其等于零，求出最优权重，而要使用梯度下降法（迭代）计算权重？](https://www.zhihu.com/question/267021131)
- [深度学习如何优化神经网络结构|架构？](https://www.zhihu.com/question/19743656)
- [是不是并不是所有问题都适合用神经网络预测？](https://www.zhihu.com/question/277551944)
- [神经网络训练时对输入有什么特别的要求吗？](https://www.zhihu.com/question/47908908)
- [为什么神经网络具有泛化能力？](https://www.zhihu.com/question/53656435)
- [如何看待指出 神经网络的训练罪魁祸首是退化一文？](https://www.zhihu.com/question/265226540)
- [怎样有效地将神经网络的学习过程用几何形式来表达？](https://www.zhihu.com/question/60308502)
- [神经网络为什么可以（理论上）拟合任何函数？](https://www.zhihu.com/question/268384579)
- [神经网络中，bias有什么用，为什么要设置 bias，当加权和大于某值时，激活才有意义？](https://www.zhihu.com/question/68247574)
- [用 c++实现神经网络一般用什么库？](https://www.zhihu.com/question/35850173)
- [神经网络的训练可以采用二阶优化方法吗(如 Newton, Quasi Newton)？](https://www.zhihu.com/question/53218358)
- [目前对神经网络有哪些理论研究？](https://www.zhihu.com/question/265917569)
- [如何直观地解释 backpropagation 算法？](https://www.zhihu.com/question/27239198?rf=24827633)
- [如何调整一个不收敛的卷积神经网络？？](https://www.zhihu.com/question/36023110)
- [为什么现在所有的卷积神经网络第一层的卷积核都是 7*7的大小？](https://www.zhihu.com/question/266291928)
- [卷积神经网络的卷积核大小、卷积层数、每层 map 个数都是如何确定下来的呢？](https://www.zhihu.com/question/38098038?rf=34729519)
- [怎么评判卷积神经网络训练得差不多了？](https://www.zhihu.com/question/56152826)
- [卷积神经网络为什么要加一层降采样层呢？](https://www.zhihu.com/question/40727704)
- [RGB图像在 CNN 中如何进行 convolution?](https://www.zhihu.com/question/46607672)
- [为什么 CNN 中的卷积核一般都是正方形，没有长方形？](https://www.zhihu.com/question/265600103)
- [为什么 CNN 中的卷积核一般都是奇数*奇数，没有偶数*偶数的？](https://www.zhihu.com/question/51603070)
- [深度学习 cnn 图片预处理方式，为什么乘以 0.0167？](https://www.zhihu.com/question/63649386)
- [卷积神经网络中二维卷积核与三维卷积核有什么区别？](https://www.zhihu.com/question/266352189)
- [Google 的神经网络生成图像 (Inceptionism) 是怎么做到的？](https://www.zhihu.com/question/31572348)
- [哪里有受限玻尔兹曼机、卷积神经网络 的讲解课程？]

- [深度学习领域有哪些瓶颈？](https://www.zhihu.com/question/40577663)

- [深度学习调参有哪些技巧？](https://www.zhihu.com/question/25097993)
- [triplet loss 在深度学习中主要应用在什么地方？有什么明显的优势？](https://www.zhihu.com/question/62486208)
- [深度学习入门必看的书和论文？有哪些必备的技能需学习？](https://www.zhihu.com/question/31785984)
- [深度学习（机器学习）的下一步如何发展？](https://www.zhihu.com/question/47602063)
- [深度学习乃至机器学习和凸论有什么本质联系？](https://www.zhihu.com/question/22125449)



- [机器视觉、机器学习及相关从业人员每天必看的站点有哪些？](https://www.zhihu.com/question/54423154)

- [深度学习领域有哪些瓶颈？](https://www.zhihu.com/question/40577663/answer/309571753)
- [基础网络架构探究之 DiracNets](https://blog.csdn.net/linolzhang/article/details/79721762) 这个人的博客还是不错的。
- [CNN卷积神经网络当前最主要的应用除了图像处理还有其他的应用方面吗？](https://www.zhihu.com/question/28340925)
- [darkknightzh 当前标签: DeepLearning](https://www.cnblogs.com/darkknightzh/tag/DeepLearning/) 这个人对一些模型的理解
- [秋招人工智能笔试题](https://blog.csdn.net/sinat_36458870/article/details/83716304)


- [人工智能必看论文系列推荐（含神经网络，计算机视觉，AI，深度学习共计四十余篇）](https://zhuanlan.zhihu.com/p/77737599)




- 《精通数据科学：从线性回归到深度学习》

- [学界 | 机遇与挑战：用强化学习自动搜索优化算法](https://cloud.tencent.com/developer/article/1117796)



- [李宏毅 机器学习及其深层与结构化ppt](http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS18.html)



- [GitHub 上有哪些有趣的关于 NLP 或者 DL 的项目？](https://www.zhihu.com/question/36853910)
- [GitHub 上有哪些有关图像处理或是机器学习的有趣项目？](https://www.zhihu.com/question/36346612)


## 补充


需要说明的是：l1 相比于 l2 会更容易获得稀疏解

[知乎](https://www.zhihu.com/question/37096933/answer/70507353)