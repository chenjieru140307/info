
# 贝叶斯网络



# MOTIVE


总是看到贝叶斯网络和贝叶斯什么的，想总结下，和隐马尔科夫模型 HMM 到底是什么，详细是怎么实现的，理论是什么？比如 前向-后向算法，Viterbi算法，EM算法等等

HMM可以做文本的自然语言处理，也可以做语音的自然语言处理

贝叶斯网络很重要的一个就是 HMM 模型。

对贝叶斯和贝叶斯网络进行总结：




机器学习后半部分的学习的基础内容。后面都是围绕贝叶斯网络展开的论述，比如主题模型的 LDA 和 HMM，都是关于贝叶斯网络的。因此本次的相关理论和概念是比较重点的。




- 朴素贝叶斯
- 贝叶斯网络的表达
  - 条件概率表参数个数分析
  - 马尔科夫模型
- D-separation
  - 条件独立的三种类型
  - Markov Blanket
- 网络的构建流程
  - 混合(离散+连续)网络：线性高斯模型
- Chow-Liu算法：最大权生成树 MSWT






OK，上面就是朴素贝叶斯的相关的东西，下面开始介绍贝叶斯网络


# 贝叶斯网络

贝叶斯网络：Bayesian Network

- 把某个研究系统中涉及的随机变量，根据是否条件独立绘制在一个有向图中，就形成了贝叶斯网络。
- 贝叶斯网络，又称有向无环图模型(directed acyclic graphical model,DAG)，是一种概率图模型，根据概率图模型的拓扑结构，考察一组随机变量 $\left\{X_{1}, X_{2} \ldots X_{n}\right\}$ 及其 $n$ 组条件概率分布
(Conditional Probability Distributions, CPD)的性质。



注意：

- 贝叶斯网络谈的都是有向图模型。如果出现无向图模型，我们谈的就是马尔科夫网络。

应用：

- 如果说重要度的话，实践中很多时候用的就是贝叶斯网络。

一般而言，贝叶斯网络的有向无环图中：

- 节点表示随机变量，它们可以是可观察到的变量，或隐变量、未知参数等。
- 连接两个节点的箭头代表此两个随机变量是具有因果关系(或非条件独立)。
- 若两个节点间以一个单箭头连接在一起，表示其中一个节点是“因(parents)”，另一个是“果(children)”，两节点就会产生一个条件概率值。
- 注意：每个结点在给定其直接前驱时，条件独立于其非后继。



## 举个例子：一个简单的贝叶斯网络


举例：

- 一个简单的贝叶斯网络：


$p(a, b, c)=p(c | a, b) p(b | a) p(a)$

<p align="center">
    <img width="40%" height="70%" src="http://images.iterate.site/blog/image/20200611/ovhxb0d95udM.png?imageslim">
</p>

说明：

- 给定条件 a 的时候能够推出条件 b
- 并且 a，b能够推出 c。

如果我把三个变量变成 k 个呢？


全连接贝叶斯网络：


- 每一对结点之间都有边连接

$$p\left(x_{1}, \ldots, x_{K}\right)=p\left(x_{K} | x_{1}, \ldots, x_{K-1}\right) \ldots p\left(x_{2} | x_{1}\right) p\left(x_{1}\right)$$

$$\mathrm{P}\left(X_{1}=x_{1}, \ldots, X_{n}=x_{n}\right)=\prod_{i=1}^{n} \mathrm{P}\left(X_{i}=x_{i} | X_{i+1}=x_{i+1}, \ldots, X_{n}=x_{n}\right)$$


正常而言有些边是缺失的：


<p align="center">
    <img width="50%" height="70%" src="http://images.iterate.site/blog/image/180728/60Albi3E6d.png?imageslim">
</p>

说明：

- 上图中，既然 1 和 2 的入度为 0，那么我们认为 1 和 2 是独立的，
- 如果 4 给定的时候，6和 7 是独立的，也就是说 6 和 7 在 4 给定下是条件独立的。
- 因此，上图中 $x1,x2,…x7$ 的联合分布为：$p\left(x_{1}\right) p\left(x_{2}\right) p\left(x_{3}\right) p\left(x_{4} | x_{1}, x_{2}, x_{3}\right) p\left(x_{5} | x_{1}, x_{3}\right) p\left(x_{6} | x_{4}\right) p\left(x_{7} | x_{4}, x_{5}\right)$
  - 也就是说，要想求它们的联合分布，只需要求出这 7 个节点各自所属的条件分布的连乘积即可。
  - 对于联合分布：
    - 联合分布的本质是什么？如果我们能够拿到手任何 n 个节点的联合分布的话，其实这 n 个节点的分布状况都是可以计算的。
      - 比如：如果给定了 $x_1$,$x_2$的联合分布，怎么算 $x_1$？
      - 求积分，把 $x_2$ 积掉就行。
      - 所以说，如果把握了联合分布，那么这 7 中节点的各种分布都 OK。所以联合分布是最重要的。



OK，我们再看一下上面的 x1,x2,…x7 的联合分布，当它写成那样的时候，背后发生了什么呢？


举例1：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/FmlHBf4C68.png?imageslim">
</p>

说明：

- 联合概率分布为：$P(S, C, B, X, D)=P(S) P(C | S) P(B | S) P(X | C, S) P(D | C, B)$
- 如果我去计算呼吸困难的出现的概率，那么给定 C 和 B 的时候，4 种情况下，D 发生的概率都是一个二项分布。
- 右下角的表格，是一个条件概率表，每一行都是一个条件下的二项分布。
  - 对于任何一个结点，想去描述它的分布情况，本质上就是给定这个结点对应的条件概率表。
  - 所以每一个结点都是一个条件概率表，就能描述这么一个图。
- 对于节点的描述
  - 如果想要描述抽烟这个结点，只需要 0.4 这一个参数就可以。
  - 而对于 lung Cancer 这个就需要两个参数来决定它，一个是抽烟的时候的二项分布，一个是不抽烟的时候的二项分布。以此类推。整体上比每个都取两种情况的时候要少很多，即 $1+2+2+4+4=13 \text{vs} 2^5$。
  - 所以，贝叶斯网络省略的边越多越好，因为假如说从 Smoking 到 Dysponea 也有一条边，那么 Dyspnoea 就有 8 中情况，就是 8 个参数。参数更多。


举例2：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/d1iE6E2mdg.png?imageslim">
</p>

说明：

- 由于每一个概率都可以通过条件概率表查到，因此全部随机变量的联合分布是可以求出来的：

$$P\left(x_{1}, x_{2}, \cdots x_{n}\right)=\prod_{i=1}^{n} P\left(x_{i} | \text { parents }\left(x_{i}\right)\right)$$

- 比如算一下：JohnCall，MaryCall，Alarm，但是没有发生 Burgary 和 Earthquake 的概率。

$$\begin{array}{l}
P(j, m, a, \bar{b}, \bar{e}) \\
=P(j | a) P(m | a) P(a | \bar{b}, \bar{e}) P(\bar{b}) P(\bar{e}) \\
=0.9 \times 0.7 \times 0.001 \times 0.999 \times 0.998 \\
\approx 0.00063
\end{array}$$




贝叶斯网络的形式化定义：


- $\mathrm{BN}(\mathrm{G}, \mathbf{\Theta})$
  - G:有向无环图
  - G的结点：随机变量
  - G的边： 结点间的有向依赖。
  - 结点X的条件概李：P(X|parent(X)) 
- 需要多少参数才能确定上述网络呢？
  - 每个结点所需参数的个数： 结点的 parent 数目是M，结点和 parent 的可取值数目都是K: $\mathrm{K}^{\mathrm{M} *}(\mathrm{K}-1)$
  - 为什么？
  - 考察结点的parent对该结点形成了多少种情况(条件分布)


马尔可夫模型:


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200611/kSrAYWasDCdd.png?imageslim">
</p>

说明：

- 结点形成一条链式网络， 称作马尔科夫模型
  - $A_{i+1}$ 只与 $A_{i}$ 有关，与 $\mathrm{A}_{1}, \ldots, \mathrm{A}_{\mathrm{i}-1}$ 无关。

举例：

- 伪随机数发生器。
  - `return( ( (holdrand = holdrand * 214013L + 2531011L) >) 16) \& 0x7fff);`
- pLSA 主题模型：
  - 给定文档，给定文档之后主题的概率，给定主题之后词的概率。

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200611/jXwVkPE47fUQ.png?imageslim">
</p>

注意：

- 马尔科夫网络是一个无向图模型，
- 但是马尔科夫模型是一个有向图模型。是一个当前结点只与之前一个结点有关系的贝叶斯网络





其实看到马尔科夫模型，我们会想，为什么这个网络的每一个只与它前一个有关呢？怎么知道的呢？OK，我们先看一下贝叶斯网络里面判断条件独立的几种条件：


# 贝叶斯网络里判断条件独立的几种网络拓扑

通过贝叶斯网络判断条件独立：

情况1：tail-to-tail:

<p align="center">
    <img width="40%" height="70%" src="http://images.iterate.site/blog/image/20200611/VLLqfcaU4qU4.png?imageslim">
</p>

- 过程：

$$
\begin{aligned}
{P}({a}, {b} | {c})=&{P}({a}, {b}, {c}) / {P}({c})
\\=&{P}({c})^{*} {P}({a} | {c})^{*} {P}({b} | {c})/P(c)
\\=&P(a|c)*P(b|c)
\end{aligned}
$$

- 说明：
  - 第一行到第二行：由图得：${P}({a}, {b}, {c})={P}({c})^{*} {P}({a} | {c})^{*} {P}({b} | {c})$
- 即：在 c 给定的条件下，a，b 是被阻断（blocked）的，是独立的。
  - 即: $c$ 是条件，如果把 $c$ 这个条件忽略掉，那么 $a$ 和 $b$ 就是独立的。也就是说，在 $c$ 给定的条件之下 $a$ 和 $b$ 是独立的。也就是说这是条件独立的。

情况2：head-to-tail:

<p align="center">
    <img width="40%" height="70%" src="http://images.iterate.site/blog/image/20200611/iXVKB1zyKyqI.png?imageslim">
</p>

- 过程：

$$\begin{aligned}
{P}({a}, {b} | {c})
=& {P}({a}, {b}, {c}) / {P}({c}) \\
=& {P}({a}) * {P}({c} | {a}) * {P}({b} | {c}) / {P}({c}) \\
=& {P}({a}, {c}) * {P}({b} | {c}) / {P}({c}) \\
=& {P}({a} | {c}) * {P}({b} | {c})
\end{aligned}$$
- 说明：
  - 第一行到第二行：由图得：$P(a, b, c)=P(a)^{*} P(c | a)^{*} P(b | c)$
- 即：在 $c$ 给定的条件下，$a$，$b$被阻断，是独立的。
- 注意，如果 $c$ 未给定，这个时候 $a$ 和 $b$ 不一定独立。嗯。

情况3：head-to-head:

<p align="center">
    <img width="40%" height="70%" src="http://images.iterate.site/blog/image/20200612/lOOOzGB2tb3b.png?imageslim">
</p>

- 过程：

$${P}({a}, {b}, {c})={P}({a})^{*} {P}({b})^{*} {P}({c} | {a}, {b}) $$

$$\begin{aligned}
\sum_{c} {P}({a}, {b}, {c})=&\sum_{{c}} {P}({a})^{*} {P}({b})^{*} {P}({c} | {a}, {b}) \\
\Rightarrow P(a, b)=&{P}({a})^{*} {P}({b})
\end{aligned}$$

- 说明：
  - 第一行到第二行：左边和右边同时对 c积分。（为什么 $P(c|a,b)$ 对 c 积分是1？）

- 即：在 c 未知得条件下，a，b被阻断，是独立的。
- 注意，如果 c 是已知的，那么就无法对 c 进行积分。
  - 如果 c 给定，a 和 b 就不是独立的了。因为，如果我观测到了 c 的某种现象，就说明 a 和 b 就建立了联系，它们之间就不再是阻断的了。（但是 c 未知到底是什么意思？未知的话怎么出现这个网络拓扑的？）


作用：

- 通过这三种非常基础的网络拓扑，就能判断出来 a 和 b 是不是独立的。


举例：

## 举例说明这三种情况



<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/DB8Kfj7fia.png?imageslim">
</p>

说明：

- 对于 Serial 来说：
  - 在不知道什么肺结核信息的时候，一个人去亚洲和一个人 x 光有阴影是有关的。
  - 但是如果只去观测那些肺结核病人的时候，那么它的 x 光是否有阴影就于是否来亚洲没有关系了。
- 对于 Diverging 来说：
  - 如果一个人不知道他是否抽烟，但是他得了支气管炎，那么就会认为他有可能抽烟，那么他还有可能得肺癌。
  - 但是如果我知道某一个人抽烟，把所有抽烟的人群放在一起进行观测得话，那么有一部分人是支气管炎，有一部分人是肺癌，他们之间是独立的。在抽烟得人群内部这二者之间是独立的。（为什么是独立的？感觉这种描述还不是很清楚。）
- 对于 Converging 来说：
  - 如果一个人有支气管炎，那么他有可能呼吸困难。
  - 如果我们没有观测到呼吸困难的情况，他如果有支气管炎，那么他跟肺癌是没有关系的。（这样的推理很奇怪吧？ 比如说如果孩子是未知的，那么我们并不能够知道两个父节点是不是有关系，但是，如果孩子是已知的，俺么这两个父母必然是有关系的。）

（再找一些自然语言说明这个的例子。）



## 现在将上面的结论推广到结点集合



D-separation：有向分离：

- 对于任意的结点集 A，B，C，考察所有通过 A 中任意结点到 B 中任意结点的路径，若要求 A，B条件独立，则需要所有的路径都被阻断(blocked)，即满足下列两个前提之一：
  - A 和 B 的“head-to-tail型”和“tail-to-tail型”路径都通过 C；
  - A 和 B 的“head-to-head型”路径不通过 C 以及 C 的子孙；
- 如果 A,B 不满足 D-separation，A,B 有时被称为 D-connected.


即虽然上面的 a,b,c 只是一个结点，但是可以把它看成一个结点集合。


举例：关于汽车发动机


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/D034LE36CB.png?imageslim">
</p>

说明：

- Gas和 Radio 是独立的吗？给定 Battery 呢？Ignition呢？Starts呢？Moves呢？(答：IIIDD)






（看到这里，后续没有看）


## 再次分析之前的马尔科夫模型


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/bKBEkh88Ja.png?imageslim">
</p>


## HMM：


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/eBegDmHcia.png?imageslim">
</p>

这个模型非常重要。

它可以做自然语言的翻译和自然语言的分词。

它本质上就是一个特殊的贝叶斯网络。


## 下面我们谈一下马尔科夫毯


Markov Blanket

一个结点的 Markov Blanket是一个集合，在这个集合中的结点都给定的条件下，该结点
条件独立于其他所有结点。

即：一个结点的 Markov Blanket是它的 parents,children以及 spouses(孩子的其他 parent)

一个结点的马尔科夫毯就是它的父母，孩子和配偶。

没明白为什么集合中的结点都给定的条件下，该结点条件独立于其它的所有结点。

**关于马尔科夫毯还是不是很清楚。**


## 举个马尔科夫毯例子


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/kDL67GA41k.png?imageslim">
</p>

背景知识：Serum Calcium(血清钙浓度)高于 2.75mmo1/L即为高钙血症。许多恶性肿瘤可并发高钙血症。恶性肿瘤病人离子钙增高的百分比大于总钙，也许可用于肿瘤的过筛试验。当高钙血症的原因难于确定时，必须考虑到恶性肿瘤的存在。http://www.wiki8.com/xueqinggai_131584/

阴影部分的结点集合，是 Cancer 的 “马尔科夫毯”  (Markov Blanket)

条件独立：P(S,L|C) = P(S|C) * P(L|C)


## 贝叶斯网络的用途

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/2kd5jcdfDD.png?imageslim">
</p>

* 诊断：\(P(病因|症状)\)
* 预测：\(P(症状|病因)\)
* 分类：\(max_{class}P(类别|数据)\)


通过给定的样本数据，建立贝叶斯网络的拓扑结构和结点的条件概率分布参数。这往往需要借助先验知识和极大似然估计来完成。

在贝叶斯网络确定的结点拓扑结构和条件概率分布的前提下，可以使用该网络，对未知数据计算条件概率或后验概率，从而达到诊断、预测或者分类的目的。


## 例子：寻找马航 MH370




已知 MH370 最后消失区域，可否根据雷达最后消失区域和洋流、大气等因素：




  * 判断留尼汪岛是否位于可能区域？


  * 残骸漂流到该岛屿的概率有多大？




<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/b8i528JDD7.png?imageslim">
</p>

建模分析：


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/mkb91L0id1.png?imageslim">
</p>



<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/34Kkha5cC7.png?imageslim">
</p>



<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/5kJ5FL4a29.png?imageslim">
</p>




### 总结：


在每个时刻，物体的当前可能区域是上一时刻所有可能区域和相应转移概率的乘积和，这恰好是矩阵
乘法(矩阵和向量乘法)的定义。

当前可能区域只和上一个时刻的区域有关，而与更上一个时刻无关，因此，是马尔科夫模型。

思考：可以使用“ 漂流位置”建立马尔科夫模型，该可能位置是不可观察的，而将“ 转移位置”认为是“ 漂流位置”的转换结果，“ 转移位置”是残骸的最终真实位置，使用增强的隐马尔科夫模型。

不要过得累加模型的复杂度，适时使用奥卡姆剃刀(Occam‘s Razor)。该模型仅个人观点。


##




# 贝叶斯网络的构建：




## 怎么通过样本构建贝叶斯网络呢？


如果你拿到手若干个样本，如何去建立贝叶斯网络呢？




  * 如果说，有领域知识，那么首先考虑领域知识，


  * 如果领域知识比较欠缺，那么根据样本实际观测来给定贝叶斯网络。


现在假定领域知识都用完了：


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/BFbeD8fBb4.png?imageslim">
</p>

什么叫 D-separation？

怎么计算 <p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/cj45c0BG90.png?imageslim">
</p>？


## 贝叶斯网络的构建举例




<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/Gl1FLdal0F.png?imageslim">
</p>

数出来 MaryCalls的收 JohnCalls 的次数，数出来 JohnCalls 的次数，如果二者基本相等，就说明 MaryCalls 打电话于 JohnCalls 是独立的。


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/C9b00mKEam.png?imageslim">
</p>

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/Hhl4CEIejI.png?imageslim">
</p>

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/BkHe68F4LD.png?imageslim">
</p>

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/K0dFjjLKg1.png?imageslim">
</p>

这种是根据样本有关的，而且跟你结点选择的顺序是极大相关的。比如这里选择的顺序是 MJABE

所以它很可能与实际的情况不同。

实际上实践中我们建立贝叶斯网络更多的是靠先验性的知识的。一定要重视领域知识。这个是提取特征，建立模型，做最初的目标函数的重要的依据，后面才能谈到如何对这个模型进行训练，进行预测。


## 混合(离散+连续)网络


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/09hmgcCJGa.png?imageslim">
</p>

丰收了 harvest  会决定我的价格，比如 cost 大家都丰收，价格就下跌

有的时候有财政补贴 subsidy 也会决定我的价格

cost 决定我是否购买 buys

是否有补助，是否购买是布尔变量，但是收成和价格是连续变量。

所以这是一个混合网络。


### 孩子结点是连续的


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/Jf8K3447gm.png?imageslim">
</p>


### 孩子结点是离散的，父节点是连续的




<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/iEGl594bB0.png?imageslim">
</p>



<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/DEIl9gc1L6.png?imageslim">
</p>

上面这些都没有详细说。


# 贝叶斯网络的推导




<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/A1IIKCLBfG.png?imageslim">
</p>

如果我这里的条件概率表都给定了，如果呼吸困难发生了，那么他抽烟的概率是什么？


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/j1KlcEckki.png?imageslim">
</p>



<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/j0c4ij9LlJ.png?imageslim">
</p>这个变成一个累加的




<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/4EmhKdlc1m.png?imageslim">
</p>这个还是能够理解的，**但是这个求和怎么算呢？，任何一个结点的概率值都是可以通过条件概率表查出来。**


而且变换成<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/9bDF1di5id.png?imageslim">
</p>**这样怎么就省事了？怎么就少做乘法了？**



本质上用的是动态规划。**什么是动态规划？为什么本质上是动态规划？**





最后谈一下无向环




# 无向环


可以发现，若贝叶斯网络中存在 “环” (无向)，则因此构造的因子图会得到环。而使用消息传递的思想，这个消息将无限传输下去，不利于概率计算。

解决方法：




  * 删除贝叶斯网络中的若干条边，使得它不含有无向环


  * 重新构造没有环的贝叶斯网络


原贝叶斯网络的近似树结构


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/ciKkJgaDC6.png?imageslim">
</p>

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/5E0c9igd46.png?imageslim">
</p>

左边是通过真实的数据算出来的贝叶斯网络，如果我们吧有向的箭头忽略掉，就有一个环

我们能不能做一个近似，对这么一个 5 个结点的图就用 4 条边形成一个树形结构，使得这个树形结构与原始的是最接近的？

如何度量这两个分布之间的距离呢？可以用 K-L散度。即相对熵。

然后有一个非常好的结论。叫做 MSWT。这个算法本质上就是我们谈到的图模型里面的最小生成树，没有任何区别。**什么是最小生成树？**



将两图的相对熵转换成变量的互信息


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/5Gabca2d19.png?imageslim">
</p>




### 最大权生成树 MSWT 的建立过程






  1. 对于分布 P(x)，对于所有的 i≠j，计算联合分布 P(xi|xj)；


  2. 使用第 1 步得到的概率分布，计算任意两个结点的互信息 I(Xi,Yj)，并把 I(Xi,Yj)作为这两个结点连接边的权值；


  3. 计算最大权生成树(Maximum-weight spanning tree)


    1. 初始状态：n个变量(结点)，0条边


    2. 插入最大权重的边


    3. 找到下一个最大的边，并且加入到树中；要求加入后，没有环生成。否则，查找次大的边；


    4. 重复上述过程 c 过程直到插入了 n-1条边(树建立完成)





  4. 选择任意结点作为根，从根到叶子标识边的方向；


  5. 可以保证，这课树的近似联合概率 P'(x)和原贝叶斯网络的联合概率 P(x)的相对熵最小。


第 3 步本质上是最小生成树。

这个树就是最接近于原始图的近似的一个图模型。

**没有很理解。**

**二者这种什么时候会用到？只要生成的贝叶斯网络是存在无向环，就必须这样处理吗？**

判断是否有环怎么判断？拓扑排序。等。**有那些方法？**




# 附：Chow-Liu算法 没讲


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180728/mH98kCFl1d.png?imageslim">
</p>






# 相关

1. 七月在线 机器学习
