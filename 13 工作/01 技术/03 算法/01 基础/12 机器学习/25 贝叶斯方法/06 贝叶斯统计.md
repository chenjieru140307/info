
# 贝叶斯统计

（没有很理解）

现在假设我们有一组数据样本 $\left\{x^{(1)}, \ldots, x^{(m)}\right\}$，通过贝叶斯规则结合数据似然 $p\left(x^{(1)}, \ldots, x^{(m)} | \boldsymbol{\theta}\right)$ 和先验，可以恢复数据对我们关于 $\boldsymbol{\theta}$ 信念的影响：

$$
p\left(\boldsymbol{\theta} | x^{(1)}, \ldots, x^{(m)}\right)=\frac{p\left(x^{(1)}, \ldots, x^{(m)} | \boldsymbol{\theta}\right) p(\boldsymbol{\theta})}{p\left(x^{(1)}, \ldots, x^{(m)}\right)}
$$



相对于最大似然估计，贝叶斯估计有两个重要区别。

- 第一，不像最大似然方法预测时使用 $\boldsymbol{\theta}$ 的点估计，贝叶斯方法使用 $\boldsymbol{\theta}$ 的全分布。
  - 例如，在观测到 $m$ 个样本后，下一个数据样本 $x^{(m+1)}$ 的预测分布如下：
  - $p\left(x^{(m+1)} | x^{(1)}, \ldots, x^{(m)}\right)=\int p\left(x^{(m+1)} | \boldsymbol{\theta}\right) p\left(\boldsymbol{\theta} | x^{(1)}, \ldots, x^{(m)}\right) d \boldsymbol{\theta}$
  - 这里，每个具有正概率密度的 $\boldsymbol{\theta}$ 的值有助于下一个样本的预测，其中贡献由后验密度本身加权。
  - 在观测到数据集 $\left\{x^{(1)}, \ldots, x^{(m)}\right\}$ 之后，如果我们仍然非常不确定 $\boldsymbol{\theta}$ 的值，那么这个不确定性会直接包含在我们所做的任何预测中。
  - 之前，我们已经知道，频率派方法解决给定点估计 $\boldsymbol{\theta}$ 的不确定性的方法是评估方差，估计的方差评估了观测数据重新从观测数据中采样后，估计可能如何变化。对于如何处理估计不确定性的这个问题，贝叶斯派的答案是积分，这往往会防止过拟合。当然，积分仅仅是概率法则的应用，使贝叶斯方法容易验证，而频率派机器学习基于相当特别的决定构建了一个估计，将数据集里的所有信息归纳到一个单独的点估计。<span style="color:red;">没明白。</span>
- 第二个最大区别是由贝叶斯先验分布造成的。先验能够影响概率质量密度朝参数空间中偏好先验的区域偏移。实践中，先验通常表现为偏好更简单或更光滑的模型。对贝叶斯方法的批判认为，先验是人为主观判断影响预测的来源。<span style="color:red;">嗯。</span>

当训练数据很有限时，贝叶斯方法通常泛化得更好，但是当训练样本数目很大时，通常会有很大的计算代价。<span style="color:red;">为什么。</span>

# 贝叶斯线性回归


- 使用贝叶斯估计方法学习线性回归的参数。


过程：

- 线性回归中，我们学习从输入向量 $\boldsymbol{x} \in \mathbb{R}^{n}$ 预测标量 $y \in \mathbb{R}$ 的线性映射。$\hat{\boldsymbol{y}}=\boldsymbol{X} \boldsymbol{w}$
- 将上式表示为 $\boldsymbol{y}$ 上的高斯条件分布，得到：

$$
\begin{aligned}
p\left(\boldsymbol{y} | \boldsymbol{X}, \boldsymbol{w}\right)&=\mathcal{N}\left(\boldsymbol{y} ; \boldsymbol{X} \boldsymbol{w}, \boldsymbol{I}\right)\\&\propto \exp \left(-\frac{1}{2}\left(\boldsymbol{y}-\boldsymbol{X} \boldsymbol{w}\right)^{\top}\left(\boldsymbol{y}-\boldsymbol{X} \boldsymbol{w}\right)\right)
\end{aligned}
$$

- 说明：
  - 其中，我们根据标准的 MSE 公式假设 $y$ 上的高斯方差为 $1$。

- 为确定模型参数向量 $\boldsymbol{w}$ 的后验分布，我们首先需要指定一个先验分布。
  - 先验应该反映我们对这些参数取值的信念。
  - 虽然有时将我们的先验信念表示为模型的参数很难或很不自然，但在实践中我们通常假设一个相当广泛的分布来表示 $\boldsymbol{\theta}$ 的高度不确定性。
  - 实数值参数通常使用高斯作为先验分布。

$$
\begin{aligned}
p(\boldsymbol{w})=&\mathcal{N}\left(\boldsymbol{w} ; \boldsymbol{\mu}_{0}, \boldsymbol{\Lambda}_{0}\right) 
\\\propto& \exp \left(-\frac{1}{2}\left(\boldsymbol{w}-\boldsymbol{\mu}_{0}\right)^{\top} \boldsymbol{\Lambda}_{0}^{-1}\left(\boldsymbol{w}-\boldsymbol{\mu}_{0}\right)\right)
\end{aligned}
$$

- 说明：
  - 其中，$\boldsymbol{\mu}_{0}$ 和 $\boldsymbol{\Lambda}_{0}$ 分别是先验分布的均值向量和协方差矩阵。
  - 除非有理由使用协方差矩阵的特定结构，我们通常假设其为对角协方差矩阵 $\boldsymbol{\Lambda}_{0}=\operatorname{diag}\left(\boldsymbol{\lambda}_{0}\right)$ 。

- 确定好先验后，我们现在可以继续确定模型参数的后验分布。


$$
\begin{aligned}
p(\boldsymbol{w} | \boldsymbol{X}, \boldsymbol{y}) &\propto p(\boldsymbol{y} | \boldsymbol{X}, \boldsymbol{w}) p(\boldsymbol{w})
\\&\propto \exp \left(-\frac{1}{2}(\boldsymbol{y}-\boldsymbol{X} \boldsymbol{w})^{\top}(\boldsymbol{y}-\boldsymbol{X} \boldsymbol{w})\right) \exp \left(-\frac{1}{2}\left(\boldsymbol{w}-\boldsymbol{\mu}_{0}\right)^{\top} \boldsymbol{\Lambda}_{0}^{-1}\left(\boldsymbol{w}-\boldsymbol{\mu}_{0}\right)\right)
\\&\propto \exp \left(-\frac{1}{2}\left(-2 \boldsymbol{y}^{\top} \boldsymbol{X} \boldsymbol{w}+\boldsymbol{w}^{\top} \boldsymbol{X}^{\top} \boldsymbol{X} \boldsymbol{w}+\boldsymbol{w}^{\top} \boldsymbol{\Lambda}_{0}^{-1} \boldsymbol{w}-2 \boldsymbol{\mu}_{0}^{\top} \boldsymbol{\Lambda}_{0}^{-1} \boldsymbol{w}\right)\right)
\end{aligned}
$$

- 现在我们定义
  - $\boldsymbol{\Lambda}_{m}=\left(\boldsymbol{X}^{\top} \boldsymbol{X}+\mathbf{\Lambda}_{0}^{-1}\right)^{-1}$
  - $\boldsymbol{\mu}_{m}=\boldsymbol{\Lambda}_{m}\left(\boldsymbol{X}^{\top} \boldsymbol{y}+\mathbf{\Lambda}_{0}^{-1} \boldsymbol{\mu}_{0}\right)$
- 使用这些新的变量，我们发现后验可改写为高斯分布：

$$
\begin{aligned}
p(\boldsymbol{w} | \boldsymbol{X}, \boldsymbol{y}) &\propto \exp \left(-\frac{1}{2}\left(\boldsymbol{w}-\boldsymbol{\mu}_{m}\right)^{\top} \boldsymbol{\Lambda}_{m}^{-1}\left(\boldsymbol{w}-\boldsymbol{\mu}_{m}\right)+\frac{1}{2} \boldsymbol{\mu}_{m}^{\top} \boldsymbol{\Lambda}_{m}^{-1} \boldsymbol{\mu}_{m}\right)
\\&\propto \exp \left(-\frac{1}{2}\left(\boldsymbol{w}-\boldsymbol{\mu}_{m}\right)^{\top} \boldsymbol{\Lambda}_{m}^{-1}\left(\boldsymbol{w}-\boldsymbol{\mu}_{m}\right)\right)
\end{aligned}
$$


- 分布的积分必须归一这个事实意味着要删去所有不包括参数向量 $\boldsymbol{w}$ 的项。下式显示了如何标准化多元高斯分布。

$$
\mathcal N(\boldsymbol x; \boldsymbol \mu, \boldsymbol \Sigma) = \sqrt{ \frac{1}{ (2\pi)^n \det(\boldsymbol \Sigma)}}  \exp \left ( -\frac{1}{2} (\boldsymbol x-\boldsymbol \mu)^\top \boldsymbol \Sigma^{-1} (\boldsymbol x- \boldsymbol \mu) \right).
$$


- 检查此后验分布可以让我们获得贝叶斯推断效果的一些直觉。
  - 大多数情况下，我们设置 $\boldsymbol{\mu}_{0}=0$ 。
  - 如果我们设置 $\mathbf{\Lambda}_{0}=\frac{1}{\alpha} \boldsymbol{I}$ ，那么 $\mu_{m}$ 对 $\boldsymbol{w}$ 的估计就和频率派带权重衰减惩罚 $\alpha \boldsymbol{w}^{\top} \boldsymbol{w}$ 的线性回归的估计是一样的。一个区别是若 $\alpha$ 设为 $0$，则贝叶斯估计是未定义的——我们不能将贝叶斯学习过程初始化为一个无限宽的 $\boldsymbol{w}$ 先验。更重要的区别是，贝叶斯估计会给出一个协方差矩阵，表示 $\boldsymbol{w}$ 所有不同值的可能范围，而不仅是估计 $\mu_{m}$。



## 最大后验(MAP)估计

（没明白）

原则上，我们应该使用参数 $\boldsymbol{\theta}$ 的完整贝叶斯后验分布进行预测，但单点估计常常也是需要的。

希望使用点估计的一个常见原因：

- 对于大多数有意义的模型而言，大多数涉及贝叶斯后验的计算是非常棘手的，点估计提供了一个可行的近似解。

最大后验点估计：Maximum A Posteriori,MAP

- 我们仍然可以让先验影响点估计的选择来利用贝叶斯方法的优点，而不是简单地回到最大似然估计。
  - 最大后验点估计就是做到这一点的合理方式。
- MAP 估计选择后验概率最大的点(或在 $\boldsymbol{\theta}$ 是连续值的更常见情况下，概率密度最大的点)：

$$
\begin{aligned}
\boldsymbol{\theta}_{\mathrm{MAP}}&=\underset{\boldsymbol{\theta}}{\arg \max } p(\boldsymbol{\theta} | \boldsymbol{x})\\&=\underset{\boldsymbol{\theta}}{\arg \max } \log p(\boldsymbol{x} | \boldsymbol{\theta})+\log p(\boldsymbol{\theta})
\end{aligned}
$$

说明：

- $\log p(\boldsymbol{x} | \boldsymbol{\theta})$ 对应着标准的对数似然项
- $\log p(\boldsymbol{\theta})$ 对应着先验分布。

举例：

- 考虑具有高斯先验权重 $\boldsymbol{w}$ 的线性回归模型。如果先验是 $\mathcal{N}\left(\boldsymbol{w} ; \mathbf{0}, \frac{1}{\lambda} I^{2}\right)$，那么上式的对数先验项正比于熟悉的权重衰减惩罚 $\lambda \boldsymbol{w}^{\top} \boldsymbol{w}$，加上一个不依赖于 $\boldsymbol{w}$ 也不会影响学习过程的项。因此，具有高斯先验权重的 MAP 贝叶斯推断对应着权重衰减。

正如全贝叶斯推断，MAP 贝叶斯推断的优势是能够利用来自先验的信息，这些信息无法从训练数据中获得。该附加信息有助于减少最大后验点估计的方差(相比于 ML 估计)。然而，这个优点的代价是增加了偏差。

许多正规化估计方法，例如权重衰减正则化的最大似然学习，可以被解释为贝叶斯推断的 MAP 近似。这个适应于正则化时加到目标函数的附加项对应着 $\log p(\boldsymbol{\theta})$ 。并非所有的正则化惩罚都对应着 MAP 贝叶斯推断。例如，有些正则化项可能不是一个概率分布的对数。还有些正则化项依赖于数据，当然也不会是一个先验概率分布。

MAP 贝叶斯推断提供了一个直观的方法来设计复杂但可解释的正则化项。例如，更复杂的惩罚项可以通过混合高斯分布作为先验得到，而不是一个单独的高斯分布(Nowlan and Hinton,1992)。
