# 频率学派 极大似然估计

极大似然估计 Maximum Likelihood Estimation，MLE

- 来自频率学派
- 是根据数据采样来估计概率分布参数的经典方法.

介绍：

- 令 $D_c$ 表示训练集 $D$ 中第 $c$ 类样本组成的集合，假设这些样本是独立同分布的，则参数 $\boldsymbol{\theta}_{c}$ 对于数据集 $D_c$ 的似然是

$$
P\left(D_{c} | \boldsymbol{\theta}_{c}\right)=\prod_{\boldsymbol{x} \in D_{c}} P\left(\boldsymbol{x} | \boldsymbol{\theta}_{c}\right)
$$

- 此时：
  - 对 $\boldsymbol{\theta}_{c}$ 进行极大似然估计，就是去寻找能最大化似然 $P(D_c|\theta_c)$ 的参数值 $\hat{\boldsymbol{\theta}}_{c}$
  - 直观上看，极大似然估计是试图在 $\boldsymbol{\theta}_{c}$ 所有可能的取值中，找到一个能使数据出现的“可能性”最大的值.

- 由于上式中的连乘操作易造成下溢，通常使用对数似然( log-likelihood )

$$
\begin{aligned} L L\left(\boldsymbol{\theta}_{c}\right) &=\log P\left(D_{c} | \boldsymbol{\theta}_{c}\right) \\ &=\sum_{\boldsymbol{x} \in D_{c}} \log P\left(\boldsymbol{x} | \boldsymbol{\theta}_{c}\right) \end{aligned}
$$

- 因此，此时的参数 $\boldsymbol{\theta}_{c}$ 的极大似然估计 $\hat{\boldsymbol{\theta}}_{c}$ 为

$$
\hat{\boldsymbol{\theta}}_{c}=\underset{\boldsymbol{\theta}_{c}}{\arg \max } L L\left(\boldsymbol{\theta}_{c}\right)
$$

举例：

- 在连续属性情形下，假设概率密度函数 $p(\boldsymbol{x} | c) \sim \mathcal{N}\left(\boldsymbol{\mu}_{c}, \boldsymbol{\sigma}_{c}^{2}\right)$
- 那么参数  $\boldsymbol{\mu}_{\mathrm{c}}$ 和 $\boldsymbol{\sigma}_{c}^{2}$ 的极大似然估计为

$$
\hat{\boldsymbol{\mu}}_{c}=\frac{1}{\left|D_{c}\right|} \sum_{\boldsymbol{x} \in D_{c}} \boldsymbol{x}
$$

$$
\hat{\sigma}_{c}^{2}=\frac{1}{\left|D_{c}\right|} \sum_{\boldsymbol{x} \in D_{c}}\left(\boldsymbol{x}-\hat{\boldsymbol{\mu}}_{c}\right)\left(\boldsymbol{x}-\hat{\boldsymbol{\mu}}_{c}\right)^{\mathrm{T}}
$$

说明：

- 上面的例子也就是说，通过极大似然法得到的正态分布均值就是样本均值，方差就是 $\left(\boldsymbol{x}-\hat{\boldsymbol{\mu}}_{c}\right)\left(\boldsymbol{x}-\hat{\boldsymbol{\mu}}_{c}\right)^{\mathrm{T}}$ 的均值，这显然是一个符合直觉的结果。
- 在离散属性情形下， 也可通过类似的方式估计类条件概率.

注意：

- 这种参数化的方法虽能使类条件概率估计变得相对简单，但估计结果的准确性严重依赖于所假设的概率分布形式是否符合潜在的真实数据分布。
- 在现实应用中，欲做出能较好地接近潜在真实分布的假设，往往需在一定程度上利用关于应用任务本身的经验知识，否则若仅凭“猜测”来假设概率分布形式，很可能产生误导性的结果。


