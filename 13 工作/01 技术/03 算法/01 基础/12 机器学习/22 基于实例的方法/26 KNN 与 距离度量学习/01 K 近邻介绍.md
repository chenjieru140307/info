# KNN

## 介绍

K近邻 K-NearestNeighbor KNN 

特质：

- 非参数学习算法
- 非概率算法
- 监督学习算法
- 可用于分类和回归
- 不具有显式的学习过程

过程：

- 假设我们已经给定一个训练数据集，其中的实例类别已定。
- 此时，对于一个新的实例，基于某种距离度量找出训练集中与其最靠近的  $k$ 个训练样本
  - 也可基于距离远近进行加权平均或加权投票，距离越近的样本权重越大。
- 然后，基于这 $k$ 个“邻居”的信息来进行预测。
  - 一般，这 K 个实例的多数属于某个类，就把该输入实例分类到这个类中。




优点：

- 精度高、
- 对异常值不敏感、
- 无数据输入假定

缺点：

- 计算复杂度高、
- 空间复杂度高
- 它的计算成本很高，在训练集较小时泛化能力很差。
- 不能学习出哪一个特征比其他更具识别力。

适用数据范围：

- 数值型和标称型 **什么是标称型？**







涉及到：

- 距离度量：什么叫最近？
- K值的选择 ：到底选几个？
- 分类决策规则：知道它周边的 k 个样本了，怎么来决定这个测试样本的类别？
  - 分类任务，可使用投票法
    - 即选择这 $k$ 个样本中出现最多的类别标记作为预测结果；
  - 回归任务，可使用平均法，
    - 即将这 $k$ 个样本的实值输出标记的平均值作为预测结果；

