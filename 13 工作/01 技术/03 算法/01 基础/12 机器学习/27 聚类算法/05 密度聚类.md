
# 密度聚类

密度聚类

亦称基于密度的聚类 density-based clustering

## 介绍

密度聚类：

- 此类算法假设聚类结构能通过样本分布的紧密程度确定。
- 通常情形下，密度聚类算法从样本密度的角度来考察样本之间的可连接性，并基于可连接样本不断扩展聚类簇以获得最终的聚类结果.


特点：

- 不依赖于距离，而是依赖于密度，只要某个样本点周边的密度大于某阈值，那么就将这个样本添加到最近的簇中。
  - 基于距离的算法只能发现 “类圆形” (凸) 的聚类，而密度聚类就比较强了，它可以发现任意形状的聚类，而且它对噪声数据不敏感。

缺点：

- 计算密度单元的计算复杂度大，需要建立空间索引来降低计算量。



比较重要的两种密度聚类的方法：

- DBSCAN
- 密度最大值算法



（DBSCAN、OPTICS、Mean shift  ）


## DBSCAN

DBSCAN Density-Based Spatial Clustering of Applicatinos with Noise

DBSCAN：

- 基于一组 “邻域”(neighborhood)参数($\epsilon$, MinPts)来刻画样本分布的紧密程度。

介绍：

- 给定数据集 $D=\left\{\boldsymbol{x}_{1}, \boldsymbol{x}_{2}, \ldots, \boldsymbol{x}_{m}\right\}$ ，定义下面这几个概念：
    - $\epsilon$-邻域：
      - 对 $\boldsymbol{x}_{j} \in D$ ，其 $\epsilon$-邻域包含样本集 $D$ 中与 $\boldsymbol{x}_{j}$ 的距离不大于 $\epsilon$ 的样本，即 $N_{\epsilon}\left(\boldsymbol{x}_{j}\right)=\left\{\boldsymbol{x}_{i} \in D | \operatorname{dist}\left(\boldsymbol{x}_{i}, \boldsymbol{x}_{j}\right) \leqslant \epsilon\right\}$。
    - 核心对象(core object):
      - 若 $\boldsymbol{x}_{j}$ 的 $\epsilon$-邻域至少包含 MinPts 个样本，即 $\left|N_{\epsilon}\left(\boldsymbol{x}_{j}\right)\right| \geqslant \operatorname{Min} P t s$ ，则 $\boldsymbol{x}_{j}$ 是一个核心对象；
    - 密度直达(directly density-reachable):
      - 若 $\boldsymbol{x}_{j}$ 位于 $\boldsymbol{x}_{i}$ 的 $\epsilon$-邻域中，且 $\boldsymbol{x}_{i}$ 是核心对象，则称 $\boldsymbol{x}_{j}$ 由 $\boldsymbol{x}_{i}$ 密度直达；
    - 密度可达(density-reachable):
      - 对 $\boldsymbol{x}_{i}$ 与 $\boldsymbol{x}_{j}$ ，若存在样本序列 $\boldsymbol{p}_{1}, \boldsymbol{p}_{2}, \dots, \boldsymbol{p}_{n}$ ，其中 $\boldsymbol{p}_{1}=\boldsymbol{x}_{i}$，$\boldsymbol{p}_{n}=\boldsymbol{x}_{j}$ 且 $\boldsymbol{p}_{i+1}$ 由 $\boldsymbol{p}_{i}$ 仍密度直达，则称 $\boldsymbol{x}_{j}$ 由 $\boldsymbol{x}_{i}$ 密度可达；
    - 密度相连(density-connected):
      - 对 $\boldsymbol{x}_{i}$ 与 $\boldsymbol{x}_{j}$ ，若存在 $\boldsymbol{x}_{k}$ 使得 $\boldsymbol{x}_{i}$ 与 $\boldsymbol{x}_{j}$ 均由 $\boldsymbol{x}_{k}$ 密度可达，则称 $\boldsymbol{x}_{i}$ 与 $\boldsymbol{x}_{j}$ 密度相连.

上述概念的直观显示如图：

<p align="center">
    <img width="60%" height="70%" src="http://images.iterate.site/blog/image/20200615/Dz598qU9Ent2.png?imageslim">
</p>

说明：

- $(M i n P t s=3)$ 
- 虚线显示出 $\epsilon$ -邻域, 
- $\boldsymbol x_{1}$ 是核心对象, $\boldsymbol{x}_{2}$ 由 $\boldsymbol{x}_{1}$ 密度直达, $\boldsymbol{x}_{3}$ 由 $\boldsymbol{x}_{1}$ 密度可达, $\boldsymbol{x}_{3}$ 与 $\boldsymbol{x}_{4}$ 密度相连.

基于这些概念，DBSCAN 将“簇”定义为：由密度可达关系导出的最大的密度相连样本集合。形式化地说，给定邻域参数($\epsilon$ ，MinPts)，簇 $C\subseteq D$ 是满足以下性质的非空样本子集：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180629/iHmGE6G6La.png?imageslim">
</p>

那么，如何从数据集 $D$ 中找出满足以上性质的聚类簇呢？实际上，若 $\boldsymbol{x}$ 为核心对象，由 $\boldsymbol{x}$ 密度可达的所有样本组成的集合记为 $X=\left\{\boldsymbol{x}^{\prime} \in D |\right.\boldsymbol{x}^{\prime}由 \boldsymbol{x}密度可达\}$ ，则不难证明 $X$ 即为满足连接性与最大性的簇.

于是，DBSCAN 算法先任选数据集中的一个核心对象为“种子”(seed)， 再由此出发确定相应的聚类簇，算法描述如图 9.9所示

- 在第 1~7行中，算法先根据给定的邻域参数($\epsilon$, MinPts)找出所有核心对象;
- 然后在第 10~24行中, 以任一核心对象为出发点，找出由其密度可达的样本生成聚类簇，直到所有核心对象均被访问过为止.

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180629/3FFafeJfC0.png?imageslim">
</p>

以表 9.1的西瓜数据集 4.0 为例，假定邻域参数($\epsilon$, MinPts)设置为 $\epsilon=0.11$，$MinPts = 5$ . DBSCAN算法先找出各样本的 $\epsilon$-邻域并确定核心对象集合 $\Omega=\left\{\boldsymbol{x}_{3}, \boldsymbol{x}_{5}, \boldsymbol{x}_{6}, \boldsymbol{x}_{8}, \boldsymbol{x}_{9}, \boldsymbol{x}_{13}, \boldsymbol{x}_{19}, \boldsymbol{x}_{24}, \boldsymbol{x}_{25}, \boldsymbol{x}_{28}, \boldsymbol{x}_{29}\right\}$。然后，从 $\Omega$ 中 随机选取一个核心对象作为种子，找出由它密度可达的所有样本，这就构成了第一个聚类簇。不失一般性，假定核心对象 $\boldsymbol{x}_{8}$ 被选中作为种子，则 DBSCAN 生成的第一个聚类簇为：

$$
C_{1}=\left\{\boldsymbol{x}_{6}, \boldsymbol{x}_{7}, \boldsymbol{x}_{8}, \boldsymbol{x}_{10}, \boldsymbol{x}_{12}, \boldsymbol{x}_{18}, \boldsymbol{x}_{19}, \boldsymbol{x}_{20}, \boldsymbol{x}_{23}\right\}
$$

然后，DBSCAN 将 $C_1$ 中包含的核心对象从 $\Omega$ 中去除：$\Omega=\Omega \backslash C_{1}=\left\{\boldsymbol{x}_{3}, \boldsymbol{x}_{5}, \boldsymbol{x}_{9}, \boldsymbol{x}_{13}, \boldsymbol{x}_{14}, \boldsymbol{x}_{24}, \boldsymbol{x}_{25}, \boldsymbol{x}_{28}, \boldsymbol{x}_{29}\right\}$ 。再从更新后的集合 $\Omega$ 中随机选取一个 核心对象作为种子来生成下一个聚类簇。上述过程不断重复，直至 $\Omega$ 为空。图 9.10显示出 DBSCAN 先后生成聚类簇的情况.

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180629/Dl8iB4jEHE.png?imageslim">
</p>

$C_1$ 之后生成的聚类簇为


$$
C_{2}=\left\{\boldsymbol{x}_{3}, \boldsymbol{x}_{4}, \boldsymbol{x}_{5}, \boldsymbol{x}_{9}, \boldsymbol{x}_{13}, \boldsymbol{x}_{14}, \boldsymbol{x}_{16}, \boldsymbol{x}_{17}, \boldsymbol{x}_{21}\right\}
$$
$$
C_{3}=\left\{\boldsymbol{x}_{1}, \boldsymbol{x}_{2}, \boldsymbol{x}_{22}, \boldsymbol{x}_{26}, \boldsymbol{x}_{29}\right\}
$$
$$
C_{4}=\left\{\boldsymbol{x}_{24}, \boldsymbol{x}_{25}, \boldsymbol{x}_{27}, \boldsymbol{x}_{28}, \boldsymbol{x}_{30}\right\}
$$





The DBSCAN 算法将聚类视为被低密度区域分隔的高密度区域。由于这个相当普遍的观点， DBSCAN发现的聚类可以是任何形状的，与假设聚类是 convex shaped 的 K-means 相反。 DBSCAN 的核心概念是 core samples, 是指位于高密度区域的样本。 因此一个聚类是一组核心样本，每个核心样本彼此靠近（通过一定距离度量测量） 和一组接近核心样本的非核心样本（但本身不是核心样本）。算法中的两个参数, min_samples 和 eps，正式的定义了我们所说的 dense（稠密）。较高的 min_samples 或者较低的 eps表示形成聚类所需的较高密度。

更正式的，我们定义核心样本是指数据集中的一个样本，存在 min_samples 个其他样本在 eps 距离范围内，这些样本被定为为核心样本的邻居 neighbors 。这告诉我们核心样本在向量空间稠密的区域。 一个聚类是一个核心样本的集合，可以通过递归来构建，选取一个核心样本，查找它所有的 neighbors （邻居样本） 中的核心样本，然后查找 their （新获取的核心样本）的 neighbors （邻居样本）中的核心样本，递归这个过程。 聚类中还具有一组非核心样本，它们是集群中核心样本的邻居的样本，但本身并不是核心样本。 显然，这些样本位于聚类的边缘。

根据定义，任何核心样本都是聚类的一部分，任何不是核心样本并且和任意一个核心样本距离都大于 eps 的样本将被视为异常值。
