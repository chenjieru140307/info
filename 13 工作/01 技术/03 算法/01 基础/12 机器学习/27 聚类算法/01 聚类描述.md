# 聚类

作用：

- 按照某个特定标准把一个数据集分割成不同的类或簇，使得：
  - 同一个簇内的数据对象的相似性尽可能大
  - 不在同一个簇中的数据对象的差异性也尽可能地大。
- 即聚类后同一类的数据尽可能聚集到一起，不同类数据尽量分离。

应用：

- 可以对用户观看视频的行为进行据类：
  - 比如从喜欢观看内容的角度，可以分为动画片、偶像剧、科幻片等；
  - 从常使用的设备角度，可以分为台式电脑、手机、平板便携式设备、电视等；
  - 从使用时间段上看，有傍晚、中午、每天、只在周末观看的用户，等等。
  - 对所有用户进行有效的分组对于理解用户并推荐给用户合适的内容是很重要的。


处理的数据：

- 通常这类问题没有观测数据的标签或者分组信息，需要通过算法模型来寻求数据内在的结构和模式。


聚类描述：

- 假定样本集 $D=\left\{\boldsymbol{x}_{1}, \boldsymbol{x}_{2}, \ldots, \boldsymbol{x}_{m}\right\}$  包含 $m$ 个无标记样本，每个样本 $\boldsymbol{x}_{i}=\left(x_{i 1} ; x_{i 2} ; \ldots ; x_{i n}\right)$  是一个 $n$ 维特征向量。
- 则聚类算法将样本集 $D$ 划分为 $k$ 个不相交的簇 $\left\{C_{l} | l=1,2 ; \ldots, k\right\}$ ，其中 $C_{l^{\prime}} \cap_{l^{\prime} \neq l} C_{l}=\varnothing$ 且 $D=\bigcup_{l=1}^{k} C_{l}$ 。
- 相应地，我们用 $\lambda_{j} \in\{1,2, \ldots, k\}$ 表示样本 $\boldsymbol{x}_{j}$ 的“簇标记” (cluster label)，即 $\boldsymbol{x}_{j} \in C_{\lambda_{j}}$ 。于是，聚类的结果可用包含 $m$ 个元素的簇标记 $\boldsymbol{\lambda}=\left(\lambda_{1} ; \lambda_{2} ; \ldots ; \lambda_{m}\right)$ 表示。

聚类的使用：

- 聚类既能作为一个单独过程，用于找寻数据内在的分布结构。
- 也可作为分类等其他学习任务的前驱过程。
  - 例如，在一些商业应用中需对新用户的类型进行判别，但定义“用户类型”对商家来说却可能不太容易，此时往往可先对用户数据进行聚类，根据聚类结果将每个簇定义为一个类，然后再基于这些类训练分类模型，用于判别新用户的类型。

主要内容：

- 先讨论聚类算法涉及的两个基本问题：性能度量和距离计算。
- 基于不同的学习策略，人们设计出的多种类型的聚类算法。





关于聚类的问题：

- 聚类问题本身是病态的。
  - 这是说没有单一的标准去度量聚类的数据在真实世界中效果如何。
  - 我们可以度量聚类的性质，例如类中元素到类中心点的欧几里得距离的均值。这使我们可以判断从聚类分配中重建训练数据的效果如何。然而我们不知道聚类的性质是否很好地对应到真实世界的性质。
  - 此外，可能有许多不同的聚类都能很好地对应到现实世界的某些属性。我们可能希望找到和一个特征相关的聚类，但是得到了一个和任务无关的，同样是合理的不同聚类。
    - 例如，
      - 假设我们在包含红色卡车图片、红色汽车图片、灰色卡车图片和灰色汽车图片的数据集上运行两个聚类算法。
      - 如果每个聚类算法聚两类，那么可能一个算法将汽车和卡车各聚一类，另一个根据红色和灰色各聚一类。
      - 假设我们还运行了第 3 个聚类算法，用来决定类别的数目。
      - 这有可能聚成了 4 类，红色卡车、红色汽车、灰色卡车和灰色汽车。
      - 现在这个新的聚类至少抓住了属性的信息，但是丢失了相似性信息。红色汽车和灰色汽车在不同的类中，正如红色汽车和灰色卡车也在不同的类中。
      - 该聚类算法没有告诉我们灰色汽车和红色汽车的相似度比灰色卡车和红色汽车的相似度更高。我们只知道它们是不同的。
  - 这些问题说明了一些我们可能更偏好于分布式表示(相对于 one-hot表示而言)的原因。分布式表示可以对每个车辆赋予两个属性 ，一个表示它的颜色，一个表示它是汽车还是卡车。
    - 目前仍然不清楚什么是最优的分布式表示(学习算法如何知道我们关心的两个属性是颜色和是否汽车或卡车，而不是制造商和车龄？)，但是多个属性减少了算法去猜我们关心哪一个属性的负担，允许我们通过比较很多属性而非测试一个单一属性来细粒度地度量相似性。
