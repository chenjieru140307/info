
# 衡量聚类算法优劣



衡量聚类算法的标准：

- 算法的处理能力：
  - 处理大的数据集的能力（即算法复杂度）；
  - 处理数据噪声的能力；
  - 处理任意形状，包括有间隙的嵌套的数据的能力；
- 算法是否需要预设条件：
  - 是否需要预先知道聚类个数，
  - 是否需要用户给出领域知识；
- 算法的数据输入属性：
  - 算法处理的结果与数据输入的顺序是否相关，也就是说算法是否独立于数据输入顺序；
  - 算法处理有很多属性数据的能力，也就是对数据维数是否敏感，对数据的类型有无要求。





## 以聚类问题为例，假设没有外部标签数据，如何评估两个聚类算法的优劣？



为了评估不同聚类算法的性能优劣，我们需要了解常见的数据簇的特点。

- 以中心定义的数据簇：
  - 这类数据集合倾向于球形分布，通常中心被定义为质心，即此数据簇中所有点的平均值。集合中的数据到中心的距离相比到其他簇中心的距离更近。
- 以密度定义的数据簇：
  - 这类数据集合呈现和周围数据簇明显不同的密度，或稠密或稀疏。当数据簇不规则或互相盘绕，并且有噪声和离群点时，常常使用基于密度的簇定义。
- 以连通定义的数据簇：
  - 这类数据集合中的数据点和数据点之间有连接关系，整个数据簇表现为图结构。该定义对不规则形状或者缠绕的数据簇有效。
- 以概念定义的数据簇：
  - 这类数据集合中的所有数据点具有某种共同性质。

评估：

- 由于数据以及需求的多样性，没有一种算法能够适用于所有的数据类型、数据簇或应用场景，似乎每种情况都可能需要一种不同的评估方法或度量标准。
  - 例如： K均值聚类可以用误差平方和来评估，但是基于密度的数据簇可能不是球形，误差平方和则会失效。
- 在许多情况下，判断聚类算法结果的好坏强烈依赖于主观解释。尽管如此，聚类算法的评估还是必需的，它是聚类分析中十分重要的部分之一。
- 聚类评估的任务是估计在数据集上进行聚类的可行性，以及聚类方法产生结果的质量。这一过程又分为三个子任务。
  - 估计聚类趋势
  - 判定数据簇数
  - 测定聚类质量


估计聚类趋势：

- 这一步骤是检测数据分布中是否存在非随机的簇结构。如果数据是基本随机的，那么聚类的结果也是毫无意义的。
- 我们可以观察聚类误差是否随聚类类别数量的增加而单调变化。
  - 如果数据是基本随机的，即不存在非随机簇结构，那么聚类误差随聚类类别数量增加而变化的幅度应该较不显著，并且也找不到一个合适的 K 对应数据的真实簇数。
- 另外，我们也可以应用霍普金斯统计量（Hopkins Statistic）来判断数据在空间上的随机性。
  - 首先，从所有样本中随机找 n 个点，记为 p1，p2，……，pn，对其中的每一个点 pi，都在样本空间中找到一个离它最近的点并计算它们之间的距离 xi，从而得到距离向量 x1，x2，……，xn；
  - 然后，从样本的可能取值范围内随机生成 n 个点，记为 $q_1,q_2,...,q_n$，对每个随机生成的点，找到一个离它最近的样本点并计算它们之间的距离，得到 y1，y2，……，yn。
  - 霍普金斯统计量 H 可以表示为：

    $$H=\frac{\sum_{i=1}^{n}y_i}{\sum_{i=1}^{n}x_i+\sum_{i=1}^{n}y_i}$$
  - 说明：
    - 如果样本接近随机分布，那么 $\sum_{i=1}^{n}x_i$ 和 $\sum_{i=1}^{n}y_i$ 的取值应该比较接近，即 $H$ 的值接近于 $0.5$ ；
    - 如果聚类趋势明显，则随机生成的样本点距离应该远大于实际样本点的距离，即 $\sum_{i=1}^{n}y_i >> \sum_{i=1}^{n}x_i$ ，$H$ 的值接近于 $1$。

判定数据簇数：

- 确定聚类趋势之后，我们需要找到与真实数据分布最为吻合的簇数，据此判定聚类结果的质量。
- 数据簇数的判定方法有很多，例如手肘法和 Gap Statistic 方法。
  - 需要说明的是，用于评估的最佳数据簇数可能与程序输出的簇数是不同的。
    - 例如，有些聚类算法可以自动地确定数据的簇数，但可能与我们通过其他方法确定的最优数据簇数有所差别。


测定聚类质量：

- 给定预设的簇数，不同的聚类算法将输出不同的结果，如何判定哪个聚类结果的质量更高呢？
  - 在无监督的情况下，我们可以通过考察簇的分离情况和簇的紧凑情况来评估聚类的效果。
  - 定义评估指标可以展现实际解决和分析问题的能力。事实上测量指标可以有很多种，以下列出了几种常用的度量指标，更多的指标可以阅读相关文献。
- 轮廓系数
  - 给定一个点 p，该点的轮廓系数定义为:

    $$s(p)=\frac{b(p)-a(p)}{max\{a(p),b(p)\}} \tag{5.16}$$

  - 其中：
    - $a(p)$ 是点 p 与同一簇中的其他点 $p'$ 之间的平均距离
    - b（p）是点 p 与另一个不同簇中的点之间的最小平均距离（如果有 n 个其他簇，则只计算和点 p 最接近的一簇中的点与该点的平均距离）。
    - a（p）反映的是 p 所属簇中数据的紧凑程度，
    - b（p）反映的是该簇与其他临近簇的分离程度。
  - 显然，b（p）越大，a（p）越小，对应的聚类质量越好，因此我们将所有点对应的轮廓系数 s（p）求平均值来度量聚类结果的质量。

- 均方根标准偏差 Root-mean-square standard deviation，RMSSTD
  - 均方根标准偏差可以用来衡量聚结果的同质性，即紧凑程度，定义为：

    $$RMSSTD=\left\{\frac{\sum_i\sum_{x\in C_i}||x-c_i||^2}{P\sum_i(n_i-1)}\right\}^{\frac{1}{2}} \tag{5.17}$$
  - 其中
    - $C_i$ 代表第 $i$ 个簇，$c_i$ 是该簇的中心，
    - $x\in C_i$ 代表属于第 $i$ 个簇的一个样本点，
    - $n_i$ 为第 $i$ 个簇的样本数量，
    - $P$ 为样本点对应的向量维数。
  - 可以看出，分母对点的维度 $P$ 做了惩罚，维度越高，则整体的平方距离度量值越大。
  - $\sum_{i}(n_i-1)=n-NC$ ，其中 $n$ 为样本点的总数，$NC$ 为聚类簇的个数，通常 $NC<<n$ ，因此 $\sum_i (n_i-1)$ 的值接近点的总数，为一个常数。
  - 综上，RMSSTD 可以看作是经过归一化的标准差。
- R方（R-Square）
  - R方可以用来衡量聚类的差异度，定义为：

    $$RS=\frac{\sum_{x\in D}||x-c||^2-\sum_i\sum_{x\in C_i}||x-c_i||^2}{\sum_{x\in D}||x-c||^2} \tag{5.18}$$

  - 其中
    - $D$ 代表整个数据集，
    - $c$ 代表数据集 $D$ 的中心点，
    - $\sum_{x\in D}||x-c||^2$ 代表将数据集 $D$ 看作单一簇时的平方误差和。
  - 与上一指标 RMSSTD 中的定义相同，$\sum_i\sum_{x\in C_i}||x-c_i||^2$ 代表将数据集聚类之后的平方误差和，所以 RS 代表了聚类之后的结果与聚类之前相比，对应的平方误差和指标的改进幅度。
- 改进的 HubertΓ 统计
  - 改进的 HubertΓ统计：通过数据对的不一致性来评估聚类的差异。
  - 定义为：
    $$\Gamma=\frac{2}{n(n-1)}\sum_{x\in D}\sum_{y\in D}d(x,y)d_{x\in C_i,y\in C_j}(c_i,c_j) \tag{5.19}$$
  - 其中
    - $d(x,y)$ 表示点 $x$ 到点 $y$ 之间的距离，
    - $d_{x\in C_i,y\in C_j}(c_i,c_j)$ 代表点 $x$ 所在的簇中心 $c_i$ 与点 $y$ 所在的簇中心 $c_j$ 之间的距离， 
    - $\frac{n(n-1)}{2}$ 为所有 $(x,y)$ 点对的个数，因此指标相当于对每个点对的和做了归一化处理。<span style="color:red;">嗯，是的。</span>
  - 理想情况下，对于每个点对 $(x,y)$，
    - 如果 $d(x,y)$ 越小，对应的 $d_{x\in C_i,y\in C_j}(c_i,c_j)$ 也应该越小（特别地，当它们属于同一个聚类类簇时， $d_{x\in C_i,y\in C_j}(c_i,c_j)=0$ ）；
    - 当 $d(x,y)$ 越大时， $d_{x\in C_i,y\in C_j}(c_i,c_j)$ 的取值也应当越大，
    - 所以 $Γ$ 值越大说明聚类的结果与样本的原始距离越吻合，也就是聚类质量越高。(为什么这个值越大说明聚类与样本的原始距离越吻合？这个式子的说明是明白了，但是这句结论没大明白。再补充下。)
- 此外，为了更加合理地评估不同聚类算法的性能，通常还需要人为地构造不同类型的数据集，以观察聚类算法在这些数据集上的效果，
  - 几个常见的例子如图所示。
    - 观察聚类误差是否随聚类类别数量的增加而单调变化：
    <p align="center">
        <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190405/8VRtc6t0Dx7c.png?imageslim">
    </p>

    - 观察聚类误差对实际聚类结果的影响：
    <p align="center">
        <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190405/DeGglJJnDNBh.png?imageslim">
    </p>

    - 观察近邻数据簇的聚类准确性：
    <p align="center">
        <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190405/YFHK08c74wa0.png?imageslim">
    </p>

    - 观察数据密度具有较大差异的数据簇的聚类效果：
    <p align="center">
        <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190405/wxqE3r4tTuC6.png?imageslim">
    </p>

    - 样本数量具有较大差异的数据簇的聚类效果：
    <p align="center">
        <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190405/x97EmAXSMFmF.png?imageslim">
    </p>

