


# 决策树中缺失值的处理



对于样本：

| 编号    | 色泽  | 根蒂 | 敲声      | 纹理 | 脐部 | 触感 | 好瓜 |
| ------- | ----- | ---- | --------- | ---- | ---- | ---- | ---- |
| 1   | -  | 蜷缩 | 浊响      | 清晰 | 凹陷 | 硬滑 | 是   |
| 2   | 乌黑  | 蜷缩 | 沉闷      | 清晰 | 凹陷 | - | 是   |
| 3   | 乌黑  | 蜷缩 | -      | 清晰 | 凹陷 | 硬滑 | 是   |
| 4   | 青绿  | 蜷缩 | 沉闷      | 清晰 | 凹陷 | 硬滑 | 是   |
| 5   | -  | 蜷缩 | 浊响      | 清晰 | 凹陷 | 硬滑 | 是   |
| 6   | 青绿  | 稍蜷 | 浊响      | 清晰 | - | 软粘 | 是   |
| 7   | 乌黑  | 稍蜷 | 浊响      | 稍糊 | 稍凹 | 软粘 | 是   |
| 8 | 乌黑  | 稍蜷 | 浊响 | - | 稍凹 | 硬滑 | 是   |
| 9   | 乌黑  | - | 沉闷      | 稍糊 | 稍凹 | 硬滑 | 否   |
| 10  | 青绿  | 硬挺 | 清脆      | - | 平坦 | 软粘 | 否   |
| 11  | 浅白  | 硬挺 | 清脆      | 模糊 | 平坦 | - | 否   |
| 12  | 浅白  | 蜷缩 | -      | 模糊 | 平坦 | 软粘 | 否   |
| 13  | -  | 稍蜷 | 浊响      | 稍糊 | 凹陷 | 硬滑 | 否   |
| 14  | 浅白  | 稍蜷 | 沉闷      | 稍糊 | 凹陷 | 硬滑 | 否   |
| 15  | 乌黑  | 稍蜷 | 浊响      | 清晰 | - | 软粘 | 否   |
| 16  | 浅白 | 蜷缩 | 浊响      | 模糊 | 平坦 | 硬滑 | 否   |
| 17  | 青绿  | - | 沉闷     | 稍糊 | 稍凹 | 硬滑 | 否   |


处理：

- 如果放弃不完整样本，则仅有编号 {4, 7, 14, 16} 的 4 个样本能被使用。




我们需解决两个问题：

1. 如何在属性值缺失的情况下进行划分属性选择?
2. 给定划分属性，若样本在该属性上的值缺失，如何对样本进行划分？



处理：

- 给定训练集 $D$ 和属性 $a$ ，
- 令 $\tilde{D}$ 表示 $D$ 中在属性 $a$ 上没有缺失值的样本子集。
- 对问题(1)，显然我们仅可根据 $\tilde{D}$ 来判断属性 $a$ 的优劣。
- 假定属性 $a$ 有 $V$ 个可取值 $\{a^1,a^2,\cdots ,a^V\}$ 。
- 令 $\tilde{D}^v$ 表示  $\tilde{D}$  中在属性 $a$ 上取值为 $a^v$ 的样本子集，$\tilde{D}_k$ 表示 $\tilde{D}$ 中属于第 $k$ 类 $(k=1,2,\cdots,|\mathcal{Y}|)$ 的样本子集，
- 则显然有 $\tilde{D}=\bigcup_{k=1}^{|\mathcal{Y}|}\tilde{D}_k$ ,$\tilde{D}=\bigcup_{v=1}^{|\mathcal{V}|}\tilde{D}_v$ 。 
- 假定我们为每个样本 $x$ 赋予一个权重 $w_x$ ，并定义


$$
\rho=\frac{\sum_{\boldsymbol{x} \in \tilde{D}} w_{\boldsymbol{x}}}{\sum_{\boldsymbol{x} \in D} w_{\boldsymbol{x}}}\tag{4.9}
$$
$$
\tilde{p}_{k}=\frac{\sum_{\boldsymbol{x} \in \tilde{D}_{k}} w_{\boldsymbol{x}}}{\sum_{\boldsymbol{x} \in \tilde{D}} w_{\boldsymbol{x}}} \quad(1 \leqslant k \leqslant|\mathcal{Y}|)\tag{4.10}
$$
$$
\tilde{r}_{v}=\frac{\sum_{\boldsymbol{x} \in \tilde{D}^{v}} w_{\boldsymbol{x}}}{\sum_{\boldsymbol{x} \in \tilde{D}} w_{\boldsymbol{x}}} \quad(1 \leqslant v \leqslant V)\tag{4.11}
$$

直观地看，对属性 a，$\rho$ 表示无缺失值样本所占的比例，$\tilde{p}_k$ 表示无缺失值样本中第 k 类所占的比例，$\tilde{r}_v$ 则表示无缺失值样本中在属性 a 上取值 $a^v$ 的样本所占的比例。显然，$\sum_{k=1}^{|\mathcal{Y}|}\tilde{p}_k=1$ ,$\sum_{v=1}^{V}\tilde{r}_v=1$ 。

基于上述定义，我们可将信息增益的计算式(4.2)推广为

$$
\begin{aligned} \operatorname{Gain}(D, a) &=\rho \times \operatorname{Gain}(\tilde{D}, a) \\ &=\rho \times\left(\operatorname{Ent}(\tilde{D})-\sum_{v=1}^{V} \tilde{r}_{v} \operatorname{Ent}\left(\tilde{D}^{v}\right)\right) \end{aligned}\tag{4.12}
$$

其中由式(4.1)，有

$$
\operatorname{Ent}(\tilde{D})=-\sum_{k=1}^{ | \mathcal{Y |}} \tilde{p}_{k} \log _{2} \tilde{p}_{k}
$$

对问题(2)，若样本 $\boldsymbol{x}$ 在划分属性 $a$ 上的取值已知，则将 $\boldsymbol{x}$ 划入与其取值对 应的子结点，且样本权值在子结点中保持为 $w_\boldsymbol{x}$ 。若样本 $\boldsymbol{x}$ 在划分属性 a 上的取值未知，则将 $\boldsymbol{x}$ 同时划入所有子结点，且样本权值在与属性值 $a^v$ 对应的子结点中调整为 $\tilde{r}_v\cdot w_x$ ；直观地看，这就是让同一个样本以不同的概率划入到不同的子结点中去.

C4.5算法使用了上述解决方案[Quinlan, 1993]。下面我们以表 4.4的数据集为例来生成一棵决策树.

在学习开始时，根结点包含样本集 D 中全部 17 个样例，各样例的权值均为 1.以属性“色泽”为例，该属性上无缺失值的样例子集 $\tilde{D}$ 乃包含编号为 {2,3,4,6,7,8,9,10,11，12,14,15,16,17} 的 14 个样例。显然，$\tilde{D}$ 的信息熵为

$$
\begin{aligned} \operatorname{Ent}(\tilde{D}) &=-\sum_{k=1}^{2} \tilde{p}_{k} \log _{2} \tilde{p}_{k} \\ &=-\left(\frac{6}{14} \log _{2} \frac{6}{14}+\frac{8}{14} \log _{2} \frac{8}{14}\right)=0.985 \end{aligned}
$$

令 $\tilde{D}^1$ ，$\tilde{D}^2$ 与 $\tilde{D}^3$ 分别表示在属性“色泽”上取值为“青绿” “乌黑”以及“浅白”的样本子集，有

$$
\operatorname{Ent}\left(\tilde{D}^{1}\right)=-\left(\frac{2}{4} \log _{2} \frac{2}{4}+\frac{2}{4} \log _{2} \frac{2}{4}\right)=1.000
$$

$$
\operatorname{Ent}\left(\tilde{D}^{2}\right)=-\left(\frac{4}{6} \log _{2} \frac{4}{6}+\frac{2}{6} \log _{2} \frac{2}{6}\right)=0.918
$$
$$
\operatorname{Ent}\left(\tilde{D}^{3}\right)=-\left(\frac{0}{4} \log _{2} \frac{0}{4}+\frac{4}{4} \log _{2} \frac{4}{4}\right)=0.000
$$

因此，样本子集 $\tilde{D}$ 上属性 “色泽” 的信息増益为

$$
\begin{aligned} \operatorname{Gain}(\tilde{D}, 色泽) &=\operatorname{Ent}(\tilde{D})-\sum_{v=1}^{3} \tilde{r}_{v} \operatorname{Ent}\left(\tilde{D}^{v}\right) \\ &=0.985-\left(\frac{4}{14} \times 1.000+\frac{6}{14} \times 0.918+\frac{4}{14} \times 0.000\right) \\ &=0.306 \end{aligned}
$$

于是，样本集 D 上属性 “色泽” 的信息增益为：


$$
\begin{aligned}
\operatorname{Gain}(\tilde{D}，色泽)&=\rho \times \operatorname(Gain)(\tilde{D}，色泽)\\&=\frac{14}{17} \times 0.306=0.252
\end{aligned}
$$

类似地可计算出所有属性在 D 上的信息增益：

- Gain（D，色泽）=0.252; Gain（D，根蒂）=0.171;
- Gain（D，敲声）=0.145; Gain（D，纹理）=0.424;
- Gain（D，脐部）=0.289; Gain（D，触感）=0.006;

“纹理” 在所有属性中取得了最大的信息增益，被用于对根结点进行划分. 划分结果是使编号为 {1,2,3,4,5,6,15} 的样本进入“纹理=清晰”分支，编号为 {7,9,13,14,17} 的样本进入 “纹理=稍糊” 分支，而编号为 {11,12,16} 的样 本进入 “纹理=模糊” 分支，且样本在各子结点中的权重保持为 1。需注意的 是，编号为 {8} 的样本在属性 “纹理” 上出现了缺失值，因此它将同时进入三个分支中，但权重在三个子结点中分别调整为 $\frac{7}{15}$、$\frac{5}{15}$ 和 $\frac{3}{15}$ 编号为 {10} 的样本有类似划分结果。

上述结点划分过程递归执行，最终生成的决策树如图 4.9所示.

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180626/HeJ1B0dgBb.png?imageslim">
</p>


