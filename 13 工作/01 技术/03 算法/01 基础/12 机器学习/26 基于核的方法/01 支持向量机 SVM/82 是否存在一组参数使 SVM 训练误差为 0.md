

## 是否存在一组参数使 SVM 训练误差为 0？

一个使用高斯核 $(K(x,z)=e-||x-z||^{2/\tau^2})$ 训练的 SVM 中，试证明若给定训练集中不存在两个点在同一位置，则存在一组参数 $\{\alpha_1,......,\alpha_m,b\}$ 以及参数 $\gamma$ 使得该 SVM 的训练误差为 0。


根据 SVM 的原理，我们可以将 SVM 的预测公式可写为：

$$f(x)=\sum_{i=1}^{m}\alpha_iy^{(i)}K(x^{(i)},x)+b \tag{3.8}$$

其中 $((x^{(1)},y^{(1)}),...,(x^{(m)},y^{(m)}))$ 为训练样本，而 $\{\alpha_1,......,\alpha_m,b\}$ 以及高斯核参数 $\gamma$ 为训练样本的参数。由于不存在两个点在同一位置，因此对于任意的 $i\neq j$，有 $x^{(i)}-x^{(i)}\geq \epsilon$ 。我们可以对任意 $i$，固定 $\alpha_i=1$ 以及 $b=0$，只保留参数 $\gamma$ ，则有：



$$
\begin{aligned} f(x) &=\sum_{i=1}^{m} \alpha_{i} y^{(i)} K\left(x^{(i)}, x\right)+b \\ &=\sum_{i=1}^{m} y^{(i)} K\left(x^{(i)}, x\right) \\ &=\sum_{i=1}^{m} y^{(i)} \mathrm{e}^{-\left\|x-x^{(i)}\right\|^{2} / \gamma^{2}} \end{aligned}\tag{3.9}
$$

将任意 $x^{(j)}$ 代入式（3.9）则有：

$$f(x^{(j)})=\sum_{i=1}^{m}y^{(i)}e^{-||x^{(j)}-x^{(i)}||^{2}/\gamma^2}
\tag{3.10}$$


$$f(x^{(j)})-y^{(j)}=\sum_{i=1,i\neq j}^{m}y^{(i)}e^{-||x^{(j)}-x^{(i)}||^{2}/\gamma^2} \tag{3.11}$$

$$||f(x^{(j)})-y^{(j)}||\leq \sum_{i=1,i\neq j}^{m}y^{(i)}e^{-||x^{(j)}-x^{(i)}||^{2}/\gamma^2} \tag{3.12}$$


由题意知 $||x^{(i)}-x^{(i)}||\geq \epsilon$ ，取 $\gamma=\varepsilon / \sqrt{\log m}$，可将式（3.12）重写为


$$
\begin{aligned}\left\|f\left(x^{(j)}\right)-y^{(j)}\right\| & \leqslant\left\|\sum_{i=1, i \neq j}^{m} \mathrm{e}^{-| | x^{(j)}-x^{(i)}||^{2} / \gamma^{2}}\right\| \\ & \leqslant\left\|\sum_{i=1, i \neq j}^{m} \mathrm{e}^{-\mathrm{logm}}\right\|=\frac{m-1}{m}<1 \end{aligned}\tag{3.13}
$$

所以，对于任意 $x^{(j)}$，预测结果 $f(x^{(j)})$ 与样本真实标签 $y^{(j)}$ 的距离小于 $1$。

注意到， $y^{(j)}\in \{1,-1\}$ ，当训练样本为正例，即 $y^{(j)}=1$ 时，预测结果 $f(x^{(j)})>0$ ，样本被预测为正例；而当训练样本为负例，即  $y^{(j)}=-1$ 时，预测结果 $f(x^{(j)})<0$ ，样本被预测为负例。

因此所有样本的类别都被正确预测，训练误差为 0。

<span style="color:red;">厉害呀，虽然看的似懂非懂，但是感觉还是有些厉害，要弄清楚。</span>








## 相关

- 《百面机器学习》
