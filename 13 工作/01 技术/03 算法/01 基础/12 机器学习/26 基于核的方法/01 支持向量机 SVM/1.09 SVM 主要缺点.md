

### 2.18.10 SVM 主要缺点

- SVM算法对大规模训练样本难以实施
	- SVM的空间消耗主要是存储训练样本和核矩阵，由于 SVM 是借助二次规划来求解支持向量，而求解二次规划将涉及 $m$ 阶矩阵的计算（$m$ 为样本的个数），当 $m$ 数目很大时该矩阵的存储和计算将耗费大量的机器内存和运算时间。
	- 如果数据量很大，SVM的训练时间就会比较长，如垃圾邮件的分类检测，没有使用 SVM 分类器，而是使用简单的朴素贝叶斯分类器，或者是使用逻辑回归模型分类。<span style="color:red;">什么是朴素贝叶斯分类器？</span>
- 用 SVM 解决多分类问题存在困难
	- 经典的支持向量机算法只给出了二类分类的算法，而在实际应用中，一般要解决多类的分类问题。可以通过多个二类支持向量机的组合来解决。主要有一对多组合模式、一对一组合模式和 SVM 决策树；再就是通过构造多个分类器的组合来解决。主要原理是克服 SVM 固有的缺点，结合其他算法的优势，解决多类问题的分类精度。如：与粗糙集理论结合，形成一种优势互补的多类问题的组合分类器。<span style="color:red;">这些思想还是要掌握的，比如 SVM 决策树、粗糙集理论等。</span>
- 对缺失数据敏感，对参数和核函数的选择敏感
	- 支持向量机性能的优劣主要取决于核函数的选取，所以对于一个实际问题而言，如何根据实际的数据模型选择合适的核函数从而构造 SVM 算法。目前比较成熟的核函数及其参数的选择都是人为的，根据经验来选取的，带有一定的随意性。在不同的问题领域，核函数应当具有不同的形式和参数，所以在选取时候应该将领域知识引入进来，但是目前还没有好的方法来解决核函数的选取问题。<span style="color:red;">现在有什么好的方法可以进行核函数的选择吗？</span>
