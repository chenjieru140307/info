

# 核方法


- 回顾式 $\begin{aligned} f(\boldsymbol{x}) &=\boldsymbol{w}^{\mathrm{T}} \phi(\boldsymbol{x})+b \\ &=\sum_{i=1}^{m} \alpha_{i} y_{i} \phi\left(\boldsymbol{x}_{i}\right)^{\mathrm{T}} \phi(\boldsymbol{x})+b \\ &=\sum_{i=1}^{m} \alpha_{i} y_{i} \kappa\left(\boldsymbol{x}, \boldsymbol{x}_{i}\right)+b \end{aligned}$ 和 $f(\boldsymbol{x})=\sum_{i=1}^{m}\left(\hat{\alpha}_{i}-\alpha_{i}\right) \kappa\left(\boldsymbol{x}, \boldsymbol{x}_{i}\right)+b$ 可发现
- 给定训练样本 $\left\{\left(\boldsymbol{x}_{1}, y_{1}\right),\left(\boldsymbol{x}_{2}, y_{2}\right), \ldots\right.\left(\boldsymbol{x}_{m}, y_{m}\right) \}$  ，若不考虑偏移项 $b$，则无论 SVM 还是 SVR，学得的模型总能表示成核函数 $\kappa\left(\boldsymbol{x}, \boldsymbol{x}_{i}\right)$ 的线性组合。

不仅如此，事实上我们有下面这个称为“表示定理”(representor theorem)的更一般的结论：

表示定理：

- 令 $\mathbb{H}$ 为核函数 $\kappa$ 对应的再生核希尔伯特空间，$||h||_{\mathbb{H} }$  表示 $\mathbb{H}$ 空间中关于 $h$ 的范数，对于任意单调递増函数 $\Omega :[0, \infty] \mapsto \mathbb{R}$ 和任意非负损失函数 $\ell : \mathbb{R}^{m} \mapsto[0, \infty]$ ，优化问题：

$$
\min _{h \in \mathbb{H}} F(h)=\Omega\left(\|h\|_{\mathbb{H}}\right)+\ell\left(h\left(\boldsymbol{x}_{1}\right), h\left(\boldsymbol{x}_{2}\right), \ldots, h\left(\boldsymbol{x}_{m}\right)\right)\tag{6.57}
$$

- 的解总可写为：

$$
h^{*}(\boldsymbol{x})=\sum_{i=1}^{m} \alpha_{i} \kappa\left(\boldsymbol{x}, \boldsymbol{x}_{i}\right)\tag{6.58}
$$

说明：

- 表示定理对损失函数没有限制，对正则化项仅要求单调递增，甚至不要求是凸函数，意味着对于一般的损失函数和正则化项，优化问题(6.57)的最优解 $h*(x)$ 都可表示为核函数 $\kappa(x,x_i)$ 的线性组合；这显示出核函数的巨大威力。

核方法：

- 人们发展出一系列基于核函数的学习方法，统称为“核方法” (kernel methods)。
- 最常见的，是通过“核化”(即引入核函数)来将线性学习器拓展为非线性学习器。


举例：

- 以线性判别分析为例来演示如何通过核化来对其进行非线性拓展，从而得到 “核线性判别分析” (Kernelized Linear Discriminant Analysis，简称 KLDA)。

过程：

- 先假设可通过某种映射 $\phi:\mathcal{X}\mapsto \mathbb{F}$ 将样本映射到一个特征空间 $\mathbb{F}$ ，然后在 $\mathbb{F}$ 中执行线性判别分析，以求得

$$
h(\boldsymbol{x})=\boldsymbol{w}^{\mathrm{T}} \phi(\boldsymbol{x})\tag{6.59}
$$


- 类似于 $J=\frac{\boldsymbol{w}^{\mathrm{T}} \mathbf{S}_{b} \boldsymbol{w}}{\boldsymbol{w}^{\mathrm{T}} \mathbf{S}_{w} \boldsymbol{w}}$ ，KLDA的学习目标是：

$$
\max _{\boldsymbol{w}} J(\boldsymbol{w})=\frac{\boldsymbol{w}^{\mathrm{T}} \mathbf{S}_{b}^{\phi} \boldsymbol{w}}{\boldsymbol{w}^{\mathrm{T}} \mathbf{S}_{w}^{\phi} \boldsymbol{w}}\tag{6.60}
$$

- 其中：
  - $S_b^\phi$ 和 $S_w^\phi$ 分别为训练样本在特征空间 $\mathbb{F}$ 中的类间散度矩阵和类内散度矩阵。
- 令 $X_i$ 表示第 $i\in \{0,1\}$ 类样本的集合，其样本数为 $m_i$ ；总样本数 $m=m_0+m_1$ 。
- 则第 $i$ 类样本在特征空间 $\mathbb{F}$ 中的均值为


$$
\boldsymbol{\mu}_{i}^{\phi}=\frac{1}{m_{i}} \sum_{\boldsymbol{x} \in X_{i}} \phi(\boldsymbol{x})\tag{6.61}
$$

- 两个散度矩阵分别为

$$
\mathbf{S}_{b}^{\phi}=\left(\boldsymbol{\mu}_{1}^{\phi}-\boldsymbol{\mu}_{0}^{\phi}\right)\left(\boldsymbol{\mu}_{1}^{\phi}-\boldsymbol{\mu}_{0}^{\phi}\right)^{\mathrm{T}}\tag{6.62}
$$

$$
\mathbf{S}_{w}^{\phi}=\sum_{i=0}^{1} \sum_{\boldsymbol{x} \in X_{i}}\left(\phi(\boldsymbol{x})-\boldsymbol{\mu}_{i}^{\phi}\right)\left(\phi(\boldsymbol{x})-\boldsymbol{\mu}_{i}^{\phi}\right)^{\mathbf{T}}\tag{6.63}
$$

- 通常我们难以知道映射 $\phi$ 的具体形式，因此使用核函数 $\kappa(x,x_i)=\phi(x_i)^T\phi(x)$ 来隐式地表达这个映射和特征空间 $\mathbb{F}$ 。
- 把 $J(w)$ 作为式(6.57)中的损失函数 $\ell$ ，再令 $\Omega \equiv 0$ ，由表示定理，函数 $h(x)$ 可写为


$$
h(\boldsymbol{x})=\sum_{i=1}^{m} \alpha_{i} \kappa\left(\boldsymbol{x}, \boldsymbol{x}_{i}\right)\tag{6.64}
$$


- 于是由式(6.59)可得

$$
\boldsymbol{w}=\sum_{i=1}^{m} \alpha_{i} \phi\left(\boldsymbol{x}_{i}\right)\tag{6.65}
$$

- 令 $K\in\mathbb{R}^{m\times m}$ 为核函数 $\kappa$ 所对应的核矩阵，$(K)_{ij}=\kappa(x_i,y_i)$。令 $l_i\in \{1,0\}^{m\times 1}$ 为第 i 类样本的指示向量，即 $l_i$ 的第 j 个分量为 1 当且仅当 $x_j\in X_i$ ，否则 $l_i$ 的第 j 个分量为 0 。再令：

$$
\hat{\mu}_{0}=\frac{1}{m_{0}} \mathbf{K} \mathbf{1}_{0}\tag{6.66}
$$
$$
\hat{\boldsymbol{\mu}}_{1}=\frac{1}{m_{1}} \mathbf{K} \mathbf{1}_{1}\tag{6.67}
$$
$$
\mathbf{M}=\left(\hat{\boldsymbol{\mu}}_{0}-\hat{\boldsymbol{\mu}}_{1}\right)\left(\hat{\boldsymbol{\mu}}_{0}-\hat{\boldsymbol{\mu}}_{1}\right)^{\mathrm{T}}\tag{6.68}
$$
$$
\mathbf{N}=\mathbf{K} \mathbf{K}^{\mathrm{T}}-\sum_{i=0}^{1} m_{i} \hat{\boldsymbol{\mu}}_{i} \hat{\boldsymbol{\mu}}_{i}^{\mathrm{T}}\tag{6.69}
$$

- 于是，式(6.60)等价为

$$
\max _{\boldsymbol{\alpha}} J(\boldsymbol{\alpha})=\frac{\boldsymbol{\alpha}^{\mathrm{T}} \mathbf{M} \boldsymbol{\alpha}}{\boldsymbol{\alpha}^{\mathrm{T}} \mathbf{N} \boldsymbol{\alpha}}\tag{6.70}
$$

- 显然，使用线性判别分析求解方法即可得到 $\alpha$ ，进而可由式 (6.64) 得到投影函数 $h(x)$ .


