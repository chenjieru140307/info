# 为什么需要学习 cuda 编程

假如你在一家做音乐的公司上班，你的工作就是每天对新发行的音乐进行鉴赏并打分，你可能会想到让 AI 来代替你做这件事情。目前来看确实可以用大量的音乐去训练 AI，让其以更加符合流行风格与群众口味的状态来给新的音乐打分，这显然比你根据自己的经验与喜好打分要公平的多，最重要的是，如果你有个老板并不知道的 AI 助手帮你做事，你就可以去玩了！

当然，要训练这样的 AI 助手有多种办法。

1、其中最简单的办法就是使用已经训练好的 AI 模型或知名模型，在 Tensorflow 等系统中导入数据进行训练，并改善结果。
2、另一种比较复杂的方法可以是完全从零开始自己设计算法与训练过程。其实在严格意义上，第一种方法仅仅是在“使用”AI，而第二种方法才是“AI开发”。

这里我们强调 CUDA 编程技能，实际上只是对很纯粹的 AI 开发者而言，例如 AlphaGo 的开发人员。

## CPU与 GPU

CUDA编程是一种依赖于 CPU 与 GPU 的编程方式，在异构计算架构中，GPU与 CPU 通过 PCIe 总线连接在一起来协同工作，这兄弟俩总结起来就一句话：CPU负责处理逻辑复杂的串行程序，而 GPU 重点处理数据密集型的并行计算程序。所以我们常用的 Tensorflow, Pytorch等深度学习系统都使用 CUDA 编写了许多代码（并行计算版本），这些代码也有不使用 CUDA 的原始版本（纯 CPU 版本）。

还是用图来说明这两者的工作方式吧，纯 CPU 版本的程序，使用 CPU 来处理数据，从左至右依次完成文件审阅。

而使用并行计算的程序，使用 GPU 来处理数据，多个任务被同时完成（矩阵）：

## 并行计算

那么什么是并行计算呢？当我们 CPU 的每个核心都在全力工作时，称为满负荷，但通常像矩阵计算这样的计算过程并不会把核心占满，假如每个核心每次计算一个乘法或加法，那么大量的时间就会浪费在下一个乘法或加法的入站过程，所以 CPU 常常受到时间魔咒的影响。

如果我们把 CPU 的每个核心看成一头公牛，他们很厉害，通常 CPU 也就有两头、四头、八头、十六头公牛等。而 GPU 的核心相比 CPU 的核心要弱的多，我们可以认为是小鸡，但是 GPU 胜在核心数量多，过千的小鸡数量妥妥的。这时如果任务是吃完 1 吨小米，显然成千上万的小鸡比十六头公牛更有优势。如果说 AI 开发人员推荐掌握 CUDA 编程，不如说 AI 开发人员推荐掌握并行计算的编程方法，这可以让程序与数据的结合更加高效。

![mark](http://images.iterate.site/blog/image/20190819/DHrSR60oVMpR.png?imageslim)

## CUDA 编程

CUDA 是 NVIDIA 开发的 GPU 编程模型，它提供了 GPU 编程的简易接口，基于 CUDA 编程可以构建基于 GPU 计算的应用程序。CUDA提供了对其它编程语言的支持，如 C/c++，python，Fortran等语言。更多资源可以关注 CUDA 官方文档。
