# 预训练


方法：

- 一种是浅层加载的参数在训练 C 任务过程中不动，这种方法被称为“Frozen”
- 另外一种是底层网络参数尽管被初始化了，在 C 任务训练过程中仍然随着训练的进程不断改变，这种一般叫“Fine-Tuning”，顾名思义，就是更好地把参数进行调整使得更适应当前的 C 任务。


## 优点

- 首先，如果手头任务 C 的训练集合数据量较少的话，现阶段的好用的 CNN 比如 Resnet/Densenet/Inception等网络结构层数很深，几百万上千万参数量算起步价，上亿参数的也很常见，训练数据少很难很好地训练这么复杂的网络，但是如果其中大量参数通过大的训练集合比如 ImageNet 预先训练好直接拿来初始化大部分网络结构参数，然后再用 C 任务手头比较可怜的数据量上 Fine-tuning过程去调整参数让它们更适合解决 C 任务，那事情就好办多了。这样原先训练不了的任务就能解决了。
- 即使手头任务训练数据也不少，加个预训练过程也能极大加快任务训练的收敛速度。


## 为什么可行



<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190926/Ws4QjMPX36f0.png?imageslim">
</p>

- CNN，层级结构
- 底层特征可复用
- 高层特征任务相关


因此，**预训练好的网络参数，尤其是底层的网络参数抽取出特征跟具体任务越无关，越具备任务的通用性**。

所以这是为何一般用底层预训练好的参数初始化新任务网络参数的原因。而高层特征跟任务关联较大，实际可以不用使用，或者采用 Fine-tuning用新数据集合清洗掉高层无关的特征抽取器。

## 一般用来做预训练的数据集


一般用 ImageNet。优点：

- 一方面 ImageNet 是图像领域里有超多事先标注好训练数据的数据集合，分量足是个很大的优势，量越大训练出的参数越靠谱；
- 另外一方面因为 ImageNet 有 1000 类，类别多，算是通用的图像数据，跟领域没太大关系，所以通用性好，预训练完后哪哪都能用，是个万金油。分量足的万金油当然老少通吃，人人喜爱。
