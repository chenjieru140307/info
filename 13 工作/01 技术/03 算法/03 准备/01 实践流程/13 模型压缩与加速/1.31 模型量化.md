
# 模型量化

模型量化是指权重或激活输出可以被聚类到一些离散、低精度（reduced precision）的数值点上，通常依赖于特定算法库或硬件平台的支持：

- 二值化网络：XNORnet [13], ABCnet with Multiple Binary Bases [14], Bin-net with High-Order Residual Quantization [15], Bi-Real Net [16]；
- 三值化网络：Ternary weight networks [17], Trained Ternary Quantization [18]；
- W1-A8 或 W2-A8量化： Learning Symmetric Quantization [19]；
- INT8量化：TensorFlow-lite [20], TensorRT [21], Quantization Interval Learning [25]；
- 其他（非线性）：Intel INQ [22], log-net, CNNPack [23] 等；



若模型压缩之后，推理精度存在较大损失，可以通过 fine-tuning予以恢复，并在训练过程中结合适当的 Tricks，例如 Label Smoothing、Mix-up、Knowledge Distillation、Focal Loss等。

此外，模型压缩、优化加速策略可以联合使用，进而可获得更为极致的压缩比与加速比。例如结合 Network Slimming与 TensorRT int8优化，在 1080ti Pascal平台上，Resnet101-v1d在压缩比为 1.4倍时（Size=170MB->121MB，FLOPS=16.14G->11.01G），经 TensorRT int8量化之后，推理耗时仅为 7.4ms（Batch size=8）。






# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
