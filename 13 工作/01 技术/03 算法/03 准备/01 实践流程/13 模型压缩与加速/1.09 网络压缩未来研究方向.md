

### 17.4.9 网络压缩未来研究方向有哪些？

网络剪枝、网络精馏和网络分解都能在一定程度上实现网络压缩的目的。回归到深度网络压缩的本质目的上，即提取网络中的有用信息，以下是一些值得研究和探寻的方向.
(1) 权重参数对结果的影响度量。深度网络的最终结果是由全部的权重参数共同作用形成的，目前，关于单个卷积核/卷积核权重的重要性的度量仍然是比较简单的方式，尽管文献[14]中给出了更为细节的分析，但是由于计算难度大，并不实用。因此，如何通过更有效的方式来近似度量单个参数对模型的影响，具有重要意义.
(2) 学生网络结构的构造。学生网络的结构构造目前仍然是由人工指定的，然而，不同的学生网络结构的训练难度不同，最终能够达到的效果也有差异。因此，如何根据教师网络结构设计合理的网络结构在精简模型的条件下获取较高的模型性能，是未来的一个研究重点.
(3) 参数重建的硬件架构支持。通过分解网络可以无损地获取压缩模型，在一些对性能要求高的场景中是非常重要的。然而，参数的重建步骤会拖累预测阶段的时间开销，如何通过硬件的支持加速这一重建过程，将是未来的一个研究方向.
(4) 任务或使用场景层面的压缩。大型网络通常是在量级较大的数据集上训练完成的，比如，在 ImageNet上训练的模型具备对 1 000 类物体的分类，但在一些具体场景的应用中，可能仅需要一个能识别其中几类的小型模型。因此，如何从一个全功能的网络压缩得到部分功能的子网络，能够适应很多实际应用场景的需求.
(5) 网络压缩效用的评价。目前，对各类深度网络压缩算法的评价是比较零碎的，侧重于和被压缩的大型网络在参数量和运行时间上的比较。未来的研究可以从提出更加泛化的压缩评价标准出发，一方面平衡运行速度和模型大小在不同应用场景下的影响；另一方面，可以从模型本身的结构性出发，对压缩后的模型进行评价.

（出自《深度网络模型压缩综述》）
