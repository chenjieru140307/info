


# 压缩和加速方法如何选择？

- 对于在线计算内存存储有限的应用场景或设备，可以选择参数共享和参数剪枝方法，特别是二值量化权值和激活、结构化剪枝．其他方法虽然能够有效的压缩模型中的权值参数，但无法减小计算中隐藏的内存大小（如特征图）．
- 如果在应用中用到的紧性模型需要利用预训练模型，那么参数剪枝、参数共享以及低秩分解将成为首要考虑的方法．相反地，若不需要借助预训练模型，则可以考虑紧性滤波设计及知识蒸馏方法．
- 若需要一次性端对端训练得到压缩与加速后模型，可以利用基于紧性滤波设计的深度神经网络压缩与加速方法．
- 一般情况下，参数剪枝，特别是非结构化剪枝，能大大压缩模型大小，且不容易丢失分类精度．对于需要稳定的模型分类的应用，非结构化剪枝成为首要选择．
- 若采用的数据集较小时，可以考虑知识蒸馏方法．对于小样本的数据集，学生网络能够很好地迁移教师模型的知识，提高学生网络的判别性．
- 主流的５个深度神经网络压缩与加速算法相互之间是正交的，可以结合不同技术进行进一步的压缩与加速．如：韩松等人结合了参数剪枝和参数共享；温伟等人结合了参数剪枝和低秩分解．此外对于特定的应用场景，如目标检测，可以对卷积层和全连接层使用不同的压缩与加速技术分别处理．
