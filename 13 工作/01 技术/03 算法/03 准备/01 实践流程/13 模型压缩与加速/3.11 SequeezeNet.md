
# SequeezeNet



SqueenzeNet出自 F. N. Iandola, S.Han等人发表的论文《SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and < 0.5MB model size》，作者在保证精度不损失的同时，将原始 AlexNet 压缩至原来的 510 倍。


## 设计思想


在网络结构设计方面主要采取以下三种方式：
* 用 1\*1卷积核替换 3\*3卷积
    * 理论上一个 1\*1卷积核的参数是一个 3\*3卷积核的 1/9，可以将模型尺寸压缩 9 倍。
* 减小 3\*3卷积的输入通道数
    * 根据上述公式，减少输入通道数不仅可以减少卷积的运算量，而且输入通道数与输出通道数相同时还可以减少 MAC。
* 延迟降采样
    * 分辨率越大的输入能够提供更多特征的信息，有利于网络的训练判断，延迟降采样可以提高网络精度。
## 网络架构
SqueezeNet提出一种多分支结构——fire model，其中是由 Squeeze 层和 expand 层构成。Squeeze层是由 s1 个 1\*1卷积组成，主要是通过 1\*1的卷积降低 expand 层的输入维度；expand层利用 e1 个 1\*1和 e3 个 3\*3卷积构成多分支结构提取输入特征，以此提高网络的精度(其中 e1=e3=4*s1)。
<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/plRPBFOTGvCu.png?imageslim">
</p>

SqueezeNet整体网络结构如下图所示：
<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/BMSTuJFWGftD.png?imageslim">
</p>


## 实验结果

不同压缩方法在 ImageNet 上的对比实验结果

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/eUgXHoDkzlEf.png?imageslim">
</p>

由实验结果可知，SqueezeNet不仅保证了精度，而且将原始 AlexNet 从 240M 压缩至 4.8M，压缩 50 倍，说明此轻量级网络设计是可行。








# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
