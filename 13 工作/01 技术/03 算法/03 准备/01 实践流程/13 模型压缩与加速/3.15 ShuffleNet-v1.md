---
title: 3.15 ShuffleNet-v1
toc: true
date: 2019-08-31
---

### 17.9.5 ShuffleNet-v1
ShuffleNet 是 Face++团队提出的，晚于 MobileNet 两个月在 arXiv 上公开《ShuffleNet： An Extremely Efficient Convolutional Neural Network for Mobile Devices 》用于移动端前向部署的网络架构。ShuffleNet基于 MobileNet 的 group 思想，将卷积操作限制到特定的输入通道。而与之不同的是，ShuffleNet将输入的 group 进行打散，从而保证每个卷积核的感受野能够分散到不同 group 的输入中，增加了模型的学习能力。
#### 5.1 设计思想
* 采用 group conv减少大量参数
    * roup conv与 DW conv存在相同的“信息流通不畅”问题
* 采用 channel shuffle解决上述问题
    * MobileNet中采用 PW conv解决上述问题，SheffleNet中采用 channel shuffle
* 采用 concat 替换 add 操作
    * avg pooling和 DW conv(s=2)会减小 feature map的分辨率，采用 concat 增加通道数从而弥补分辨率减小而带来信息的损失

#### 5.2 网络架构
MobileNet中 1\*1卷积的操作占据了约 95%的计算量，所以作者将 1\*1也更改为 group 卷积，使得相比 MobileNet 的计算量大大减少。
<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/UNuK8p5vxLiN.png?imageslim">
</p>

group卷积与 DW 存在同样使“通道信息交流不畅”的问题，MobileNet中采用 PW conv解决上述问题，SheffleNet中采用 channel shuffle。
ShuffleNet的 shuffle 操作如图所示
<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/g8fe7TxskW9r.png?imageslim">
</p>

avg pooling和 DW conv(s=2)会减小 feature map的分辨率，采用 concat 增加通道数从而弥补分辨率减小而带来信息的损失；实验表明：多多使用通道(提升通道的使用率)，有助于提高小模型的准确率。
<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/uQVCFksL6byd.png?imageslim">
</p>

网络结构：
<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190722/hk9qw297z1P3.png?imageslim">
</p>








# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
