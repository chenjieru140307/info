
# 模型选择


准备好 Feature 以后，就可以开始选用一些常见的模型进行训练了。Kaggle 上最常用的模型基本都是基于树的模型：

- **Gradient Boosting**
- Random Forest
- Extra Randomized Trees

以下模型往往在性能上稍逊一筹，但是很适合作为 Ensemble 的 Base Model。这一点之后再详细解释。（当然，在跟图像有关的比赛中神经网络的重要性还是不能小觑的。）

- SVM
- Linear Regression
- Logistic Regression
- Neural Networks

以上这些模型基本都可以通过 **sklearn** 来使用。

当然，这里不能不提一下 **Xgboost**。**Gradient Boosting** 本身优秀的性能加上 **Xgboost** 高效的实现，使得它在 Kaggle 上广为使用。几乎每场比赛的获奖者都会用 **Xgboost** 作为最终 Model 的重要组成部分。在实战中，我们往往会以 Xgboost 为主来建立我们的模型并且验证 Feature 的有效性。顺带一提，**在 Windows 上安装** Xgboost **很容易遇到问题，目前已知最简单、成功率最高的方案可以参考我在这篇帖子中的描述**。
