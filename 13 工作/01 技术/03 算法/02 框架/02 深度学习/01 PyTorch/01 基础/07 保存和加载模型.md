# 保存和加载模型

序列化和恢复模型有两种主要方法。

- 第一种：只保存和加载模型参数。
- 第二种：保存和加载整个模型。

## 第一种：只保存和加载模型参数。


```py
torch.save(the_model.state_dict(), PATH)

the_model = TheModelClass(*args, **kwargs)
the_model.load_state_dict(torch.load(PATH))
```

## 第二种：保存和加载整个模型。

```py
torch.save(the_model, PATH)

the_model = torch.load(PATH)
```

说明：

- 这个还是有用的，比如，用 c++ 来加载 python 训练出来的模型，这样就直接把权重包括模型本身加载进来了，就不用再使用 c++ 再重新搭建模型，嗯，挺好的。

<span style="color:red;">不知道这种类型一般在那种情况下使用，还是要详细总结下的，上面这个只是一个猜测。</span>

