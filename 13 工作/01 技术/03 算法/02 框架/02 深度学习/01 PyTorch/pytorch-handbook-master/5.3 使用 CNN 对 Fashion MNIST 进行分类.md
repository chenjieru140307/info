

# 使用 CNN 对 Fashion MNIST 进行分类

Fashion MNIST 数据集：

- 包含10个类别的70000个灰度图像。这些图片显示的是每件衣服的低分辨率(28×28像素)

地址：

- [数据集的下载](https://www.kaggle.com/zalando-research/fashionmnist/)
- [百度网盘地址](https://pan.baidu.com/s/1czRoqPzDOf-_M9_TvNou6Q) 提取码：dcr4

数据格式：

- label 是分类的标签
- pixel1-pixel784 是每一个像素代表的值 因为是灰度图像，所以是一个0-255之间的数值。 28 * 28 = 784
- ubyte 文件标识了数据的格式，其中 idx3 的数字表示数据维度。也就是图像为3维，idx1 标签维1维。


举例：

```py
import struct
import torch
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
import torch.nn as NN

# 查看数据
DATA_PATH = Path('C://Users/wanfa/Desktop/fashionmnist/')
train = pd.read_csv(DATA_PATH / "fashion-mnist_train.csv")
print(train.head(10))
test = pd.read_csv(DATA_PATH / "fashion-mnist_test.csv")
print(test.head(10))
print(train.max())

with open(DATA_PATH / "train-images-idx3-ubyte", 'rb') as file_object:
    header_data = struct.unpack(">4I", file_object.read(16))
    print(header_data)

with open(DATA_PATH / "train-labels-idx1-ubyte", 'rb') as file_object:
    header_data = struct.unpack(">2I", file_object.read(8))
    print(header_data)

with open(DATA_PATH / "train-images-idx3-ubyte", 'rb') as file_object:
    raw_img = file_object.read(28 * 28)
    img = struct.unpack(">784B", raw_img)
    image = np.asarray(img)
    image = image.reshape((28, 28))
    print(image.shape)
    plt.imshow(image, cmap=plt.cm.gray)
    plt.show()

with open(DATA_PATH / "train-labels-idx1-ubyte", 'rb') as file_object:
    raw_img = file_object.read(1)
    label = struct.unpack(">B", raw_img)
    print(label)



# 建立 Dataset
class FashionMNISTDataset(Dataset):
    def __init__(self, csv_file, transform=None):
        data = pd.read_csv(csv_file)
        self.X = np.array(data.iloc[:, 1:]).reshape(-1, 1, 28, 28).astype(float)
        self.Y = np.array(data.iloc[:, 0]);
        del data;  # 结束data对数据的引用,节省空间
        self.len = len(self.X)

    def __len__(self):
        # return len(self.X)
        return self.len

    def __getitem__(self, idx):
        item = self.X[idx]
        label = self.Y[idx]
        return (item, label)

train_dataset = FashionMNISTDataset(csv_file=DATA_PATH / "fashion-mnist_train.csv")
test_dataset = FashionMNISTDataset(csv_file=DATA_PATH / "fashion-mnist_test.csv")

# 超参数
DEVICE = torch.device("cpu")
if torch.cuda.is_available():
    DEVICE = torch.device("cuda")
print(DEVICE)
BATCH_SIZE = 256
LEARNING_RATE = 0.01
TOTAL_EPOCHS = 50

train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=BATCH_SIZE,
                                           shuffle=True)
test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                          batch_size=BATCH_SIZE,
                                          shuffle=False)

# 查看一下数据
a = iter(train_loader)
data = next(a)
img = data[0][0].reshape(28, 28)
print(data[0][0].shape, img.shape)
plt.imshow(img, cmap=plt.cm.gray)
plt.show()


# 三层的简单的CNN网络
class CNN(NN.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.layer1 = NN.Sequential(
            NN.Conv2d(1, 16, kernel_size=5, padding=2),
            NN.BatchNorm2d(16),
            NN.ReLU())  # 16, 28, 28
        self.pool1 = NN.MaxPool2d(2)  # 16, 14, 14
        self.layer2 = NN.Sequential(
            NN.Conv2d(16, 32, kernel_size=3),
            NN.BatchNorm2d(32),
            NN.ReLU())  # 32, 12, 12
        self.layer3 = NN.Sequential(
            NN.Conv2d(32, 64, kernel_size=3),
            NN.BatchNorm2d(64),
            NN.ReLU())  # 64, 10, 10
        self.pool2 = NN.MaxPool2d(2)  # 64, 5, 5
        self.fc = NN.Linear(5 * 5 * 64, 10)

    def forward(self, x):
        out = self.layer1(x)
        # print(out.shape)
        out = self.pool1(out)
        # print(out.shape)
        out = self.layer2(out)
        # print(out.shape)
        out = self.layer3(out)
        # print(out.shape)
        out = self.pool2(out)
        # print(out.shape)
        out = out.view(out.size(0), -1)
        # print(out.shape)
        out = self.fc(out)
        return out


cnn = CNN()
# 可以通过以下方式验证，没报错说明没问题，
cnn(torch.rand(1, 1, 28, 28))
# 打印下网络，做最后的确认
print(cnn)

# 先把网络放到gpu上
cnn = cnn.to(DEVICE)

# 损失函数也需要放到GPU中
criterion = NN.CrossEntropyLoss().to(DEVICE)
# 优化器不需要放GPU
optimizer = torch.optim.Adam(cnn.parameters(), lr=LEARNING_RATE)

# 记录损失函数
losses = []
for epoch in range(TOTAL_EPOCHS):
    for i, (images, labels) in enumerate(train_loader):
        images = images.float().to(DEVICE)
        labels = labels.to(DEVICE)
        # 清零
        optimizer.zero_grad()
        outputs = cnn(images)
        # 计算损失函数
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        losses.append(loss.cpu().data.item())
        if (i + 1) % 100 == 0:
            print('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' % (
                epoch + 1, TOTAL_EPOCHS, i + 1, len(train_dataset) // BATCH_SIZE, loss.data.item()))

# 可视化损失函数
plt.xkcd()
plt.xlabel('Epoch #')
plt.ylabel('Loss')
plt.plot(losses)
plt.show()

# 保存模型
torch.save(cnn.state_dict(), "fm-cnn3.pth")
# cnn.load_state_dict(torch.load("fm-cnn3.pth")) # 加载用这个

# 模型评估
cnn.eval()
correct = 0
total = 0
for images, labels in test_loader:
    images = images.float().to(DEVICE)
    outputs = cnn(images).cpu()
    _, predicted = torch.max(outputs.data, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum()
print('准确率: %.4f %%' % (100 * correct / total))
```

输出：

```txt
   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784
0      2       0       0       0  ...         0         0         0         0
1      9       0       0       0  ...         0         0         0         0
2      6       0       0       0  ...         0         0         0         0
3      0       0       0       0  ...         0         0         0         0
4      3       0       0       0  ...         0         0         0         0
5      4       0       0       0  ...         5         0         0         0
6      4       0       0       0  ...         0         0         0         0
7      5       0       0       0  ...         0         0         0         0
8      4       0       0       0  ...         0         0         0         0
9      8       0       0       0  ...         0         0         0         0

[10 rows x 785 columns]
   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784
0      0       0       0       0  ...         0         0         0         0
1      1       0       0       0  ...         0         0         0         0
2      2       0       0       0  ...        31         0         0         0
3      2       0       0       0  ...       222        56         0         0
4      3       0       0       0  ...         0         0         0         0
5      2       0       0       0  ...         0         0         0         0
6      8       0       0       0  ...         0         0         0         0
7      6       0       0       0  ...         0         0         0         0
8      5       0       0       0  ...         0         0         0         0
9      0       0       0       0  ...         0         0         0         0

[10 rows x 785 columns]
label         9
pixel1       16
pixel2       36
pixel3      226
pixel4      164
           ... 
pixel780    255
pixel781    255
pixel782    255
pixel783    255
pixel784    170
Length: 785, dtype: int64
(2051, 60000, 28, 28)
(2049, 60000)
(28, 28)
(0,)
cuda
torch.Size([1, 28, 28]) torch.Size([28, 28])
CNN(
  (layer1): Sequential(
    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (layer2): Sequential(
    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (layer3): Sequential(
    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (fc): Linear(in_features=1600, out_features=10, bias=True)
)
Epoch : 1/50, Iter : 100/234,  Loss: 0.5016
Epoch : 1/50, Iter : 200/234,  Loss: 0.4076
...略...
Epoch : 50/50, Iter : 100/234,  Loss: 0.0423
Epoch : 50/50, Iter : 200/234,  Loss: 0.0390
准确率: 91.0000 %
```

图像：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200524/B1pM7UaiTG1c.png?imageslim">
</p>

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200524/SCEVWxLbqbwT.png?imageslim">
</p>

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200524/2DzdzmOqO6Li.png?imageslim">
</p>



说明：

- 多分类因为使用Softmax回归将神经网络前向传播得到的结果变成概率分布 所以使用交叉熵损失。
- 模型评估的步骤如下：
  1. 将网络的模式改为eval。
  2. 将图片输入到网络中得到输出。
  3. 通过取出one-hot输出的最大值来得到输出的 标签。
  4. 统计正确的预测值。

- Adam优化器的使用一般情况下是首先使用0.1进行预热，然后再用0.01进行大批次的训练，最后使用0.001这个学习率进行收尾，再小的学习率一般情况就不需要了。
- 介绍一下几个超参数:
  - `BATCH_SIZE`: 批次数量，定义每次训练时多少数据作为一批，这个批次需要在dataloader初始化时进行设置，并且需要这对模型和显存进行配置，如果出现OOM有线减小，一般设为2的倍数
  - `DEVICE`：进行计算的设备，主要是CPU还是GPU
  - `LEARNING_RATE`：学习率，反向传播时使用
  - `TOTAL_EPOCHS`：训练的批次，一般情况下会根据损失和准确率等阈值

