
## Torch.nn

Torch.nn 包里面包含了如何定义 Module 神经网络模型，各种 Functional 函数以及如何通过 Optim 实现各种优化算法。Module 是神经网络的基本组成部分，作为一个抽象类，可以通过定义成员函数实现不同的神经网络结构。

Functional 包括 Convolution 函数、Pooling 函数、非线性激活函数、Normalization函数、线性函数、Dropout函数、距离函数（Distance functions）、损失函数（Loss functions）等。

Optim 包含了各种优化算法，Momentum算法、NesterovMomentum算法、AdaGrad算法、RMSProp算法、Adam（Adaptive Moment Estimation）算法等，我们可以根据神经网络模型的需求选择合适的优化算法。

## 我们先来看看如何定义神经网络模型的架构



我们先来看看如何定义神经网络模型的架构。

```py
from torch import autograd
import torch.nn as nn
import torch.nn.functional as F
import torch


class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x1 = F.relu(self.conv1(x))
        x2 = F.relu(self.conv2(x1))
        return x2


m = nn.Conv1d(16, 33, 3, stride=2)
inputs = autograd.Variable(torch.randn(20, 16, 50))
output = m(inputs)
print(output)

m = nn.MaxPool1d(3, stride=2)
input = autograd.Variable(torch.randn(20, 16, 50))
output = m(input)
print(output)
```

输出：

```
tensor([[[ 0.1236,  0.2449,  0.3994,  ...,  0.1510, -0.1974,  0.8267],
         [-0.1522,  0.2074,  0.8476,  ...,  0.6513,  0.6508,  0.4559],
         [-0.0128,  0.7039,  0.2138,  ...,  1.2886,  0.1088,  0.3225],
         ...,
         [-0.3567, -0.0725, -0.1031,  ...,  0.2381, -0.6905, -1.1810],
         [ 0.0642,  0.7130, -0.0990,  ...,  1.0802, -0.1841, -0.6215],
         [-0.2725, -0.6753, -0.7085,  ..., -0.0235, -0.0887,  0.2105]],

        ...,

        [[ 0.6814,  0.4702,  0.2764,  ..., -0.4782, -0.2463,  0.2685],
         [-0.2675, -0.4607, -0.0655,  ...,  1.2515,  0.2431,  1.1982],
         [-0.5187,  0.5073, -0.6547,  ...,  0.5086, -0.2443,  0.8765],
         ...,
         [ 0.2201, -0.1339,  1.1612,  ..., -0.4644,  0.1616, -0.7448],
         [ 0.6162,  0.3758, -0.0604,  ...,  0.7693,  0.0168, -0.0721],
         [ 0.4441, -1.3265, -0.5386,  ..., -0.0463,  0.1088,  0.1608]]],
       grad_fn=<SqueezeBackward1>)
tensor([[[ 1.0129,  0.2220,  0.7168,  ...,  0.7732,  0.1694, -0.5897],
         [ 0.4734,  1.4124, -0.0539,  ...,  1.7507, -0.1575,  0.2386],
         [ 0.9980,  1.1280,  1.1280,  ..., -0.0573, -0.1587,  0.6075],
         ...,
         [ 0.8042,  0.8042, -0.6341,  ..., -1.2106, -0.4443,  1.0243],
         [ 1.4810,  0.1086,  0.1783,  ...,  1.2473,  1.4648,  1.4648],
         [ 1.7875,  1.1158,  2.9751,  ...,  0.0134,  0.0650,  0.5081]],

        ...,

        [[ 1.4090,  0.4197,  0.5057,  ...,  1.1865,  0.8468,  1.0781],
         [ 1.0629,  1.0629, -0.2840,  ...,  0.9020,  2.9856,  2.9856],
         [-0.4402,  1.4463,  1.4463,  ...,  0.5108,  0.7884,  0.4710],
         ...,
         [ 1.4762,  1.0526,  1.0526,  ...,  1.4964,  0.5206,  0.4718],
         [ 1.9082,  1.9082, -0.1724,  ..., -0.7160,  1.0883,  2.1306],
         [-0.0177,  1.8617,  1.8617,  ...,  1.4076,  1.0290,  0.6920]]])
```

简单介绍：

Modules 还可以包含其他模块，允许将它们嵌套在树结构中。可以将子模块分配为常规属性。<span style="color:red;">什么意思？没明白？允许嵌套在树结构中是什么意思？</span>

以 `Model(nn.Module)` 这种方式分配的子模块将被注册，并且在调用 `.cuda()` 等时也会转换参数。<span style="color:red;">是这样吗？</span>

