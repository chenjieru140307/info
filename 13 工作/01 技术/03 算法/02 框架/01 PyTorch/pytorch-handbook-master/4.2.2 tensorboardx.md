
# 可视化 Tensorboard

Tensorboard：

- 是tensorflow内置的一个可视化工具，通过将 tensorflow 程序输出的日志文件的信息可视化使得 tensorflow 程序的理解、调试和优化更加简单高效。
- Tensorboard的可视化依赖于tensorflow程序运行输出的日志文件，因而tensorboard和tensorflow程序在不同的进程中运行。

作用：

- 给我们提供了极其方便而强大的可视化环境。它可以帮助我们理解整个神经网络的学习过程、数据的分布、性能瓶颈等等。

官网：

- [github](https://github.com/lanpa/tensorboardX)


安装tensorboard：

- `pip install tensorboard=2.0`
  - 注：使用 2.0 版本，如果不指定，可能有显示问题。


使用：

- `conda activate xxx` 激活环境
- 使用 `tensorboard --logdir logs` 启动并保持打开，此时，将监听 logs 窗口内的日志文件，当生成日志到 logs 文件夹时，网页刷新。
- 默认的端口是 6006，在浏览器中打开 `http://localhost:6006/` 即可看到web页面。





页面分类：

- SCALAR
  - 对标量数据进行汇总和记录，通常用来可视化训练过程中随着迭代次数准确率(val acc)、损失值(train/test loss)、学习率(learning rate)、每一层的权重和偏置的统计量(mean、std、max/min)等的变化曲线
- IMAGES
  - 可视化当前轮训练使用的训练/测试图片或者 feature maps
- GRAPHS
  - 可视化计算图的结构及计算图上的信息，通常用来展示网络的结构
- HISTOGRAMS
  - 可视化张量的取值分布，记录变量的直方图(统计张量随着迭代轮数的变化情况）
- PROJECTOR
  - 全称Embedding Projector 高维向量进行可视化






举例：

```py
import torch
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
from torchvision import transforms
from torchvision import models, datasets
from torch.utils.tensorboard import SummaryWriter
import torch
import torchvision.utils as vutils
import numpy as np
import torchvision.models as models
from torchvision import datasets
from tensorboardX import SummaryWriter




# 展示图片
cat_img = Image.open('cat.jpg')
print(cat_img.size)
transform_224 = transforms.Compose([
    transforms.Resize(224),  # 这里要说明下 Scale 已经过期了，使用Resize
    transforms.CenterCrop(224),
    transforms.ToTensor(),
])
cat_img_224 = transform_224(cat_img)
writer = SummaryWriter(log_dir='./logs', comment='cat image')  # 这里的logs要与--logdir的参数一样
writer.add_image("cat", cat_img_224)
writer.close()  # 执行 close 立即刷新，否则将每 120 秒自动刷新

# 展示 scalars
x = torch.FloatTensor([100])
y = torch.FloatTensor([500])
for epoch in range(30):
    x = x * 1.2
    y = y / 1.1
    loss = np.random.random()
    with SummaryWriter(log_dir='./logs', comment='train') as writer:  # 可以直接使用python的with语法，自动调用close方法
        writer.add_histogram('his/x', x, epoch)
        writer.add_histogram('his/y', y, epoch)
        writer.add_scalar('data/x', x, epoch)
        writer.add_scalar('data/y', y, epoch)
        writer.add_scalar('data/loss', loss, epoch)
        writer.add_scalars('data/data_group', {'x': x,
                                               'y': y}, epoch)


# 展示 3D 投影

BATCH_SIZE=512
EPOCHS=20
train_loader = torch.utils.data.DataLoader(
        datasets.MNIST('data', train=True, download=True,
                       transform=transforms.Compose([
                           transforms.ToTensor(),
                           transforms.Normalize((0.1307,), (0.3081,))
                       ])),
        batch_size=BATCH_SIZE, shuffle=True)


class ConvNet(nn.Module):
    def __init__(self):
        super().__init__()
        # 1,28x28
        self.conv1=nn.Conv2d(1,10,5) # 10, 24x24
        self.conv2=nn.Conv2d(10,20,3) # 128, 10x10
        self.fc1 = nn.Linear(20*10*10,500)
        self.fc2 = nn.Linear(500,10)
    def forward(self,x):
        in_size = x.size(0)
        out = self.conv1(x) #24
        out = F.relu(out)
        out = F.max_pool2d(out, 2, 2)  #12
        out = self.conv2(out) #10
        out = F.relu(out)
        out = out.view(in_size,-1)
        out = self.fc1(out)
        out = F.relu(out)
        out = self.fc2(out)
        out = F.log_softmax(out,dim=1)
        return out
model = ConvNet()
optimizer = torch.optim.Adam(model.parameters())


def train(model, train_loader, optimizer, epoch):
    n_iter=0
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        optimizer.zero_grad()
        output = model(data)
        loss = F.nll_loss(output, target)
        loss.backward()
        optimizer.step()
        if(batch_idx+1)%30 == 0:
            n_iter=n_iter+1
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * len(data), len(train_loader.dataset),
                100. * batch_idx / len(train_loader), loss.item()))
            #相对于以前的训练方法 主要增加了以下内容
            out = torch.cat((output.data, torch.ones(len(output), 1)), 1) # 因为是投影到3D的空间，所以我们只需要3个维度
            with SummaryWriter(log_dir='./logs', comment='mnist') as writer:
                #使用add_embedding方法进行可视化展示
                writer.add_embedding(
                    out,
                    metadata=target.data,
                    label_img=data.data,
                    global_step=n_iter)

train(model, train_loader, optimizer, 0)




# 展示网络
vgg16 = models.vgg16(pretrained=True) # 这里下载预训练好的模型
print(vgg16) # 打印一下这个模型
# 在前向传播前，先要把图片做一些调整
transform_2 = transforms.Compose([
    transforms.Resize(224),
    transforms.CenterCrop((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                std=[0.229, 0.224, 0.225])
])
# 使用上一张猫的图片进行前向传播
vgg16_input=transform_2(cat_img)[np.newaxis] # 因为pytorch的是分批次进行的，所以我们这里建立一个批次为1的数据集
print(vgg16_input.shape)
# 开始前向传播，打印输出值
out = vgg16(vgg16_input)
_, preds = torch.max(out.data, 1)
label=preds.numpy()[0]
print(label)
# 将结构图在tensorboard进行展示
with SummaryWriter(log_dir='./logs', comment='vgg161') as writer:
    writer.add_graph(vgg16, vgg16_input)



# 展示模型
resnet18 = models.resnet18(False)
writer = SummaryWriter(log_dir='./logs', comment='renet')
sample_rate = 44100
freqs = [262, 294, 330, 349, 392, 440, 440, 440, 440, 440, 440]

for n_iter in range(100):

    dummy_s1 = torch.rand(1)
    dummy_s2 = torch.rand(1)
    # data grouping by `slash`
    writer.add_scalar('data/scalar1', dummy_s1[0], n_iter)
    writer.add_scalar('data/scalar2', dummy_s2[0], n_iter)

    writer.add_scalars('data/scalar_group', {'xsinx': n_iter * np.sin(n_iter),
                                             'xcosx': n_iter * np.cos(n_iter),
                                             'arctanx': np.arctan(n_iter)}, n_iter)

    dummy_img = torch.rand(32, 3, 64, 64)  # output from network
    if n_iter % 10 == 0:
        x = vutils.make_grid(dummy_img, normalize=True, scale_each=True)
        writer.add_image('Image', x, n_iter)

        dummy_audio = torch.zeros(sample_rate * 2)
        for i in range(x.size(0)):
            # amplitude of sound should in [-1, 1]
            dummy_audio[i] = np.cos(freqs[n_iter // 10] * np.pi * float(i) / float(sample_rate))
        writer.add_audio('myAudio', dummy_audio, n_iter, sample_rate=sample_rate)

        writer.add_text('Text', 'text logged at step:' + str(n_iter), n_iter)

        for name, param in resnet18.named_parameters():
            writer.add_histogram(name, param.clone().cpu().data.numpy(), n_iter)

        # needs tensorboard 0.4RC or later
        writer.add_pr_curve('xoxo', np.random.randint(2, size=100), np.random.rand(100), n_iter)

dataset = datasets.MNIST('data', train=False, download=True)
images = dataset.data[:100].float()
label = dataset.targets[:100]

features = images.view(100, 784)
writer.add_embedding(features, metadata=label, label_img=images.unsqueeze(1))

# export scalar data to JSON for external processing
writer.export_scalars_to_json("./all_scalars.json")
writer.close()
```

说明：

- 使用前请先确认执行`tensorboard --logdir logs` 并保证 `http://localhost:6006/` 页面能够正常打开
- 浏览器访问 `http://localhost:6006/#images` 即可看到猫的图片 
- 展示 scalars 可以在浏览器访问 `http://localhost:6006/#scalars` 即可看到图形
- 使用PROJECTOR对高维向量可视化。PROJECTOR的的原理是通过PCA，T-SNE等方法将高维向量投影到三维坐标系（降维度）。Embedding Projector从模型运行过程中保存的checkpoint文件中读取数据，默认使用主成分分析法（PCA）将高维数据投影到3D空间中，也可以通过设置设置选择T-SNE投影方法，这里做一个简单的展示。打开 `http://localhost:6006/#projector` 即可看到效果。
  - 目前测试投影这部分也是有问题的，根据官网文档的代码进行测试，也显示不出来，正在找原因
- 绘制网络结构。使用 tensorboard 的GRAPHS 来实现网络结构的可视化。
由于pytorch使用的是动态图计算，所以我们这里要手动进行一次前向的传播.


疑问：

- 为什么使用的时候，tensorboard 网页是一片空白，好像不是路径的问题，是 tensorflow 版本的问题吗？