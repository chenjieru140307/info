# 句法和文法

感觉依存句法和语义依存分析并没有怎么讲。。

## 依存句法和语义依存分析


依存句法分析

- 介绍
  - 依存语法 (Dependency Parsing, DP) 通过分析语言单位内成分之间的依存关系揭示其句法结构。
  - 直观来讲，依存句法分析识别句子中的“主谓宾”、“定状补”这些语法成分，并分析各成分之间的关系。

- 依存句法分析标注关系及含义 (共14种) 
  - 主谓关系 SBV subject-verb 我送她一束花 (我 <– 送)
  - 动宾关系 VOB 直接宾语，verb-object 我送她一束花 (送 –> 花)
  - 间宾关系 IOB 间接宾语，indirect-object 我送她一束花 (送 –> 她)
  - 前置宾语 FOB 前置宾语，fronting-object 他什么乢都读 (乢 <– 读)
  - 兼语 DBL double 他请我吃饭 (请 –> 我)
  - 定中关系 ATT attribute 红苹果 (红 <– 苹果)
  - 状中结构 ADV adverbial 非常美丽 (非常 <– 美丽)
  - 动补结构 CMP complement 做完了作业 (做 –> 完)
  - 并列关系 COO coordinate 大山和大海 (大山 –> 大海)
  - 介宾关系 POB preposition-object 在贸易区内 (在 –> 内)
  - 左附加关系 LAD left adjunct 大山和大海 (和 <– 大海)
  - 右附加关系 RAD right adjunct 孩子们 (孩子 –> 们)
  - 独立结构 IS independent structure 两个单句在结构上彼此独立
  - 核心关系 HED head 指整个句子的核心
  - 标点 WP punctuation (这个算吗？确认下)


语义依存分析 (Semantic Dependency Parsing, SDP)

- 介绍：
  - 分析句子各个语言单位之间的语义关联，并将语义关联以依存结构呈现。
  - 使用语义依存刻画句子语义，好处在于不需要去抽象词汇本身，而是通过词汇所承受的语义框架来描述该词汇，而论元的数目相对词汇来说数量总是少了很多的。
  - 语义依存分析目标是跨越句子表层句法结构的束缚，直接获取深层的语义信息。
    - 举例：
      - 以下三个句子，用不同的表达方式表达了同一个语义信息，即张三实施了一个吃的动作，吃的动作是对苹果实施的。
        <p align="center">
            <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200712/e00JYwcR2QdR.png?imageslim">
        </p>
  - 注意：
    - 语义依存分析不受句法结构的影响，将具有直接语义关联的语言单元直接连接依存弧并标记上相应的语义关系。这也是语义依存分析与句法依存分析的重要区别。
- 语义依存关系 3 类
  - 主要语义角色，每一种语义角色对应存在一个嵌套关系和反关系；
  - 事件关系，描述两个事件间的关系；
  - 语义依附标记，标记说话者语气等依附性信息。
- 语义依存关系：
  - 关系类型  Tag  Description  Example
  - 施事关系  Agt  Agent  我送她一束花 (我 <-- 送)
  - 当事关系  Exp  Experiencer  我跑得快 (跑 --> 我)
  - 感事关系  Aft  Affection  我思念家乡 (思念 --> 我)
  - 领事关系  Poss  Possessor  他有一本好读 (他 <-- 有)
  - 受事关系  Pat  Patient 他打了小明 (打 --> 小明)
  - 客事关系  Cont  Content 他听到鞭炮声 (听 --> 鞭炮声)
  - 成事关系  Prod  Product 他写了本小说 (写 --> 小说)
  - 源事关系  Orig  Origin 我军缴获敌人四辆坦克 (缴获 --> 坦克)
  - 涉事关系  Datv  Dative 他告诉我个秘密 ( 告诉 --> 我 )
  - 比较角色  Comp  Comitative  他成绩比我好 (他 --> 我)
  - 属事角色  Belg  Belongings  老赵有俩女儿 (老赵 <-- 有)
  - 类事角色  Clas  Classification  他是中学生 (是 --> 中学生)
  - 依据角色  Accd  According  本庭依法宣判 (依法 <-- 宣判)
  - 缘故角色  Reas  Reason 他在愁女儿婚事 (愁 --> 婚事)
  - 意图角色  Int  Intention 为了金牌他拼命努力 (金牌 <-- 努力)
  - 结局角色  Cons  Consequence  他跑了满头大汗 (跑 --> 满头大汗)
  - 方式角色  Mann  Manner 球慢慢滚迚空门 (慢慢 <-- 滚)
  - 工具角色  Tool  Tool  她用砂锅熬粥 (砂锅 <-- 熬粥)
  - 材料角色  Malt  Material 她用小米熬粥 (小米 <-- 熬粥)
  - 时间角色  Time  Time  唐朝有个李白 (唐朝 <-- 有)
  - 空间角色  Loc  Location 这房子朝南 (朝 --> 南)
  - 历程角色  Proc  Process  火车正在过长江大桥 (过 --> 大桥)
  - 趋向角色  Dir  Direction 部队奔向南方 (奔 --> 南)
  - 范围角色  Sco  Scope  产品应该比质量 (比 --> 质量)
  - 数量角色  Quan  Quantity 一年有365天 (有 --> 天)
  - 数量数组  Qp  Quantity-phrase  三本乢 (三 --> 本)
  - 频率角色  Freq  Frequency  他每天看乢 (每天 <-- 看)
  - 顺序角色  Seq  Sequence 他跑第一 (跑 --> 第一)
  - 描写角色  Desc(Feat)  Description  他长得胖 (长 --> 胖)
  - 宿主角色  Host  Host  住房面积 (住房 <-- 面积)
  - 名字修饰角色  Nmod  Name-modifier  果戈里大街 (果戈里 <-- 大街)
  - 时间修饰角色  Tmod  Time-modifier  星期一上午 (星期一 <-- 上午)
  - 反角色 r + main role  打篮球的小姑娘 (打篮球 <-- 姑娘)
  - 嵌套角色  d + main role  爷爷看见孙子在跑 (看见 --> 跑)
  - 并列关系  eCoo  event Coordination 我喜欢唱歌和跳舞 (唱歌 --> 跳舞)
  - 选择关系  eSelt  event Selection  您是喝茶还是喝咖啡 (茶 --> 咖啡)
  - 等同关系  eEqu  event Equivalent  他们三个人一起走 (他们 --> 三个人)
  - 先行关系  ePrec  event Precedent  首先，先
  - 顺承关系  eSucc  event Successor  随后，然后
  - 递迚关系  eProg  event Progression 况且，并且
  - 转折关系  eAdvt  event adversative  却，然而
  - 原因关系  eCau  event Cause  因为，既然
  - 结果关系  eResu  event Result  因此，以致
  - 推论关系  eInf  event Inference  才，则
  - 条件关系  eCond  event Condition  只要，除非
  - 假设关系  eSupp  event Supposition 如果，要是
  - 让步关系 eConc  event Concession  纵使，哪怕
  - 手段关系 eMetd  event Method 
  - 目的关系 ePurp  event Purpose  为了，以便
  - 割舍关系 eAban  event Abandonment  不其，也不
  - 选取关系 ePref event Preference 不如，宁愿
  - 总括关系 eSum event Summary 总而言之
  - 分叙关系 eRect event Recount  例如，比方说
  - 连词标记 mConj  Recount Marker 和，或
  - 的字标记 mAuxAuxiliary  的，地，得
  - 介词标记 mPrep  Preposition 把，被
  - 语气标记 mTone  Tone 吗，呢
  - 时间标记  mTime Time  才，曾经
  - 范围标记  mRang Range 都，到处
  - 程度标记  mDegr Degree 很，稍微
  - 频率标记  mFreq Frequency Marker  再，常常
  - 趋向标记  mDir  Direction Marker  上去，下来
  - 揑入语标记  mPars Parenthesis Marker  总的来说，众所周知
  - 否定标记  mNeg Negation Marker  不，没，未
  - 情态标记  mMod Modal Marker 幸亏，会，能
  - 标点标记  mPunc Punctuation Marker  ，。！
  - 重复标记  mPept Repetition Marker  走啊走 (走 --> 走)
  - 多数标记  mMaj Majority Marker  们，等
  - 实词虚化标记 mVain Vain Marker 
  - 离合标记  mSepa Seperation Marker  吃了个饭 (吃 --> 饭) 洗了个澡 (洗 --> 澡)
  - 根节点  Root  Root  全句核心节点



举例：


- 如图
  <p align="center">
      <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200712/N9hukGWl3CkE.png?imageslim">
  </p>
- 说明：
  - 从分析结果中我们可以看到，句子的核心谓词为“提出”，主语是“李克强”，提出的宾语是“支持上海…”，“调研…时”是“提出”的(时间) 状语，“李克强”的修饰语是“国务院总理”，“支持”的宾语是“探索 新机制”。
  - 有了上面的句法分析结果，我们就可以比较容易的看到，“提出者”是“李克强”，而不是“上海”或“外高桥”，即使它们都是名词，而且距离“提出”更近。
  - 依存句法分析的 tag 含义：
    <p align="center">
        <img width="65%" height="70%" src="http://images.iterate.site/blog/image/20200712/lP3RBXlkgV0q.png?imageslim">
    </p>
  - 语义依存分析的 tag 含义：
    <p align="center">
        <img width="80%" height="70%" src="http://images.iterate.site/blog/image/20200712/XH1tOncXnE1u.png?imageslim">
    </p>



## 依存句法树解析（子树遍历，递归搜索，叶子节点提取等）

举例：

提取动名词对，来查看简历中描述的个人的能力。

比如：组织 各类公关
其中，各类 公关在分词的时候是分开的，此处要如何进行合并。



举例：

```py
import re, os, json
from stanfordcorenlp import StanfordCoreNLP
from nltk import Tree, ProbabilisticTree
import nltk, re
import nltk.tree
import nltk.chunk.regexp

stanford_corenlp = StanfordCoreNLP('D:\stanford-corenlp', lang='zh', memory='4g', timeout=1500, quiet=True)  # port=9555

grammer = "NP: {<DT>?<JJ>*<NN>}"
cp = nltk.RegexpParser(grammer)  # 生成规则
pattern = re.compile(u'[^a-zA-Z\u4E00-\u9FA5]')
pattern_del = re.compile('(\a-zA-Z0-9+)')


# 整理文本
def pre_process_text(text):
    table_in = ",?!()"  # 将英文符号替换为中文符号
    table_out = "，？！（）"
    table_delete = " \n<li>< li>+_-.><li \U0010fc01 _"  # 删除文本的噪音
    trans_table = text.maketrans(table_in, table_out, table_delete)
    replaced_text = text.translate(trans_table)
    return replaced_text


# 遍历树，查找动名词对
def get_vp_pair_from_tree(tree):
    if not isinstance(tree, nltk.tree.Tree):
        return []
    vp_pair = []
    stack = []
    stack.append(tree)
    while stack:
        current_tree = stack.pop()
        if isinstance(current_tree, nltk.tree.Tree) and current_tree.label() == "ROOT": # 根节点
            for i in range(len(current_tree)):
                stack.append(current_tree[i])
        if isinstance(current_tree, nltk.tree.Tree) and current_tree.label() == "IP": # 从句
            for i in range(len(current_tree)):
                stack.append(current_tree[i])
        if isinstance(current_tree, nltk.tree.Tree) and current_tree.label() == "VP": # 动词从句
            duplicate = []
            if len(current_tree) >= 2:
                for i in range(1, len(current_tree)):
                    if current_tree[0].label() == 'VV' and current_tree[i].label() == "NP": # VV 动词 NP 名词从句
                        verb = ''.join(current_tree[0].leaves()) # 将动词的叶子动词合并起来
                        noun=[]
                        noun.append(''.join(current_tree[i].leaves())) # 将名词从句合并起来
                        if verb and noun:
                            vp_pair.append((verb, noun))
                            duplicate.append(noun)
                    elif current_tree[0].label() == 'VV' and current_tree[i].label() != "NP":
                        verb = ''.join(current_tree[0].leaves())
                        noun = get_np_chunk_from_tree(current_tree[i]) # 对这个 tree 遍历，将这个 tree 的名词短语都合并起来为  noun
                        if verb and noun and noun not in duplicate: # 如果名词短语不重复
                            vp_pair.append((verb, noun))
                            duplicate.append(noun)
    return vp_pair

# 遍历树，将树中的名词短语合并起来返回
def get_np_chunk_from_tree(tree):
    if not isinstance(tree, nltk.tree.Tree):
        return False
    stack = []
    np = []
    stack.append(tree)
    while stack:
        current_tree = stack.pop()
        if isinstance(current_tree, nltk.tree.Tree) and current_tree.label() == 'VP': # 如果是动词短语，那么略过不看
            continue
        elif isinstance(current_tree, nltk.tree.Tree) and current_tree.label() != 'NP': # 如果不是名词短语，那么继续
            for i in range(len(current_tree)):
                stack.append(current_tree[i])
        elif isinstance(current_tree, nltk.tree.Tree) and current_tree.label() == 'NP': # 如果是名词短语，那么将这几个名词短语合并起来
            noun_chunk = []
            if current_tree.label() == "NP":
                nouns_phase = ''.join(current_tree.leaves())
                noun_chunk.append(nouns_phase)
            np.append(noun_chunk)
    return np


if __name__ == "__main__":
    # 加载文本
    lines = []
    with open('text.txt', "r", encoding="utf8") as f:
        lines=f.readlines()

    # 找到每一行的 vp pair
    for line in lines:
        text = pre_process_text(line)
        if len(text.strip()) > 6:
            parsed_text=stanford_corenlp.parse(text.strip())
            tree = Tree.fromstring(parsed_text)
            vp_pair = get_vp_pair_from_tree(tree)
            print(vp_pair)
    stanford_corenlp.close()
```


输入：

text.txt：

```txt
主要收获：半年市场总监工作经验，成功稳固公司在上海的品牌形象和客户关系，有效
利用各种手段推广公司品牌。
两年半网络广告销售从业及管理经验，成功组建易车网华东区域大客户销售团队，以直客为导向，兼顾渠道。
有丰富的互联网广告知识，同时也有华东区域的所有汽车客户及周边产品的直客关系，及相关的渠道关系。
策划组织公司内部各项活动,落实凝聚力工程;
组织各类公关接待及外联工作;
各类活动的主持及执行等事宜主要收获: 积累了更丰富的策划经验,多次的主持经历让我在语言表达方面有了进一步的提高,不断接触到的不同人群,也让我积累了良好的社会关系,现场的活动执行,更让我在面对突发事件时,有了冷静思考的能力
```

输出：

```txt
[]
[('利用', ['各种手段推广公司品牌'])]
[]
[]
[('落实', ['凝聚力工程'])]
[('组织', ['各类公关'])]
[]
```

说明：


- Tree 内容如下：
  ```txt
  Tree('ROOT', [Tree('IP', [Tree('VP', [Tree('ADJP', [Tree('JJ', ['主要'])]), Tree('IP', [Tree('IP', [Tree('VP', [Tree('NP', [Tree('NP', [Tree('NN', ['收获'])]), Tree('PU', ['：']), Tree('PRN', [Tree('NP', [Tree('QP', [Tree('CD', ['半']), Tree('CLP', [Tree('M', ['年'])])]), Tree('NP', [Tree('NN', ['市场']), Tree('NN', ['总监']), Tree('NN', ['工作']), Tree('NN', ['经验'])])])])]), Tree('PU', ['，']), Tree('ADVP', [Tree('AD', ['成功'])]), Tree('VP', [Tree('VV', ['稳固']), Tree('IP', [Tree('NP', [Tree('NP', [Tree('NN', ['公司'])]), Tree('DNP', [Tree('PP', [Tree('P', ['在']), Tree('NP', [Tree('NR', ['上海'])])]), Tree('DEG', ['的'])]), Tree('NP', [Tree('NN', ['品牌']), Tree('NN', ['形象'])])]), Tree('VP', [Tree('PP', [Tree('CC', ['和']), Tree('NP', [Tree('NN', ['客户'])])]), Tree('VP', [Tree('NN', ['关系'])])])])])])]), Tree('PU', ['，']), Tree('IP', [Tree('VP', [Tree('VA', ['有效'])])])])])])])
  ```
- 可在调试的时候，使用 s.draw() 画出对应的树图：
  <p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200713/4K2ujvl5JtxN.png?imageslim">
    </p>







## 名词短语块挖掘

每个 chunking 都有一个核心词。比如：黄金珠宝营业员。以营业员为核心词，把它们合并起来。

这个在 NLP 中，经常这样合并，因为，如果拆开，意思表达就不是很完整了。

比如，对于 市场 总监 工作 经验，全是 NN，那么怎么把他们合并起来呢？


举例：

```py
import os, json, nltk, re
import os, gc, re, sys
from itertools import chain
import hanlp

huanhang = {'。', '？', '！', '?'}
keep_pos = "q,qg,qt,qv,s,t,tg,g,gb,gbc,gc,gg,gm,gp,mg,Mg,n,an,ude1,nr,ns,nt,nz,nb,nba,nbc,nbp,nf,ng,nh,nhd,o,nz,nx,ntu,nts,nto,nth,ntch,ntcf,ntcb,ntc,nt,nsf,ns,nrj,nrf,nr2,nr1,nr,nnt,nnd,nn,nmc,nm,nl,nit,nis,nic,ni,nhm,nhd"
keep_pos_nouns = set(keep_pos.split(","))
keep_pos_v = "v,vd,vg,vf,vl,vshi,vyou,vx,vi,vn"
keep_pos_v = set(keep_pos_v.split(","))
keep_pos_p = {'p', 'pbei', 'pba'} # 介词 把 被
merge_pos = keep_pos_p | keep_pos_v
keep_flag = {'：', '，', '？', '。', '！', '；', '、', '-', '.', '!', ',', ':', ';', '?', '(', ')', '（', '）', '<', '>', '《',
             '》'}
drop_pos_set = {'xu', 'xx', 'y', 'yg', 'wh', 'wky', 'wkz', 'wp', 'ws', 'wyy', 'wyz', 'wb', 'u', 'ud', 'ude1', 'ude2',
                'ude3', 'udeng', 'udh'}

recognizer = hanlp.load(hanlp.pretrained.ner.MSRA_NER_BERT_BASE_ZH)
tokenizer = hanlp.load('PKU_NAME_MERGED_SIX_MONTHS_CONVSEG')
tagger = hanlp.load(hanlp.pretrained.pos.CTB5_POS_RNN_FASTTEXT_ZH)


def get_token_tag_pair_list(sentence):
    token = tokenizer(sentence)
    tag = tagger(token)
    return list(zip(token, tag))


def get_filtered_tree(pair_list):  # {内/f 训/v 师/ng 单/b 柜/ng}
    """
    input sentences shape like :[('工作', 'vn'), ('描述', 'v'), ('：', 'w'), ('我', 'rr'), ('曾', 'd'), ('在', 'p')]
    """
    grammar = r"""NP: 
        {<m|mg|Mg|mq|q|qg|qt|qv|s|>*<a|an|ag>*<s|g|gb|gbc|gc|gg|gm|gp|n|an|nr|ns|nt|nz|nb|nba|nbc|nbp|nf|ng|nh|nhd|o|nz|nx|ntu|nts|nto|nth|ntch|ntcf|ntcb|ntc|nt|nsf|ns|nrj|nrf|nr2|nr1|nr|nnt|nnd|nn|nmc|nm|nl|nit|nis|nic|ni|nhm|nhd>+<f>?<ude1>?<g|gb|gbc|gc|gg|gm|gp|n|an|nr|ns|nt|nz|nb|nba|nbc|nbp|nf|ng|nh|nhd|o|nz|nx|ntu|nts|nto|nth|ntch|ntcf|ntcb|ntc|nt|nsf|ns|nrj|nrf|nr2|nr1|nr|nnt|nnd|nn|nmc|nm|nl|nit|nis|nic|ni|nhm|nhd>+}
        {<n|an|nr|ns|nt|nz|nb|nba|nbc|nbp|nf|ng|nh|nhd|nz|nx|ntu|nts|nto|nth|ntch|ntcf|ntcb|ntc|nt|nsf|ns|nrj|nrf|nr2|nr1|nr|nnt|nnd|nn|nmc|nm|nl|nit|nis|nic|ni|nhm|nhd>+<cc>+<n|an|nr|ns|nt|nz|nb|nba|nbc|nbp|nf|ng|nh|nhd|nz|nx|ntu|nts|nto|nth|ntch|ntcf|ntcb|ntc|nt|nsf|ns|nrj|nrf|nr2|nr1|nr|nnt|nnd|nn|nmc|nm|nl|nit|nis|nic|ni|nhm|nhd>+}
        {<m|mg|Mg|mq|q|qg|qt|qv|s|>*<q|qg|qt|qv>*<f|b>*<vi|v|vn|vg|vd>+<ude1>+<n|an|nr|ns|nt|nz|nb|nba|nbc|nbp|nf|ng|nh|nhd|nz|nx|ntu|nts|nto|nth|ntch|ntcf|ntcb|ntc|nt|nsf|ns|nrj|nrf|nr2|nr1|nr|nnt|nnd|nn|nmc|nm|nl|nit|nis|nic|ni|nhm|nhd>+}
        {<g|gb|gbc|gc|gg|gm|gp|n|an|nr|ns|nt|nz|nb|nba|nbc|nbp|nf|ng|nh|nhd|nz|nx|ntu|nts|nto|nth|ntch|ntcf|ntcb|ntc|nt|nsf|ns|nrj|nrf|nr2|nr1|nr|nnt|nnd|nn|nmc|nm|nl|nit|nis|nic|ni|nhm|nhd>+<vi>?}
        VP:{<v|vd|vg|vf|vl|vshi|vyou|vx|vi|vn>+}
        """
    # 定义了一个名词块，每个大括号对应一条规则。<> 对应一个单元，* 即前面的单元重复 0 次或 多次。中间的 | 为或。
    # 上面的 NP 有 4 条规则，匹配时，先匹配第一条，然后再匹配第二条，等等，一般我们把相对严格的规则放在前面让它优先匹配。
    rp = nltk.RegexpParser(grammar)
    try:
        result = rp.parse(pair_list)  # 解析完后变为树
        return result
    except:
        return ""



# 遍历
def get_merged_mark(tree):
    text = ''
    for node in tree:
        if type(node) is nltk.Tree:
            if node.label() == 'NP': # 将 np 下面的 合并起来
                text += ''.join(node_child[0].strip() for node_child in node.leaves()) + "/NP" + 3 * " "
            if node.label() == 'VP': # 将动词短语下面的 合并起来
                text += ''.join(node_child[0].strip() for node_child in node.leaves()) + "/VP" + 3 * " "
        else:
            if node[1] in keep_pos_p: # 不是树，说明是叶子节点
                text += node[0].strip() + "/PP" + 3 * " " # p 介词
            if node[0] in huanhang:
                text += node[0].strip() + "/O" + 3 * " " # o others 不是我们关心的
            if node[1] not in merge_pos:
                text += node[0].strip() + "/O" + 3 * " "
    print(text)
    return text


if __name__ == '__main__':
    with open('text2.txt', 'r', encoding='utf8') as f:
        lines = f.readlines()

    texts = []
    for line in lines:
        line = line.strip()
        if len(line.strip()) > 0:
            pair_list = get_token_tag_pair_list(line)
            print(pair_list)
            tree = get_filtered_tree(pair_list)
            print(tree)
            mark = get_merged_mark(tree)
            print(mark)
            texts.append(mark)

    with open('nvp2.txt', 'w', encoding='utf8') as f:
        f.writelines(texts)
```

输入：

text2.txt：

```py
所属行业： 快速消费品(食品,饮料,化妆品) 
业务部 采购主管 
本人是从黄金珠宝营业员开始做起,现从事黄金珠宝和化妆品的招商工作,曾参与1999年和2004年3家商场的招商工作,在公司我能比较完美的贯彻和执行公司的营销策略和销售计划,并能提出合理化建议,在工作中能与供应商保持良好的合作关系.
RESUMEDOCSSTARTFLAG	销售总监	半年市场部总监工作，之后公司开始华东地区大客户销售业务，转为华东区
销售总监，创建易车网华东地区大客户销售团队，并带领团队完成公司下达
的销售任务。
主要收获：半年市场总监工作经验，成功稳固公司在上海的品牌形象和客户关系，有效
利用各种手段推广公司品牌。
两年半网络广告销售从业及管理经验，成功组建
易车网华东区域大客户销售团队，以直客为导向，兼顾渠道。
有丰富的互联网
广告知识，同时也有华东区域的所有汽车客户及周边产品的直客关系，及相
关的渠道关系。
RESUMEDOCSSTARTFLAG	市场部高级经理	负责东方网旗下的<东方社区>刊物的市场推广及合作
主要收获: 了解纸媒体特点,熟悉期刊编辑出版流程,并结合活动推广刊物
同时也参与
部分平面广告销售工作,熟悉平面广告销售的所有流程
RESUMEDOCSSTARTFLAG	事业发展部主管	（自 2004 年 3 月——2005 年 3 月，在共青团上海市委管理信息部挂职锻炼）网站编辑;
公司内部活动策划组织,项目管理;
协调. 联络并保持与团市委机关的良好合作关系
主要收获: 对网络与信息化有了进一步的认识,了解网站的运营模式
在团市委机关挂职
期间,加强了自身思想道德等各方面的学习,积累了广泛的人脉,多次参与
一些市大型活动的策划组织及执行,列: 上海 IT 青年十大新锐评选活动. 上
海市信息化青年人才协会第一次会员大会--暨“世博会与信息化”青年论
坛等等,使自身各方面综合素质有了一个更全面的提高
RESUMEDOCSSTARTFLAG	市场公关专员	策划组织各类活动,包括户外拓展训练,团队建设等;
策划组织公司内部各项活动,落实凝聚力工程;
组织各类公关接待及外联工作;
各类活动的主持及执行等事宜
主要收获: 积累了更丰富的策划经验,多次的主持经历让我在语言表达方面有了进一步
的提高,不断接触到的不同人群,也让我积累了良好的社会关系,现场的活
动执行,更让我在面对突发事件时,有了冷静思考的能力
```


视频中输出：

nvp.txt：

```txt
所属行业/NP   ：/O   /O   快速消费品/NP   (/O   食品/NP   ,/O   饮料/NP   ,/O   化妆品/NP   )/O   
业务部/NP   /O   采购主管/NP   
本人/O   是从/VP   黄金珠宝营业员/NP   开始做起/VP   ,/O   现/O   从事/VP   黄金珠宝/NP   和/O   化妆品的招商工作/NP   ,/O   曾/O   参与/VP   1999/O   年/O   和/O   2004年3家商场的招商工作/NP   ,/O   在/PP   公司/NP   我/O   能/VP   比较/NP   完美/O   的/O   贯彻/VP   和/O   执行公司的营销策略/NP   和/O   销售计划/NP   ,/O   并能提出/VP   合理化建议/NP   ,/O   在工作中/O   能/VP   与/O   供应商保持良好/NP   的/O   合作/VP   关系/NP   ./O   
RESUMEDOCSSTARTFLAG/NP   /O   销售总监/NP   /O   半年市场部总监工作/NP   ，/O   之后/O   公司/NP   开始/VP   华东地区大客户销售业务/NP   ，/O   转为/VP   华东区/NP   
销售总监/NP   ，/O   创建/VP   易车网华东地区大客户销售团队/NP   ，/O   并/O   带领/VP   团队/NP   完成/VP   公司/NP   下达/VP   
的/O   销售任务/NP   。/O   。/O   
主要/O   收获/NP   ：/O   半年市场总监工作经验/NP   ，/O   成功/O   稳固/O   公司/NP   在/PP   上海的品牌形象/NP   和/O   客户关系/NP   ，/O   有效/NP   
利用/VP   各种手段推广公司品牌/NP   。/O   。/O   
两年半网络广告销售/NP   从业/O   及/O   管理经验/NP   ，/O   成功/O   组建/VP   
易车网华东区域大客户销售团队/NP   ，/O   以/PP   直/O   客/NP   为/PP   导向/NP   ，/O   兼顾/VP   渠道/NP   。/O   。/O   
有/VP   丰富/O   的/O   互联网/NP   
广告知识/NP   ，/O   同时/O   也/O   有/VP   华东区域/NP   的/O   所有/O   汽车客户/NP   及/O   周边产品/NP   的/O   直/O   客关系/NP   ，/O   及/O   相/O   
关的渠道关系/NP   。/O   。/O   
RESUMEDOCSSTARTFLAG/NP   /O   市场部高级经理/NP   /O   负责东方网/NP   旗下/O   的/O   <东方社区>刊物的市场推广/NP   及/O   合作/VP   
主要/O   收获/NP   :/O   /O   了解/VP   纸媒体特点/NP   ,/O   熟悉/VP   期刊编辑/NP   出版/VP   流程/NP   ,/O   并/O   结合/VP   活动推广刊物/NP   
同时/O   也/O   参与/VP   
部分平面广告销售工作/NP   ,/O   熟悉/VP   平面广告销售/NP   的/O   所有/O   流程/NP   
RESUMEDOCSSTARTFLAG/NP   /O   事业发展部主管/NP   /O   （/O   自/PP   /O   2004/O   /O   年/O   /O   3/O   /O   月/NP   ——/O   2005/O   /O   年/O   /O   3/O   /O   月/NP   ，/O   在/PP   共青团上海市委管理信息/NP   部/O   挂职锻炼/NP   ）/O   网站编辑/NP   ;/O   
公司内部活动策划组织/NP   ,/O   项目管理/NP   ;/O   
协调/NP   ./O   /O   联络并保持/NP   与/O   团市委机关/NP   的/O   良好/O   合作/VP   关系/NP   
主要/O   收获/NP   :/O   /O   对/PP   网络与信息化/NP   有/VP   了/O   进一步/O   的/O   认识/VP   ,/O   了解/VP   网站的运营模式/NP   
在/PP   团市委机关挂职/NP   
期间/O   ,/O   加强/VP   了/O   自身/O   思想道德/NP   等/O   各/O   方面的学习/NP   ,/O   积累/VP   了/O   广泛/O   的/O   人脉/NP   ,/O   多次/O   参与/VP   
一些市大型活动的策划组织/NP   及/O   执行/NP   ,/O   列/VP   :/O   /O   上海/NP   /O   IT/NP   /O   青年/NP   十大新锐评选活动/NP   ./O   /O   上/O   
海市信息化青年人才协会/NP   第一次会员大会--/NP   暨/O   “/O   世博会与信息化/NP   ”/O   青年/NP   论/VP   
坛/NP   等等/O   ,/O   使/VP   自身/O   各/O   方面综合素质/NP   有/VP   了/O   一个/O   更/O   全面/O   的/O   提高/VP   
RESUMEDOCSSTARTFLAG/NP   /O   市场公关专员/NP   /O   策划组织/NP   各类/O   活动/NP   ,/O   包括/VP   户外拓展/NP   训练/VP   ,/O   团队建设/NP   等/O   ;/O   
策划组织公司内部/NP   各项/O   活动/NP   ,/O   落实/VP   凝聚力工程/NP   ;/O   
组织/NP   各类/O   公关接待/NP   及/O   外联工作/NP   ;/O   
各类/O   活动的主持/NP   及/O   执行/NP   等/O   事宜/NP   
主要/O   收获/NP   :/O   /O   积累/VP   了/O   更/O   丰富/O   的/O   策划经验/NP   ,/O   多次/O   的/O   主持经历/NP   让/VP   我/O   在/PP   语言表达方面/NP   有/VP   了/O   进一步/O   
的/O   提高/VP   ,/O   不断/O   接触/NP   到/VP   的/O   不同/O   人群/NP   ,/O   也/O   让/VP   我/O   积累/VP   了/O   良好/O   的/O   社会关系/NP   ,/O   现场/NP   的/O   活/VP   
动/VP   执行/NP   ,/O   更/O   让/VP   我/O   在/PP   面对/VP   突发事件/NP   时/O   ,/O   有/VP   了/O   冷静/NP   思考的能力/NP   
```


疑问：

- 程序无法运行
  - 为什么 hanlp 词性标注的内容与 grammar 里面的完全不同？






## 自定义语法与 CFG

什么是语法解析？

- 在自然语言学习过程中，每个人一定都学过语法，例如句子可以用主语、谓语、宾语来表示。在自然语言的处理过程中，有许多应用场景都需要考虑句子的语法，因此研究语法解析变得非常重要。
- 语法解析有两个主要的问题，
  - 句子语法在计算机中怎么表达与存储？使用什么语料数据集？
    - 可以用树状结构图来表示。
      - 如下图所示，
        <p align="center">
          <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200713/qdJKsOIuoD9z.png?imageslim">
        </p>
      - 说明：
        - S 表示句子；
        - NP、VP、PP是名词、动词、介词短语（短语级别）；
        - N、V、P 分别是名词、动词、介词。
  - 其二是语法解析的算法。
    - 上下文无关语法（Context-Free Grammer）
      - 为了生成句子的语法树，我们可以定义如下的一套上下文无关语法。
        - $N$ 表示一组非叶子节点的标注，例如 {S、NP、VP、N...}
          - 如上图中红色文字。
        - $\Sigma$ 表示一组叶子结点的标注，例如 {boeing、is...}
          - 如上图中蓝色文字。
        - $R$ 表示一组规则，每条规则可以表示为
          $$X \rightarrow Y_{1}, Y_{2}, \ldots, Y_{n}, X \in N, Y_{i} \in(N \cup \Sigma)$$
        - $S$ 表示语法树开始的标注
      - 用处：
        - 什么时候需要自定义语法呢？
          - 使用分词工具进行词性识别时，可能不准，这时候，我们可以用我们的规则同样提取名词块。这样可以在词性识别之后自定义语法，来继续提取词块。
      - 举例来说，语法的一个语法子集可以表示为下图所示。当给定一个句子时，我们便可以按照从左到右的顺序来解析语法。
        - 例如，句子 the man sleeps 就可以表示为(S (NP (DT the) (NN man)) (VP sleeps))。
          <p align="center">
            <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200713/moDi8uMTEO6v.png?imageslim">
          </p>
        - 说明：
          - 这里，我们假定规则 $R$ 如下：
            - S 可以由名词短语 NP 和动词短语 VP 组成。
            - 其中 VP 
              - 可以由及物动词 Vi 组成
              - 也可以由 Vt 和 名词短语 NP 组成。
              - 也可以由动词短语 VP 和介词 PP 组成
            - 其中 NP
              - 可以由 量词 DT 和名词 NN 组成。
              - 也可以由名词短语 NP 和 介词 PP 组成
            - 而介词 PP
              - 又可以由 IN 和 名词短语 NP 组成。
    - 概率分布的上下文无关语法（Probabilistic Context-Free Grammar）
      - 缘由：
        - 使用上面的上下文无关的语法可以很容易的推导出一个句子的语法结构，但是缺点是推导出的结构可能存在二义性。即规则冲突。
        - 由于语法的解析存在二义性，我们就需要找到一种方法从多种可能的语法树种找出最可能的一棵树。
          - 一种常见的方法既是 PCFG （Probabilistic Context-Free Grammar）。
      - PCFG 介绍：
        - 与上下文无关语法相同，不过，除了常规的语法规则以外，我们还对每一条规则赋予了一个概率。
        - 而对于每一棵生成的语法树，我们将其中所有规则的概率的乘积作为语法树的出现概率。
      - 举例：
        - 如图
          <p align="center">
            <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200713/IFJlLLnmKiFI.png?imageslim">
          </p>
        - 说明：
          - 比如句子 S 由名词短语 NP 和动词短语 VP 构成的概率是 1.0。
          - 当我们获得多颗语法树时，我们可以分别计算每颗语法树的概率 $p(t)$ ，出现概率最大的那颗语法树就是我们希望得到的结果，即 $\arg \max p(t)$。
      - 两个问题：
        - 怎么得到最优的概率设定？
        - 怎么得到概率最大的语法树？
      - 第一个问题：
        - 问题：
          - 怎么得到最优的概率设定？
        - 解答：
          - 从语料库中训练处 PCFG 需要的概率参数。
        - 注意：
          - 在 CFG 的定义的基础上，我们重新定义一种叫 Chomsky 的语法格式。这种格式要求每条规则只能是 $X \rightarrow Y1 Y2$ 或者 $X \rightarrow Y$ 的格式。
            - 实际上 Chomsky 语法格式保证生产的语法树总是二叉树的格式，同时任意一棵语法树总是能够转化成 Chomsky 语法格式。
        - 流程：
          - 01 统计出语料库中所有的 $N$ 与 $Σ$；
          - 02 利用语料库中的所有规则作为R；
          - 03 针对每个规则 $A \rightarrow B$，从语料库中估算 $p(x) = p(A \rightarrow B) / p(A)$；
      - 第二个问题：
        - 问题：
          - 假设我们已经有一个 PCFG 的模型，包含 $N$、 $\Sigma$、 $R$、 $S$、 $p(x)$ 等参数，并且语法树总数 Chomsky 语法格式。当输入一个句子 $x1, x2, ... , xn$时，我们要如何计算句子对应的语法树呢？
        - 解答：
          - 第一种方法
            - 暴力遍历。每个单词 $x$ 可能有 $m = len(N)$ 种取值，句子长度是 $n$，每种情况至少存在 $n$ 个规则，所以在时间复杂度 $O(m n n)$的情况下，我们可以判断出所有可能的语法树并计算出最佳的那个。
          - 第二种方法
            - 动态规划。我们定义 $w[i, j, X]$ 是第 $i$ 个单词至第 $j$ 个单词由标注 $X$ 来表示的最大概率。直观来讲，例如 $x_i, x_{i+1}, \ldots , x_j$，当 $X=PP$ 时，子树可能是 (P NP) 或者 (PP PP)，但是，当 $w[i,j, PP]$ 代表的是继续往上一层递归时，我们只选择当前概率最大的组合方式。（没有很明白？）
      - PCFG 的缺点
        - 缺乏词法信息；
        - 连续短语（如名词、介词）的处理等。但总体来讲它给语法解析提供了一种非常有效的实现方法。

举例：

```py
import nltk, os, jieba
from nltk.tree import Tree
from nltk.draw import TreeWidget
from nltk.draw.tree import TreeView
from nltk.draw.util import CanvasFrame


def cfg_en():
    # Det 为限定词 P 为介词
    grammar = nltk.CFG.fromstring("""
     S -> NP VP
     VP -> V NP | V NP PP
     V -> "saw" | "ate"
     NP -> "John" | "Mary" | "Bob" | Det N | Det N PP
     Det -> "a" | "an" | "the" | "my"
     N -> "dog" | "cat" | "cookie" | "park"
     PP -> P NP
     P -> "in" | "on" | "by" | "with"
     """)
    rd_parser = nltk.parse.RecursiveDescentParser(grammar)
    sentence = "Mary saw Bob"
    tree = list(rd_parser.parse(sentence.split()))
    print(tree)


def cfg_zh():
    grammar = nltk.CFG.fromstring("""
         S -> N VP
         VP -> V NP | V NP | V N
         V -> "尊敬"
         N -> "我们" | "老师" 
         """)
    rd_parser = nltk.parse.RecursiveDescentParser(grammar)
    sentence = "我们 尊敬 老师"
    tree = list(rd_parser.parse(sentence.split()))
    tree[0].draw()
    print(tree)


if __name__ == '__main__':
    cfg_en()
    cfg_zh()
```

输出：

```txt
[Tree('S', [Tree('NP', ['Mary']), Tree('VP', [Tree('V', ['saw']), Tree('NP', ['Bob'])])])]
[Tree('S', [Tree('N', ['我们']), Tree('VP', [Tree('V', ['尊敬']), Tree('N', ['老师'])])])]
```

图像：

<p align="center">
  <img width="30%" height="70%" src="http://images.iterate.site/blog/image/20200713/cBKme4NhcUjc.png?imageslim">
</p>


这个例子太简单了，不实用。补充下。关键是 PCFG 的训练和应用的例子。