
# Seq2seq 自然语言处理简介

使用计算机对自然语言进行处理，便需要将自然语言处理成机器能够识别的符号，在机器学习过程中，就需要将其进行数值化。

而词是自然语言理解与处理的基础，因此需要对词进行数值化，词向量便是一种可行又有效的方法。

何为词向量，即使用一个指定长度的实数向量 $V$ 来表示一个词。有一种最简单的表示方法，就是使用 One-hot vector 表示单词，即根据单词的数量 $|V|$ 生成一个 $|V|×1$ 的向量，当某一位为 $1$ 的时候其他位都为 $0$，然后这个向量就代表一个单词。

目前比较流行的 Seq2Seq 模型，由 Sutskever 等人提出，基于一个 Encoder-Decoder 的结构，将 Source 句子先 Encode 成一个固定维度 $d$ 的向量，然后通过 Decoder 部分一个字符一个字符生成 Target 句子。加入了 Attention 注意力分配机制后，使得 Decoder 在生成新的 Target Sequence 时，能得到之前 Encoder 编码阶段每个字符的隐藏层的信息向量 Hidden State，使得生成新序列的准确度提高。<span style="color:red;">为什么 Attention 机制能得到 Encoder 编码的每个字符的隐藏层的信息向量？为什么能提高准确度？</span>Seq2seq 模型就像一个翻译模型，输入是一个序列（比如一个英文句子），输出也是一个序列（比如该英文句子所对应的法文翻译）。这种结构最重要的地方在于输入序列和输出序列的长度是可变的。<span style="color:red;">非常想知道怎么做到的长度的变化？</span>

比如在机器翻译中输入（hello）-> 输出（你好）。输入是 1 个英文单词，输出为两个汉字。

在对话机器中我们提（输入）一个问题，机器会自动生成（输出）回答。这里的输入和输出显然是长度没有确定的序列（Sequences）。<span style="color:red;">是的。</span>

最基础的 Seq2Seq 模型包含了三个部分，即 Encoder、Decoder 以及连接两者的中间状态向量，Encoder 通过学习输入，将其编码成一个固定大小的状态向量 S，继而将 S 传给 Decoder，Decoder 再通过对状态向量 S 的学习来进行输出。

下面是它的工作原理：

- 有一个 RNN 层（或其堆叠）作为“编码器”：它负责处理输入序列并返回其自身的内部状态。注意，我们将丢弃编码器 RNN 的输出，只恢复状态。该状态将在下一步骤中用作解码器的 “上下文” 或 “环境”。<span style="color:red;">哇塞，这也可以！丢弃 RNN 的输出，只恢复状态。怎么做的？</span>

- 另外还有一个 RNN 层（或其堆叠）作为“解码器”：在给定目标序列前一个字符的情况下，对其进行训练以预测目标序列的下一个字符。具体来说，就是训练该层，使其能够将目标序列转换成将来偏移了一个时间步长的同一个序列，这种训练过程被称为 “Teacher Forcing（老师强迫）” 。<span style="color:red;">将目标序列转换成将来偏移了一个时间步长的同一个序列。 teacher forcing 没有很明白。</span>有一点很重要，解码器将来自编码器的状态向量作为初始状态，这样，解码器就知道了它应该产生什么样的信息。实际上就是解码器以输入序列为条件，对于给定的 targets[...t] 学习生成 targets[t+1...]。


其实基础的 Seq2Seq 是有很多弊端的，首先 Encoder 将输入编码为固定大小状态向量的过程，实际上是一个 “信息有损压缩” 的过程，如果信息量越大，那么这个转化向量的过程对信息的损失就越大，<span style="color:red;">是的，是信息有损压缩。</span>同时，随着 sequence length 的增加，意味着时间维度上的序列很长，RNN 模型也会出现梯度弥散。最后，基础的模型连接 Encoder和 Decoder 模块的组件仅仅是一个固定大小的状态向量，这使得 Decoder 无法直接去关注输入信息的更多细节。<span style="color:red;">嗯。</span>由于基础 Seq2Seq 的种种缺陷，之后引入了 Attention 的概念以及 Bi-directional encoder layer等。<span style="color:red;">想知道 attention 和 Bi-directional encoder layer 是怎么解决这些问题的？现在还有别的解决方式吗？</span>

Seq2seq 其实可以用在很多地方，比如机器翻译、自动对话机器人、文档摘要自动生成、图片描述自动生成。比如 Google 就基于 Seq2seq 开发了一个对话模型，使用两个 LSTM 的结构，LSTM1 将输入的对话编码成一个固定长度的实数向量，LSTM2 根据这个向量不停地预测后面的输出（解码）。只是在对话模型中，使用的语料是（你说的话-我答的话）这种类型的 pairs 。而在机器翻译中使用的语料是（hello-你好）这样的 pairs。<span style="color:red;">是的，不过感觉这样的对话模型真的可行吗？这样的训练方式？应该要对于底层的信息非常清楚后才知道吧？</span>

此外，如果我们的输入是图片，输出是对图片的描述，用这样的方式来训练的话就能够完成图片描述的任务。

可以看出来，Seq2seq 具有非常广泛的应用场景，而且效果也是非常明显的。同时，因为是端到端的模型（大部分的深度模型都是端到端的），它减少了很多人工处理和规则制定的步骤。在 Encoder-Decoder 的基础上，人们又引入了 Attention Mechanism 等技术，使得这些深度方法在各个任务上表现更加突出。

<span style="color:red;">这他妈讲了跟没讲一样。</span>




# 相关

- 《深度学习框架 Pytorch 快速开发与实战》
