
# 可以补充进来的

- 这个是线性回归吗？不是吧？是一个简单的前馈网络吧？而且，为啥我跑出来的结果与书上的结果不同？重新看下。

# 线性回归预测股价

线性回归是利用数理统计中的回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，运用十分广泛。

在统计学中，线性回归（Linear Regression）是利用称为线性回归方程的最小平方函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个被称为回归系数的模型参数的线性组合。

只有一个自变量的情况称为简单回归，大于一个自变量的情况叫作多元回归。回归分析中，只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。

如果回归分析中包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为多元线性回归分析。线性回归模型经常用最小二乘来逼近来拟合。

前面讲了基本的线性回归以及模型框架，按照这个框架就可以写出一个线性回归模型。

首先我们看一下采集到的上证指数的数据，如图所示。


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190622/XM4WwzFnBh6i.png?imageslim">
</p>

从 2017 年 1 月 3 日，包括开盘价、收盘价、最高价、最低价。涨跌采用 0 和 1 模式。如果当天的收盘价高于昨天的收盘价定义为 1，如果当天的收盘价低于昨天的收盘价定义为 0。<span style="color:red;">对于股票不了解，是看得收盘价来判断好坏吗？不是什么时间点都可以买卖的吗？</span>


OK，那我们可以用前 100 天的开盘价、收盘价、最高价、最低价当作输入数据，第 2 天到 101 天的涨跌数据作为输出数据，来进行训练，进行股价次日涨跌预测。<span style="color:red;">哈哈，是的。</span>


下面是具体的代码实现。

```py
# -*- coding: utf-8 -*-
import numpy as np
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import torch.nn.functional as F
import torch.autograd as autograd
import pandas as pd
from torch.autograd import Variable

df = pd.read_excel(r"./shanghai_index.xlsx")
df1 = df.iloc[:100, 3:7].values
xtrain_features = torch.FloatTensor(df1)
df2 = df.iloc[1:101, 7].values
xtrain_labels = torch.FloatTensor(df2)
xtrain = torch.unsqueeze(xtrain_features, dim=1)
ytrain = torch.unsqueeze(xtrain_labels, dim=1)

x, y = torch.autograd.Variable(xtrain), Variable(ytrain)


class Net(torch.nn.Module):  # 继承 torch 的 Module
    def __init__(self, n_feature, n_hidden, n_output):
        super(Net, self).__init__()  # 继承 __init__ 功能
        # 定义每层用什么样的形式
        self.hidden = torch.nn.Linear(n_feature, n_hidden)  # 隐藏层线性输出
        self.predict = torch.nn.Linear(n_hidden, n_output)

    def forward(self, x):  # 这同时也是 Module 中的 forward 功能
        # 正向传播输入值, 神经网络分析出输出值
        x = F.relu(self.hidden(x))  # 激励函数(隐藏层的线性值)
        x = self.predict(x)  # 输出值
        return x


model = Net(n_feature=4, n_hidden=10, n_output=1)
criterion = nn.MSELoss()
optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)
num_epochs = 300000
for epoch in range(num_epochs):
    inputs = x
    target = y
    out = model(inputs)  # 前向传播
    out_reshape = out.reshape(100, 1)
    loss = criterion(out_reshape, target)  # 计算 loss
    # backward
    optimizer.zero_grad()  # 梯度归零
    loss.backward()  # 方向传播
    optimizer.step()  # 更新参数

    if (epoch + 1) % 20 == 0:
        print('Epoch[{}/{}], loss: {:.6f}'.format(epoch + 1, num_epochs, loss.data[0]))

model.eval()
predict = model(x)
predict = predict.data.numpy()
print(predict)
```

输出：

```
Epoch[20/300000], loss: 5737078.000000
Epoch[40/300000], loss: 5691360.000000
Epoch[60/300000], loss: 5646006.500000
略..
Epoch[299960/300000], loss: 0.245100
Epoch[299980/300000], loss: 0.245100
Epoch[300000/300000], loss: 0.245100
[[[0.570149]]
 [[0.570149]]
 略..
 [[0.570149]]
 [[0.570149]]]
```

<span style="color:red;">奇怪了，为什么预测的结果列表是相同的？不应该呀？</span>


训练完成之后我们就可以开始测试模型了。

特别注意的是需要用 `model.eval（）`，让 model 变成测试模式，这主要是因为 Dropout 和 Batch Normalization 的操作在训练和测试的时候是不一样的。<span style="color:red;">是的是的。哎？为什么 Batch Normalization 在测试的时候也是不一样的？而且，上面没有使用 Dropout 和 Batch Normalization 吧？</span>

我们来看一下经过处理的前 10 个数据的预测结果：1,0,1,0,1,0, 1,0,1。真实的数据如下：1,0,1,1,1,1,1,0,1。

<span style="color:red;">为什么我这边输出的结果都是相同的？而不是 1,0,1 这样的？奇怪了，是程序少了什么部分吗？</span>

尝试修改的，但是也没有效果的：

```py
class Net(torch.nn.Module):  # 继承 torch 的 Module
    def __init__(self, n_feature, n_hidden, n_output):
        super(Net, self).__init__()  # 继承 __init__ 功能

        self.dropout_p=0.5
        # 定义每层用什么样的形式
        self.hidden = torch.nn.Linear(n_feature, n_hidden)  # 隐藏层线性输出
        self.predict = torch.nn.Linear(n_hidden, n_output)
        self.dropout = nn.Dropout(self.dropout_p)
        self.bn=nn.BatchNorm1d(1, momentum=0.5)

    def forward(self, x):  # 这同时也是 Module 中的 forward 功能
        # 正向传播输入值, 神经网络分析出输出值
        # x = F.relu(self.hidden(self.bn(x)))  # 激励函数(隐藏层的线性值)
        # x = (self.predict(self.bn((x))))  # 输出值# self.dropout

        x = F.relu(self.hidden(x))  # 激励函数(隐藏层的线性值)
        x =( self.predict((x)) ) # 输出值
        return x
```


从中可以看出，经过 100000 次训练之后，由于数据量较少，可能出现过拟合现象，为此我们在进行预测的时候，需要进行参数的调整优化，找到最合适的参数进行训练。<span style="color:red;">对于这个例子来讲，需要调整那些参数？</span>




# 相关


- 《深度学习框架 Pytorch 快速开发与实战》
- 数据如下：https://pan.baidu.com/s/1_pSY6_qP7zzzcJQLtjK08Q 提取码：ypas
