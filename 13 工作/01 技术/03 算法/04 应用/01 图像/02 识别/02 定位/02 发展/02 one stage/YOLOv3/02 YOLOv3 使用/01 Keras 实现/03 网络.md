
# 第 3 篇，网络，以 DarkNet 为基础


## 1. 网络

在模型中，通过传入输入层 image_input、每层的 anchor 数 num_anchors//3 和类别数 num_classes，调用 yolo_body 方法，构建 YOLO v3 的网络 model_body。其中，image_input 的结构是 (?, 416, 416, 3)。

```python
model_body = yolo_body(image_input, num_anchors // 3, num_classes)  # model
```

在 model_body 中，最终的输入是 image_input，最终的输出是 3 个矩阵的列表：

```python
[(?, 13, 13, 18), (?, 26, 26, 18), (?, 52, 52, 18)]
```

YOLO v3 的基础网络是 DarkNet 网络，将 DarkNet 网络中底层和中层的特征矩阵，通过卷积操作和多个矩阵的拼接操作，创建 3 个尺度的输出，即[y1, y2, y3]。<span style="color:red;">DarkNet 网络还是要了解下的。</span>

```python
def yolo_body(inputs, num_anchors, num_classes):
    darknet = Model(inputs, darknet_body(inputs))

    x, y1 = make_last_layers(darknet.output, 512, num_anchors * (num_classes + 5))

    x = compose(
        DarknetConv2D_BN_Leaky(256, (1, 1)),
        UpSampling2D(2))(x)
    x = Concatenate()([x, darknet.layers[152].output])
    x, y2 = make_last_layers(x, 256, num_anchors * (num_classes + 5))

    x = compose(
        DarknetConv2D_BN_Leaky(128, (1, 1)),
        UpSampling2D(2))(x)
    x = Concatenate()([x, darknet.layers[92].output])
    x, y3 = make_last_layers(x, 128, num_anchors * (num_classes + 5))

    return Model(inputs, [y1, y2, y3])
```

## 2. Darknet

Darknet 网络的输入是图片数据集 inputs，即 (?, 416, 416, 3)，输出是 darknet_body 方法的输出。将网络的核心逻辑封装在 darknet_body 方法中。即：

```python
darknet = Model(inputs, darknet_body(inputs))
```

其中，darknet_body 的输出格式是 (?, 13, 13, 1024)。

Darknet 的网络简化图，如下：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180925/cd66k23f5C.png?imageslim">
</p>

网络简化图

YOLO v3 所使用的 Darknet 版本是 Darknet53。那么，为什么是 Darknet53 呢？因为 Darknet53 是 53 个卷积层和池化层的组合，与 Darknet 简化图一一对应，即：

```
53 = 2 + 1*2 + 1 + 2*2 + 1 + 8*2 + 1 + 8*2 + 1 + 4*2 + 1
```

在 darknet_body 中，Darknet 网络含有 5 组重复的 resblock_body 单元，即：

```python
def darknet_body(x):
    '''Darknent body having 52 Convolution2D layers'''
    x = DarknetConv2D_BN_Leaky(32, (3, 3))(x)
    x = resblock_body(x, num_filters=64, num_blocks=1)
    x = resblock_body(x, num_filters=128, num_blocks=2)
    x = resblock_body(x, num_filters=256, num_blocks=8)
    x = resblock_body(x, num_filters=512, num_blocks=8)
    x = resblock_body(x, num_filters=1024, num_blocks=4)
    return x
```

在第 1 个卷积操作 DarknetConv2D_BN_Leaky 中，是 3 个操作的组合，即：

- 1 个 Darknet 的 2 维卷积 Conv2D 层，即 DarknetConv2D；
- 1 个批正则化层，即 BatchNormalization()；
- 1 个 LeakyReLU 层，斜率是 0.1，LeakyReLU 是 ReLU 的变换；

即：

```python
def DarknetConv2D_BN_Leaky(*args, **kwargs):
    """Darknet Convolution2D followed by BatchNormalization and LeakyReLU."""
    no_bias_kwargs = {'use_bias': False}
    no_bias_kwargs.update(kwargs)
    return compose(
        DarknetConv2D(*args, **no_bias_kwargs),
        BatchNormalization(),
        LeakyReLU(alpha=0.1))
```

其中，LeakyReLU的激活函数，如下：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180925/ik0llFbHeA.png?imageslim">
</p>

LeakyReLU

其中，Darknet 的 2 维卷积 DarknetConv2D，具体操作如下：

- 将核权重矩阵的正则化，使用 L2 正则化，参数是 5e-4，即操作 w 参数；
- Padding，一般使用 same 模式，只有当步长为 (2,2) 时，使用 valid 模式。避免在降采样中，引入无用的边界信息；
- 其余参数不变，都与二维卷积操作 Conv2D()一致；

kernel_regularizer 是将核权重参数 w 进行正则化，而 BatchNormalization 是将输入数据 x 进行正则化。

实现：

```python
@wraps(Conv2D)
def DarknetConv2D(*args, **kwargs):
    """Wrapper to set Darknet parameters for Convolution2D."""
    darknet_conv_kwargs = {'kernel_regularizer': l2(5e-4)}
    darknet_conv_kwargs['padding'] = 'valid' if kwargs.get('strides') == (2, 2) else 'same'
    darknet_conv_kwargs.update(kwargs)
    return Conv2D(*args, **darknet_conv_kwargs)
```

下一步，第 1 个残差结构 resblock_body，输入的数据 x 是(?, 416, 416, 32)，通道 filters 是 64 个，重复次数 num_blocks 是 1 次。第 1 个残差结构是网络简化图第 1 部分。

```python
x = resblock_body(x, num_filters=64, num_blocks=1)
```

在 resblock_body 中，含有以下逻辑：

- ZeroPadding2D：填充 x 的边界为 0，由(?, 416, 416, 32)转换为(?, 417, 417, 32)。因为下一步卷积操作的步长为 2，所以图的边长需要是奇数；
- DarknetConv2D_BN_Leaky：DarkNet的 2 维卷积操作，核是 (3,3)，步长是 (2,2)，注意，这会导致特征尺寸变小，由 (?, 417, 417, 32) 转换为 (?, 208, 208, 64)。由于 num_filters 是 64，所以产生 64 个通道。
- compose：输出预测图 y，功能是组合函数，先执行 1x1 的卷积操作，再执行 3x3 的卷积操作，filter先降低 2 倍后恢复，最后与输入相同，都是 64；
- x = Add()([x, y])：残差操作，将 x 的值与 y 的值相加。残差操作可以避免，在网络较深时所产生的梯度弥散问题。

实现：

```python
def resblock_body(x, num_filters, num_blocks):
    '''A series of resblocks starting with a downsampling Convolution2D'''
    # Darknet uses left and top padding instead of 'same' mode
    x = ZeroPadding2D(((1, 0), (1, 0)))(x)
    x = DarknetConv2D_BN_Leaky(num_filters, (3, 3), strides=(2, 2))(x)
    for i in range(num_blocks):
        y = compose(
            DarknetConv2D_BN_Leaky(num_filters // 2, (1, 1)),
            DarknetConv2D_BN_Leaky(num_filters, (3, 3)))(x)
        x = Add()([x, y])
    return x
```

残差操作流程，如图：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180925/Dagm9JE54G.png?imageslim">
</p>

Residual

同理，在 darknet_body 中，执行 5 组 resblock_body 残差块，重复[1, 2, 8, 8, 4]次，双卷积操作，每组均含有一次步长为 2 的卷积操作，因而一共降维 5 次 32 倍，即 32=2^5，则输出的特征图维度是 13，即 13=416/32 。最后 1 层的通道数是 1024，因此，最终的输出结构是 (?, 13, 13, 1024)，即：

```python
Tensor("add_23/add:0", shape=(?, 13, 13, 1024), dtype=float32)
```

至此，Darknet模型的输入是(?, 416, 416, 3)，输出是(?, 13, 13, 1024)。

------

## 3. 特征图

在 YOLO v3网络中，输出 3 个不同尺度的检测图，用于检测不同大小的物体。调用 3 次 make_last_layers，产生 3 个检测图，即 y1、y2 和 y3。

## 13x13检测图

第 1 个部分，输出维度是 13x13。在 make_last_layers方法中，输入参数如下：

- darknet.output：DarkNet网络的输出，即(?, 13, 13, 1024)；
- num_filters：通道个数 512，用于生成中间值 x，x会传导至第 2 个检测图；
- out_filters：第 1 个输出 y1 的通道数，值是锚框数*(类别数+4个框值+框置信度)；

即：

```python
x, y1 = make_last_layers(darknet.output, 512, num_anchors * (num_classes + 5))
```

在 make_last_layers 方法中，执行 2 步操作：

- 第 1 步，x执行多组 1x1 的卷积操作和 3x3 的卷积操作，filter先扩大再恢复，最后与输入的 filter 保持不变，仍为 512，则 x 由(?, 13, 13, 1024)转变为(?, 13, 13, 512)；
- 第 2 步，x先执行 3x3 的卷积操作，再执行不含 BN 和 Leaky 的 1x1 的卷积操作，作用类似于全连接操作，生成预测矩阵 y；

实现：

```python
def make_last_layers(x, num_filters, out_filters):
    '''6 Conv2D_BN_Leaky layers followed by a Conv2D_linear layer'''
    x = compose(
        DarknetConv2D_BN_Leaky(num_filters, (1, 1)),
        DarknetConv2D_BN_Leaky(num_filters * 2, (3, 3)),
        DarknetConv2D_BN_Leaky(num_filters, (1, 1)),
        DarknetConv2D_BN_Leaky(num_filters * 2, (3, 3)),
        DarknetConv2D_BN_Leaky(num_filters, (1, 1)))(x)
    y = compose(
        DarknetConv2D_BN_Leaky(num_filters * 2, (3, 3)),
        DarknetConv2D(out_filters, (1, 1)))(x)
    return x, y
```

最终，第 1 个 make_last_layers方法，输出的 x 是(?, 13, 13, 512)，输出的 y 是(?, 13, 13, 18)。由于模型只有 1 个检测类别，因而 y 的第 4 个维度是 18，即 3*(1+5)=18。

## 26x26检测图

第 2 个部分，输出维度是 26x26，包含以下步骤：

- 通过 DarknetConv2D_BN_Leaky卷积，将 x 由 512 的通道数，转换为 256 的通道数；
- 通过 2 倍上采样 UpSampling2D，将 x 由 13x13 的结构，转换为 26x26 的结构；
- 将 x 与 DarkNet 的第 152 层拼接 Concatenate，作为第 2 个 make_last_layers的输入，用于生成第 2 个预测图 y2；

其中，输入的 x 和 darknet.layers[152].output的结构都是 26x26 的尺寸，如下：

```python
x: shape=(?, 26, 26, 256)
darknet.layers[152].output: (?, 26, 26, 512)
```

在拼接之后，输出的 x 的格式是(?, 26, 26, 768)。

这样做的目的是：将 Darknet 最底层的高级抽象信息 darknet.output，经过若干次转换之后，除了输出给第 1 个检测部分，还被用于第 2 个检测部分，经过上采样，与 Darknet 骨干中，倒数第 2 次降维的数据拼接，共同作为第 2 个检测部分的输入。底层抽象特征含有全局信息，中层抽象特征含有局部信息，这样拼接，两者兼顾，用于检测较小的物体。

最后，还是调用相同的 make_last_layers，输出第 2 个检测层 y2 和临时数据 x。

实现：

```python
x = compose(
    DarknetConv2D_BN_Leaky(256, (1, 1)),
    UpSampling2D(2))(x)
x = Concatenate()([x, darknet.layers[152].output])
x, y2 = make_last_layers(x, 256, num_anchors * (num_classes + 5))
```

最终，第 2 个 make_last_layers方法，输出的 x 是(?, 26, 26, 256)，输出的 y 是(?, 26, 26, 18)。

## 52x52检测图

第 3 个部分，输出维度是 52x52，与第 2 个部分类似，包含以下步骤：

```python
x = compose(
    DarknetConv2D_BN_Leaky(128, (1, 1)),
    UpSampling2D(2))(x)
x = Concatenate()([x, darknet.layers[92].output])
_, y3 = make_last_layers(x, 128, num_anchors * (num_classes + 5))
```

逻辑如下：

- x经过 128 个 filter 的卷积，再执行上采样，输出为(?, 52, 52, 128)；
- darknet.layers[92].output，与 152 层类似，结构是(?, 52, 52, 256)；
- 两者拼接之后，x是(?, 52, 52, 384)；
- 最后输入至 make_last_layers，生成 y3 是(?, 52, 52, 18)，忽略 x 的输出；

最后，则是根据整个逻辑的输入和输出，构建模型。输入 inputs 依然保持不变，即(?, 416, 416, 3)，而输出则转换为 3 个尺度的预测层，即[y1, y2, y3]。

```python
return Model(inputs, [y1, y2, y3])
```

[y1, y2, y3]的结构如下：

```python
Tensor("conv2d_59/BiasAdd:0", shape=(?, 13, 13, 18), dtype=float32)
Tensor("conv2d_67/BiasAdd:0", shape=(?, 26, 26, 18), dtype=float32)
Tensor("conv2d_75/BiasAdd:0", shape=(?, 52, 52, 18), dtype=float32)
```

最终，在 yolo_body中，完成整个 YOLO v3网络的构建，基础网络是 DarkNet。

```
model_body = yolo_body(image_input, num_anchors // 3, num_classes)
```

网络的示意图，层次序号略有不同：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180925/a3FBdGLldc.png?imageslim">
</p>

网络的示意图

------

## 补充 1. 卷积 Padding

在卷积操作中，针对于边缘数据，有两种操作，一种是舍弃 valid，一种是填充 same。

如：

```
数据：1 2 3 4 5 6 7 8 9 10 11 12 13
输入数据 = 13
过滤器宽度 = 6
步长 = 5
```

第 1 种，valid 操作，宽度是 6，步长是 5，执行数据：

```
1 2 3 4 5 6
6 7 8 9 10 11
11 12 13（不足，舍弃）
```

第 2 种，same操作，执行数据：

```
1 2 3 4 5 6（前两步相同）
6 7 8 9 10 11
11 12 13 0 0（不足，填充）
```

其中，same 模式中数据利用率更高，valid 模式中避免引入无效的边缘数据，两种模式各有千秋。


## 补充 2. compose函数

compose 函数，使用 python 的 Lambda 表达式，顺次执行函数列表，且前一个函数的输出是后一个函数的输入。compose 函数适用于在神经网络中连接两个层。

例如：

```python
def compose(*funcs):
    if funcs:
        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)
    else:
        raise ValueError('Composition of empty sequence not supported.')
def func_x(x):
    return x * 10
def func_y(y):
    return y - 6
z = compose(func_x, func_y)  # 先执行 x 函数，再执行 y 函数
print(z(10))  # 10*10-6=94
```

## 补充 3. UpSampling2D上采样

UpSampling2D 上采样操作，将特征矩阵按倍数扩大，其核心是通过 resize 的方式，默认使用最邻近（Nearest Neighbor）插值算法。data_format 是数据模式，默认是 channels_last，即通道在最后，如 (128,128,3)。

源码：

```python
def call(self, inputs):
    return K.resize_images(inputs, self.size[0], self.size[1],
                           self.data_format)
// ...
x = tf.image.resize_nearest_neighbor(x, new_shape)
```

例如：数据 (?, 13, 13, 256)，经过上采样 2 倍操作，即 UpSampling2D(2)，生成 (?, 26, 26, 256) 的特征图。

## 补充 4. 1x1卷积操作与全连接

1x1 的卷积层和全连接层都可以作为最后一层的预测输出，两者之间略有不同。

第 1 点：

- 1x1 的卷积层，可以不考虑输入的通道数，输出固定通道数的特征矩阵；
- 全连接层（Dense），输入和输出都是固定的，在设计网络时，固定就不能修改；

这样，1x1 的卷积层，比全连接层，更为灵活；

第 2 点：

例如：输入 (13,13,1024)，输出为 (13,13,18)，则两种操作：

- 1x1 的卷积层，参数较少，只需与输出通道匹配的参数，如 13x13x1x1x18 个参数；
- 全连接层，参数较多，需要与输入和输出都匹配的参数，如 13x13x1028x18 个参数；


# 相关

- [探索 YOLO v3 实现细节 - 第 3 篇 网络](https://mp.weixin.qq.com/s/hC4P7iRGv5JSvvPe-ri_8g)
