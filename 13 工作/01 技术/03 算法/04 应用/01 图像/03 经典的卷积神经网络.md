
# 可以补充进来的

- 大部分都知道，不错还是有些新的东西的。


# 经典的卷积神经网络

## LeNet-5 神经网络结构

LeNet-5 是一种典型的用来识别数字的卷积网络。当年美国大多数银行就是用它来识别支票上面的手写数字的，如图 7.5所示。

LeNet-5神经网络识别手写数字：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190615/U9nALkuPlD7g.png?imageslim">
</p>

LeNet-5 共有 7 层，不包含输入，每层都包含可训练参数(连接权重)，如图 7.6所示。输入图像大小为 32×32。

LeNet-5 神经网络结构：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190615/9r7g2NEqhlFK.png?imageslim">
</p>

简单说明：

- 输入层 Input 到 C1 之间：Input 为 32×32，通过 5×5 的卷积运算得到，由 6 个特征图构成。特征图每层为 $(32-5+1)×(32-5+1)=28×28$ 。由于特征图相同层共享权值，而不同层之间权值不同，因此，共有 $6×(5×5+1)=156$ 个参数。

- C1到 S2 之间：S2 层是一个下采样层，有 6 个 14×14 的特征图，S2 中的每个点对应 C1 中 2×2 的区域，再乘以一个系数，再加上一个偏差，结果通过 Sigmoid 函数计算。因此这层共有 6×(1+1)=12 个参数。

- S2到 C3 之间：有 16 种不同的卷积核，所以就存在 16 个特征图。C3总共有 16 层，这层共有 $1516=5×5×(6×3+9×4+1×6)+16$ ，其中最后一项 16 代表 16 个偏差。

- C3到 S4之间：S4层是一个下采样层，由 16 个 5×5大小的特征图构成。

- C5是一个卷积层，共有 120 个特征图，每个特征图的尺寸是 1×1,C5的每个单元与 S4 的 16 个 Feature Map相连。

- F6有 84 个单元，与 C5 全连接，共有(120+1)×84=10164。F6层的计算都是通过输入向量和权值向量相乘，并加偏置，最后通过一个 Sigmoid 函数计算。

- 最后的输出层由欧几里得 RBF 单元组成，每个单元代表一个类别，输入向量与权值向量相差越大，RBF输出越大。F6层为 84 个元素输出。<span style="color:red;">这个 RBF 单元是什么？以前好像没有注意这个地方。补充下。</span>

## ImageNet-2010 网络结构

与计算机视觉顶会 CVPR 2017同期举行的 Workshop——“超越 ILSVRC” (Beyond ImageNet Large Scale Visual Recogition Challenge)，宣布计算机视觉乃至整个人工智能发展史上的里程碑——IamgeNet 大规模视觉识别挑战赛将于 2017 年正式结束，此后将专注于目前尚未解决的问题及以后的发展方向。


截至 2016 年年末，ImageNet 中含有超过 1500 万个由人手工注释的图片网址，也就是带标签的图片，标签说明了图片中的内容，超过 2.2 万个类别。其中，至少有 100 万张里面提供了边框 (Bounding Box)。ImageNet 项目仍在进行中，目前有来自 21841 个不同类别的 14197122 张图像。自 2010 年以来，ImageNet 举办了视觉识别领域的年度竞赛赛事，为参赛者提供来自 1000 个不同类别的 120 万张图像。因此，每个网络架构的准确率都建立在这 1200 万张图像之上，如图 7.7和图 7.8所示：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190615/CBYdCMiv6529.png?imageslim">
</p>


ImageNet LSVRC 是一个图片分类的比赛，其训练集包括 127万张图片，验证集有 5 万张图片，测试集有 15 万张图片。本文截取 2010 年 Alex Krizhevsky 的 CNN 结构进行说明，该结构在 2010 年取得冠军，top-5 错误率为 15.3%。值得一提的是，在 2017 年的 ImageNet LSVRC 比赛中，取得冠军的 GoogNet 已经达到了 top-5 错误率 6.67%。可见，深度学习的提升空间还很巨大。

ImageNet 分类图像：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190615/52xrcrshhvA0.png?imageslim">
</p>

图 7.9 即为 Alex 的 CNN 结构图。需要注意的是，该模型采用了 2-GPU 并行结构，即第 1、2、4、5 卷积层都是将模型参数分为两部分进行训练的。在这里，更进一步，并行结构分为数据并行与模型并行。数据并行是指在不同的 GPU 上，模型结构相同，但将训练数据进行切分，分别训练得到不同的模型，然后再将模型进行融合。而模型并行则是，将若干层的模型参数进行切分，不同的 GPU 上使用相同的数据进行训练，得到的结果直接连接作为下一层的输入。<span style="color:red;">嗯，并行结构，不错。不过这个地方还是想知道 2-GPU 并行结构是什么，是怎么做到的，现在还需要这样做吗？什么场景下需要这么做？如果做的话 用 pytorch 怎么实现？</span>

Alex 的 CNN 结构图：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190615/KKX2X8fE8QDP.png?imageslim">
</p>

基本介绍如下：

- 输入：224×224 大小的图片，3 通道。
- 第一层卷积：5×5 大小的卷积核 96 个，每个 GPU 上 48 个。
- 第一层 Max-pooling:2×2 的核。
- 第二层卷积：3×3 卷积核 256 个，每个 GPU 上 128 个。
- 第二层 Max-pooling:2×2的核。
- 第三层卷积：与上一层是全连接，3×3的卷积核 384 个。分到两个 GPU 上各 192 个。
- 第四层卷积：3×3 的卷积核 384 个，两个 GPU 各 192 个。该层与上一层连接没有经过池化层。
- 第五层卷积：3×3 的卷积核 256 个，两个 GPU 上各 128 个。
- 第五层 Max-pooling: 2×2 的核。
- 第一层全连接：4096 维，将第五层 Max-pooling 的输出连接成为一个一维向量，作为该层的输入。
- 第二层全连接：4096 维。<span style="color:red;">为什么这个地方需要有第二层全连接？而且，第二层全连接的维数与第一层相同？降一点可以吗？</span>
- Softmax层：输出为 1000，输出的每一维都是图片属于该类别的概率。


<span style="color:red;">感觉现在这种深度的网络使用 GPU 还是比较容易训练的。</span>

AlexNet 相比传统的 CNN(比如 LeNet) 有哪些重要改动呢？如图 7.10、图 7.11和图 7.12所示。

- 水平翻转<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190615/QyVIYSR3J9uL.png?imageslim">
</p>

- 随机裁剪、平移变换<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190615/oa7CdzGu1ft1.png?imageslim">
</p>

- 颜色、光照变换<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190615/sLRR7mhCWNwt.png?imageslim">
</p>



AlexNet 由 Alex Krizhevsky 提出，使用 ReLU 处理非线性的部分，而非传统神经网络早期的标准是 Tanh 或 Sigmoid 函数。ReLU的公式为：f(x)= max(0,x)。

ReLU 与 Sigmoid 相比，其优势在于训练速度更快，因为 Sigmoid 的导数在饱和区变得很小，导致权重几乎没有得到更新(如图 7.13所示)。这种情况就是梯度消失问题。


Dropout 应该算是 AlexNet 中一个很大的创新方法，Dropout 方法和数据增强一样，都是防止过拟合的。同时，用 ReLU 代替了传统的 Tanh 或者 Logistic。在每个全连接层后面使用一个 Dropout 层，从而减少过拟合。Dropout 层设置的概率为 $p$，表示每个神经元连接到后层神经元的概率为 $1-p$ 。该架构以概率 $p$ 随机关闭激活函数，如图 7.14和图 7.15所示。

未经过舍弃神经元的模型：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190615/caCoyayYpKlm.png?imageslim">
</p>

经过舍弃神经元的模型：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190615/FKSuoGMM4fbA.png?imageslim">
</p>

AlexNet 中用到了一些非常大的卷积核，比如 11×11、5×5卷积核，之前人们的观念是，卷积核越大，Receptive Field(感受野)越大，看到的图片信息越多，因此获得的特征越好。虽说如此，但是大的卷积核会导致计算量的暴增，不利于模型深度的增加，计算性能也会降低。<span style="color:red;">哦，看到这个地方我知道为什么之前我搭的一个网络对于平移的识别效果不好了，还是要把卷积核调大一点。好吧，刚有理解就被这个被下面这句推翻了。。</span>于是在 VGG (最早使用)、Inception网络中，利用 2 个 3×3卷积核的组合比 1 个 5×5卷积核的效果更佳，同时参数量(3×3×2+1 vs 5×5×1+1)被降低，因此后来 3×3卷积核被广泛应用在各种模型中。<span style="color:red;">好吧，为啥说两个 3×3 的卷积核比一个 5×5 的卷积核效果更好呢？是直接用模型来测试的吗？</span>

## VGGNet网络结构

VGGNet由牛津大学的视觉几何组(Visual Geometry Group)提出，是 ILSVRC 2014中定位任务第一名和分类任务第二名。其突出贡献在于证明使用很小的卷积 (3×3)，增加网络深度可以有效提升模型的效果，而且 VGGNet 对其他数据集具有很好的泛化能力。<span style="color:red;">对，想知道为什么 VGGNet 对于其他数据集有很好的泛化能力呢？</span>


VGGNet 各级别的网络结构图：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190615/CYcG2wTAWtjm.png?imageslim">
</p>

VGGNet 拥有 5 段卷积，每一段卷积 2~3 个卷积层，同时每段尾部会连接一个最大池化层来缩小图片尺寸。VGGNet 一个重要的改变就是使用 3×3的卷积核，用多个卷积核串联来减少总的参数，同时增加非线性变换的能力。<span style="color:red;">嗯，每一段是 2~3 个卷积层加上一个池化层，之前我搭的时候还以为一个卷积加上一个池化会更好呢。。为什么这个是更加合理的？</span>

VGGNet-16 网络结构有六段，前五段是卷积网络，最后一段是全连接网络。

简单介绍如下：

- 第一段卷积网络，两个卷积层(conv_op)，一个最大池化层(mpool_op)。卷积核大小 3×3，卷积核数量(输出通道数)64，步长 1×1，全像素扫描。第一卷积层输入 input_op尺寸 224×224×3，输出尺寸 224×224×64。第二卷积层输入输出尺寸 224×224×64。最大池化层 2×2，输出尺寸 112×112×64。

- 二段卷积网络，2个卷积层，1个最大池化层。卷积输出通道数 128。输出尺寸 56×56×128。

- 第三段卷积网络，3个卷积层，1个最大池化层。卷积输出通道数 256。输出尺寸 28×28×256。
- 第四段卷积网络，3个卷积层，1个最大池化层。卷积输出通道数 512。输出尺寸 14×14×512。
- 第五段卷积网络，3个卷积层，1个最大池化层。卷积输出通道数 512。输出尺寸 7×7×512。
- 输出结果是每个样本扁平化长度为 7×7×512=25088的一维向量。
- 然后连接 4096 隐含点全连接层，激活函数 ReLU。所有隐藏层都使用 ReLU 函数。
- 最后连接 1000 隐含点全连接层，Softmax 分类输出概率。


在 AlexNet 基础上将单层网络替换为堆叠的 3×3的卷积层和 2×2的最大池化层，减少卷积层参数，同时加深网络结构，提高性能。<span style="color:red;">嗯。</span>

采用 Pre-trained 方法，利用浅层网络(A)训练参数，初始化深层网络参数(D,E)，加速收敛。<span style="color:red;">嗯，这个真的有效果吗？为什么是有效果的？感觉 A 抽取的特征在 DE 中并不是很像？为什么这样能加速收敛？</span>采用 Multi-Scale 方法进行数据增强、训练、测试，提高准确率。<span style="color:red;">什么是 Multi-Scale 方法？</span>

去掉 LRN，减少内存的消耗和计算时间。<span style="color:red;">LRN 是什么？</span>

与 ILSVRC-2012 和 ILSVRC-2013 最好的结果相比，VGGNet 优势很大。与 GoogLeNet 对比，虽然 7 个网络集成效果不如 GoogLeNet，但是单一网络测试误差好一些，而且只用 2 个网络集成效果就与 GoogLeNet 的 7 个网络集成效果差不多。效果表现如图 7.17所示。<span style="color:red;">哦，那还真的挺好的，不过这样深的网络的预测结果也要进行集成吗？这种集成的原理是什么？跟简单的分类器的集成感觉还是有些区别的吧？</span>

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190615/oVP2FFk5HJSa.png?imageslim">
</p>


## GoogLeNet 网络结构

GoogLeNet,2014年 ILSVRC 挑战赛冠军，将 Top5的错误率降低到 6.67%。

GoogLeNet是一个 22 层的深度网络。特点有如下。

1. 网络包含 22 个带参数的层。一般来说，提升网络性能最直接的办法就是增加网络深度和宽度，这也就意味着巨量的参数。但是，巨量参数容易产生过拟合，会大大增加计算量。
2. 网络的感受野大小是 224×224，采用 RGB 彩色通道，且减去均值。<span style="color:red;">嗯，为什么强调感受野大小？</span>
3. 网络中间的层次生成的特征非常有区分性，可以给这些层增加一些辅助分类器。采用均值池化层，滤波器大小为 5×5，步长为 3,(4a)的输出为 4×4×512,(4d)的输出为 4×4×528。<span style="color:red;">为什么使用均值池化层？感觉之前的网络都使用的最大池化层吧？有什么好处吗？</span>1×1的卷积由用于降维的 128 个滤波器和修正线性激活。<span style="color:red;">对了，要在什么情况下使用 1×1 的卷积？这个不知道要怎么使用。</span>全连接层有 1024 个单元和修正线性激活，Dropout 层的 Dropped 的输出比例为 70%。线性层将 Softmax 损失作为分类器。



在 3×3 和 5×5 的卷积前用一个 1×1 的卷积来减少计算，修正线性激活。显著增加每一步的单元数目，计算复杂性可受控制。<span style="color:red;">是这样吗？</span>

采用了 Inception 模块的网络要比没有采用 Inception 模块的网络快 2~3 倍。<span style="color:red;">Inception 模块是什么模块？</span>

GoogLeNet(22层) 结构如图 7.18 所示。

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190615/kVQGs0NMEGMq.png?imageslim">
</p>

LSVRC 2014的分类任务有 1000 个子类，120 万张训练图像，5万张验证图像，10 万张测试图像，每张图像中有一个 Ground Truth，性能测量是基于得分最高的分类器预测的，常用指标为 top-1 准确率和 top-5 错误率。

GoogLeNet 最终的 top-5 错误率在验证集和测试集上都是 6.67%，获得了第一。与其他方法相比的提高如图 7.19所示。
<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190615/TRRe0tDf5xQ1.png?imageslim">
</p>




## ResNet网络结构

<span style="color:red;">话说还没有尝试过使用这种残差网络结构来搭建网络，还是要尝试下的，看看有什么样的区别。嗯。</span>

ResNet ， MSRA 何凯明团队的 Residual Networks，在 2015 年 ImageNet 上大放异彩，在 ImageNet的 Classification、Detection、Localization 以及 COCO 的 Detection 和 Segmentation 上均斩获了第一名的成绩，而且 Deep Residual Learning for Image Recognition 也获得了 CVPR2016 的最佳论文。<span style="color:red;">厉害呀</span>

深度学习网络常见问题：

- 深度学习网络的深度越深，常规的网络的堆叠(Plain Network)效果越不好。
- 网络越深，梯度消失的现象就越来越明显，网络的训练效果也不会很好。
- 浅层的网络(Shallower Network)无法明显提升网络的识别效果，如图 7.20所示。

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190615/PFTanDVdo9ql.png?imageslim">
</p>

ResNet引入了残差网络结构(Residual Network)，通过残差网络，可以把网络层做得很深，据说现在达到了 1000 多层，最终的网络分类的效果也非常好，残差网络的基本结构如图 7.21所示：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190615/xiSJk1UCJKOu.png?imageslim">
</p>




ResNet 用神经网络分解来降低拟合函数的复杂度，而损失函数是拟合函数的函数，所以降低拟合函数的复杂度也等同于降低了损失函数的复杂度。假设我们需要拟合的复杂函数为 H(x)，现在我们把 H(x)分解为两个更简单的函数 f(x)和 g(x)，即令 H(x) = f(x) + g(x)。这相当于对于相同数量的层减少了参数量，因此可以拓展成更深的模型。于是作者提出了 50、101、152层的 ResNet，而且不仅没有出现退化问题，错误率也大大降低，同时计算复杂度也保持在很低的程度。<span style="color:red;">啥？这一段感觉没有看懂，你说分解成相乘的可以降低复杂度差不多，分解为相加的怎么降低复杂度？而且以前看的时候好像是强调的减少传播的衰减呀。。</span>

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190615/fDeXKqlE3BlW.png?imageslim">
</p>

图 7.22是 ResNet 网络结构，相当于在普通网络上面插入跳跃结构，对于跳跃结构，当输入与输出的维度一样时，不需要做其他处理，两者相加即可，但当两者维度不同时，输入要进行变换以后去匹配输出的维度，主要经过两种方式，用 Zero-padding 增加维度以及用 1x1 卷积来增加维度。<span style="color:red;">是这样吗？</span>


残差网络结构简单，解决了极深度条件下深度卷积神经网络性能退化的问题，分类性能表现出色。残差网络的广泛使用已推进计算机视觉各任务的性能达到了新的高度。

残差网络表现出的良好图像分类性能，同样也可以进一步推广到人脸识别领域上来。使用残差网络，可以大幅提升人脸分类性能。在人脸识别准确率每 3 个月提升一个数量级的今天，残差网络及未来更高性能的网络结构必定会将这个周期进一步缩短。<span style="color:red;">是吗？人脸识别的准确率每 3 个月都会提升一个数量级？</span>



AlexNet、VGG、GoogLeNet、ResNet对比，如图所示：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190615/nBMlGoe7FrXb.png?imageslim">
</p>

最适合 CNN 的莫过于分类任务，如语义分析、垃圾邮件检测和话题分类。卷积运算和池化会丢失局部区域某些单词的顺序信息，因此纯 CNN 的结构框架不太适用于 PoS Tagging 和 Entity Extraction 等顺序标签任务。<span style="color:red;">什么是 PoS Tagging 词性标注和 Entity Extraction 实体关系抽取？为什么这样的情景 CNN 的结构不太适用？</span>



# 相关

- 《深度学习框架 Pytorch 快速开发与实战》
