# ECCV 2018 共面性检测网络 助力三维场景重建



>
> 长期以来，三维场景重建一直是计算机视觉、计算机图形学和机器人领域亟待攻克的核心、难点问题。最近，国防科技大学徐凯团队与普林斯顿大学、慕尼黑工业大学、谷歌等机构合作提出用于三维重建的共面性检测网络 PlaneMatch，让这一现状得以改变。



共面性检测网络为解决这一问题提供了新的思路，并能够显著提升三维场景重建的质量。目前这项研究工作已被欧洲计算机视觉大会 (ECCV 2018) 收录，并被邀请赴会进行口头报告 (Oral Presentation)。



这项研究工作的完成者包括：国防科技大学-普林斯顿大学联合培养博士施逸飞，国防科技大学副教授、普林斯顿大学访问学者徐凯，慕尼黑工业大学教授 Matthias Niessner，普林斯顿大学教授 Szymon Rusinkiewicz，普林斯顿大学教授 Thomas Funkhouser。



![img](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiblwpDPicLtNnGelOd1CtsZZib5JgL1UV08tqZnqh4BwPe7WCCxaMwc4oo74n2dtRXfZfT4Bywf4Cdg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

*图 1 三维场景重建*



所谓三维场景重建，就是利用输入的二维图像数据恢复场景的三维结构。三维重建在多个领域有着广泛的应用，例如，室内环境设计、增强现实、机器人导航与场景理解。近些年来，随着消费者级别的深度摄像机日益成熟，使用手持式深度摄像机 (例如 Kinect, structure sensor) 获取室内场景的深度数据，再使用特定算法对不同角度拍摄到的数据进行融合，成为了三维场景重建的研究热点。而这当中最难的问题无疑是确定每一个时刻相机在三维空间中的位置。为了实现这一目标，算法必须对从不同角度拍摄的图片进行配准。



在此之前，传统方法往往通过检测不同图片中的共同特征点来实现图片配准。但是由于图片曝光不统一、相机运动太快导致图像模糊等因素，关键点的检测和特征计算差强人意，基于特征点的配准算法有很强的局限性。



为了解决这一问题，人们开始尝试利用较特征点更大的几何体来提高三维场景重建的精度。过去的五年里，这方面的研究工作大多集中于利用平面的共面性对配准结果进行优化矫正。以 CVPR 2017 文章 [1] 中的方法为例，该方法首先利用 SIFT 特征点实现初步配准，然后通过将近似共面平面矫正成完全共面平面来优化相机位置。这种递进式的优化方法虽然能够在一定程度上提高三维场景重建精度，但是却严重依赖于对相机位姿的初始估计。当初始位姿误差很大的时候，该方法无法正确检测帧间的共面平面，从而带来巨大的重建误差。那么，如何才能更好地利用平面提高三维重建精度呢？



![img](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiblwpDPicLtNnGelOd1CtsZZkFic8DrBMwypCZFQkbfMqThhyarVrickzYfkEPYN2B2icLbTtOvFRXwVw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

 *图 2 平面共面性预测*



「我们注意到，人类在判断两个平面是否共面时并不需要估计相机的位姿。为了解决上述问题，一个很直接的想法是让机器具有像人类一样对共面性进行判断的能力。我们提出使用深度网络预测不同帧中的两个平面是否共面，这在三维重建领域尚属首次。」论文的第一作者施逸飞这样介绍这项工作。「人类在做这种判断时，既会观察两个平面的纹理颜色是否一致，也会考虑平面的语义信息。例如，假设我知道两个平面都是地面，那么它们极有可能是共面的。」



![img](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiblwpDPicLtNnGelOd1CtsZZHPlFaMbpQeV8iccJOKcbbwUoCkKicxuQJORnAyh8hVvFdsMtBDd6DLgQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

*图 3 PlaneMatch 算法流程图*



为了使算法具有这种判断能力，网络首先需要计算平面的共面性特征描述。为此，文章作者设计了一种 siamese 网络并用 triplet loss 进行训练。网络的每一个训练样本包括一个参考平面 (anchor)，一个与 anchor 共面的平面 (positive) 以及一个与 anchor 不共面的平面 (negative)。该网络的关键在于以下三大机制：



1) Multiple channel input: 将 color image、depth map、normal map 和 mask map 同时作为网络的输入。多通道输入能够为网络提供更多的信息，其中 color image 和 depth map 提供图片的颜色和深度信息；normal map 由 depth map 计算得到，它显式地提供了与平面直接相关法向信息；mask map 则告诉网络当前关注的平面在整个图像中所处的位置；



2) Multiple resolution input：将两个 scale 的图像数据分别输入网络提取特征，然后在网络的高层进行特征融合。其中 local tower 主要负责提取平面自身的特征，而 global tower 更多地关注该平面的上下文 (context)；



3) Triplet focal loss: 大多数不共面的平面有着完全不同的颜色，随机产生的 triplet 样本往往过于简单，用这样的数据对网络进行训练效率很低。传统方法一般使用在 mini-batch 中选择 hard examples 的策略应对这一问题。本文受 focal loss[3] 的启发，提出一种新的 triplet loss 计算方法 triplet focal loss 更好地挖掘训练数据中的有效信息 (hard example)，提高网络训练的效率。



![img](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiblwpDPicLtNnGelOd1CtsZZyQvwIyEQzzXzGB3zmHXRwfjr8H1mkiajlxAXfM5n4w47h5aPMIwoU1Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

*图 4 Triplet Focal Loss 及其收敛性*



深度网络的训练往往离不开海量的数据。对于平面共面性检测这一全新的问题，文章作者通过三维场景数据集 ScanNet [2] 全自动地生成训练数据。每一个 ScanNet 场景都含有高精度的相机位置参数，通过这些相机位置参数能够准确地计算得到大量的共面训练数据。一共有一百万个这样的样本被用于训练共面性检测网络。



为了验证该网络的有效性，文章作者提出了一个共面检测基准 (Coplanarity Benchmark, COP)。其中包括 6000 个共面的平面对和 6000 个不共面的平面对。在该共面基准上的实验结果表明，该文章提出的共面性检测网络的检测结果远优于其它方法。



![img](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiblwpDPicLtNnGelOd1CtsZZC6thFYLHy4oThNicySkNnicdWonZUL4HhibvnibAbXVsmIiauZO0MneMJXA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

*图 5 共面基准 COP 上的测试结果*



共面性检测网络的直接应用是三维场景重建。文章提出了一种基于共面性的鲁棒优化方法，用于实现基于共面的相机配准，并且使用该方法在 TUM、ScanNet 和 SUN3D 等公开数据集上进行了测试。实验结果表明，该方法的重建精度高，并且能够弥补基于特征点配准算法的不足。其原因在于：



1）平面的面积远大于点，因此平面特征往往比点特征更可靠，这大大提高了算法回环检测 (loop detection) 的能力；



2）在两张图片完全没有重叠 (overlap) 的情况下，共面性网络仍然可以检测到长程的共面平面，给重建提供额外的信息，这对于大规模场景的重建尤为关键。



![img](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWiblwpDPicLtNnGelOd1CtsZZ168Xic186b5CMTZCxIg20iceHH9EL5AAr56iaLweHqz8zHQP6HmKgt2eg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

*图 6 PlaneMatch 三维场景重建结果*



从对场景结构和语义的分析中获取信息实现三维场景重建是非常有前景的研究方向，而平面间的共面约束是一个很好的起点。希望该项研究能够引起业界对该方向的更多关注，推动三维重建由「几何」迈向「语义」。 *![img](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)*



- 项目主页: http://www.yifeishi.net/planematch.html
- 源码发布：https://github.com/yifeishi/PlaneMatch



# 相关

- [ECCV 2018 | 国防科大、普林斯顿提出共面性检测网络：助力三维场景重建](https://mp.weixin.qq.com/s?__biz=MzIxOTczOTM4NA==&mid=2247485764&idx=1&sn=d66683c249f1ccfc7c88d0483a297e35&chksm=97d7ecd3a0a065c56a89c3b7da789569c3f41fee22d296994ebe052b6f7ef5fb7fab356de352&mpshare=1&scene=1&srcid=08203O6LgIdiRpYB4ndNcyGr#rd)
