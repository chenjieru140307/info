
# 物体检测

物体检测技术是无人驾驶感知必不可少的部分。自从2012年CNN在图片分类问题上取得突破，物体检测这个问题自然成为了CNN应用的下一个目标，使用CNN的物体检测算法层出不穷，我们只挑选有代表性的几个算法做介绍。

在CNN在物体识别领域里大行其道之前，通常的做法是类似于DPM（DeformableParts Model）这样的解决方案：在图像上抽取局部特征的组合作为模板，比如基于图像的空间梯度的HOG特征，为了能够处理形变、遮挡等变化，我们建立一个“弹性”的结构把这些“刚性”的部分组合起来，最后加上一个分类器判断物体是否出现。这样的算法一般复杂度较高，需要大量的经验，而且改进和优化难度较大。CNN的到来改变了一切。

R-CNN系列算法是一个两段式的算法，它把物体识别这个问题分为两方面。

- 物体可能所在区域的选择：输入一张图片，由于物体在其中的位置大小有太多可能性，我们需要一个高效的方法找出它们，这里的重点是在区域个数的一定上限下，尽可能地找到所有的物体，关键指标是召回率。
- 候选区域的识别：给定了图片中的一块矩形区域，识别其中的物体并修正区域大小和长宽比，输出物体类别和更“紧”的矩形框。这里的重点在识别的精度。

在了解了算法的大致架构后，我们来看看算法的具体实现，这里我们主要描述R-CNN这一系列算法的最新版：Faster R-CNN，它对应上面的两步分为RPN（Region Proposal Network）和Fast R-CNN，我们将分别介绍。

## 1 RPN

我们称物体可能所在区域为候选，RPN 的功能就是最高效地产生这样一个候选列表。

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200208/MFRDSzk0GIVk.png?imageslim">
</p>

如图所示，RPN选择使用CNN为基础，图片通过多个（比如4个）卷积层进行特征提取，在最后一个卷积层输出的特征图上使用一个3×3的滚动窗口连接到一个256或者512维的全连接隐层，最后再分支到两个全连接层，一个输出物体类别，一个输出物体的位置大小。为了能够使用不同的物体大小和长宽比，在每一个位置上我们考虑三个尺度（128×128、256×256、512×512）和三个长宽比（1：1、1：2、2：1）一共9种组合。这样一个1000×600的图片上我们考虑了（1000/16）×（600/16）×9～20，000种位置大小和长宽比的组合，由于我们使用CNN计算，这一步耗时不多。最后，我们根据空间重叠程度去掉冗余的候选区域，一张图片获得2000个左右的物体可能区域。

## 2 Fast R-CNN

在候选区域分类阶段，我们使用的是基于全连接的神经网络，如图所示的右侧部分。

Fast R-CNN算法原理图：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200208/23qiSgY6U6VQ.png?imageslim">
</p>


根据图左侧的特征提取部分我们可以重用RPN中的CNN计算结果，这大大节约了计算时间，能达到5～17帧每秒的速度。

## 3 MS-CNN

虽然Faster R-CNN算法大名鼎鼎，但在物体尺度变化很大的场景（比如无人驾驶）中还有提升的空间，Multi-scale CNN（MS-CNN）正是针对这个问题的一个尝试。CNN的层级结构由于pooling层的存在自然形成了和不同尺度的对应关系。那我们为什么不把对物体的检测放到CNN的不同层里去呢？这正是MS-CNN的想法。

MS-CNN分层模型示意图：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200208/u5M6O716kh0U.png?imageslim">
</p>


在选择物体候选区域阶段，MS-CNN使用了如图所示的网络结构，我们看到如果把CNN网络里的卷积层看成一个大树的“主干”，那么在conv3、conv4和conv5三个卷积层之后这个网络都长出了“分支”，每个“分支”都连接了一个检测层，负责一定的尺度范围，这样多个“分支”一起，就能覆盖比较宽的物体尺度范围，达到我们的目的。

在候选区域识别阶段，如图所示，我们让上一阶段多个检测层的输出特征图分别输入到一个子网络里，这里有几个值得注意的细节。

MS-CNN算法原理图：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200208/O1sFHorib691.png?imageslim">
</p>


- （1）第一层是个“deconvolution”层，目的是提高特征图的分辨率，保证物体检测的准确率，特别是对尺度偏小的物体来说。
- （2）Deconvolution之后，在抽取物体特征的时候（外框），我们同时还抽取了物体周边的信息（内框），这些“上下文”信息对识别准确率的提高有明显帮助。

总的来说，MS-CNN和Faster R-CNN相比，优势是识别的准确度有很大提高，尤其在物体尺度变化的情况下，比如 KITTI 数据集里的行人和自行车，但Faster R-CNN还是有速度的优势。


## 4 SSD

虽然Faster R-CNN的速度相比之前的R-CNN已经有了很大提高，但还是达不到实时的要求。

Single Shot Detector（SSD）就是一个能够实时运行，有更佳准确度的算法，最近人气很高。SSD沿用了滑动窗口的思想，通过离散化物体的位置、大小和长宽比，使用CNN高效计算了各种可能的物体情况，从而达到高速检测物体的目的，如图所示。

SSD算法原理图：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20200208/dz8UztVoD1NR.png?imageslim">
</p>


SSD使用了VGG-16网络做底层的图片特征提取，通过取消生成候选区域、图片缩放和特征图采样的步骤，一步到位判断物体位置和分类，SSD是一种高速的物体检测算法。

在VGG网络的基础上，SSD加入了逐步变小的卷积层，这些不同尺度的卷积层分别使用3×3大小的卷积核进行物体位置偏移和分类的判断，使得SSD能够检测到不同大小的物体。




