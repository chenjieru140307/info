
# 自动驾驶方案介绍

介绍一下自动驾驶汽车相关的计算机视觉技术。今天在市面上存在着很多和智能汽车有关的视觉公司，但是这些公司基本分为两类：



第一种是ADAS (Advanced Driver Assistant System)技术，就是先进驾驶辅助系统。ADAS的主要功能就是给司机在行驶过程中提供一些和安全有关的提醒，最主要的作用就是驾驶辅助。它是一个辅助功能，它并不参与驾驶，也不对驾驶负任何责任。



第二种是Automatic Driving自主驾驶技术，自主驾驶技术又分为三种形态：

- 辅助驾驶（有的时候是人开、有的时候是机器人开）
- 自动驾驶
- 无人驾驶



自动驾驶和无人驾驶的差别就是汽车里面到底有没有人类司机，如果完全没有的话，它就是无人驾驶。在应用层面上，无人驾驶可以进行分享交通的服务，也就是说这个车有的时候可以为你服务，有的时候可以为他服务。



今天在中国有很多很多的ADAS公司，大多数都是一些计算机视觉公司，自动驾驶公司其实是非常非常少的，大多数也都是一些汽车电子行业有造车能力的公司。以我的理解，严格定义来说，今天我听到的中国做自动驾驶的公司应该只有百度、驭势科技（格灵深瞳分离出来的新公司），还有就是清华大学的智行者。



我们今天介绍的重点在自动驾驶。在自动驾驶层面上视觉感知的意义是什么？



**第一件事情是参与到防碰撞的过程。**也就是说它能够检测出所有可能被碰撞的物体，然后给这个汽车一个安全的决策依据。很幸运的是今天在市场上有一些特别适合做防碰撞的传感器，比如说激光雷达、毫米波雷达，它们都做得非常好。这里面有一个很重要的原因，这些传感器它的工作原理基本上基于物理检测，它们把电磁波发出去，然后根据回波来判断这个障碍物的存在。



在驭势科技，我们主要是使用一种深度传感器，能够把所有物体的点云恢复出来，然后我们把有可能跟汽车碰撞的那部分点云呈现给决策系统。也就是说我们并不去判断这个物体是什么，而是把存在感交给决策系统，事实上什么都不能碰，这就是我对于防碰撞的理解。所以我们的方案是**以物理传感器为主，以计算机视觉为辅，让他们形成一种相互独立的互补系统**。



**第二件事情是Traffic Understanding，即理解交通里面有哪些要素。**这里面包括道路本身的要素，比如说旁边的路标，它会告诉你这里该怎么开，有的时候是单行线、限速、交通灯以及其他的一些原因。我个人觉得用计算机视觉去检测所有的静态交通单元并不是特别好，虽然今天我们检测交通标志以及交通灯的准确度越来越高了，但是我仍然觉得像这些信息完全可以通过无线传输的方式传给车里面。



未来，在自动驾驶汽车这个领域将会出现一个新的方向叫做“v2i”（vehicle to infrastructure），也就是说**未来的汽车会和基础设施进行通话，在地图信息里面会包含所有的路标**。每一个路灯未来都会通过很有效的通讯方式，把他们的状态传递给汽车。那么这样一来汽车只要有效地检测行人、车辆（汽车、三轮车、自行车）就可以了，而这个任务其实用今天的深度学习来解决已经效果比较显著了。



<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190930/28WrGDG0BlqS.png?imageslim">
</p>



既然我们防碰撞已经有了其他的方法，我们为什么要检测这些物体的种类呢？其实这就是跟我们驾驶的决策息息相关的。比如说在一个十字路口，你的汽车要左转，那么按照交通规则你必须让有路权的车，比如说对面需要直行的车辆。如果激光雷达和毫米波雷达，它们没有能力去做识别，它只能告诉你，周围的地形怎么样，哪个地方有一个物体，但是它不能告诉你这个物体是什么。当这个物体是一辆汽车，或者这个物体是一块水泥墩的时候，你的驾驶决策是完全不一样的。



再比如你开车要路过一个斑马线的时候，即使这个斑马线没有任何物体阻挡，但是如果斑马线的旁边站着一个路人，他试图去过斑马线的话，按照很多国家的交通规则，我们是应该让行人先走的，这个时候就涉及到必须识别出这个物体是一个行人。



**第三件事情是定位。**定位非常重要，因为当你要自主驾驶的话，前提条件就是知道你自己在哪，应该开到哪个方向去。但是这个定位的要求精度又很高，你必须很详细地知道你在什么位置，今天在行业内大家普遍对于定位的期待是10厘米左右，但是怎么样获得10厘米精度的定位结果呢？比较成熟的方法有这么几种：



- 第一种是通过高精度的**激光雷达**来定位。它的基本思路是首先有一个地图车，把街景全部扫描一遍，得到这个地区的三维点云，然后经过一定处理后方便来做匹配。下一次当这个汽车开到这个位置的时候，它用激光雷达扫描出来一个新的三维点云，然后通过GPS大概得到自己在一个粗略的方位，这个方位基本上是在100米精度之内的。然后把新的点云信息跟数据库里面的点云进行一个对比，这个匹配的结果就是定位。这个精度可以做到比较高，但是这里面有几个显著的问题：

  a. 用来做定位的激光雷达今天还非常非常昂贵，在中国买一个这样的雷达今天的成本是10万美元；

  b. 它的数据量非常大，它的地图存储很大，很不方便使用。你可以想象有一天一辆汽车装载着全中国所有道路的三维点云吗？我觉得这事想想就挺可怕的。另外，这种场景匹配的过程过多的依赖于整个场景的信息，有些信息是不稳定的。比如说，路旁边的树木它在夏天的时候很茂盛，在冬天的时候都枯萎了。包括你在扫地图的时候可能旁边有一辆车停着，你下次来的时候这辆车又不在了，这些变化的因素都会给激光视觉定位带来潜在的噪音。

- 第二种方式就是使用所谓的**差分GPS**，也叫GPS RTK。它是一种通过天空的定位卫星，以及地面的定位基站共同辅助的方式来提高定位精度的一种技术。这种技术在条件合适的情况下精度非常高，甚至可以达到几毫米，但是这种技术非常非常昂贵。在今天的中国想要购买一套差分GPS的天线成本也是几十万，而且这种技术本身也有缺陷。比如说在隧道里、桥底下、城市的核心区域、被大楼包围的区域，GPS RTK的信号仍然很不理想。百度公司在去年12月份展出的自动驾驶视频里面就采用了这种技术。但他们当时为了做这个展示，也需要临时铺设一些GPS RTK的天线和基站，这种行为其实不具备可商业化的条件。




问题就来了，无论你使用激光雷达，还是使用GPS RTK，往往还要配合一颗精度非常高的惯导，叫Inertial Sensor(INS)，这个INS精度高的时候也是贵的不得了，便宜的也要二三十万，我听说有一些创业公司希望能够把这种传感器的成本大大降低，比如说降低5倍，那也要好几万，所以我觉得这些方法都不具备可商业化的可能性。



所以计算机视觉在这个时候的重要性就体现出来了。大家思考一个问题，是不是有一天我们**可以用计算机视觉就能够完成精度很高的全局定位**？如果这件事情可以做到的话，我觉得它的意义非常大，远远比做防碰撞要重要的多。



今天我们在机器人视觉里面做定位的视觉技术，比如说visual slam、visual odometry这些技术，在一个小的范围内用的还不错。但是当我们在世界范围使用的时候，比如说我们想象一下**如何运用visual slam的技术，使其在全中国所有的道路适用**。我觉得我们过去的算法都是不可靠的，今天格灵深瞳也在研发相关的技术，我们希望我们未来可以实现这个目标，我个人认为这是我们对无人驾驶技术最大的贡献。


# 相关

- [【万字实录】格灵深瞳赵勇：计算机视觉在安防、交通、机器人、无人车等领域的应用](https://mp.weixin.qq.com/s?__biz=MzAxMzc2NDAxOQ==&mid=2650357389&idx=1&sn=6b26d45cfb878f50ff3624308547914d&scene=21#wechat_redirect)
