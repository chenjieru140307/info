

## **无人驾驶为什么需要机器学习？**

很多人可能不理解为什么自动驾驶需要机器学习技术，让我们首先来看人是怎么驾驶车辆的。现在要开车从清华大学东门去北京首都机场 T3 航站楼，你作为司机要完成这一次驾驶任务。接下来你会怎么做？



1. 首先，你要知道本次行驶的起始地和目的地。如果是老司机，你会知道按照什么样的路线开到机场去；如果不是，则需要借助导航软件，它将为你计算出一条最优的行驶路径。下面是搜狗地图为我们计算出来的路径：

![mark](http://images.iterate.site/blog/image/20190905/9CgkVPeepM69.png?imageslim)

这里涉及到**定位，路径规划**的问题。前者可以通过 GPS 或其他技术手段来实现，后者也有成熟的算法，如 Dijkstra 或者 A*搜索算法，学过数据结构和算法的同学对 Dijkstra 算法都不会陌生，它给出了计算图的两个节点之间最短距离的方案。目前，这一问题已经很好的解决了，而且计算机比人要强。



2. 接下来，你就要启动汽车开始行驶了。首先你要知道的是：路在什么地方？应该上哪个车道？

![mark](http://images.iterate.site/blog/image/20190905/kurcjJaguSOv.png?imageslim)


这就是机器学习登场的时候了，它要解决**路面和车道线检测**问题。目前主流的自动驾驶系统一般都采用了激光雷达+摄像机+其他传感器相结合的方案。无论是激光雷达扫描得到的 3D 距离数据，还是摄像机成像的 2D 数据，我们都要对它们进行分析，以准确的确定路面的位置，车道线和每个车道的范围。


3. 在找到了道路和车道之后，我们就要开始行驶了，你要控制油门，刹车，方向盘。现在问题又来了，怎么开？

![mark](http://images.iterate.site/blog/image/20190905/LjYD1Vp8vqs6.png?imageslim)


你得知道路上有没有车，有没有人，有多少车，有多少人，以及其他障碍物，它们在路面的什么地方。这又是机器学习和机器视觉要解决的问题，同样是**检测**问题。我们需要对激光雷达或者摄像机的图像进行分析，得到这些障碍物的准确位置。



4. 行驶过程中，你遇到的这些行人，车辆都是移动的，因此你必须要对他们的运动趋势做出预判。你前面的车辆、后面的车辆的行驶速度和轨迹都会影响你要采取的动作。如果有人要过马路，距离你还有 30 米，你是停下来等他过去，还是慢速行驶过去？

![mark](http://images.iterate.site/blog/image/20190905/KzQ1nNbE9LT5.png?imageslim)


这是机器视觉中的**目标跟踪**问题，我们要准确的跟踪出人，车辆，动物等移动目标的运动轨迹，估计出他们的运动速度与方向，以便于做出决策。



5. 行驶一会儿之后，你遇到了第一个十字路口，这里有红绿灯，当前是红灯，因此你需要停下来等待，而不是硬闯过去，这又涉及到一个问题，你怎么知道这些交通灯？

![mark](http://images.iterate.site/blog/image/20190905/raChAF3dAbNU.png?imageslim)


这依然是机器视觉要解决的问题，即准确的**检测**出图像中的交通灯，并知道它们当前的状态。除了红绿灯之外，还有其他交通标志需要我们识别，比如速度限制、是否允许调头等。



6. 还有一个问题没有解决，在知道这些环境参数之后，我们该怎么行驶？即根据环境参数得到要执行的动作，在这里是车辆行驶的速度（速度是一个矢量，具有大小和方向）。最简单的做法是用规则来做决策，我们总结出人驾驶车辆的经验，前面没有车，后面没有车的时候该怎么行驶；前面有 2 辆车，后面有 3 辆车的时候该怎么行驶.....。问题是：各种情况实在是太多了，我们无法穷举出所有的情况。



对于这个问题的一个解决方案是深度强化学习，和 AlphaGo 类似的一种技术，这也是一种机器学习算法。它的思路是根据环境的参数预测出要执行的动作，我们用一些数据进行训练，得到这样一个模型，也就是人开车时的经验，然后用它来做决策。

但是这种方法有一个严重的问题，神经网络的预测结果不具有可解释性，有时候会出现莫名其妙的结果，这会严重影响安全性。关注过 AlphaGo 的同学都知道，在一次对战中，它下出了一个完全无法理解的棋，对于自动驾驶来说，这可能是一个灾难。


# 相关

- [机器学习在自动驾驶中的应用-以百度阿波罗平台为例【上】](https://zhuanlan.zhihu.com/p/37472084)
