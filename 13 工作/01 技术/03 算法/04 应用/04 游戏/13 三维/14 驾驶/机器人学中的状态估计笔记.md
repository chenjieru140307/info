有感而发
《机器人学中的状态估计》中文译本，买回了二十天，到今晚大概扫了一遍。虽然大部分内容都是不看详细的公式推导的，相比看这本书前，还是有不小收获的。

再次相信了“开卷有益”这句话，也确实觉得这本书要比《概率机器人》讲的更加明白，也可能是看概率机器人时，只有一点点的基础，而现在大部分东西基本都搞明白了，所以看这本书相对来说并没有看《概率机器人》时那么吃力。

也再次对自己说一句，你不可能看一遍就把一本书中的所有内容都掌握了，要求不要太高，有所收获有所领悟哪怕是一点点都是很值得的。不管看懂看不懂，当你看第一次看完这本书的时候，你已经掌握了这本书里10%的内容了。

自问自答
1、粒子滤波和无迹卡尔曼讲的比《概率机器人》要简单易懂，大概是看明白了。

2、先验、似然、后验到底是什么意思？

说真的，现在才真正明白。。（菜是原罪）在状态估计中，可以这么理解，先验就是没有得到观测值时的概率分布，似然就是观测的概率分布，后验就是在得到观测值后对先验校正后的概率分布。

3、线性高斯系统和非线性非高斯系统有什么区别？

高斯分布，也就是正太分布，在线性系统中，通过线性变换后，依然是高斯分布。比如一个x~N(1,9)的分布，通过线性变换函数y=2x后，y的分布为y~N(2,36)依然是高斯分布。卡尔曼滤波的推导就是基于这种线性高斯系统的。
但是如果经过非线性变换函数z=x2，那么z就不再是一个高斯分布了，既然它不是高斯分布，自然就也不能用z~(均值,方差)这种形式表示了，只有高斯分布才可以这样写。但是你非要把它当做一个高斯分布也可以，就是把它的均值算出来，方差算出来，然后近似用高斯分布去表示。这就是通过滤波来求解非线性非高斯系统的思路，虽然不是高斯，但是我把你均值方差求出来，强行当做高斯。扩展卡尔曼、无迹卡尔曼、粒子滤波都是这种思路。

而如果使用优化的方法求解的话，就跳过了高斯分布的这个假设，它并没有涉及到均值方差的概念，直接构建误差函数，求得使总误差最小时的状态量即可。

4、递归估计和批量估计有什么区别？

递归是滤波形式的，只考虑上一时刻的状态；而批量是优化形式的，会考虑前面所有时刻的状态。

滤波器分类，卡尔曼、粒子滤波全都是基于贝叶斯滤波推导出来的。

而非线性优化是基于最大似然估计（MAP，maximum a posteriori）或最大后验估计的 (ＭＬ，maximum likelihood)推导的。这是两种推导方式。

<p align="center">
    <img width="50%" height="50%" src="http://images.iterate.site/blog/image/20200207/duybA1Hac0gr.png?imageslim">
</p>


5、迭代扩展卡尔曼滤波（IEKF）相较于非迭代版本有什么区别？

普通的扩展卡尔曼滤波在线性化时泰勒展开是在均值处展开的，而迭代卡扩展尔曼滤波则是随便选了个点展开，然后通过迭代方法求得一个收敛的值。

6、（BA）bundle adjustment和SLAM的区别是什么？

最本质的区别是：BA是一个最大似然问题，SLAM是一个最大后验问题。也就是说，BA只有观测值，而SLAM还要知道机器人是如何运动的，即要有一个运动模型。见中文书P308

7、为什么GPS+IMU融合时还要要估计加速度和陀螺仪的偏差？

看了第五章后明白了，因为在经典的卡尔曼滤波中，都是在假设噪声是零均值高斯误差模型下推导的。但是像加速度这种控制量，它是会有零偏的，也就是它所测量的值随时间会有一个固定的偏差，这样的话加速度的误差就不是零均值高斯误差模型了。如果卡尔曼滤波不考虑这些，会导致误差不是无偏的。按我之前的理解，状态量只要速度、朝向、位置就够了，但是看别的书上都是还要把偏差也估计出来，之前不理解，现在终于理解了。

实战才是王道
看了这么多理论，总的大概是入们SLAM了。其实最重要是实战，你不可能自己写一个后端优化的东西，学会熟练使用开源库是一项很重要的技能。动手能力才是真正的能力，老板让你做一个东西，不是让你看书学习的（虽然看书学习很重要），他要听的是结果，你做出了什么，不是你学了什么，弄明白了什么。所以，下一步，重点学习GTSAM库的使用，用它来做一些东西出来。
————————————————
版权声明：本文为CSDN博主「冰冻三尺go」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/u012686154/article/details/89222363