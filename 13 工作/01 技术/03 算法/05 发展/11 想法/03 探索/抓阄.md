# 受婴儿抓阄启发，谷歌让机器臂自学抓取物体，不用标注数据




![img](https://pic2.zhimg.com/v2-c0c44f184fb73848e61f8130e1d5feb9_b.webp)
谷歌大脑让AI更像儿童了，至少在对象识别和感知方面是这样。最近，他们和加州大学伯克利分校的学生研究了一种算法**Grasp2Vec**，通过观察和操纵来“学习”物体的特征。在硬件方面，谷歌团队与X Robotics合作，调教出一个能够**无目的**、像婴儿抓阄一样抓住物体的机器人手臂，并在训练过程中让它学习各种物体的表征，最终实现“有目的”地抓取某个确定的物体。
![img](https://pic3.zhimg.com/v2-37c6046b388d0d75984af6de6dbe1be2_b.jpg)
在这项工作公布几个月之前，OpenAI展示过一种类似算法**Dense Object Nets**（DON），它能让机器人发现、理解和操纵它们从未见过的物体。
谷歌这套机器人对于已经见过的物体，有80%识别并成功抓取的概率，对从未见过的物体也有59%的正确率。

![img](https://pic3.zhimg.com/80/v2-75120ecb3e99d66ab76e300da8ace2e6_hd.jpg)

**从婴儿获得启发**
谷歌研究人员表示，这套算法是基于对自我监督的认知发展研究。人类从婴儿时代开始，就能够识别喜欢的物品并将它们捡起来，在与周围世界的互动中自我监督学习。因为我们知道自己做了什么，并且会从实践的结果中获得认知。在机器人技术中，人们正在积极研究这种类型的自我监督学习方法。因为有了它，在不需要大量训练数据或人工监督的情况下，机器人系统也能够进行学习。
![img](https://pic4.zhimg.com/80/v2-b04359be834ca0d93f7b7a191e58500f_hd.jpg)
**机器人的奖励函数**想让机器人找到并抓取我们给定的物体，需要解决2个问题1、对任意角度和位置摆放的物体，能够与给定的照片进行对比，判断二者是否为同一个物体。2、在一堆杂乱摆放的物体中，找到与“目标”最相似的物体，排除其他错误选项。实现这两点，首先要对这套强化学习系统构建奖励函数。在强化学习（RL）的框架中，任务是否成功通过**奖励函数**来衡量。 通过最大化奖励，机器人可以从头开始自学各种各样的技能。然而，针对机器人对物体的感知理解，设计奖励函数要困难得多。向机器人提供期望被抓起物体的图片，在机器人试图抓住该物体后，它会检查抓取的内容。
![img](https://pic1.zhimg.com/80/v2-c5101df9faab7e161a1327fa25689414_hd.jpg)
因此任务的奖励函数归结为回答对象识别问题：这些对象是否与抓取的目标匹配？接着，为了解决识别问题，需要设计一种感知系统。该系统能从没有人为标注的非结构化图像数据中提取有意义的对象概念，以无监督的方式习得对物体的视觉感知力。无监督学习算法的核心是，对数据做出结构性假设。然而，如果没有对数据内容的进一步假设，则不足以让AI学会分离出对象的表征。而可以活动的机器人，恰好为表征学习提供了一个非常合适的条件。因为机器人可以操纵对象移动，为数据提供了变化因素。**寻找目标**
![img](https://pic4.zhimg.com/80/v2-a1deee76a15e948e2f59b710e31a3057_hd.jpg)
对于从场景中识别被抓取对象，有以下3幅图像：
1）抓取前的场景图像，2）抓取后的场景图像，3）抓取物体本身的视图。
![img](https://pic4.zhimg.com/80/v2-47f056b4d0e85418185d9a9df1cf44cf_hd.jpg)
如果定义一个从图像中提取“对象”的嵌入函数，它应该存在以下减法关系：

![img](https://pic2.zhimg.com/80/v2-a0561de8ef69dae4f47b9042b2f68cc1_hd.jpg)
谷歌使用完全卷积架构和简单的度量学习算法，来实现这种等式关系。 在训练时，将抓取前图像和抓取后图像放入密度空间特征图中，用“抓取前”和“抓取后”向量之间的差异表示一组对象。
这个差值向量和被抓取对象的相应向量表征，通过**N配对目标**（N-pairs object）归于等价。
![img](https://pic4.zhimg.com/80/v2-a5356c089d9b53559cf1b1474847d5df_hd.jpg)
经过训练，模型中会自然出现两个有用的属性：1、**对象的相似性**第一个属性是向量嵌入之间的**余弦距离**（即两个向量之间夹角的余弦）。它用来比较对象，并确定它们是否相同，可以用于实现强化学习的奖励功能，并允许机器人在没有人类提供的标签情况下学习抓取。
![img](https://pic1.zhimg.com/80/v2-6350fa5f5543b2e9f8a433a12b5f48f0_hd.jpg)
2、**本地化目标对象**
第二个属性是本地化图像空间中的**查询对象**，可以通过组合场景空间映射和对象嵌入来实现。
通过获取空间要素图的元素乘积和对应于查询对象的向量，我们可以找到空间映射中与查询对象匹配的所有图像中的物体。
![img](https://pic2.zhimg.com/80/v2-c6893d808893ba26b1dd76750ef936dd_hd.jpg)
最终得到的“热图”，可用于规划机器人寻找目标对象的方法。
谷歌将**有目的**的Grasp2Vec物体识别算法，与之前**无目的**的“机器人抓阄”策略相结合，实现了对已认识物体80％的找到成功率。最后，附上论文地址：
[https://arxiv.org/pdf/1811.06964.pdf](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1811.06964.pdf)
— **完** —
量子位 · QbitAI
վ'ᴗ' ի 追踪AI技术和产品新动态
[量子位​www.zhihu.com![图标](https://pic4.zhimg.com/v2-ca6e7ffc10a0d10edbae635cee82d007_ipico.jpg)](https://www.zhihu.com/org/liang-zi-wei-48)欢迎大家关注我们，以及订阅[我们的知乎专栏](https://zhuanlan.zhihu.com/qbitai)
**诚挚招聘**
量子位正在招募编辑/记者，工作地点在北京中关村。期待有才气、有热情的同学加入我们！