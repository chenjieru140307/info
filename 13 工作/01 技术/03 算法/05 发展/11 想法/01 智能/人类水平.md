
如今，设计和建立一个机器学习系统比以前变得更为简单高效，一些机器学习算法的在很多领域的表现已经可以和人类一决高下了，例如由Google DeepMind开发的声名全球AlphaGo。

然而，很多任务对于我们人类来说，都能够几近完美地完成，机器学习系统也在试图达到甚至超越人类的表现水平。

![img](https://mmbiz.qpic.cn/mmbiz_jpg/nJZZib3qIQW7MI8THInaNxBDv18iawhZCgs2QIIZic1gricuzWIFm0BCmA4oiaXOfyibdgDs77mUogwBrQx2U0JicibE9w/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

上图展示了随着时间的推进机器学习和人的表现水平的变化，一般的，当机器学习超过人的表现水平后，它就进步地很缓慢了，其中有一个重要的原因是人类的对于一些自然感知问题的表现水平几近于**贝叶斯误差（Bayes Error）**。

贝叶斯误差被定义为**最优的可能误差**，换句话说，就是**任何从 x 到精确度 y 的映射函数都不可能超过这个值**。

当建立的机器学习模型的表现还没达到人类的表现水平时，可以通过各种手段来提升它。例如采用人工标记过的数据进行训练，通过**人工误差分析**了解为什么人能够正确识别，或者是进行**方差、偏差分析**。

在优化神经网络中曾涉及过**偏差**和**方差**的概念，通过与人类在某件事情上的表现水平向比较，可以清楚地表明一个机器学习模型对此的表现的好坏程度，由此作出判断出后续应该进行减小偏差还是减小方差。



![img](https://mmbiz.qpic.cn/mmbiz_jpg/nJZZib3qIQW7MI8THInaNxBDv18iawhZCg3m70tzZZCJaXOc0nJPpLfwIhvVfTxF3t1fBH1tW8GZhLJoAgFSLm4A/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**训练集的误差和人类表现水平的误差之间的差值**称为**可避免偏差（Avoidable Bias）**。

例如上图中的两个场景下，将人的错误率和机器学习模型的错误率进行比较，看以看出在A场景下，学习算法的错误率和人的错误率的可避免偏差较大，这种情况下后续的工作就是通过之前介绍过的方法来降低训练集的错误率，以减小偏差。而在B场景下，学习算法和人的表现相当，偏可避免偏差只有0.5%，，后续的工作就应该转向尽可能地减小开发集和训练集那部分2%的方差。

**人类表现水平给出了一种贝叶斯误差的估算方式**，训练针对某类事物的机器学习系统时，以该事物上人类表现水平作为贝叶斯误差，避免了训练过程中将训练的错误率直接以0%为目标进行优化。

所以在获取到某项任务的人为误差数据时，就可以将这些数据作为贝叶斯误差的代理，以此来分析学习算法的偏差及方差。

如果训练集与人类表现水平之间的误差差值大于训练集与开发集之间的差值，往后就应该专注于降低偏差，反之，就应该专注于降低方差。

![img](https://mmbiz.qpic.cn/mmbiz_jpg/nJZZib3qIQW7MI8THInaNxBDv18iawhZCgCnYTg7FRBU93gg12F5YFlrufMfsSI5l0CegYH5Ke7MN50JIYUVulHw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

上图中总结出了各种应对偏差及方差的方法。总之，可避免偏差小，便意味着模型的训练过程做的比较好；可接受范围内的方差意味着建立的模型在开发、测试集上的表现与在训练集上是同样好的。

此外，如果出现可避免误差为负值，也就是机器学习模型的表现超过人类表现水平（贝叶斯误差的代理）情况时，并不意味着你的模型的性能已经达到极点了，往后还想要提高其表现水平，就要另寻一些常规方法进行优化。


# 相关

- [【deeplearning.ai】深度学习：结构化机器学习项目上](https://mp.weixin.qq.com/s?__biz=MzI4MDYzNzg4Mw==&mid=2247487547&idx=1&sn=7be7334ca0c209a34736797cfc50366a&chksm=ebb428efdcc3a1f9cfc9a6c325b8fd6961a5bd84d3b00ca7c700396e62720ad92f9cee1bae9c&mpshare=1&scene=1&srcid=0414krwUEZREbT0uLXrsn8gb#rd)
