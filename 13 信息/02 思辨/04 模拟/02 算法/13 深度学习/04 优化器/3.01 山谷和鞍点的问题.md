

进一步地，有人会说深度学习中的优化问题本身就很难，有太多 **局部最优点的陷阱。没错，这些陷阱对随机梯度下降法和批量梯度下降法都是普遍存在的。** <span style="color:red;">是的。</span>

但对随机梯度下降法来说，可怕的不是局部最优点，而是**山谷和鞍点**两类地形。山谷顾名思义就是狭长的山间小道，左右两边是峭壁；鞍点的形状像是一个马鞍，一个方向上两头翘，另一个方向上两头垂，而中心区域是一片近乎水平的平地。

为什么随机梯度下降法最害怕遇上这两类地形呢？

- 在山谷中，准确的梯度方向是沿山道向下，稍有偏离就会撞向山壁，而粗糙的梯度估计使得它在两山壁间来回反弹震荡，不能沿山道方向迅速下降，导致收敛不稳定和收敛速度慢。
- 在鞍点处，随机梯度下降法会走入一片平坦之地（此时离最低点还很远，故也称 plateau）。想象一下蒙着双眼只凭借脚底感觉坡度，如果坡度很明显，那么基本能估计出下山的大致方向；如果坡度不明显，则很可能走错方向。同样，在梯度近乎为零的区域，随机梯度下降法无法准确察觉出梯度的微小变化，结果就停滞下来。

<span style="color:red;">是的。</span>






# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions) 原文
