
## Graph Networks：

Graph networks是由众多**graph network（GN）block**连接而成的网络。其中，GN block是一切的核心，也是上述 structured representation，high RIB的集中体现。GNN中流动的数据往往是 graphs，这有别与 CNN 和 RNN 中的 vectors and tensors。

顾名思义，GN是基于 Graph 设计的，而 graph，无非就是 node，edge，（**nodes和 edge 各自有自己的 attributes，attributes可以是一个 vectors 或者 tensors**）和 attributes。GN block的定义如下：input a graph, do some computations on it, then output a graph with same topology.


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190901/zENJUvSFz71G.png?imageslim">
</p>

在训练时，对 GN block的 update 遵循 3 个 update function和 3 个 aggregate function（CNN中的 update function就是加权求和）：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190901/3yszufIpcCqV.png?imageslim">
</p>

一个 GN 的 update 和 aggreate function是全局 reused 的，这与 CNN 中 conv filter的全局 reuse 相似，这造就了一定的 locality 和一定的可增值性，也就是一定的 CG，因为 CG 的体现可以理解为可增殖可 configurable 性，这体现了模型对于不同数据的适应性。**这其中，update function往往是 CNN，RNN或者 MLP，aggregate functions是 sum, mean, max or min。换言之，一个 GNN 中的 learnable part是 update functions。**

每个 iteration 一个 GN update是由一定流程的：总的来说就是由 edge 到 node 再到全局 global attributes，中间伴随着每一次升级的 aggregation。

![mark](http://images.iterate.site/blog/image/20190901/oKsgUHBHEY4O.png?imageslim)

1. Characteristics and design principles：
Flexibility；configurability；composable multi-block architecture；

       **GN block的最大优势是强有力的 RIBs：而 RIB 是 CG 的保证！！**

    1. Flexibility：Can facilitate arbitrary relationships among entities, which means can hold whatever he input graph presents;
    1. Ordering Invariance：Entities (nodes) and their relations (edges) are presented in sets, so they are invariant to permutations, GNs are invariant to the order of the elements.
    1. CG with high configurability: GN’s per-edge and per-node functions are reused across all edges and nodes, this copy&paste reusing functionalities supports a form of CG, because a GN block with its defined 3 update and 3 aggregate functions can be reused in a graph input with arbitrary numbers of nodes and edges and topologies.
 

GNN是由众多 GN blocks通过某种方式连接而成。这种 multi-block连接（级联）与 CNN 中组合 Conv layers的方式类似。

![mark](http://images.iterate.site/blog/image/20190901/4qVu4CkCSnVf.png?imageslim)

GNN的 configurability:

1. GN block configurable: update function & aggregate function
2. GNN structure configurable: MPNN，NLNN

![mark](http://images.iterate.site/blog/image/20190901/YUmn8jcQPbM9.png?imageslim)


Discussion

MLP, CNN, RNN all have RIBs, but they can not handle more structured representations such as sets or graphs. GN can build stronger RIB into DL, performing computations over graph-structure data.

GN naturally supports CG because they do not perform computations strictly at the system level, but also apply shared computations across entities and across the relations as well. This allows never-before-seen systems to be reasoned about, because they are bulti from familiar components.



# 相关

- [GNN新作《Relational inductive biases，deep learning，and graph networks》读书笔记](https://blog.csdn.net/Trasper1/article/details/81475667)
