
# 得分匹配和比率匹配

得分匹配(Hyvrinen,2005b)提供了另一种训练模型而不需要估计 Z 或其导数的一致性方法。对数密度关于参数的导数-xlog p(x)，被称为其得分(score)，得分匹配这个名称正是来自这样的术语。得分匹配采用的策略是，最小化模型对数密度和数据对数密度关于输入的导数之间的平方差期望：

该目标函数避免了微分配分函数 Z 带来的难题，因为 Z 不是 x 的函数，所以-xZ=0。最初，得分匹配似乎有一个新的困难：计算数据分布的得分需要知道生成训练数据的真实分布 pdata。幸运的是，最小化 L(x,θ)的期望等价于最小化下式的期望

其中 n 是 x 的维度。

因为得分匹配需要关于 x 的导数，所以它不适用于具有离散数据的模型，但是模型中的潜变量可以是离散的。

类似于伪似然，得分匹配只有在我们能够直接估计及其导数的时候才有效。它与对仅提供下界的方法不兼容，因为得分匹配需要的导数和二阶导数，而下限不能传达关于导数的任何信息。这意味着得分匹配不能应用于隐藏单元之间具有复杂相互作用的模型估计，例如稀疏编码模型或深度玻尔兹曼机。虽然得分匹配可以用于预训练较大模型的第一个隐藏层，但是它没有被用于预训练较大模型的较深层网络。这可能是因为这些模型的隐藏层通常包含一些离散变量。

虽然得分匹配没有明确显示具有负相信息，但是它可以被视为使用特定类型马尔可夫链的对比散度的变种(Hyvrinen,2007a)。在这种情况下，马尔可夫链并没有采用 Gibbs 采样，而是采用一种由梯度引导局部更新的不同方法。当局部更新的大小接近于 0 时，得分匹配等价于具有这种马尔可夫链的对比散度。

Lyu(2009)将得分匹配推广到离散的情况(但是推导有误，后由 Marlin et al.(2010)修正)。Marlin et al.(2010)发现，广义得分匹配(generalized score matching，GSM)在许多样本观测概率为 0 的高维离散空间中不起作用。

一种更成功地将得分匹配的基本想法扩展到离散数据的方法是比率匹配(ratio matching)(Hyvrinen,2007b)。比率匹配特别适用于二值数据。比率匹配最小化以下目标函数在样本上的均值：

其中 f(x,j)返回 j 处位值取反的 x。比率匹配使用了与伪似然估计相同的策略来绕开配分函数：配分函数会在两个概率的比率中抵消掉。Marlin et al.(2010)发现，训练模型给测试集图像去噪时，比率匹配的效果要优于 SML、伪似然和 GSM。


类似于伪似然估计，比率匹配对每个数据点都需要 n 个的估计，因此每次更新的计算代价大约比 SML 的计算代价高出 n 倍。
与伪似然估计一样，我们可以认为比率匹配减小了所有只有一个变量不同于训练样本的状态的概率。由于比率匹配特别适用于二值数据，这意味着在与数据的汉明距离为 1 内的所有状态上，比率匹配都是有效的。

比率匹配还可以作为处理高维稀疏数据(例如词计数向量)的基础。这类稀疏数据对基于 MCMC 的方法提出了挑战，因为以密集格式表示数据是非常消耗计算资源的，而只有在模型学会表示数据分布的稀疏性之后

，MCMC采样才会产生稀疏值。Dauphin and Bengio(2013)设计了比率匹配的无偏随机近似来解决这个问题。该近似只估计随机选择的目标子集，不需要模型生成完整的样本。

读者可以参考 Marlin and de Freitas(2011)了解比率匹配渐近效率的理论分析。




# 相关

- 《深度学习》花书
