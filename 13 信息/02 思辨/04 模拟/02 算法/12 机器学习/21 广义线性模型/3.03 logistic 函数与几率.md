

# Logistic 函数与几率


## Logistic 函数

Logistic 函数 (logistic function) 正是这样的一个常用来近似单位阶跃函数的函数。

$$
y=\frac{1}{1+e^{-z}}\tag{3.17}
$$

从之前的图可以看出，Logistic 函数是一种 "Sigmoid 函数"，Sigmoid 函数即形似字母 s 的函数，它将 $z$ 值转化为一个接近 $0$ 或 $1$ 的 $y$ 值，并且其输出值在 $z= 0$ 附近变化很陡。嗯，我们将 Logistic 函数作为 $g^-(\cdot )$  代入广义线性模型，就得到了：

$$
y=\frac{1}{1+e^{-\left(\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}+b\right)}}\tag{3.18}
$$

这个式子可以变化为：

$$
\ln \frac{y}{1-y}=\boldsymbol{w}^{\mathrm{T}} \boldsymbol{x}+b\tag{3.19}
$$


## 几率

OK，看到这个式子，我们要注意，如果我们将 $y$ 视为样本 $\boldsymbol{x}$ 作为正例的可能性，那么 $1-y$ 就是其反例可能性，那么两者的比称为"几率" (odds) ，几率反映了作为正例的相对可能性：


$$\frac{y}{1-y}\tag{3.20}$$

而我们对几率取对数则得到 "对数几率" (log odds，亦称 logit )，即：


$$
\ln \frac{y}{1-y}\tag{3.21}
$$

<span style="color:red;">厉害了，没想到对数几率是在这里出现的，对于 Logistic 回归函数进行变换就可以得到。</span>

由此我们可以把这个式子 $ln\frac{y}{1-y}=w^Tx+b$ 解读成：我们是在用线性回归模型的预测结果去逼近真实标记的对数几率。<span style="color:red;">嗯是的。很精彩！</span>

因此，其对应的模型 $y=\frac{1}{1+e^{-(w^Tx+b)} }$ 称为 "Logistic 回归" (logistic regression，亦称 logit regrssion) 。






# 相关

- 《机器学习》 周志华
- [pumpkin-book](https://github.com/datawhalechina/pumpkin-book)
