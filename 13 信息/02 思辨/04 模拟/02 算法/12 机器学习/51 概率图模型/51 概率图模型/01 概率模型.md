
# 概率模型


机器学习最重要的任务，是根据一些已观察到的证据(例如训练样本)来 对感兴趣的未知变量(初如类别标记)进行估计和推测。

概率模型(probabilistic model)提供了一种描述框架，将学习任务归结于计算变量的概率分布。

在概率模型中，利用已知变量推测未知变量的分布称为“推断”(inference)，其核心是如何基于可观测变量推测出未知变量的条件分布。

具体来说，假定所关心的变量集合为 $Y$ ，可观测变量集合为 $O$ ，其他变量的集合为 $R$，“生成式”(generative)模型考虑联合分布 $P(Y,R,O)$ ，“判别式”(discriminative)模型考虑条件分布 $P(Y,R|O)$。

给定一组观测变量值，推断就是要由 $P(Y,R,O)$ 或 $P(Y,R|O)$ 得到条件概率分布 $P(Y|O)$.

直接利用概率求和规则消去变量 $R$ 显然不可行，因为即便每个变量仅有两 种取值的简单问题，其复杂度已至少是 $O(2^{|Y|+|R|})$ 。

另一方面，属性变量之间往往存在复杂的联系，因此概率模型的学习，即基于训练样本来估计变量分布的 参数往往相当困难。为了便于研究高效的推断和学习算法，需有一套能简洁紧凑地表达变量间关系的工具.






# 相关

- 《机器学习》周志华
