

# 对类别特征进行编码

我们经常会遇到一些类别特征，这些特征不是离散型的数值，而是这样的：["男性","女性"],["来自欧洲","来自美国","来自亚洲"],["使用 Firefox 浏览器","使用 Chrome 浏览器","使用 Safari 浏览器","使用 IE 浏览器"]等等。这种类型的特征可以被编码为整型（int），如["男性","来自美国","使用 IE 浏览器"]可以表示成[0,1,3]，["女性","来自亚洲","使用 Chrome 浏览器"]可以表示成[1,2,1]。这些整数式的表示不能直接作为 sklearn 的参数，因为我们需要的是连续型的输入，而且我们通常是有序的翻译这些特征，而不是所有的特征都是有序化的（譬如浏览器就是按人工排的序列）。

将这些类别特征转化成 sklearn 参数中可以使用的方法是：使用 one-of-K或者 one-hot编码（独热编码`OneHotEncoder`）。它可以把每一个有 m 种类别的特征转化成 m 中二值特征。举例如下：


```
enc = preprocessing.OneHotEncoder()
#input
enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])
OneHotEncoder(categorical_features='all', dtype=<... 'float'>,handle_unknown='error', n_values='auto', sparse=True)
#transform
enc.transform([[0, 1, 3]]).toarray()
#out
array([[ 1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.]])
```

默认情况下，特征的类别数量是从数据集里自动判断出来的。当然，你也可以用 n_values这个参数。我们刚刚举的例子中有两种性别，三种地名和四种浏览器，当我们 fit 之后就可以将我们的数据转化为数值了。从结果中来看，第一个数字代表性别([0,1]代表男性，女性），第二个数字代表地名（[0,1,2]代表欧洲、美国、亚洲），最后一个数字代表浏览器（[3,0,1,2]代表四种浏览器）

此外，字典格式也可以编码： [Loading features from dicts](http://scikit-learn.org/stable/modules/feature_extraction.html#dict-feature-extraction)

OneHotEncoder参数：*class* `sklearn.preprocessing.` `OneHotEncoder(n_values='auto', categorical_features='all', dtype=<class 'float'>, sparse=True, handle_unknown='error')`

> **n_values** : ‘auto’, int or array of ints
>
> 每个特征的数量
>
> - - ‘auto’ : 从训练数据的范围中得到
>   - int : 所有特征的最大值（number）
>   - array : 每个特征的最大值（number）
>
> **categorical_features: “all” or array of indices or mask** :
>
> 确定哪些特征是类别特征
>
> - - ‘all’ (默认): 所有特征都是类别特征，意味着所有特征都要进行 OneHot 编码
>   - array of indices: 类别特征的数组索引
>   - mask: n_features 长度的数组，切 dtype = bool
>
> 　　非类别型特征通常会放到矩阵的右边
>
> **dtype** : number type, default=np.float
>
> 　　输出数据的类型
>
> **sparse** : boolean, default=True
>
> 　　设置 True 会返回稀疏矩阵，否则返回数组
>
> **handle_unknown** : str, ‘error’ or ‘ignore’
>
> 　　当一个不明类别特征出现在变换中时，报错还是忽略



# 相关

- [机器学习基础与实践（二）----数据转换](https://www.cnblogs.com/charlotte77/p/5622325.html)
