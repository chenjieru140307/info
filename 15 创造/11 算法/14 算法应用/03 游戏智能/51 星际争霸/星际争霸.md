---
title: 星际争霸
toc: true
date: 2019-10-01
---
# Deepmind和Facebook两大AI巨头，为何都爱上了《星际争霸》？


8月7日，Facebook的AI团队发布了史上最大的《星际争霸：母巢之战》游戏数据集。紧接着10号，Deepmind就和暴雪联合发布了《星际争霸2》的游戏数据集与AI训练平台SC2LE。

为什么Deepmind、Facebook、阿里等AI巨头先后迷上了对《星际争霸》的研究？为什么他们做的不是制造一个人工智能去打败人类选手，而是不约而同走上了开源数据、发布研究工具的这条路？

此外，相信关注AI的各位都注意到了，众多媒体和专家们都认为《星际争霸》的研究可以引导AI走向通用智能之路。但大部分解释都知其然不知其所以然，到底《星际争霸》跟通用智能之间是怎样一个逻辑关系？

本文尝试回答以上这些问题——到底《星际争霸》是如何让AI巨头们集体为之着迷的？

在开始详细分析之前，我们必须要重申这样一个常识：顶级AI专家们并不是游戏宅（至少工作时不是），AI会打游戏这事本身对他们来说并没有任何价值。就像AI在围棋上的建树也绝不是为了显摆AI好厉害，或者意图羞辱亚洲国家传统文化（没错，微博上有人就是这么认为的）。

AlphaGo之所以选择围棋，是因为这项智力运动具有无法被暴力穷举的特质，可以检验AI的非运算能力。比如我们看到最终版的AlphaGo已经展现出了布局能力、对抽象形势的判断力，甚至具体行为中的创造力——这都是传统计算机绝不会具备的能力。

对于AI研究者来说，游戏只是方法，绝非目标。AI公司的目标只有两个：一是做出更好的AI，二是用它卖钱。但游戏在训练AI上有天然的实验室属性：用数据支撑、成败标准清晰、大量的人类训练数据可用。

有了这点共识，我们就可以开始破解AI企业对《星际争霸》的图谋。但第一步我们要先明白AI公司对《星际争霸》究竟做了什么，做这些事的目的又何在？

**Deepmind和Facebook都对星际争霸做了什么？**

首先我们来分别看一下Facebook和Deepmind这次很有“打擂台”意味的动作中，到底都发布了什么。

根据时间顺序，首先是Facebook。简单来说，Facebook这次发布的是达到365GB，包含6万多条内容的《母巢之战》游戏数据集。当然这些数据不是给人看的，而是专门为了机器学习任务训练使用的数据。

尤其值得注意的是，Facebook在发布的论文中特意强调了这些数据的通用性。它们可以适配不同的算法、不同的平台，可以说是提供了相对标准化的机器学习训练数据。



而到了Deepmind这里，事情就有一点复杂了。他们的对象不是《母巢之战》，而是更加高级的《星际争霸2》。Deepmind这次发布的是被称为SC2LE（星际争霸2学习环境）的整合式AI训练工具包。



![img](http://s9.rr.itc.cn/r/wapChange/20178_14_17/a4xysd3215390102619.jpg)



在这个大礼包里包含四样东西，还有一篇专门讨论《星际争霸2》机器学习环境的论文。

首先，Deepmind也给出了游戏数据集，包含6万5千场暴雪官方回收的匿名游戏数据。未来还会持续增加。

其次，发布了由暴雪研发的《星际争霸2》机器学习编程入口，方便研究人员和开发者将自己的智能体接入游戏进行研究。

此外，Deepmind还开源了自己研发的PySC2工具包，让研究者更方便的训练自己的智能体。

最后，大礼包里还包括一系列从《星际争霸2》里抽象出来的增强学习迷你游戏。这些迷你游戏可以让研究者更方便的测试特定场景下的智能体效果。

这样看来，Deepmind和暴雪的科学家更加贴心一些，不仅送上了主食，还附带了各种餐具和甜点，还有食品说明书。

但无论Deepmind还是Facebook，目标都只有一个：**提供尽可能方便舒适的研究环境，吸引更多研发者加入《星际争霸》的前沿AI训练中来。**

这样做的基本动机，在于《星际争霸》这类游戏的动作和情景近乎是无穷的，一家公司的人力无从进行面面俱到的深入开发与实验。所以开源和共享数据，帮助更多研究者跳过基础步骤直接研究前沿的、具体的动作算法和多任务协调方案，才是AI公司目前真正的重心。

这种动作思路来源于即时战略游戏的特殊性。这里我们就可以开始解答另一个问题了：为什么一定是《星际争霸》？

**为什么一定是《星际争霸》？**

训练深度学习等AI系统，最多被使用的有三种游戏：迷你游戏、沙盒游戏和即时战略游戏。但这三种当中，迷你游戏和沙盒游戏AI扮演的都是单一智能体。只有即时战略游戏提供了独一无二的训练特征：复杂与协作。

刚刚OpenAI的AI打败了DOTA2顶级选手，马斯克激动地连发推特庆祝（顺便没忘了提AI威胁论），但很多其他AI巨头的科学家却相当不屑，这是为什么？

原因在于1V1模式的DOTA2里AI仅适用一个智能体，目标比较单一，1对1遭遇战也谈不上不完全信息博弈。拼手速和反应人类是肯定比不上AI的，OpenAI的这款AI价值更多在于用AI系统自主学习电竞的规则。



![img](http://s9.rr.itc.cn/r/wapChange/20178_14_17/a2yfji3215403434619.jpg)



而大型即时战略游戏则有着完全不同的环境：



- 1、复杂多变的环境，考验智能体对大量环境信息空间、时间和数据变化的理解能力。
- 2、众多独立单位的配合。人类选手称之为“微操”的技术，就是考验混战下对多个单位、建筑、编队的协同运作能力，这对AI是核心考验。
- 3、不完全信息博弈。这类游戏开局时由战争迷雾，无法观察对手动向。需要智能体进行布局和长远判断。



这些特征让即时战略游戏成为已知AI实验环境中最复杂的其中之一，要知道AI的目标不是可以赢，而是一定赢。

**至于为什么一定是《星际争霸》，或许也可以归纳出几个原因：**

首先，暴雪有开源打造AI的意愿，《星际争霸》本身的素材和接口也都非常流畅。整个游戏数据化的成本很低。

其次，相比于拼效果和画面的即时战略游戏，《星际争霸》的竞技属性更强。其动作众多、元素复杂，像围棋一样具有难以被暴力计算拆解的基本特质。

同时，因为竞技属性强烈、竞技历史悠久，《星际争霸》的战术、战略讨论非常丰富，每一个子动作的价值基本都有判断依据，这是机器学习系统的先决条件之一。

这三点之外，其实还有个最最最重要的原因：《星际争霸》是对战量最大的即时战略游戏，同时战网等平台建设非常完整——换言之，就是留给AI的训练数据够多喽。

**AI巨头的真实目的**

宁愿采取开源众包的模式，也要攻克《星际争霸》这种超复杂的训练环境，AI巨头们难道是吃饱撑的吗？他们到底想要从中获得什么呢？

按照Deepmind把《星际争霸2》拆解成系列小游戏的原理逆推。我们可以知道AI公司希望的是破解一个又一个细节动作后，把这些集合在一起组成大的智能体集合。而这个集合将汇集的不仅仅是无数解决方案，更是这些方案背后普遍蕴藏的通用能力。



![img](http://s9.rr.itc.cn/r/wapChange/20178_14_17/a1tjkj3215415411619.jpg)



如果与围棋进行参照，我们可以从《星际争霸》作为训练环境中推测出至少四种围棋无法给予的能力：

**1、机器记忆力。**区别于棋类游戏，即时战略游戏中过去的信息可能被完全抹杀，比如刚才造的兵都死了……但这些信息却将左右接下来的故事。这就需要AI具有记忆力，和对记忆进行运用，给出反制措施。根据记忆的快速调整，将是一种全新且商业价值极强的AI能力。

**2、弱信息环境下的长期规划能力。**就像上文所说，《星际争霸》这种游戏开局是完全信息封闭的。开局时做的事可能跟战争的结果完全无关，但却具有货真价实的因果关系。这类人类独有的长期规划和调整规划能力，对应的是机器的预测和判断能力。

**3、多智能体协作能力。**通过与人类近似的键盘鼠标，一个智能体如何在终端指挥大量智能体协作，绝对是个迷人的话题。甚至战略性牺牲、设置诱饵和集中火力，对照的可能是未来AI在现实社会中的中枢作用。

**4、动作连贯性。**打游戏的都知道，取胜的关键是打出“节奏”。所谓节奏，来自玩家每一个指令之间如何衔接，是否具备连贯性。对于AI来说也是如此，一个细节上超越人类智慧并不难，但如何把每一个动作衔接起来，整体取得价值最大化，就是AI向前发展的关键了。

这四个方向，最精彩的部分在于都对应着现实中人的能力——不仅是人类认知和解释世界的智能，更是记忆、协作、坚持这种人类反作用于物理世界的“动能”。

至此，或许我们就可以理解为什么《星际争霸》被称为通用智能的关键了。因为它预示着AI将在更加混乱和真实的环境里，学得更加类似人类心智的可能性。

它不仅是实验环境向真实环境的过渡，长远来看，这类游戏被AI完全攻克，甚至可能成为智能体向类人智能体过渡的关键。

即使不说那么宏大的命题，类似智能也可能成为AI代替股票分析员、AI代替广告策划、AI代替律师，这类巨大商业变革的基石——至少这类智能游戏，恐怕不比与顶级玩家打《星际》困难。



# 相关

- [Deepmind和Facebook两大AI巨头，为何都爱上了《星际争霸》？](http://m.sohu.com/n/506700627/)
