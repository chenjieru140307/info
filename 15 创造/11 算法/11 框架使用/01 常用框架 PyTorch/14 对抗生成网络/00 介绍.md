---
title: 00 介绍
toc: true
date: 2019-06-20
---
# 可以补充进来的

- 感觉还是不清楚，拆分后补充到主干中。

# 对抗生成网络 介绍


Ian J.Goodfellow 在 2014 年的 Generative Adversative Nets 论文中，第一次提出了对抗网络模型，如今对抗网络模型在深度学习生成模型领域已经取得了不错的成果。论文提出利用对抗过程估计生成模型，可以认为是在无监督表示学习（Unsuperivised representation learning）上的一个突破，现在主要的应用是用其生成自然图片（natural images）。包括 Goodfellow 如今所在的 OpenAI 公司一直在致力于研究推广 GAN，并将其应用在不同的任务上。同时 Facebook 和 Twitter 最近两年也投入了大量的精力来研究，并将 GAN 应用在了图像生成和视频生成上。<span style="color:red;">现阶段的 GAN 还是只是这些应用场景吗？感觉应该很厉害才是呀？</span>

GAN 的原理很简单，简单说是概率生成模型的目的，就是找出给定观测数据内部的统计规律，并且能够基于所得到的概率分布模型，产生全新的，与观测数据类似的数据。

下面是 Ian J.Goodfellow 在论文中对 GAN 的简单介绍，如图所示：

<center>

![](http://images.iterate.site/blog/image/20190620/BX4NXY2Y7psq.png?imageslim){ width=55% }

</center>


由于我们需要大量的先验知识去对真实世界进行建模，其中包括选择什么样的先验知识、什么样的分布等。而建模的好坏直接影响着我们的生成模型的表现。


真实世界的数据往往很复杂，我们要用来拟合模型的计算量往往非常庞大，甚至难以承受。

GAN 很好地解决了这两大难题。GAN 网络的巧妙在于其设计思维，而技术上是对现有算法的组合，GAN 网络主要由两个网络合成。一个是 G 生成网络：输入为随机数，输出为生成数据。目的是为了生成数据的取值范围与真实数据相似，具体使用什么函数视情况而定。另一个是 D 区分网络。D 区分网络输入数据为混合 G 的输出数据及样本数据。输出一个判别概率。Ian J.Goodfellow 在论文中指出训练方式 G 网络的 loss 是 $\log (1-D(G(z)))$，而 D 的 loss 是 $-(\log (D(x))+\log (1-D(G(z)))$。

为了使 G 生成网络的损失函数 loss 最小，在 G 生成网络的训练的时候希望  $\log (1-D(G(z)))$ 最小，而 D 的 loss 损失函数是  $-(\log (D(x))+\log (1-D(G(z)))$ 希望真实数据的 D 区分网络输出趋近于 1，而生成数据的输出即 $D(G(z))$ 趋近于 0。从而分清楚真实数据和生成数据。<span style="color:red;">没有很明白？主要是符号意义不明确。合并到之前的 GAN 里面去。</span>

由于 GAN 是一个非常灵活的设计框架，各种类型的损失函数都可以整合到 GAN 模型当中，这样针对不同的任务，我们可以设计不同类型的损失函数，都会在 GAN 的框架下进行学习和优化。

在 Ian J.Goodfellow 的 Generative Adversative Nets 论文中有下面一幅图片，如图 10.2所示：


<center>

![](http://images.iterate.site/blog/image/20190620/de1GXvctLusV.png?imageslim){ width=55% }

</center>

图中点线为真实数据分布，实线为生成的数据分布，虚线表示生成的数据对应于真实数据分布的概率。

- （a）中是初始状态，由于刚开始训练，需要更新参数，经过若干次训练之后，实线能够趋近于圆点线，直到更新 G 的模型使其生成的数据分布更加趋近与真实数据分布。
- 从（a）图训练到（b）图，可以很明显地看到随着实线向着圆点线的偏移，实线开始逐渐地下降。
- 随后经过逐步训练如（c），实线逐渐向圆点线的线靠拢。
- 直到训练形成（d）为止。此时，G 网络和 D 网络就处于平衡状态，无法再进一步更新了。


<center>

![](http://images.iterate.site/blog/image/20190620/tF8pLGegw3mw.png?imageslim){ width=55% }

</center>

Z 是 G 的输入，一般情况下是高斯随机分布生成的数据。其中 G 的输出是 G（z），对于真实的数据，一般都为图片，将分布变量用 X 来表示。那么对于 D 的输出判断则是来自 X 的可能性，是一个常量。


由于生成对抗网络的优点不需要大量的带标签的数据，损失函数来源于 D 上午判定，同时产生大量生成数据用于训练，相当于接近无监督学习，在一定的情况下可以和深度神经网络结合，比如说与卷积神经网络结合的 DCGAN。<span style="color:red;">难道还有与普通机器学习方法进行结合的 GAN？为什么要强调与卷积神经网络结合呢？</span>由于产生大量生成数据没有推导过程，缺少数学理论，生成器，判别器需要共同训练，导致训练难度加大，容易出现训练失败。<span style="color:red;">训练失败是个什么情况？有那些情况导致训练失败？</span>

GAN 最直接的应用，就是用于真实数据分布的建模和生成，包括可以生成一些图像和视频，以及生成一些自然语句和音乐等。由于 GAN 可以生成大量数据，可以解决一些传统的机器学习中所面临的数据不足的问题，因此可以应用在半监督学习、无监督学习、多视角、多任务学习的任务中。<span style="color:red;">什么是多视角、多任务学习？</span>








# 相关

- 《深度学习框架 Pytorch 快速开发与实战》
