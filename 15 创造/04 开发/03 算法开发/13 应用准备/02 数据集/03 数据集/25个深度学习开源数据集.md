---
title: 25个深度学习开源数据集
toc: true
date: 2019-10-29
---
# 25个深度学习开源数据集


数据集分为三类-图像处理，自然语言处理，以及音频/语音处理。




> **图像处理**



1**MNIST**



![img](https://mmbiz.qpic.cn/mmbiz_jpg/nJZZib3qIQW5DVbYpsibPoqt40t1kJceibdh990hL6xaic8H5zSWjajtAzXPUb58vG98rBUibVibEpkR2pYq48SffmcA/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

MNIST是最受欢迎的深度学习数据集之一。这是一个手写数字数据集，包含一组60,000个示例的训练集和一组10,000个示例的测试集。这是一个对于在实际数据中尝试学习技术和深度识别模式的很好的数据库，同时尝试学习如何在数据预处理中花费最少的时间和精力。



> **大小：**〜50 MB
>
> **记录数量：**分为10个类别的70，000个图片
>
> **SOTA：**Dynamic Routing Between Capsules



##

2**MS-COCO**

##



![img](https://mmbiz.qpic.cn/mmbiz_jpg/nJZZib3qIQW5DVbYpsibPoqt40t1kJceibdJN9BNliaoAfnXTuxQmnhWslzicKJzsEWx2yo3J9qy8fK7xKUjjxeXjZA/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



COCO是一个规模大且丰富的物体检测，分割和字幕数据集。它有几个特点：



- 物体分割
- 文中识别
- 超像素物质分割
- 330K图像（> 200K标记）
- 150万个物体实例
- 80个物体类别
- 91个物质类别
- 每张图片5个字幕
- 250,000有关键点的人



> **大小：**〜25 GB（压缩）
>
> **记录数量：**330K图像，80个物体类别，每幅图像5个字幕，250，000个有关键点的人
>
> **SOTA:**Mask R-CNN



##

3**ImageNet**

##

##

## ![img](https://mmbiz.qpic.cn/mmbiz_jpg/nJZZib3qIQW5DVbYpsibPoqt40t1kJceibdM4qzalxUMRiaia4ibO9IkFQJ1K5Y07fXnasTFshiauZhteXnnwwn7uqtHQ/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



ImageNet是依据WordNet层次结构组织的图像数据集。WordNet包含大约100,000个短语，ImageNet提供了平均大约1000个图像来说明每个短语。



> **大小：**〜150GB
>
> **记录数量：**图像总数：〜1,500,000;每个都有多个边界框和相应的类标签
>
> **SOTA：**Aggregated Residual Transformations for Deep Neural Networks



##

4**Open Images Dataset**

##

##

## ![img](https://mmbiz.qpic.cn/mmbiz_jpg/nJZZib3qIQW5DVbYpsibPoqt40t1kJceibd7W0vMzicU8n9WWpY8BdiafiazdZ6H2Qd1ynnwDT1KZwg2iaxqfA05y2FAg/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



Open Images是一个包含近900万个图像URL的数据集。这些图像已经用数千个类别的图像级标签边框进行了注释。该数据集包含9,011,219张图像的训练集，41,260张图像的验证集以及125,436张图像的测试集。



> **大小：**500 GB（压缩）
>
> **记录数量：**9,011,219张超过5k标签的图像
>
> **SOTA：**Resnet 101图像分类模型（在V2数据上训练）：Model checkpoint, Checkpoint readme, Inference code.



##

5**VisualQA**

##

##

## ![img](https://mmbiz.qpic.cn/mmbiz_jpg/nJZZib3qIQW5DVbYpsibPoqt40t1kJceibdDSsDln0PUGk7XqibXr80M8DNbNcdq2fJhaTHt3oLlAvPEFQgqR86eqQ/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



VQA是一个包含有关图像的开放式问题的数据集。这些问题需要理解是视觉和语言。这个数据集有一些有趣的特点：



- 265,016张图片（COCO和抽象场景）
- 每张图片至少有3个问题（平均5.4个问题）
- 每个问题10个基于事实答案
- 每个问题3个似乎合理（但看起来不正确）的答案
- 自动评估指标



> **大小：**25 GB（压缩）
>
> **记录数量：**265,016张图片，每张图片至少3个问题，每个问题10个基于事实答案
>
> **SOTA:**Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge



##

6**The Street View House Numbers (SVHN)**

##

##

## ![img](https://mmbiz.qpic.cn/mmbiz_jpg/nJZZib3qIQW5DVbYpsibPoqt40t1kJceibdabp0b7UM3oGNibibObYEScwibicsJfDIvMKrTHvsLKB9hu0TgVjc7PUTvw/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



这是用于开发物体检测算法的真实世界图像数据集。这些只需要最少的数据预处理。它与本列表中提到的MNIST数据集类似，但拥有更多标签数据（超过600,000个图像）。这些数据是从谷歌街景中查看的房屋号码中收集的。



> **大小：**2.5 GB
>
> **记录数量：**10个课程中的6,30,420张图片
>
> **SOTA:**Distributional Smoothing With Virtual Adversarial Training



##

7**CIFAR-10**

##



## ![img](https://mmbiz.qpic.cn/mmbiz_jpg/nJZZib3qIQW5DVbYpsibPoqt40t1kJceibdlapbZJpA4aib9iaiaueicL3s5q2BEAoGZ6vGHPoKmFIuY00bAKbZ6eyC2g/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



 这是另一个图像分类的数据集。它包含了10个类别的60,000个图像（每个类在上图中表示为一行）。总共有50,000个训练图像和10,000个测试图像。数据集分为6个部分- 5个培训批次和1个测试批次。每批有10,000个图像。



> **大小：**170 MB
>
> **记录数量：**10个类别的60,000张图片
>
> **SOTA:**ShakeDrop regularization



##

8**Fashion-MNIST**

##



## ![img](https://mmbiz.qpic.cn/mmbiz_jpg/nJZZib3qIQW5DVbYpsibPoqt40t1kJceibd9LzmXCQLT4WP33k6WeWW9icxBgvl3Y0qeZ6DkBrQGdbAe1pdfNVTbfw/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)  Fashion-MNIST包含60,000个训练图像和10,000个测试图像。它是一个类似MNIST的时尚产品数据库。开发人员认为MNIST已被过度使用，因此他们将其作为MNIST的直接替代品。每张图片都以灰度显示，并与10个类别的标签相关联。



> ## **大小：**30 MB
>
> ## **记录数量：**10个类别的70,000张图片
>
> **SOTA:**Random Erasing Data Augmentation





> **自然语言处理**



9**IMDB Reviews**

##

## 这是一个电影爱好者的梦寐以求的数据集。它意味着二元情感分类，并具有比此领域以前的任何数据集更多的数据。除了训练和测试评估示例之外，还有更多未标记的数据可供使用。包括文本和预处理的词袋格式。

##

> ## **大小：**80 MB
>
> ## **记录数量：**25,000个高度差异化的电影评论用于训练，25,000个测试
>
> **SOTA：**Learning Structured Text Representations



##

10**Twenty Newsgroups**

##



## 顾名思义，该数据集包含有关新闻组的信息。为了选择这个数据集，从20个不同的新闻组中挑选了1000篇新闻文章。这些文章具有一定特征，如主题行，签名和引用。



> ## **大小：**20 MB
>
> ## **记录数量：**来自20个新闻组的20,000条消息
>
> **DOTA:**Very Deep Convolutional Networks for Text Classification



##

11**Sentiment140**

##

##

## Sentiment140是一个可用于情感分析的数据集。一个流行的数据集，非常适合开始你的NLP旅程。情绪已经从数据中预先移除。最终的数据集具有以下6个特征：



- ## 推文的极性

- ## 推文的ID

- ## 推文的日期

- ## 问题

- ## 推文的用户名

- ## 推文的文本

##

> ## **大小：**80 MB（压缩）
>
> ## **记录数量：**160,000条推文
>
> **SOTA:**Assessing State-of-the-Art Sentiment Models on State-of-the-Art Sentiment Datasets



##

12**WordNet**

##

##

## 在上面的ImageNet数据集中提到，WordNet是一个很大的英文同义词集。 同义词集是每个都描述了不同的概念的同义词组。WordNet的结构使其成为NLP非常有用的工具。

##

> ## **大小：**10 MB
>
> ## **记录数量：**117,000个同义词集通过少量“概念关系”与其他同义词集相关联。
>
> **SOTA:**Wordnets: State of the Art and Perspectives



##

13**Yelp Reviews**

##

##

## 这是Yelp为了学习目的而发布的一个开源数据集。它包含了由数百万用户评论，商业属性和来自多个大都市地区的超过20万张照片。这是一个非常常用的全球NLP挑战数据集。

##

> ## **大小：**2.66 GB JSON，2.9 GB SQL和7.5 GB照片（全部压缩）
>
> ## **记录数量：**5,200,000条评论，174,000条商业属性，20万张图片和11个大都市区
>
> **SOTA：**Attentive Convolution



##

14**The Wikipedia Corpus**

##

## 这个数据集是维基百科全文的集合。它包含来自400多万篇文章的将近19亿字。使得这个成为强大的NLP数据集的是你可以通过单词，短语或段落本身的一部分进行搜索。



> ## **大小：**20 MB
>
> ## **记录数量：**4,400,000篇文章，19亿字
>
> **SOTA:**Breaking The Softmax Bottelneck: A High-Rank RNN language Model



##

15**The Blog Authorship Corpus**

##



这个数据集包含了从blogger.com收集的数千名博主的博客帖子。每个博客都作为一个单独的文件提供。每个博客至少包含200个常用英语单词。



> **大小：**300 MB
>
> **记录数量：**681,288个帖子，超过1.4亿字
>
> **SOTA:**Character-level and Multi-channel Convolutional Neural Networks for Large-scale Authorship Attribution

16**Machine Translation of Various Languages**



此数据集包含四种欧洲语言的训练数据。这里的任务是改进当前的翻译方法。您可以参加以下任何语言组合：



- 英语-汉语和汉语-英语
- 英语-捷克语和捷克语-英语
- 英语-爱沙尼亚语和爱沙尼亚语-英语
- 英语-芬兰语和芬兰语-英语
- 英语-德语和德语-英语
- 英语-哈萨克语和哈萨克语-英语
- 英文-俄文和俄文-英文
- 英语-土耳其语和土耳其语-英语



> **大小：**〜15 GB
>
> **记录数量：**约30,000,000个句子及其翻译
>
> **SOTA:**Attention Is All You Need





> **音频/语音处理**



17**Free Spoken Digit Dataset**



此列表中的另一个被MNIST启发而创建的数据集！这是为了解决识别音频样本中的口头数字而创建。这是一个开源数据集，所以希望随着人们继续贡献更多样本帮助它不断成长。目前，它包含以下特点：



- 3个说话者
- 1500个录音（每个数字每个说话者读50个）
- 英语发音



> **大小：**10 MB
>
> **记录数量：**1500个音频样本
>
> **SOTA:**Raw Waveform-based Audio Classification Using Sample-level CNN Architectures



##

18**Free Music Archive (FMA)**

##



FMA是一个音乐分析的数据集。数据集包括了完整长度和HQ音频，预先计算的特征，以及音轨和用户级元数据。它是一个用于评估MIR中的一些任务的开源数据集。下面是数据集的csv文件列表以及它们包含的内容：



- tracks.csv：每首曲目元数据，如ID，标题，艺术家，流派，标签和播放次数，共106,574首曲目
- genres.csv：所有163种风格的ID与他们的名字和起源（用于推断流派层次和顶级流派）。
- features.csv：用 librosa提取的常用特征。
- echonest.csv：由 Echonest(现在的Spotify)提供的为13,129首音轨的子集的音频功能。



> **大小：**〜1000 GB
>
> **记录数量：**约100,000轨道
>
> **SOTA:**Learning to Recognize Musical Genre from Audio



19**Ballroom**



该数据集包含舞池跳舞音频文件。以真实音频格式提供了许多舞蹈风格的一些特征摘录。以下是数据集的一些特点：



- 实例总数：698
- 持续时间：约30秒
- 总持续时间：约20940秒



> **大小：**14GB（压缩）
>
> **记录数量：**约700个音频样本
>
> **SOTA:**A Multi-Model Approach To Beat Tracking Considering Heterogeneous Music Styles



##

20**Million Song Dataset**

##



## ![img](https://mmbiz.qpic.cn/mmbiz_jpg/nJZZib3qIQW5DVbYpsibPoqt40t1kJceibdMdvjYvfagLZcPB0FHJHfge7kxnQdQEwL7G2GWg38r5tGguYsicSpSibQ/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



Million Song Dataset是免费的一百万首当代流行音乐曲目的音频特征和元数据集合。其目的是：



- 鼓励对扩大到商业规模的算法进行研究
- 为评估研究提供参考数据集
- 作为使用API创建大型数据集的捷径（例如The Echo Nest）
- 帮助新研究人员在MIR领域开始工作



数据集的核心是一百万首歌曲的特征分析和元数据。这个数据集不包含任何音频，只是派生的功能。示例音频可以通过使用哥伦比亚大学提供的code从7digital等服务中获取。



> **大小：**280 GB
>
> **记录数量：**PS - 它的一百万首歌曲！
>
> **SOTA:**Preliminary Study on a Recommender System for the Million Songs Dataset Challenge



21**LibriSpeech**



该数据集是大约1000小时的英语演讲的大型语料库。这些数据来自LibriVox项目的有声读物。它们已被分割并适当对齐。如果您正在寻找一个起点，请查看在kaldi-asr.org和语言模型上进行了训练了的已准备好的声学模型，这些模型适合在http://www.openslr.org/11/进行评测。



> **大小：**〜60 GB
>
> **记录数量：**1000小时的演讲
>
> **SOTA:**Letter-Based Speech Recognition with Gated ConvNets



##

22**VoxCeleb**

##

##

## VoxCeleb是一个大规模演讲者识别数据集。它包含了来自YouTube视频的约1,251位知名人士的约10万个话语。数据大部分是性别平衡的（男性占55％）。这些名人横跨不同的口音，职业和年龄。开发和测试集之间没有重叠。对于独立和识别哪个超级巨星的音频来说，这是一个有趣的使用案例。



> **大小：**150 MB
>
> **记录数量：**1,251位名人的100,000条话语
>
> **SOTA:**VoxCeleb: a large-scale speaker identification dataset
>
> **分析Vidhya实践问题：**为了您的练习，我们还提供实际生活问题和数据集让你可以实际演练。在本节中，我们列举了在我们DataHack平台上的深度学习实践问题。



23**Twitter Sentiment Analysis**



仇恨型演讲以种族主义和性别歧视为形式的言论已成为推特上的麻烦事，重要的是将这类推文与其他的分开。在这个实际问题中，我们同时提供正常的和仇恨型推文的推特数据。你作为数据科学家的任务是确定哪些推文是仇恨型推文，哪些不是。



> **大小：**3 MB
>
> **记录数量：**31,962条推文



24**Age Detection of Indian Actors**



对于任何深度学习爱好者来说，这是一个令人着迷的挑战。该数据集包含数千个印度演员的图像，你的任务是确定他们的年龄。所有图像都是手动选择，并从视频帧中剪切的，这使得尺度，姿势，表情，照度，年龄，分辨率，遮挡和化妆的高度干扰性。



> **大小：**48 MB（压缩）
>
> **记录数量：**训练集中的19,906幅图像和测试集中的6636幅图像
>
> **SOTA：**Hands on with Deep Learning – Solution for Age Detection Practice Problem

25**Urban Sound Classification**



这个数据集包含超过8000个来自10个类别的城市声音摘录。这个实践问题是为了在向您介绍常见分类方案中的音频处理。



> **大小：**训练集-3 GB（压缩），测试集- 2 GB（压缩）
>
> **记录数量：**来自10个类别的8732个城市声音标注的声音片段（<= 4s）




# 相关

- [25个深度学习开源数据集，good luck !](https://mp.weixin.qq.com/s?__biz=MzI4MDYzNzg4Mw==&mid=2247487565&idx=1&sn=63bb584d0cd9c4a8435f1e958deebb2a&chksm=ebb42899dcc3a18f24a0f55a55eebb79fb7b7a69b523d1188b3ed22b12540644b92ebeb5bc3c&mpshare=1&scene=1&srcid=0414eWRyexMO7JaLoKEpavOB#rd)
