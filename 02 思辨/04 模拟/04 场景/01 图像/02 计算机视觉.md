
# 可以补充进来的

- 想更多的了解在深度学习中图像预处理方面的理论。

# 计算机视觉

长久以来，计算机视觉就是深度学习应用中几个最活跃的研究方向之一。因为视觉是一个对人类以及许多动物毫不费力，但对计算机却充满挑战的任务(Ballard et al.,1983)。深度学习中许多流行的标准基准任务包括对象识别和光学字符识别。

计算机视觉是一个非常广阔的发展领域，其中包括多种多样的处理图片的方式以及应用方向。计算机视觉的应用广泛：从复现人类视觉能力(比如识别人脸)到创造全新的视觉能力。举个后者的例子，近期一个新的计算机视觉应用是从视频中可视物体的振动识别相应的声波(Davis et al.,2014)。<span style="color:red;">哇塞！这么强的吗？之前看到过一个新闻是根据薯条袋子的震动知道说的是什么话，这个是指的这个吗？真的可行吗？准确率能达到多少？</span>大多数计算机视觉领域的深度学习研究未曾关注过这样一个奇异的应用，它扩展了图像的范围，而不是仅仅关注于人工智能中较小的核心目标——复制人类的能力。<span style="color:red;">是的不仅仅是复现人类的能力。</span>无论是报告图像中存在哪个物体，还是给图像中每个对象周围添加注释性的边框，或从图像中转录符号序列，或给图像中的每个像素标记它所属对象的标识，大多数计算机视觉中的深度学习往往用于对象识别或者某种形式的检测。由于生成模型已经是深度学习研究的指导原则，因此还有大量图像合成工作使用了深度模型。尽管图像合成(“无中生有”)通常不包括在计算机视觉内，但是能够进行图像合成的模型通常用于图像恢复，即修复图像中的缺陷或从图像中移除对象这样的计算机视觉任务。<span style="color:red;">嗯。</span>

## 1. 预处理

由于原始输入往往以深度学习架构难以表示的形式出现，许多应用领域需要复杂精细的预处理。计算机视觉通常只需要相对少的这种预处理。图像应该被标准化，从而使得它们的像素都在相同并且合理的范围内，比如`[0,1]`或者`[-1,1]`。将`[0,1]`中的图像与`[0,255]`中的图像混合，通常会导致失败。<span style="color:red;">嗯，对于这个地方一直想知道用`[0,1]`好还是用`[-1,1]`好？有什么差别吗？ </span>将图像格式化为具有相同的比例，严格上说是唯一一种必要的预处理。许多计算机视觉架构需要标准尺寸的图像，因此必须裁剪或缩放图像以适应该尺寸。然而，严格地说即使是这种重新调整比例的操作并不总是必要的。一些卷积模型接受可变大小的输入，并动态地调整它们的池化区域大小以保持输出大小恒定(Waibel et al.,1989)。<span style="color:red;">真的吗？怎么动态调整它们的池化区域的？那么训练的时候是什么样的？这样真的不会使抽到的特征发生问题吗？</span>其他卷积模型具有可变大小的输出，其尺寸随输入自动缩放，例如对图像中的每个像素进行去噪或标注的模型(Hadsell et al.,2007)。<span style="color:red;">嗯。这个是的。</span>

数据集增强可以被看作一种只对训练集做预处理的方式。数据集增强是减少大多数计算机视觉模型泛化误差的一种极好方法。在测试时可用的一个相关想法是将同一输入的许多不同版本传给模型(例如，在稍微不同的位置处裁剪的相同图像)，并且在模型的不同实例上决定模型的输出。<span style="color:red;">嗯，想知道，模型的不同实例这样的集成效果好吗？这样在预测的时候会不会比较占资源。</span>后一个想法可以被理解为集成方法，并且有助于减少泛化误差。

其他种类的预处理需要同时应用于训练集和测试集，其目的是将每个样本置于更规范的形式，以便减少模型需要考虑的变化量。减少数据中的变化量既能够减少泛化误差，也能够减小拟合训练集所需模型的大小。更简单的任务可以通过更小的模型来解决，而更简单的解决方案泛化能力一般更好。这种类型的预处理通常被设计为去除输入数据中的某种可变性，这对于人工设计者来说是容易描述的，并且人工设计者能够保证不受到任务影响。当使用大型数据集和大型模型训练时，这种预处理通常是不必要的，并且最好只是让模型学习哪些变化性应该保留。例如，用于分类 Image Net的 Alex Net系统仅具有一个预处理步骤：对每个像素减去训练样本的平均值(Krizhevsky et al.,2012b)。<span style="color:red;">嗯，一直不知道为什么 Alex Net 这种对于么个像素减去训练样本的平均值这个操作为什么是有道理的。</span>

### 1.1 对比度归一化

在许多任务中，对比度是能够安全移除的最为明显的变化源之一。简单地说，对比度指的是图像中亮像素和暗像素之间差异的大小。量化图像对比度有许多方式。在深度学习中，对比度通常指的是图像或图像区域中像素的标准差。假设我们有一个张量表示的图像 $\mathbf{X} \in \mathbb{R}^{r \times c \times 3}$ ，其中，$X_{i, j, 1}$ 表示第 $i$ 行第 $j$ 列红色的强度，$X_{i, j, 2}$ 对应的是绿色的强度，$X_{i, j, 3}$ 对应的是蓝色的强度。然后整个图像的对比度可以表示如下：


$$
\sqrt{\frac{1}{3 r c} \sum_{i=1}^{r} \sum_{j=1}^{c} \sum_{k=1}^{3}\left(X_{i, j, k}-\overline{\mathbf{X}}\right)^{2}}\tag{12.1}
$$

<span style="color:red;">为什么是红绿蓝都减去的这个平均值？而不是减去对应 channel 上的平均值？</span>

其中 $\overline{\mathbf{X}}$ 是整个图片的平均强度，满足：

$$
\overline{\mathbf{X}}=\frac{1}{3 r c} \sum_{i=1}^{r} \sum_{j=1}^{c} \sum_{k=1}^{3} X_{i, j, k}\tag{12.2}
$$

全局对比度归一化(global contrast normalization,GCN)旨在通过从每个图像中减去其平均值，然后重新缩放使其像素上的标准差等于某个常数 $s$ 来防止图像具有变化的对比度。<span style="color:red;">嗯，虽然做可以这么做，但是为什么要防止图像具有变化的对比度？为什么能够防止图像有变化的对比度？</span>这种方法非常复杂，因为没有缩放因子可以改变零对比度图像(所有像素都具有相等强度的图像)的对比度。具有非常低但非零对比度的图像通常几乎没有信息内容。在这种情况下除以真实标准差通常仅能放大传感器噪声或压缩伪像。<span style="color:red;">仅能放大传感器误差这个知道，压缩伪图像是什么意思？</span>这种现象启发我们引入一个小的正的正则化参数 $\lambda$ 来平衡估计的标准差。或者，我们至少可以约束分母使其大于等于 $\epsilon$ 。给定一个输入图像 $\mathbf{X}$ ，全局对比度归一化产生输出图像 $\mathbf{X}^{\prime}$，定义为

$$
X_{i, j, k}^{\prime}=s \frac{X_{i, j, k}-\overline{X}}{\max \left\{\epsilon, \sqrt{\lambda+\frac{1}{3 r c} \sum_{i=1}^{r} \sum_{j=1}^{c} \sum_{k=1}^{3}\left(X_{i, j, k}-\overline{X}\right)^{2}}\right\}}
$$

<span style="color:red;">嗯，缩放到 s 了。为什么这个 $\lambda$ 叫正则化参数？虽然它的确平衡了标准差。 </span>

从大图像中剪切感兴趣的对象所组成的数据集不可能包含任何强度几乎恒定的图像。在这些情况下，通过设置 $\lambda=0$ 来忽略小分母问题是安全的，<span style="color:red;">嗯。</span>并且在非常罕见的情况下为了避免除以 $0$ ，通过将 $\epsilon$ 设置为一个非常小的值比如说 $10^{-8}$ 。这也是 Goodfellow et al.(2013c)在 CIFAR-10数据集上所使用的方法。随机剪裁的小图像更可能具有几乎恒定的强度，使得激进的正则化更有用。在处理从 CIFAR-10 数据中随机选择的小区域时，Coates et al.(2011)使用 $\epsilon=0, \lambda=10$ 。<span style="color:red;">嗯。随机裁剪小图像这个是用在什么项目上的？</span>

尺度参数 $s$ 通常可以设置为 $1$ (如 Coates et al.(2011)所采用的)，或选择使所有样本上每个像素的标准差接近 $1$(如 Goodfellow et al.(2013c)所采用的)。<span style="color:red;">这句 使所有样本上每个像素的标准差接近 $1$ 是什么意思？</span>

式(12.3)中的标准差仅仅是对图片 $L^{2}$ 范数的重新缩放(假设图像的平均值已经被移除)。我们更偏向于根据标准差而不是 $L^{2}$ 范数来定义 GCN，因为标准差包括除以像素数量这一步，从而基于标准差的 GCN 能够使用与图像大小无关的固定的 $s$。然而，观察到 $L^{2}$ 范数与标准差成比例，这符合我们的直觉。我们可以把 GCN 理解成到球壳的一种映射，图 12.1对此有所说明。这可能是一个有用的属性，因为神经网络往往更好地响应空间方向，而不是精确的位置。响应相同方向上的多个距离需要具有共线权重向量但具有不同偏置的隐藏单元。这样的情况对于学习算法来说可能是困难的。此外，许多浅层的图模型把多个分离的模式表示在一条线上会出现问题。GCN 采用一个样本一个方向，而不是不同的方向和距离来避免这些问题。<span style="color:red;">GCN 就是全局对比度归一化。但是这一段还是有些不明白。</span>


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190719/vEzgp9HOmyNx.png?imageslim">
</p>

> 图 12.1　GCN 将样本投影到一个球上。
>
> - (左)原始的输入数据可能拥有任意的范数。
> - (中) $\lambda=0$ 时，GCN可以完美地将所有的非零样本投影到球上。这里我们令 $s=1, \epsilon=10^{-8}$。由于我们使用的 GCN 是基于归一化标准差而不是 $L^{2}$ 范数，所得到的球并不是单位球。
> - (右) $\lambda>0$ 的正则化 GCN 将样本投影到球上，但是并没有完全地丢弃其范数中变化。$s$ 和 $\epsilon$ 的取值与之前一样。


与直觉相反的是，存在被称为 sphering 的预处理操作，并且它不同于 GCN。sphering并不会使数据位于球形壳上，而是将主成分重新缩放以具有相等方差，使得 PCA 使用的多变量正态分布具有球形等高线。sphering通常被称为白化(whitening)。<span style="color:red;">没明白。</span>

全局对比度归一化常常不能突出我们想要突出的图像特征，例如边缘和角。如果我们有一个场景，包含了一个大的黑暗区域和一个大的明亮区域(例如一个城市广场有一半的区域处于建筑物的阴影之中)，则全局对比度归一化将确保暗区域的亮度与亮区域的亮度之间存在大的差异。然而，它不能确保暗区内的边缘突出。<span style="color:red;">嗯。</span>

这催生了局部对比度归一化(local contrast normalization,LCN)。局部对比度归一化确保对比度在每个小窗口上被归一化，而不是作为整体在图像上被归一化。关于局部对比度归一化和全局对比度归一化的比较可以参考图 12.2。

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190719/xm8kWjWJ03gD.png?imageslim">
</p>


> 图 12.2　全局对比度归一化和局部对比度归一化的比较。直观上说，全局对比度归一化的效果很巧妙。它使得所有图片的尺度都差不多，这减轻了学习算法处理多个尺度的负担。局部对比度归一化更多地改变了图像，丢弃了所有相同强度的区域。这使模型能够只关注于边缘。较好的纹理区域，如第二行的屋子，可能会由于归一化核的过高带宽而丢失一些细节<span style="color:red;">嗯。</span>

局部对比度归一化的各种定义都是可行的。在所有情况下，我们可以通过减去邻近像素的平均值并除以邻近像素的标准差来修改每个像素。在一些情况下，要计算以当前要修改的像素为中心的矩形窗口中所有像素的平均值和标准差(Pinto et al.,2008)。在其他情况下，使用的则是以要修改的像素为中心的高斯权重的加权平均和加权标准差。在彩色图像的情况下，一些策略单独处理不同的颜色通道，而其他策略组合来自不同通道的信息以使每个像素归一化(Sermanet et al.,2012)。<span style="color:red;">嗯，这些都有道理吗？或者为啥是有道理的？</span>

局部对比度归一化通常可以通过使用可分离卷积(参考第 9.8节)来计算特征映射的局部平均值和局部标准差，然后在不同的特征映射上使用逐元素的减法和除法。<span style="color:red;">嗯，什么是可分离卷积？补充下。</span>

局部对比度归一化是可微分的操作，并且还可以作为一种非线性作用应用于网络隐藏层，以及应用于输入的预处理操作。<span style="color:red;">哇塞！这个真的可以作为一种非线性作用应用于网络隐藏层吗？那么它突出的是什么呢？这样真的有效果吗？效果咋样？</span>

与全局对比度归一化一样，我们通常需要正则化局部对比度归一化来避免出现除以零的情况。事实上，因为局部对比度归一化通常作用于较小的窗口，所以正则化更加重要。较小的窗口更可能包含彼此几乎相同的值，因此更可能具有零标准差。<span style="color:red;">嗯。</span>

<span style="color:red;">那么到底使用什么？全局对比度归一化还是局部对比度归一化？感觉全局更考虑色块的颜色，局部更考虑边界。那么什么场景下使用什么呢？</span>

### 1.2 数据集增强

如第 7.4节中讲到的一样，我们很容易通过增加训练集的额外副本来增加训练集的大小，进而改进分类器的泛化能力。这些额外副本可以通过对原始图像进行一些变化来生成，但是并不改变其类别。对象识别这个分类任务特别适合于这种形式的数据集增强，因为类别信息对于许多变换是不变的，而我们可以简单地对输入应用诸多几何变换。如前所述，分类器可以受益于随机转换或者旋转，某些情况下输入的翻转可以增强数据集。在专门的计算机视觉应用中，存在很多更高级的用以增强数据集的变换。这些方案包括图像中颜色的随机扰动(Krizhevsky　et al.,2012b)，以及对输入的非线性几何变形(LeCun et al.,1998c)。<span style="color:red;">是的这个是有很多的，imgaug 还是要看下的。</span>



# 相关

- 《深度学习》花书
