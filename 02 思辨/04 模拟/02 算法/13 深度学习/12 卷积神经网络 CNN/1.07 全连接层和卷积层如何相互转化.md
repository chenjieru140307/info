


### 9.2.4 全连接层和卷积层如何相互转化？

<span style="color:red;">还是没明白为什么可以转化？</span>

**两者相互转换的可能性：**

全连接层和卷积层之间唯一的不同就是卷积层中的神经元只与输入数据中的一个局部区域连接，并且在卷积列中的神经元共享参数。然而在两类层中，神经元都是计算点积，所以它们的函数形式是一样的。因此，将此两者相互转化是可能的：

1. 对于任一个卷积层，都存在一个能实现和它一样的前向传播函数的全连接层。权重矩阵是一个巨大的矩阵，除了某些特定块，其余部分都是零。而在其中大部分块中，元素都是相等的。<span style="color:red;">真的是这样吗？详细理解下。</span>
2. 任何全连接层都可以被转化为卷积层。比如 VGG16 中第一个全连接层是 $25088 * 4096$ 的数据尺寸，将它转化为 $512 * 7 * 7 * 4096$ 的数据尺寸，即一个 K=4096的全连接层，输入数据体的尺寸是 $7 * 7 * 512$，<span style="color:red;">哪里来的 $512$ ？输入不是 1 个 channel 吗？</span>这个全连接层可以被等效地看做一个 $F=7, P=0, S=1, K=4096$ 的卷积层。换句话说，就是将滤波器的尺寸设置为和输入数据体的尺寸一致 $7*7$，这样输出就变为 $1 * 1 * 4096$，本质上和全连接层的输出是一样的。

**输出激活数据体深度是由卷积核的数目决定的(K=4096)。**

在两种变换中，将全连接层转化为卷积层在实际运用中更加有用。假设一个卷积神经网络的输入是 227\times 227\times 3 的图像，一系列的卷积层和下采样层将图像数据变为尺寸为 7\times 7\times 512 的激活数据体，AlexNet的处理方式为使用了两个尺寸为 4096 的全连接层，最后一个有 1000 个神经元的全连接层用于计算分类评分。我们可以将这 3 个全连接层中的任意一个转化为卷积层：

1. 第一个连接区域是 $[7\times 7\times 512]$ 的全连接层，令其滤波器尺寸为 $F=7,K=4096$，这样输出数据体就为 $[1\times 1\times 4096]$。
2. 第二个全连接层，令其滤波器尺寸为 F=1,K=4096，这样输出数据体为 $[1\times 1\times 4096]$。
3. 最后一个全连接层也做类似的，令其 F=1,K=1000，最终输出为 $[1\times 1\times 1000]$ 。

<span style="color:red;">这样的转化是可以，但是不是等价转化吧？</span>



# 相关

- [DeepLearning-500-questions](https://github.com/scutan90/DeepLearning-500-questions)
