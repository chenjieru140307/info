

# 使用计算图描述神经网络


为了更精确地描述反向传播算法，使用更精确的计算图语言是很有帮助的。

## 结点和操作

节点：

图中的每一个节点来表示一个变量。变量可以是标量、向量、矩阵、张量、或者甚至是另一类型的变量。

操作：

引入操作这一概念。操作是指一个或多个变量的简单函数。我们的图形语言伴随着一组被允许的操作。我们可以通过将多个操作复合在一起来描述更为复杂的函数。

不失一般性，我们定义一个操作仅返回单个输出变量。这并没有失去一般性，是因为输出变量可以有多个条目，例如向量。反向传播的软件实现通常支持具有多个输出的操作，但是我们在描述中避免这种情况，因为它引入了对概念理解不重要的许多额外细节。

如果变量 $y$ 是变量 $x$ 通过一个操作计算得到的，那么我们画一条从 $x$ 到 $y$ 的有向边。我们有时用操作的名称来注释输出的节点，当上下文很明确时，有时也会省略这个标注。

## 一些示例

一些示例：


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190712/Jud7qm96dUg5.png?imageslim">
</p>


> 一些计算图的示例。
>
> - (a) 使用 $\times$ 操作计算 $z = xy$ 的图。
> - (b) 用于逻辑回归预测 $\hat{y} = \sigma(\boldsymbol x^\top \boldsymbol w + b)$ 的图。 一些中间表达式在代数表达式中没有名称，但在图形中却需要。我们简单地将第 $i$ 个这样的变量命名为 $\boldsymbol u^{(i)}$。
> - (c) 表达式 $\boldsymbol H = \max \{ 0, \boldsymbol X\boldsymbol W+ \boldsymbol b \}$ 的计算图，在给定包含小批量输入数据的设计矩阵 $\boldsymbol X$ 时，它计算整流线性单元激活的设计矩阵 $\boldsymbol H$。
> - (d) 示例 a-c对每个变量最多只实施一个操作，但是对变量实施多个操作也是可能的。 这里我们展示一个计算图，它对线性回归模型的权重 $\boldsymbol w$ 实施多个操作。这个权重不仅用于预测 $\hat{y}$，也用于权重衰减罚项 $\lambda \sum_i w_i^2$。<span style="color:blue;">嗯嗯，看图的时候这个地方有疑惑，看到了这个解释还是非常清楚的。</span>






# 相关

- 《深度学习》花书
