

# Dropout 率的选择

<span style="color:red;">这一段完全没明白？是不是从书上摘下来的时候漏掉了什么？查找下。</span>

1. 经过交叉验证，隐含节点 dropout 率等于 0.5 的时候效果最好，原因是 0.5 的时候 dropout 随机生成的网络结构最多。<span style="color:red;">嗯， 0.5 的时候 dropout 随机生成的网络结构最多。是的。</span>
2. dropout 也可以被用作一种添加噪声的方法，直接对 input 进行操作。输入层设为更接近 1 的数。使得输入变化不会太大（0.8）。<span style="color:red;">怎么对 input 进行操作的？怎么把输入层设置为接近 1 的数的？</span>
3. 对参数 $w$ 的训练进行球形限制 (max-normalization)，对 dropout 的训练非常有用。<span style="color:red;">？什么意思？与 $w$ 有关系吗？</span>
4. 球形半径 $c$ 是一个需要调整的参数，可以使用验证集进行参数调优。<span style="color:red;">？没明白？</span>
5. dropout 自己虽然也很牛，但是 dropout、max-normalization、large decaying learning rates and high momentum 组合起来效果更好，比如 max-norm regularization 就可以防止大的 learning rate 导致的参数 blow up。<span style="color:red;">怎么组合的？</span>
6. 使用 pretraining 方法也可以帮助 dropout 训练参数，在使用 dropout 时，要将所有参数都乘以 $1/p$。<span style="color:red;">什么意思？</span>
