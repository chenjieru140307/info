

## 点估计


点估计试图为一些感兴趣的量提供单个 “最优” 预测。<span style="color:red;">怎么提供单个最优预测的？</span>一般地，感兴趣的量可以是单个参数，或是某些参数模型中的一个向量参数，例如第 5.1.4节线性回归中的权重，但是也有可能是整个函数。<span style="color:red;">整个函数？</span>

为了区分参数估计和真实值，我们习惯将参数 $\theta$ 的点估计表示为 $\hat{\theta}$。

令 $\left\{\boldsymbol{x}^{(1)}, \ldots, \boldsymbol{x}^{(m)}\right\}$ 是 $m$ 个独立同分布(i.i.d.)的数据点。点估计(point estimator)或统计量(statistics)是这些数据的任意函数：


$$
\hat{\boldsymbol{\theta}}_{m}=g\left(\boldsymbol{x}^{(1)}, \ldots, \boldsymbol{x}^{(m)}\right)\tag{5.19}
$$

<span style="color:red;">嗯，点估计是这些函数的任意函数。</span>

这个定义不要求 $g$ 返回一个接近真实 $\boldsymbol{\theta}$ 的值，或者 $g$ 的值域恰好是 $\boldsymbol{\theta}$ 的允许取值范围。点估计的定义非常宽泛，给了估计量的设计者极大的灵活性。虽然几乎所有的函数都可以称为估计量，但是一个良好的估计量的输出会接近生成训练数据的真实参数 $\boldsymbol{\theta}$ 。<span style="color:red;">嗯。</span>

现在，我们采取频率派在统计上的观点。换言之，我们假设真实参数 $\boldsymbol{\theta}$ 是固定但未知的，而点估计 $\hat{\boldsymbol{\theta}}$ 是数据的函数。由于数据是随机过程采样出来的，数据的任何函数都是随机的，因此 $\hat{\boldsymbol{\theta}}$ 是一个随机变量。

<span style="color:red;">没有很明白。</span>


点估计也可以指输入和目标变量之间关系的估计，我们将这种类型的点估计称为函数估计。

### 函数估计

函数估计 有时我们会关注函数估计(或函数近似)。这时我们试图从输入向量 $\boldsymbol{x}$ 预测变量 $\boldsymbol{y}$ 。假设有一个函数 $f(\boldsymbol{x})$ 表示 $\boldsymbol{y}$ 和 $\boldsymbol{x}$ 之间的近似关系。例如，我们可能假设 $y=f(x)+\epsilon$ ，其中 $\epsilon$ 是 $y$ 中未能从 $x$ 预测的一部分。在函数估计中，我们感兴趣的是用模型估计去近似 $f$，或者估计 $\hat{f}$。函数估计和估计参数 $\theta$ 是一样的，函数估计 $\hat{f}$ 是函数空间中的一个点估计。线性回归示例(第 5.1.4节中讨论的)和多项式回归示例(第 5.2节中讨论的)都既可以被解释为估计参数 $w$ ，又可以被解释为估计从 $x$ 到 $y$ 的函数映射 $\hat{f}$ 。

现在我们回顾点估计最常研究的性质，并探讨这些性质说明了估计的哪些特点。



# 相关

- 《深度学习》花书
