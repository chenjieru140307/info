
# 语音识别

语音识别任务是将一段包括了自然语言发音的声学信号投影到对应说话人的词序列上。令 $\boldsymbol{X}=\left(\boldsymbol{x}^{(1)}, \boldsymbol{x}^{(2)}, \ldots, \boldsymbol{x}^{(T)}\right)$ 表示语音的输入向量(传统做法以 20ms 为一帧分割信号)。<span style="color:red;">为什么是 20ms？是对于人声的处理的经验吗？如果对于动物呢？</span>许多语音识别的系统通过特殊的手工设计方法预处理输入信号，从而提取特征，但是某些深度学习系统(Jaitly and Hinton,2011)直接从原始输入中学习特征。令 $\boldsymbol{y}=\left(y_{1}, y_{2}, \ldots, y_{N}\right)$ 表示目标的输出序列(通常是一个词或者字符的序列)。自动语音识别(automatic speech recognition,ASR)任务指的是构造一个函数，使得它能够在给定声学序列 $\boldsymbol{X}$ 的情况下计算最有可能的语言序列 $\boldsymbol{y}$：

$$
f_{\mathrm{ASR}}^{*}(\boldsymbol{X})=\underset{y}{\arg \max } P^{*}(\mathbf{y} | \mathbf{X}=\boldsymbol{X})\tag{12.4}
$$

其中 $P^{*}$ 是给定输入值 $\boldsymbol{X}$ 时对应目标 $\boldsymbol{y}$ 的真实条件分布。


## 回顾历史

从 20 世纪 80 年代直到 2009～2012年，最先进的语音识别系统是隐马尔可夫模型(hidden markov model,HMM)和高斯混合模型(gaussian mixture model,GMM)的结合。

GMM 对声学特征和音素(phoneme)之间的关系建模(Bahl et al.,1987)，HMM 对音素序列建模。GMM-HMM 模型将语音信号视作由如下过程生成：首先，一个 HMM 生成了一个音素的序列以及离散的子音素状态(比如每一个音素的开始、中间、结尾)，然后 GMM把每一个离散的状态转化为一个简短的声音信号。<span style="color:red;">没有很明白。</span>

尽管直到最近 GMM-HMM 一直在 ASR 中占据主导地位，语音识别仍然是神经网络所成功应用的第一个领域。从 20 世纪 80 年代末期到 90 年代初期，大量语音识别系统使用了神经网络(Bourlard and Wellekens,1989;Waibel et al.,1989;Robinson and Fallside,1991; Bengio et al.,1991,1992; Konig et al.,1996)。当时，基于神经网络的 ASR的表现和 GMM-HMM 系统的表现差不多。比如说，Robinson and Fallside(1991)在 TIMIT数据集(Garofolo et al.,1993)(有 39 个区分的音素)上达到了 26%的音素错误率，这个结果优于或者说是可以与基于 HMM 的结果相比。从那时起，TIMIT成为音素识别的一个基准数据集，在语音识别中的作用就和 MNIST 在对象识别中的作用差不多。然而，由于语音识别软件系统中复杂的工程因素以及在基于 GMM-HMM的系统中已经付出的巨大努力，工业界并没有迫切转向神经网络的需求。结果，直到 21世纪 00年代末期，学术界和工业界的研究者们更多的是用神经网络为 GMM-HMM系统学习一些额外的特征。<span style="color:red;">嗯。使用神经网络为 GMM-HMM 系统学习一些额外的特征，不错，这个也是可以的。</span>

## 更大更深的模型以及更大的数据集的出现

之后，随着更大更深的模型以及更大的数据集的出现，通过使用神经网络代替 GMM 来实现将声学特征转化为音素(或者子音素状态)的过程可以大大地提高识别的精度。

从 2009 年开始，语音识别的研究者们将一种无监督学习的深度学习方法应用于语音识别。这种深度学习方法基于训练一个被称作是受限玻尔兹曼机的无向概率模型，从而对输入数据建模。<span style="color:red;">受限玻尔兹曼机要补充下。</span>受限玻尔兹曼机将会在第 3 部分中描述。为了完成语音识别任务，无监督的预训练被用来构造一个深度前馈网络，这个神经网络每一层都是通过训练受限玻尔兹曼机来初始化的。<span style="color:red;">什么意思？通过训练受限玻尔兹曼机来初始化是什么意思？</span>这些网络的输入是从一个固定规格的输入窗(以当前帧为中心)的谱声学表示抽取，预测了当前帧所对应的 HMM 状态的条件概率。<span style="color:red;">谱声学表示是什么样的表示。</span>

训练一个这样的神经网络能够可以显著提高在 TIMIT 数据集上的识别率(Mohamed et al.,2009,2012a)，并将音素级别的错误率从大约 26%降到了 20.7%。关于这个模型成功原因的详细分析可以参考 Mohamed et al.(2012b)。

对于基本的电话识别工作流程的一个扩展工作是添加说话人自适应相关特征(Mohamed et al.,2011)的方法，这可以进一步地降低错误率。

紧接着的工作则将结构从音素识别(TIMIT所主要关注的)转向了大规模词汇语音识别(Dahl et al.,2012)，这不仅包含了识别音素，还包括了识别大规模词汇的序列。语音识别上的深度网络从最初的使用受限玻尔兹曼机进行预训练发展到了使用诸如整流线性单元和 Dropout 这样的技术(Zeiler et al.,2013;Dahl et al.,2013)。从那时开始，工业界的几个语音研究组开始寻求与学术圈的研究者之间的合作。Hinton et al.(2012a)描述了这些合作所带来的突破性进展，这些技术现在被广泛应用在产品中，比如移动手机端。

随后，当研究组使用了越来越大的带标签的数据集，加入了各种初始化、训练方法以及调试深度神经网络的结构之后，他们发现这种无监督的预训练方式是没有必要的，或者说不能带来任何显著的改进。<span style="color:red;">。。。为啥</span>

用语音识别中词错误率来衡量，在语音识别性能上的这些突破是史无前例的(大约 30%的提高)。在这之前的长达十年左右的时间内，尽管数据集的规模是随时间增长的(见 Deng and Yu(2014)的图 2.4)，但基于 GMM-HMM的系统的传统技术已经停滞不前了。这也导致了语音识别领域快速地转向深度学习的研究。在大约两年的时间内，工业界大多数的语音识别产品都包含了深度神经网络，这种成功也激发了 ASR 领域对深度学习算法和结构的新一波研究浪潮，并且影响至今。

其中的一个创新点是卷积网络的应用(Sainath et al.,2013)。卷积网络在时域与频域上复用了权重，改进了之前的仅在时域上使用重复权值的时延神经网络。<span style="color:red;">怎么在时域和频域上复用权重的？</span>这种新的二维卷积模型并不是将输入的频谱当作一个长的向量，而是当成一个图像，其中一个轴对应着时间，另一个轴对应的是谱分量的频率。<span style="color:red;">哇塞！这样也可以吗？</span>

完全抛弃 HMM 并转向研究端到端的深度学习语音识别系统是至今仍然活跃的另一个重要推动。这个领域第一个主要突破是 Graves et al.(2013)，他训练了一个深度的长短期记忆循环神经网络(见第 10.10节)，使用了帧-音素排列的 MAP 推断，就像 Le Cun et al.(1998c)以及 CTC 框架(Graves et al.,2006;Graves,2012)中一样。<span style="color:red;">什么是 MAP 推断？</span>


一个深度循环神经网络(Graveset al.,2013)每个时间步的各层都有状态变量，两种展开图的方式导致两种不同深度：一种是普通的根据层的堆叠衡量的深度，另一种是根据时间展开衡量的深度。这个工作把 TIMIT 数据集上音素的错误率记录降到了新低 17.7%。关于应用于其他领域的深度循环神经网络的变种可以参考 Pascanu et al.(2014a);Chung et al.(2014)。

另一个端到端深度学习语音识别方向的最新方法是，让系统学习如何利用语音(phonetic)层级的信息“排列”声学(acoustic)层级的信息(Chorowski et al.,2014;Lu et al.,2015)。<span style="color:red;">没明白。补充下。</span>




# 相关

- 《深度学习》花书
