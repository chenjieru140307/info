---
title: 2.11 K-means 聚类
toc: true
date: 2019-08-28
---

下面介绍几种著名的原型聚类算法.

## k 均值算法

给定样本集 $D=\left\{\boldsymbol{x}_{1}, \boldsymbol{x}_{2}, \ldots, \boldsymbol{x}_{m}\right\}$  “k均值” (k-means)算法针对聚类所
得簇划分 $\mathcal{C}=\left\{C_{1}, C_{2}, \ldots, C_{k}\right\}$ 最小化平方误差

$$
E=\sum_{i=1}^{k} \sum_{\boldsymbol{x} \in C_{i}}\left\|\boldsymbol{x}-\boldsymbol{\mu}_{i}\right\|_{2}^{2}\tag{9.24}
$$

其中 $\boldsymbol{\mu}_{i}=\frac{1}{\left|C_{i}\right|} \sum_{\boldsymbol{x} \in C_{i}} \boldsymbol{x}$ 是簇 $C_{i}$ 的均值向量。直观来看，式(9.24)在一定程度上刻画了簇内样本围绕簇均值向量的紧密程度， $E$ 值越小则簇内样本相似度越高.

最小化式(9.24)并不容易，找到它的最优解需考察样本集 $D$ 所有可能的簇划分，这是一个 NP 难问题。因此，$k$ 均值算法采用了贪心策略，通过迭代优化来近似求解式(9.24)。算法流程如图 9.2所示，其中第 1 行对均值向量进行初始化，在第 4-8行与第 9-16行依次对当前簇划分及均值向量迭代更新，若迭代更新后聚类结果保持不变，则在第 18 行将当前簇划分结果返回.

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180628/Ebkbfhgaal.png?imageslim">
</p>

下面以表 9.1的西瓜数据集 4.00为例来演示 k 均值算法的学习过程。为方便叙述，我们将编号为 $i$ 的样本称为 $\boldsymbol{x}_{i}$ ，这是一个包含“密度”与“含糖率” 两个属性值的二维向量.

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180628/9G4k5Ce25C.png?imageslim">
</p>


假定聚类簇数 $k = 3$，算法开始时随机选取三个样本 $x_6$,$x_{12}$,$x_{27}$ 作为初始均值向量，即

$$
\mu_{1}=(0.403 ; 0.237), \mu_{2}=(0.343 ; 0.099), \mu_{3}=(0.532 ; 0.472)
$$

考察样本 $\boldsymbol{x}_{1}=(0.697 ; 0.460)$，它与当前均值向量 $\boldsymbol{\mu}_{1}, \boldsymbol{\mu}_{2}, \boldsymbol{\mu}_{3}$ 的距离分别为 $0.369,0.506,0.166$，因此 $\boldsymbol{x}_{1}$ 将被划入簇 $C_3$ 中。类似的，对数据集中的所有样本考察一遍后，可得当前簇划分为


$$
C_{1}=\left\{\boldsymbol{x}_{5}, \boldsymbol{x}_{6}, \boldsymbol{x}_{7}, \boldsymbol{x}_{8}, \boldsymbol{x}_{9}, \boldsymbol{x}_{10}, \boldsymbol{x}_{13}, \boldsymbol{x}_{14}, \boldsymbol{x}_{15}, \boldsymbol{x}_{17}, \boldsymbol{x}_{18}, \boldsymbol{x}_{19}, \boldsymbol{x}_{20}, \boldsymbol{x}_{23}\right\}
$$
$$
C_{2}=\left\{\boldsymbol{x}_{11}, \boldsymbol{x}_{12}, \boldsymbol{x}_{16}\right\}
$$
$$
C_{3}=\left\{\boldsymbol{x}_{1}, \boldsymbol{x}_{2}, \boldsymbol{x}_{3}, \boldsymbol{x}_{4}, \boldsymbol{x}_{21}, \boldsymbol{x}_{22}, \boldsymbol{x}_{24}, \boldsymbol{x}_{25}, \boldsymbol{x}_{26}, \boldsymbol{x}_{27}, \boldsymbol{x}_{28}, \boldsymbol{x}_{29}, \boldsymbol{x}_{30}\right\}
$$

于是，可从 $C_1$、 $C_2$、 $C_3$ 分别求出新的均值向量

$$
\boldsymbol{\mu}_{1}^{\prime}=(0.473 ; 0.214), \boldsymbol{\mu}_{2}^{\prime}=(0.394 ; 0.066), \boldsymbol{\mu}_{3}^{\prime}=(0.623 ; 0.388)
$$

更新当前均值向量后，不断重复上述过程，如图 9.3所示，第五轮迭代产生的结果与第四轮迭代相同，于是算法停止，得到最终的簇划分.

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/180628/Ldbddlm2kL.png?imageslim">
</p>




# 相关

- 《机器学习》周志华
- [pumpkin-book](https://github.com/datawhalechina/pumpkin-book)
