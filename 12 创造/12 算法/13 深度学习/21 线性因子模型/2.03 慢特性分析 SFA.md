---
title: 2.03 慢特性分析 SFA
toc: true
date: 2019-06-05
---

# 慢特征分析

慢特征分析是使用来自时间信号的信息学习不变特征的线性因子模型。


慢特征分析的想法源于所谓的慢性原则。其基本思想是，与场景中起描述作用的单个量度相比，场景的重要特性通常变化得非常缓慢。例如，在计算机视觉中，单个像素值可以非常快速地改变。如果斑马从左到右移动穿过图像并且它的条纹穿过对应的像素时，该像素将迅速从黑色变为白色，并再次恢复成黑色。通过比较，指示斑马是否在图像中的特征将不发生改变，并且描述斑马位置的特征将缓慢地改变。因此，我们可能希望将模型正则化，从而能够学习到那些随时间变化较为缓慢的特征。


慢性原则早于慢特征分析，并已被应用于各种模型。一般来说，我们可以将慢性原则应用于可以使用梯度下降训练的任何可微分模型。为了引入慢性原则，我们可以向代价函数添加以下项


$$\begin{aligned}
\lambda \sum_t L(f(\boldsymbol x^{(t+1)}),f(\boldsymbol x^{(t)})),
\end{aligned}$$


其中 $\lambda$ 是确定慢度正则化强度的超参数项，$t$ 是样本时间序列的索引，$f$ 是需要正则化的特征提取器，$L$ 是测量 $f(\boldsymbol x^{(t)})$ 和 $f(\boldsymbol x^{(t+1)})$ 之间的距离的损失函数。$L$ 的一个常见选择是均方误差。


慢特征分析是慢性原则中一个特别高效的应用。由于它被应用于线性特征提取器，并且可以通过闭式解训练，所以它是高效的。像 ICA 的一些变种一样，SFA 本身并不是生成模型，只是在输入空间和特征空间之间定义了一个线性映射，但是没有定义特征空间的先验，因此没有在输入空间上施加分布 $p(\boldsymbol x)$。



SFA 算法 先将 $f(\boldsymbol x;\theta)$ 定义为线性变换，然后求解如下优化问题


$$\begin{aligned}
	\min_{\boldsymbol \theta} \mathbb E_t  (f(\boldsymbol x^{(t+1)})_i - f(\boldsymbol x^{(t)})_i  )^2
\end{aligned}$$


并且满足下面的约束：

$$\begin{aligned}
	\mathbb E_t  f(\boldsymbol x^{(t)})_i = 0
\end{aligned}$$


以及

$$\begin{aligned}
	\mathbb E_t [ f(\boldsymbol x^{(t)})_i^2 ] =1.
\end{aligned}$$ % 485


学习特征具有零均值的约束对于使问题具有唯一解是必要的；否则我们可以向所有特征值添加一个常数，并获得具有相等慢度目标值的不同解。特征具有单位方差的约束对于防止所有特征趋近于 $0$ 的病态解是必要的。与 PCA 类似，SFA 特征是有序的，其中学习第一特征是最慢的。要学习多个特征，我们还必须添加约束

$$\begin{aligned}
\forall i<j,\ \  \mathbb E_t [f(\boldsymbol x^{(t)})_i  f(\boldsymbol x^{(t)})_j] = 0.
\end{aligned}$$

这要求学习的特征必须彼此线性去相关。没有这个约束，所有学习到的特征将简单地捕获一个最慢的信号。可以想象使用其他机制，如最小化重构误差，也可以迫使特征多样化。但是由于 SFA 特征的线性，这种去相关机制只能得到一种简单的解。SFA 问题可以通过线性代数软件获得闭式解。



在运行 SFA 之前，SFA 通常通过对 $\boldsymbol x$ 使用非线性的基扩充来学习非线性特征。例如，通常用 $\boldsymbol x$ 的二次基扩充来代替原来的 $\boldsymbol x$，得到一个包含所有 $x_ix_j$ 的向量。由此，我们可以通过反复地学习一个线性 SFA 特征提取器，对其输出应用非线性基扩展，然后在该扩展之上学习另一个线性 SFA 特征提取器的方式来组合线性 SFA 模块从而学习深度非线性慢特征提取器。


当在自然场景视频的小块空间部分上训练时，使用二次基扩展的 SFA 所学习到的特征与 V1 皮层中那些复杂细胞的特征有许多共同特性~。当在计算机渲染的 3D 环境内随机运动的视频上训练时，深度 SFA 模型能够学习的特征与大鼠脑中用于导航的神经元学到的特征有许多共同特性~。因此从生物学角度上来说 SFA 是一个合理的有依据的模型。



SFA 的一个主要优点是，即使在深度非线性条件下，它依然能够在理论上预测 SFA 能够学习哪些特征。为了做出这样的理论预测，必须知道关于配置空间的环境动力（例如，在 3D 渲染环境中随机运动的例子中，理论分析是从相机位置、速度的概率分布中入手的）。已知潜在因子如何改变的情况下，我们能够通过理论分析解出表达这些因子的最佳函数。在实践中，基于模拟数据的实验上，使用深度 SFA 似乎能够恢复理论预测的函数。相比之下，在其他学习算法中，代价函数高度依赖于特定像素值，使得难以确定模型将学习到什么特征。


深度 SFA 也已经被用于学习用在对象识别和姿态估计的特征~。到目前为止，慢性原则尚未成为任何最先进应用的基础。究竟是什么因素限制了其性能仍有待研究。我们推测，或许慢度先验太过强势，并且，最好添加这样一个先验使得当前时间步到下一个时间步的预测更加容易，而不是加一个先验使得特征近似为一个常数。对象的位置是一个有用的特征，无论对象的速度是高还是低。但慢性原则鼓励模型忽略具有高速度的对象的位置。


# 相关

- 《深度学习》花书
