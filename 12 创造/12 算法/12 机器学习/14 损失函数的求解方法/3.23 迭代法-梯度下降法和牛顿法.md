---
title: 3.23 迭代法-梯度下降法和牛顿法
toc: true
date: 2019-08-27
---

# 迭代法

迭代法就是迭代地修正对最优解的估计。

说明：

- 对于无约束问题：$\arg \min_{\theta} L(\theta)$，假设当前对最优解的估计值为 $\theta_{t}$
- 我们希望求解下面的优化问题来得到更好的估计值 $\theta_{t+1}=\theta_{t}+\delta_{t}$。<span style="color:red;">没有很清楚。</span>


$$
\delta_{t}=\underset{\delta}{\arg \min } L\left(\theta_{t}+\delta\right)
$$

划分：

- 迭代法又可以分为一阶法和二阶法两类。

一阶法：

- 对 $L\left(\theta_{t}+\delta\right)$ 做一阶泰勒展开，得到近似式

$$
L\left(\theta_{t}+\delta\right) \approx L\left(\theta_{t}\right)+\nabla L\left(\theta_{t}\right)^{\mathrm{T}} \delta
$$

由于该近似式仅在 $\delta$ 较小时才比较准确，因此在求解 $\delta_t$ 时一般加上 L2 正则项：

$$
\begin{aligned}
\delta_{t}&=\underset{\delta}{\arg \min }\left(L\left(\theta_{t}\right)+\nabla L\left(\theta_{t}\right)^{\mathrm{T}} \delta+\frac{1}{2 \alpha}\|\delta\|_{2}^{2}\right)\\&=-\alpha \nabla L\left(\theta_{t}\right)\end{aligned}\tag{7.20}
$$


由此，一阶法的迭代公式表示为：

$$
\theta_{t+1}=\theta_{t}-\alpha \nabla L\left(\theta_{t}\right)\tag{7.21}
$$

其中 $\alpha$ 称为学习率。一阶法也称梯度下降法，梯度就是目标函数的一阶信息。



二阶法对函数 $L\left(\theta_{t}+\delta\right)$ 做二阶泰勒展开，得到近似式：


$$
L\left(\theta_{t}+\delta\right) \approx L\left(\theta_{t}\right)+\nabla L\left(\theta_{t}\right)^{\mathrm{T}} \delta+\frac{1}{2} \delta^{\mathrm{T}} \nabla^{2} L\left(\theta_{t}\right) \delta\tag{7.22}
$$

其中 $\nabla^{2} L\left(\theta_{t}\right)$ 是函数 $L$ 在 $\theta_{t}$ 处的 Hessian 矩阵。通过求解近似优化问题，


$$
\begin{aligned}
\delta_{t}&=\underset{\delta}{\arg \min }\left(L\left(\theta_{t}\right)+\nabla L\left(\theta_{t}\right)^{\mathrm{T}} \delta+\frac{1}{2} \delta^{\mathrm{T}} \nabla^{2} L\left(\theta_{t}\right) \delta\right)\\&=-\nabla^{2} L\left(\theta_{t}\right)^{-1} \nabla L\left(\theta_{t}\right)
\end{aligned}\tag{7.23}
$$


可以得到二阶法的迭代公式

$$
\theta_{t+1}=\theta_{t}-\nabla^{2} L\left(\theta_{t}\right)^{-1} \nabla L\left(\theta_{t}\right)\tag{7.24}
$$


二阶法也称为牛顿法，Hessian 矩阵就是目标函数的二阶信息。二阶法的收敛速度一般要远快于一阶法，但是在高维情况下，Hessian 矩阵求逆的计算复杂度很大，而且当目标函数非凸时，二阶法有可能会收敛到鞍点（Saddle Point）。











# 相关

- 《百面机器学习》
