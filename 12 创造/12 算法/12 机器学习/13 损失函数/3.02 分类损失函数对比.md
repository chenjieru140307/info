
# 分类损失函数对比


最后，我们将 

- 0-1 Loss
- Cross Entropy Loss
- Hinge Loss
- Exponential Loss
- Modified Huber Loss

画在一张图中：


<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190902/3iumpccC1aMb.png?imageslim">
</p>




上图 $ys$ 的取值范围是 $[-2,+2]$，若我们把 $ys$ 的坐标范围取得更大一些，上面 5 种 Loss 的差别会更大一些，见下图：

<p align="center">
    <img width="70%" height="70%" src="http://images.iterate.site/blog/image/20190902/7NcqsvAw48va.png?imageslim">
</p>


显然，这时候 Exponential Loss 会远远大于其它 Loss。从训练的角度来看，模型会更加偏向于惩罚较大的点，赋予其更大的权重。如果样本中存在离群点，Exponential Loss 会给离群点赋予更高的权重，但却可能是以牺牲其他正常数据点的预测效果为代价，可能会降低模型的整体性能，使得模型不够健壮（robust）。

相比 Exponential Loss，其它四个 Loss，包括 Softmax Loss，都对离群点有较好的“容忍性”，受异常点的干扰较小，模型较为健壮。

